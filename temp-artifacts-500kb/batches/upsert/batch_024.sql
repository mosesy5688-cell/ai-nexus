/* LOGS:
Downloading image for github-x1xhlol-system-prompts-and-models-of-ai-tools from https://github.com/x1xhlol.png
Image converted to WebP: data/images/github-x1xhlol-system-prompts-and-models-of-ai-tools.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-comfyanonymous-ComfyUI', 'github--comfyanonymous--comfyui', 'ComfyUI', 'comfyanonymous', '<div align="center"> **The most powerful and modular visual AI engine and application.** [![Website][website-shield]][website-url] [![Dynamic JSON Badge][discord-shield]][discord-url] [![Twitter][twitter-shield]][twitter-url] [![Matrix][matrix-shield]][matrix-url] <br> [![][github-release-shield]][github-release-link] [![][github-release-date-shield]][github-release-link] [![][github-downloads-shield]][github-downloads-link] [![][github-downloads-latest-shield]][github-downloads-link] [matrix...', '["ai","comfy","comfyui","python","pytorch","stable-diffusion","python"]', 'other', 96115, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/comfyanonymous/ComfyUI","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'model', '<div align="center">\n\n# ComfyUI\n**The most powerful and modular visual AI engine and application.**\n\n\n[![Website][website-shield]][website-url]\n[![Dynamic JSON Badge][discord-shield]][discord-url]\n[![Twitter][twitter-shield]][twitter-url]\n[![Matrix][matrix-shield]][matrix-url]\n<br>\n[![][github-release-shield]][github-release-link]\n[![][github-release-date-shield]][github-release-link]\n[![][github-downloads-shield]][github-downloads-link]\n[![][github-downloads-latest-shield]][github-downloads-link]\n\n[matrix-shield]: https://img.shields.io/badge/Matrix-000000?style=flat&logo=matrix&logoColor=white\n[matrix-url]: https://app.element.io/#/room/%23comfyui_space%3Amatrix.org\n[website-shield]: https://img.shields.io/badge/ComfyOrg-4285F4?style=flat\n[website-url]: https://www.comfy.org/\n<!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 -->\n[discord-shield]: https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&query=%24.approximate_member_count&logo=discord&logoColor=white&label=Discord&color=green&suffix=%20total\n[discord-url]: https://www.comfy.org/discord\n[twitter-shield]: https://img.shields.io/twitter/follow/ComfyUI\n[twitter-url]: https://x.com/ComfyUI\n\n[github-release-shield]: https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&sort=semver\n[github-release-link]: https://github.com/comfyanonymous/ComfyUI/releases\n[github-release-date-shield]: https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat\n[github-downloads-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat\n[github-downloads-latest-shield]: https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&label=downloads%40latest\n[github-downloads-link]: https://github.com/comfyanonymous/ComfyUI/releases\n\n![ComfyUI Screenshot](https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe)\n</div>\n\nComfyUI lets you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. Available on Windows, Linux, and macOS.\n\n## Get Started\n\n#### [Desktop Application](https://www.comfy.org/download)\n- The easiest way to get started.\n- Available on Windows & macOS.\n\n#### [Windows Portable Package](#installing)\n- Get the latest commits and completely portable.\n- Available on Windows.\n\n#### [Manual Install](#manual-install-windows-linux)\nSupports all operating systems and GPU types (NVIDIA, AMD, Intel, Apple Silicon, Ascend).\n\n## [Examples](https://comfyanonymous.github.io/ComfyUI_examples/)\nSee what ComfyUI can do with the [example workflows](https://comfyanonymous.github.io/ComfyUI_examples/).\n\n## Features\n- Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\n- Image Models\n   - SD1.x, SD2.x ([unCLIP](https://comfyanonymous.github.io/ComfyUI_examples/unclip/))\n   - [SDXL](https://comfyanonymous.github.io/ComfyUI_examples/sdxl/), [SDXL Turbo](https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/)\n   - [Stable Cascade](https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/)\n   - [SD3 and SD3.5](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)\n   - Pixart Alpha and Sigma\n   - [AuraFlow](https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/)\n   - [HunyuanDiT](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/)\n   - [Flux](https://comfyanonymous.github.io/ComfyUI_examples/flux/)\n   - [Lumina Image 2.0](https://comfyanonymous.github.io/ComfyUI_examples/lumina2/)\n   - [HiDream](https://comfyanonymous.github.io/ComfyUI_examples/hidream/)\n   - [Qwen Image](https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/)\n   - [Hunyuan Image 2.1](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_image/)\n   - [Flux 2](https://comfyanonymous.github.io/ComfyUI_examples/flux2/)\n   - [Z Image](https://comfyanonymous.github.io/ComfyUI_examples/z_image/)\n- Image Editing Models\n   - [Omnigen 2](https://comfyanonymous.github.io/ComfyUI_examples/omnigen/)\n   - [Flux Kontext](https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-kontext-image-editing-model)\n   - [HiDream E1.1](https://comfyanonymous.github.io/ComfyUI_examples/hidream/#hidream-e11)\n   - [Qwen Image Edit](https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/#edit-model)\n- Video Models\n   - [Stable Video Diffusion](https://comfyanonymous.github.io/ComfyUI_examples/video/)\n   - [Mochi](https://comfyanonymous.github.io/ComfyUI_examples/mochi/)\n   - [LTX-Video](https://comfyanonymous.github.io/ComfyUI_examples/ltxv/)\n   - [Hunyuan Video](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/)\n   - [Wan 2.1](https://comfyanonymous.github.io/ComfyUI_examples/wan/)\n   - [Wan 2.2](https://comfyanonymous.github.io/ComfyUI_examples/wan22/)\n   - [Hunyuan Video 1.5](https://docs.comfy.org/tutorials/video/hunyuan/hunyuan-video-1-5)\n- Audio Models\n   - [Stable Audio](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n   - [ACE Step](https://comfyanonymous.github.io/ComfyUI_examples/audio/)\n- 3D Models\n   - [Hunyuan3D 2.0](https://docs.comfy.org/tutorials/3d/hunyuan3D-2)\n- Asynchronous Queue system\n- Many optimizations: Only re-executes the parts of the workflow that changes between executions.\n- Smart memory management: can automatically run large models on GPUs with as low as 1GB vram with smart offloading.\n- Works even if you don''t have a GPU with: ```--cpu``` (slow)\n- Can load ckpt and safetensors: All in one checkpoints or standalone diffusion models, VAEs and CLIP models.\n- Safe loading of ckpt, pt, pth, etc.. files.\n- Embeddings/Textual inversion\n- [Loras (regular, locon and loha)](https://comfyanonymous.github.io/ComfyUI_examples/lora/)\n- [Hypernetworks](https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/)\n- Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.\n- Saving/Loading workflows as Json files.\n- Nodes interface can be used to create complex workflows like one for [Hires fix](https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/) or much more advanced ones.\n- [Area Composition](https://comfyanonymous.github.io/ComfyUI_examples/area_composition/)\n- [Inpainting](https://comfyanonymous.github.io/ComfyUI_examples/inpaint/) with both regular and inpainting models.\n- [ControlNet and T2I-Adapter](https://comfyanonymous.github.io/ComfyUI_examples/controlnet/)\n- [Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)](https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/)\n- [GLIGEN](https://comfyanonymous.github.io/ComfyUI_examples/gligen/)\n- [Model Merging](https://comfyanonymous.github.io/ComfyUI_examples/model_merging/)\n- [LCM models and Loras](https://comfyanonymous.github.io/ComfyUI_examples/lcm/)\n- Latent previews with [TAESD](#how-to-show-high-quality-previews)\n- Works fully offline: core will never download anything unless you want to.\n- Optional API nodes to use paid models from external providers through the online [Comfy API](https://docs.comfy.org/tutorials/api-nodes/overview).\n- [Config file](extra_model_paths.yaml.example) to set the search paths for models.\n\nWorkflow examples can be found on the [Examples page](https://comfyanonymous.github.io/ComfyUI_examples/)\n\n## Release Process\n\nComfyUI follows a weekly release cycle targeting Monday but this regularly changes because of model releases or large changes to the codebase. There are three interconnected repositories:\n\n1. **[ComfyUI Core](https://github.com/comfyanonymous/ComfyUI)**\n   - Releases a new stable version (e.g., v0.7.0) roughly every week.\n   - Commits outside of the stable release tags may be very unstable and break many custom nodes.\n   - Serves as the foundation for the desktop release\n\n2. **[ComfyUI Desktop](https://github.com/Comfy-Org/desktop)**\n   - Builds a new release using the latest stable core version\n\n3. **[ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend)**\n   - Weekly frontend updates are merged into the core repository\n   - Features are frozen for the upcoming core release\n   - Development continues for the next release cycle\n\n## Shortcuts\n\n| Keybind                            | Explanation                                                                                                        |\n|------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n| `Ctrl` + `Enter`                      | Queue up current graph for generation                                                                              |\n| `Ctrl` + `Shift` + `Enter`              | Queue up current graph as first for generation                                                                     |\n| `Ctrl` + `Alt` + `Enter`                | Cancel current generation                                                                                          |\n| `Ctrl` + `Z`/`Ctrl` + `Y`                 | Undo/Redo                                                                                                          |\n| `Ctrl` + `S`                          | Save workflow                                                                                                      |\n| `Ctrl` + `O`                          | Load workflow                                                                                                      |\n| `Ctrl` + `A`                          | Select all nodes                                                                                                   |\n| `Alt `+ `C`                           | Collapse/uncollapse selected nodes                                                                                 |\n| `Ctrl` + `M`                          | Mute/unmute selected nodes                                                                                         |\n| `Ctrl` + `B`                           | Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)            |\n| `Delete`/`Backspace`                   | Delete selected nodes                                                                                              |\n| `Ctrl` + `Backspace`                   | Delete the current graph                                                                                           |\n| `Space`                              | Move the canvas around when held and moving the cursor                                                             |\n| `Ctrl`/`Shift` + `Click`                 | Add clicked node to selection                                                                                      |\n| `Ctrl` + `C`/`Ctrl` + `V`                  | Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)                     |\n| `Ctrl` + `C`/`Ctrl` + `Shift` + `V`          | Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes) |\n| `Shift` + `Drag`                       | Move multiple selected nodes at the same time                                                                      |\n| `Ctrl` + `D`                           | Load default graph                                                                                                 |\n| `Alt` + `+`                          | Canvas Zoom in                                                                                                     |\n| `Alt` + `-`                          | Canvas Zoom out                                                                                                    |\n| `Ctrl` + `Shift` + LMB + Vertical drag | Canvas Zoom in/out                                                                                                 |\n| `P`                                  | Pin/Unpin selected nodes                                                                                           |\n| `Ctrl` + `G`                           | Group selected nodes                                                                                               |\n| `Q`                                 | Toggle visibility of the queue                                                                                     |\n| `H`                                  | Toggle visibility of history                                                                                       |\n| `R`                                  | Refresh graph                                                                                                      |\n| `F`                                  | Show/Hide menu                                                                                                      |\n| `.`                                  | Fit view to selection (Whole graph when nothing is selected)                                                        |\n| Double-Click LMB                   | Open node quick search palette                                                                                     |\n| `Shift` + Drag                       | Move multiple wires at once                                                                                        |\n| `Ctrl` + `Alt` + LMB                   | Disconnect all wires from clicked slot                                                                             |\n\n`Ctrl` can also be replaced with `Cmd` instead for macOS users\n\n# Installing\n\n## Windows Portable\n\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the [releases page](https://github.com/comfyanonymous/ComfyUI/releases).\n\n### [Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z)\n\nSimply download, extract with [7-Zip](https://7-zip.org) or with the windows explorer on recent windows versions and run. For smaller models you normally only need to put the checkpoints (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints but many of the larger models have multiple files. Make sure to follow the instructions to know which subfolder to put them in ComfyUI\models\\n\nIf you have trouble extracting it, right click the file -> properties -> unblock\n\nUpdate your Nvidia drivers if it doesn''t start.\n\n#### Alternative Downloads:\n\n[Experimental portable for AMD GPUs](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_amd.7z)\n\n[Portable with pytorch cuda 12.8 and python 3.12](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia_cu128.7z).\n\n[Portable with pytorch cuda 12.6 and python 3.12](https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia_cu126.7z) (Supports Nvidia 10 series and older GPUs).\n\n#### How do I share models between another UI and ComfyUI?\n\nSee the [Config file](extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\n\n\n## [comfy-cli](https://docs.comfy.org/comfy-cli/getting-started)\n\nYou can install and start ComfyUI using comfy-cli:\n```bash\npip install comfy-cli\ncomfy install\n```\n\n## Manual Install (Windows, Linux)\n\nPython 3.14 works but you may encounter issues with the torch compile node. The free threaded variant is still missing some dependencies.\n\nPython 3.13 is very well supported. If you have trouble with some custom node dependencies on 3.13 you can try 3.12\n\n### Instructions:\n\nGit clone this repo.\n\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\n\nPut your VAE in: models/vae\n\n\n### AMD GPUs (Linux)\n\nAMD users can install rocm and pytorch with pip if you don''t have it already installed, this is the command to install the stable version:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.4```\n\nThis is the command to install the nightly with ROCm 7.0 which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm7.1```\n\n\n### AMD GPUs (Experimental: Windows and Linux), RDNA 3, 3.5 and 4 only.\n\nThese have less hardware support than the builds above but they work on windows. You also need to install the pytorch version specific to your hardware.\n\nRDNA 3 (RX 7000 series):\n\n```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx110X-dgpu/```\n\nRDNA 3.5 (Strix halo/Ryzen AI Max+ 365):\n\n```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx1151/```\n\nRDNA 4 (RX 9000 series):\n\n```pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx120X-all/```\n\n### Intel GPUs (Windows and Linux)\n\nIntel Arc GPU users can install native PyTorch with torch.xpu support using pip. More information can be found [here](https://pytorch.org/docs/main/notes/get_start_xpu.html)\n\n1. To install PyTorch xpu, use the following command:\n\n```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu```\n\nThis is the command to install the Pytorch xpu nightly which might have some performance improvements:\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu```\n\n### NVIDIA\n\nNvidia users should install stable pytorch using this command:\n\n```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu130```\n\nThis is the command to install pytorch nightly instead which might have performance improvements.\n\n```pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130```\n\n#### Troubleshooting\n\nIf you get the "Torch not compiled with CUDA enabled" error, uninstall torch with:\n\n```pip uninstall torch```\n\nAnd install it again with the command above.\n\n### Dependencies\n\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\n\n```pip install -r requirements.txt```\n\nAfter this you should have everything installed and can proceed to running ComfyUI.\n\n### Others:\n\n#### Apple Mac silicon\n\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\n1. Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).\n1. Follow the [ComfyUI manual installation](#manual-install-windows-linux) instructions for Windows and Linux.\n1. Install the ComfyUI [dependencies](#dependencies). If you have another Stable Diffusion UI [you might be able to reuse the dependencies](#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies).\n1. Launch ComfyUI by running `python main.py`\n\n> **Note**: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in [ComfyUI manual installation](#manual-install-windows-linux).\n\n#### Ascend NPUs\n\nFor models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the [installation](https://ascend.github.io/docs/sources/ascend/quick_install.html) page. Here''s a step-by-step guide tailored to your platform and installation method:\n\n1. Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.\n2. Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.\n3. Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the [Installation](https://ascend.github.io/docs/sources/pytorch/install.html#pytorch) page.\n4. Finally, adhere to the [ComfyUI manual installation](#manual-install-windows-linux) guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.\n\n#### Cambricon MLUs\n\nFor models compatible with Cambricon Extension for PyTorch (torch_mlu). Here''s a step-by-step guide tailored to your platform and installation method:\n\n1. Install the Cambricon CNToolkit by adhering to the platform-specific instructions on the [Installation](https://www.cambricon.com/docs/sdk_1.15.0/cntoolkit_3.7.2/cntoolkit_install_3.7.2/index.html)\n2. Next, install the PyTorch(torch_mlu) following the instructions on the [Installation](https://www.cambricon.com/docs/sdk_1.15.0/cambricon_pytorch_1.17.0/user_guide_1.9/index.html)\n3. Launch ComfyUI by running `python main.py`\n\n#### Iluvatar Corex\n\nFor models compatible with Iluvatar Extension for PyTorch. Here''s a step-by-step guide tailored to your platform and installation method:\n\n1. Install the Iluvatar Corex Toolkit by adhering to the platform-specific instructions on the [Installation](https://support.iluvatar.com/#/DocumentCentre?id=1&nameCenter=2&productId=520117912052801536)\n2. Launch ComfyUI by running `python main.py`\n\n\n## [ComfyUI-Manager](https://github.com/Comfy-Org/ComfyUI-Manager/tree/manager-v4)\n\n**ComfyUI-Manager** is an extension that allows you to easily install, update, and manage custom nodes for ComfyUI.\n\n### Setup\n\n1. Install the manager dependencies:\n   ```bash\n   pip install -r manager_requirements.txt\n   ```\n\n2. Enable the manager with the `--enable-manager` flag when running ComfyUI:\n   ```bash\n   python main.py --enable-manager\n   ```\n\n### Command Line Options\n\n| Flag | Description |\n|------|-------------|\n| `--enable-manager` | Enable ComfyUI-Manager |\n| `--enable-manager-legacy-ui` | Use the legacy manager UI instead of the new UI (requires `--enable-manager`) |\n| `--disable-manager-ui` | Disable the manager UI and endpoints while keeping background features like security checks and scheduled installation completion (requires `--enable-manager`) |\n\n\n# Running\n\n```python main.py```\n\n### For AMD cards not officially supported by ROCm\n\nTry running it with this command if you have issues:\n\nFor 6700, 6600 and maybe other RDNA2 or older: ```HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py```\n\nFor AMD 7600 and maybe other RDNA3 cards: ```HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py```\n\n### AMD ROCm Tips\n\nYou can enable experimental memory efficient attention on recent pytorch in ComfyUI on some AMD GPUs using this command, it should already be enabled by default on RDNA3. If this improves speed for you on latest pytorch on your GPU please report it so that I can enable it by default.\n\n```TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 python main.py --use-pytorch-cross-attention```\n\nYou can also try setting this env variable `PYTORCH_TUNABLEOP_ENABLED=1` which might speed things up at the cost of a very slow initial run.\n\n# Notes\n\nOnly parts of the graph that have an output with all the correct inputs will be executed.\n\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\n\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\n\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\( or \\).\n\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax "{wild|card|test}" will be randomly replaced by either "wild", "card" or "test" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\{ or \\}.\n\nDynamic prompts also support C-style comments, like `// comment` or `/* comment */`.\n\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\n\n```embedding:embedding_filename.pt```\n\n\n## How to show high-quality previews?\n\nUse ```--preview-method auto``` to enable previews.\n\nThe default installation includes a fast latent preview method that''s low-resolution. To enable higher-quality previews with [TAESD](https://github.com/madebyollin/taesd), download the [taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth](https://github.com/madebyollin/taesd/) and place them in the `models/vae_approx` folder. Once they''re installed, restart ComfyUI and launch it with `--preview-method taesd` to enable high-quality previews.\n\n## How to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj "/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname"`\n\nUse `--tls-keyfile key.pem --tls-certfile cert.pem` to enable TLS/SSL, the app will now be accessible with `https://...` instead of `http://...`.\n\n> Note: Windows users can use [alexisrolland/docker-openssl](https://github.com/alexisrolland/docker-openssl) or one of the [3rd party binary distributions](https://wiki.openssl.org/index.php/Binaries) to run the command example above.\n<br/><br/>If you use a container, note that the volume mount `-v` can be a relative path so `... -v ".\:/openssl-certs" ...` would create the key & cert files in the current directory of your command prompt or powershell terminal.\n\n## Support and dev channel\n\n[Discord](https://comfy.org/discord): Try the #help or #feedback channels.\n\n[Matrix space: #comfyui_space:matrix.org](https://app.element.io/#/room/%23comfyui_space%3Amatrix.org) (it''s like discord but open source).\n\nSee also: [https://www.comfy.org/](https://www.comfy.org/)\n\n## Frontend Development\n\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: [ComfyUI Frontend](https://github.com/Comfy-Org/ComfyUI_frontend). This repository now hosts the compiled JS (from TS/Vue) under the `web/` directory.\n\n### Reporting Issues and Requesting Features\n\nFor any bugs, issues, or feature requests related to the frontend, please use the [ComfyUI Frontend repository](https://github.com/Comfy-Org/ComfyUI_frontend). This will help us manage and address frontend-specific concerns more efficiently.\n\n### Using the Latest Frontend\n\nThe new frontend is now the default for ComfyUI. However, please note:\n\n1. The frontend in the main ComfyUI repository is updated fortnightly.\n2. Daily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n1. For the latest daily release, launch ComfyUI with this command line argument:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@latest\n   ```\n\n2. For a specific version, replace `latest` with the desired version number:\n\n   ```\n   --front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n   ```\n\nThis approach allows you to easily switch between the stable fortnightly release and the cutting-edge daily updates, or even specific versions for testing purposes.\n\n### Accessing the Legacy Frontend\n\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n\n```\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n```\n\nThis will use a snapshot of the legacy frontend preserved in the [ComfyUI Legacy Frontend repository](https://github.com/Comfy-Org/ComfyUI_legacy_frontend).\n\n# QA\n\n### Which GPU should I buy for this?\n\n[See this page for some recommendations](https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI)\n', '{"language":"Python","stars":96115,"forks":10872,"watchers":96115,"open_issues":3276,"topics":["ai","comfy","comfyui","python","pytorch","stable-diffusion"],"default_branch":"master","size_kb":76756,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:badges:shields","source_url":"https://github.com/badges/shields"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:Comfy-Org:desktop","source_url":"https://github.com/Comfy-Org/desktop"},{"type":"has_code","target_id":"github:Comfy-Org:ComfyUI_frontend","source_url":"https://github.com/Comfy-Org/ComfyUI_frontend"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"},{"type":"has_code","target_id":"github:Comfy-Org:ComfyUI-Manager","source_url":"https://github.com/Comfy-Org/ComfyUI-Manager"},{"type":"has_code","target_id":"github:madebyollin:taesd","source_url":"https://github.com/madebyollin/taesd"},{"type":"has_code","target_id":"github:madebyollin:taesd","source_url":"https://github.com/madebyollin/taesd"},{"type":"has_code","target_id":"github:alexisrolland:docker-openssl","source_url":"https://github.com/alexisrolland/docker-openssl"},{"type":"has_code","target_id":"github:Comfy-Org:ComfyUI_frontend","source_url":"https://github.com/Comfy-Org/ComfyUI_frontend"},{"type":"has_code","target_id":"github:Comfy-Org:ComfyUI_frontend","source_url":"https://github.com/Comfy-Org/ComfyUI_frontend"},{"type":"has_code","target_id":"github:Comfy-Org:ComfyUI_legacy_frontend","source_url":"https://github.com/Comfy-Org/ComfyUI_legacy_frontend"},{"type":"has_code","target_id":"github:comfyanonymous:ComfyUI","source_url":"https://github.com/comfyanonymous/ComfyUI"}]', NULL, 'GPL-3.0', 'approved', 80, 'ccecae2cc0f34fc681358c248a32b7a8', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-comfyanonymous-ComfyUI from https://github.com/comfyanonymous.png
Image converted to WebP: data/images/github-comfyanonymous-ComfyUI.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-supabase-supabase', 'github--supabase--supabase', 'supabase', 'supabase', '<p align="center"> <img src="https://user-images.githubusercontent.com/8291514/213727234-cda046d6-28c6-491a-b284-b86c5cede25d.png#gh-light-mode-only"> <img src="https://user-images.githubusercontent.com/8291514/213727225-56186826-bee8-43b5-9b15-86e839d89393.png#gh-dark-mode-only"> </p> Supabase is the Postgres development platform. We''re building the features of Firebase using enterprise-grade open source tools. - [x] Hosted Postgres Database. Docs - [x] Authentication and Authorization. Docs...', '["ai","alternative","auth","database","deno","embeddings","example","firebase","nextjs","oauth2","pgvector","postgis","postgres","postgresql","postgrest","realtime","supabase","vectors","websockets","typescript"]', 'other', 94301, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/supabase/supabase","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center">\n<img src="https://user-images.githubusercontent.com/8291514/213727234-cda046d6-28c6-491a-b284-b86c5cede25d.png#gh-light-mode-only">\n<img src="https://user-images.githubusercontent.com/8291514/213727225-56186826-bee8-43b5-9b15-86e839d89393.png#gh-dark-mode-only">\n</p>\n\n# Supabase\n\n[Supabase](https://supabase.com) is the Postgres development platform. We''re building the features of Firebase using enterprise-grade open source tools.\n\n- [x] Hosted Postgres Database. [Docs](https://supabase.com/docs/guides/database)\n- [x] Authentication and Authorization. [Docs](https://supabase.com/docs/guides/auth)\n- [x] Auto-generated APIs.\n  - [x] REST. [Docs](https://supabase.com/docs/guides/api)\n  - [x] GraphQL. [Docs](https://supabase.com/docs/guides/graphql)\n  - [x] Realtime subscriptions. [Docs](https://supabase.com/docs/guides/realtime)\n- [x] Functions.\n  - [x] Database Functions. [Docs](https://supabase.com/docs/guides/database/functions)\n  - [x] Edge Functions [Docs](https://supabase.com/docs/guides/functions)\n- [x] File Storage. [Docs](https://supabase.com/docs/guides/storage)\n- [x] AI + Vector/Embeddings Toolkit. [Docs](https://supabase.com/docs/guides/ai)\n- [x] Dashboard\n\n![Supabase Dashboard](https://raw.githubusercontent.com/supabase/supabase/master/apps/www/public/images/github/supabase-dashboard.png)\n\nWatch "releases" of this repo to get notified of major updates.\n\n<kbd><img src="https://raw.githubusercontent.com/supabase/supabase/d5f7f413ab356dc1a92075cb3cee4e40a957d5b1/web/static/watch-repo.gif" alt="Watch this repo"/></kbd>\n\n## Documentation\n\nFor full documentation, visit [supabase.com/docs](https://supabase.com/docs)\n\nTo see how to Contribute, visit [Getting Started](./DEVELOPERS.md)\n\n## Community & Support\n\n- [Community Forum](https://github.com/supabase/supabase/discussions). Best for: help with building, discussion about database best practices.\n- [GitHub Issues](https://github.com/supabase/supabase/issues). Best for: bugs and errors you encounter using Supabase.\n- [Email Support](https://supabase.com/docs/support#business-support). Best for: problems with your database or infrastructure.\n- [Discord](https://discord.supabase.com). Best for: sharing your applications and hanging out with the community.\n\n## How it works\n\nSupabase is a combination of open source tools. We‚Äôre building the features of Firebase using enterprise-grade, open source products. If the tools and communities exist, with an MIT, Apache 2, or equivalent open license, we will use and support that tool. If the tool doesn''t exist, we build and open source it ourselves. Supabase is not a 1-to-1 mapping of Firebase. Our aim is to give developers a Firebase-like developer experience using open source tools.\n\n**Architecture**\n\nSupabase is a [hosted platform](https://supabase.com/dashboard). You can sign up and start using Supabase without installing anything.\nYou can also [self-host](https://supabase.com/docs/guides/hosting/overview) and [develop locally](https://supabase.com/docs/guides/local-development).\n\n![Architecture](apps/docs/public/img/supabase-architecture.svg)\n\n- [Postgres](https://www.postgresql.org/) is an object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\n- [Realtime](https://github.com/supabase/realtime) is an Elixir server that allows you to listen to PostgreSQL inserts, updates, and deletes using websockets. Realtime polls Postgres'' built-in replication functionality for database changes, converts changes to JSON, then broadcasts the JSON over websockets to authorized clients.\n- [PostgREST](http://postgrest.org/) is a web server that turns your PostgreSQL database directly into a RESTful API.\n- [GoTrue](https://github.com/supabase/gotrue) is a JWT-based authentication API that simplifies user sign-ups, logins, and session management in your applications.\n- [Storage](https://github.com/supabase/storage-api) a RESTful API for managing files in S3, with Postgres handling permissions.\n- [pg_graphql](http://github.com/supabase/pg_graphql/) a PostgreSQL extension that exposes a GraphQL API.\n- [postgres-meta](https://github.com/supabase/postgres-meta) is a RESTful API for managing your Postgres, allowing you to fetch tables, add roles, and run queries, etc.\n- [Kong](https://github.com/Kong/kong) is a cloud-native API gateway.\n\n#### Client libraries\n\nOur approach for client libraries is modular. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing tools.\n\n<table style="table-layout:fixed; white-space: nowrap;">\n  <tr>\n    <th>Language</th>\n    <th>Client</th>\n    <th colspan="5">Feature-Clients (bundled in Supabase client)</th>\n  </tr>\n  <!-- notranslate -->\n  <tr>\n    <th></th>\n    <th>Supabase</th>\n    <th><a href="https://github.com/postgrest/postgrest" target="_blank" rel="noopener noreferrer">PostgREST</a></th>\n    <th><a href="https://github.com/supabase/gotrue" target="_blank" rel="noopener noreferrer">GoTrue</a></th>\n    <th><a href="https://github.com/supabase/realtime" target="_blank" rel="noopener noreferrer">Realtime</a></th>\n    <th><a href="https://github.com/supabase/storage-api" target="_blank" rel="noopener noreferrer">Storage</a></th>\n    <th>Functions</th>\n  </tr>\n  <!-- TEMPLATE FOR NEW ROW -->\n  <!-- START ROW\n  <tr>\n    <td>lang</td>\n    <td><a href="https://github.com/supabase-community/supabase-lang" target="_blank" rel="noopener noreferrer">supabase-lang</a></td>\n    <td><a href="https://github.com/supabase-community/postgrest-lang" target="_blank" rel="noopener noreferrer">postgrest-lang</a></td>\n    <td><a href="https://github.com/supabase-community/gotrue-lang" target="_blank" rel="noopener noreferrer">gotrue-lang</a></td>\n    <td><a href="https://github.com/supabase-community/realtime-lang" target="_blank" rel="noopener noreferrer">realtime-lang</a></td>\n    <td><a href="https://github.com/supabase-community/storage-lang" target="_blank" rel="noopener noreferrer">storage-lang</a></td>\n  </tr>\n  END ROW -->\n  <!-- /notranslate -->\n  <th colspan="7">‚ö°Ô∏è Official ‚ö°Ô∏è</th>\n  <!-- notranslate -->\n  <tr>\n    <td>JavaScript (TypeScript)</td>\n    <td><a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer">supabase-js</a></td>\n    <td><a href="https://github.com/supabase/postgrest-js" target="_blank" rel="noopener noreferrer">postgrest-js</a></td>\n    <td><a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer">gotrue-js</a></td>\n    <td><a href="https://github.com/supabase/realtime-js" target="_blank" rel="noopener noreferrer">realtime-js</a></td>\n    <td><a href="https://github.com/supabase/storage-js" target="_blank" rel="noopener noreferrer">storage-js</a></td>\n    <td><a href="https://github.com/supabase/functions-js" target="_blank" rel="noopener noreferrer">functions-js</a></td>\n  </tr>\n    <tr>\n    <td>Flutter</td>\n    <td><a href="https://github.com/supabase/supabase-flutter" target="_blank" rel="noopener noreferrer">supabase-flutter</a></td>\n    <td><a href="https://github.com/supabase/postgrest-dart" target="_blank" rel="noopener noreferrer">postgrest-dart</a></td>\n    <td><a href="https://github.com/supabase/gotrue-dart" target="_blank" rel="noopener noreferrer">gotrue-dart</a></td>\n    <td><a href="https://github.com/supabase/realtime-dart" target="_blank" rel="noopener noreferrer">realtime-dart</a></td>\n    <td><a href="https://github.com/supabase/storage-dart" target="_blank" rel="noopener noreferrer">storage-dart</a></td>\n    <td><a href="https://github.com/supabase/functions-dart" target="_blank" rel="noopener noreferrer">functions-dart</a></td>\n  </tr>\n  <tr>\n    <td>Swift</td>\n    <td><a href="https://github.com/supabase/supabase-swift" target="_blank" rel="noopener noreferrer">supabase-swift</a></td>\n    <td><a href="https://github.com/supabase/supabase-swift/tree/main/Sources/PostgREST" target="_blank" rel="noopener noreferrer">postgrest-swift</a></td>\n    <td><a href="https://github.com/supabase/supabase-swift/tree/main/Sources/Auth" target="_blank" rel="noopener noreferrer">auth-swift</a></td>\n    <td><a href="https://github.com/supabase/supabase-swift/tree/main/Sources/Realtime" target="_blank" rel="noopener noreferrer">realtime-swift</a></td>\n    <td><a href="https://github.com/supabase/supabase-swift/tree/main/Sources/Storage" target="_blank" rel="noopener noreferrer">storage-swift</a></td>\n    <td><a href="https://github.com/supabase/supabase-swift/tree/main/Sources/Functions" target="_blank" rel="noopener noreferrer">functions-swift</a></td>\n  </tr>\n  <tr>\n    <td>Python</td>\n    <td><a href="https://github.com/supabase/supabase-py" target="_blank" rel="noopener noreferrer">supabase-py</a></td>\n    <td><a href="https://github.com/supabase/postgrest-py" target="_blank" rel="noopener noreferrer">postgrest-py</a></td>\n    <td><a href="https://github.com/supabase/gotrue-py" target="_blank" rel="noopener noreferrer">gotrue-py</a></td>\n    <td><a href="https://github.com/supabase/realtime-py" target="_blank" rel="noopener noreferrer">realtime-py</a></td>\n    <td><a href="https://github.com/supabase/storage-py" target="_blank" rel="noopener noreferrer">storage-py</a></td>\n    <td><a href="https://github.com/supabase/functions-py" target="_blank" rel="noopener noreferrer">functions-py</a></td>\n  </tr>\n  <!-- /notranslate -->\n  <th colspan="7">üíö Community üíö</th>\n  <!-- notranslate -->\n  <tr>\n    <td>C#</td>\n    <td><a href="https://github.com/supabase-community/supabase-csharp" target="_blank" rel="noopener noreferrer">supabase-csharp</a></td>\n    <td><a href="https://github.com/supabase-community/postgrest-csharp" target="_blank" rel="noopener noreferrer">postgrest-csharp</a></td>\n    <td><a href="https://github.com/supabase-community/gotrue-csharp" target="_blank" rel="noopener noreferrer">gotrue-csharp</a></td>\n    <td><a href="https://github.com/supabase-community/realtime-csharp" target="_blank" rel="noopener noreferrer">realtime-csharp</a></td>\n    <td><a href="https://github.com/supabase-community/storage-csharp" target="_blank" rel="noopener noreferrer">storage-csharp</a></td>\n    <td><a href="https://github.com/supabase-community/functions-csharp" target="_blank" rel="noopener noreferrer">functions-csharp</a></td>\n  </tr>\n  <tr>\n    <td>Go</td>\n    <td>-</td>\n    <td><a href="https://github.com/supabase-community/postgrest-go" target="_blank" rel="noopener noreferrer">postgrest-go</a></td>\n    <td><a href="https://github.com/supabase-community/gotrue-go" target="_blank" rel="noopener noreferrer">gotrue-go</a></td>\n    <td>-</td>\n    <td><a href="https://github.com/supabase-community/storage-go" target="_blank" rel="noopener noreferrer">storage-go</a></td>\n    <td><a href="https://github.com/supabase-community/functions-go" target="_blank" rel="noopener noreferrer">functions-go</a></td>\n  </tr>\n  <tr>\n    <td>Java</td>\n    <td>-</td>\n    <td>-</td>\n    <td><a href="https://github.com/supabase-community/gotrue-java" target="_blank" rel="noopener noreferrer">gotrue-java</a></td>\n    <td>-</td>\n    <td><a href="https://github.com/supabase-community/storage-java" target="_blank" rel="noopener noreferrer">storage-java</a></td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>Kotlin</td>\n    <td><a href="https://github.com/supabase-community/supabase-kt" target="_blank" rel="noopener noreferrer">supabase-kt</a></td>\n    <td><a href="https://github.com/supabase-community/supabase-kt/tree/master/Postgrest" target="_blank" rel="noopener noreferrer">postgrest-kt</a></td>\n    <td><a href="https://github.com/supabase-community/supabase-kt/tree/master/Auth" target="_blank" rel="noopener noreferrer">auth-kt</a></td>\n    <td><a href="https://github.com/supabase-community/supabase-kt/tree/master/Realtime" target="_blank" rel="noopener noreferrer">realtime-kt</a></td>\n    <td><a href="https://github.com/supabase-community/supabase-kt/tree/master/Storage" target="_blank" rel="noopener noreferrer">storage-kt</a></td>\n    <td><a href="https://github.com/supabase-community/supabase-kt/tree/master/Functions" target="_blank" rel="noopener noreferrer">functions-kt</a></td>\n  </tr>\n  <tr>\n    <td>Ruby</td>\n    <td><a href="https://github.com/supabase-community/supabase-rb" target="_blank" rel="noopener noreferrer">supabase-rb</a></td>\n    <td><a href="https://github.com/supabase-community/postgrest-rb" target="_blank" rel="noopener noreferrer">postgrest-rb</a></td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>Rust</td>\n    <td>-</td>\n    <td><a href="https://github.com/supabase-community/postgrest-rs" target="_blank" rel="noopener noreferrer">postgrest-rs</a></td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>Godot Engine (GDScript)</td>\n    <td><a href="https://github.com/supabase-community/godot-engine.supabase" target="_blank" rel="noopener noreferrer">supabase-gdscript</a></td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n    <td>-</td>\n  </tr>\n  <!-- /notranslate -->\n</table>\n\n<!--- Remove this list if you''re translating to another language, it''s hard to keep updated across multiple files-->\n<!--- Keep only the link to the list of translation files-->\n\n## Badges\n\n![Made with Supabase](./apps/www/public/badge-made-with-supabase.svg)\n\n```md\n[![Made with Supabase](https://supabase.com/badge-made-with-supabase.svg)](https://supabase.com)\n```\n\n```html\n<a href="https://supabase.com">\n  <img\n    width="168"\n    height="30"\n    src="https://supabase.com/badge-made-with-supabase.svg"\n    alt="Made with Supabase"\n  />\n</a>\n```\n\n![Made with Supabase (dark)](./apps/www/public/badge-made-with-supabase-dark.svg)\n\n```md\n[![Made with Supabase](https://supabase.com/badge-made-with-supabase-dark.svg)](https://supabase.com)\n```\n\n```html\n<a href="https://supabase.com">\n  <img\n    width="168"\n    height="30"\n    src="https://supabase.com/badge-made-with-supabase-dark.svg"\n    alt="Made with Supabase"\n  />\n</a>\n```\n\n## Translations\n\n- [Arabic | ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](/i18n/README.ar.md)\n- [Albanian / Shqip](/i18n/README.sq.md)\n- [Bangla / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](/i18n/README.bn.md)\n- [Bulgarian / –ë—ä–ª–≥–∞—Ä—Å–∫–∏](/i18n/README.bg.md)\n- [Catalan / Catal√†](/i18n/README.ca.md)\n- [Croatian / Hrvatski](/i18n/README.hr.md)\n- [Czech / ƒçe≈°tina](/i18n/README.cs.md)\n- [Danish / Dansk](/i18n/README.da.md)\n- [Dutch / Nederlands](/i18n/README.nl.md)\n- [English](https://github.com/supabase/supabase)\n- [Estonian / eesti keel](/i18n/README.et.md)\n- [Finnish / Suomalainen](/i18n/README.fi.md)\n- [French / Fran√ßais](/i18n/README.fr.md)\n- [German / Deutsch](/i18n/README.de.md)\n- [Greek / ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](/i18n/README.el.md)\n- [Gujarati / ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä](/i18n/README.gu.md)\n- [Hebrew / ◊¢◊ë◊®◊ô◊™](/i18n/README.he.md)\n- [Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä](/i18n/README.hi.md)\n- [Hungarian / Magyar](/i18n/README.hu.md)\n- [Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä](/i18n/README.ne.md)\n- [Indonesian / Bahasa Indonesia](/i18n/README.id.md)\n- [Italiano / Italian](/i18n/README.it.md)\n- [Japanese / Êó•Êú¨Ë™û](/i18n/README.jp.md)\n- [Korean / ÌïúÍµ≠Ïñ¥](/i18n/README.ko.md)\n- [Lithuanian / lietuvi≈≥](/i18n/README.lt.md)\n- [Latvian / latviski](/i18n/README.lv.md)\n- [Malay / Bahasa Malaysia](/i18n/README.ms.md)\n- [Norwegian (Bokm√•l) / Norsk (Bokm√•l)](/i18n/README.nb.md)\n- [Persian / ŸÅÿßÿ±ÿ≥€å](/i18n/README.fa.md)\n- [Polish / Polski](/i18n/README.pl.md)\n- [Portuguese / Portugu√™s](/i18n/README.pt.md)\n- [Portuguese (Brazilian) / Portugu√™s Brasileiro](/i18n/README.pt-br.md)\n- [Romanian / Rom√¢nƒÉ](/i18n/README.ro.md)\n- [Russian / P—É—Å—Å–∫–∏–π](/i18n/README.ru.md)\n- [Serbian / Srpski](/i18n/README.sr.md)\n- [Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω](/i18n/README.si.md)\n- [Slovak / slovensk√Ω](/i18n/README.sk.md)\n- [Slovenian / Sloven≈°ƒçina](/i18n/README.sl.md)\n- [Spanish / Espa√±ol](/i18n/README.es.md)\n- [Simplified Chinese / ÁÆÄ‰Ωì‰∏≠Êñá](/i18n/README.zh-cn.md)\n- [Swedish / Svenska](/i18n/README.sv.md)\n- [Thai / ‡πÑ‡∏ó‡∏¢](/i18n/README.th.md)\n- [Traditional Chinese / ÁπÅÈ´î‰∏≠Êñá](/i18n/README.zh-tw.md)\n- [Turkish / T√ºrk√ße](/i18n/README.tr.md)\n- [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](/i18n/README.uk.md)\n- [Vietnamese / Ti·∫øng Vi·ªát](/i18n/README.vi-vn.md)\n- [List of translations](/i18n/languages.md) <!--- Keep only this -->\n', '{"language":"TypeScript","stars":94301,"forks":10930,"watchers":94301,"open_issues":704,"topics":["ai","alternative","auth","database","deno","embeddings","example","firebase","nextjs","oauth2","pgvector","postgis","postgres","postgresql","postgrest","realtime","supabase","vectors","websockets"],"default_branch":"master","size_kb":2266533,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:supabase:supabase","source_url":"https://github.com/supabase/supabase"},{"type":"has_code","target_id":"github:supabase:supabase","source_url":"https://github.com/supabase/supabase"},{"type":"has_code","target_id":"github:supabase:realtime","source_url":"https://github.com/supabase/realtime"},{"type":"has_code","target_id":"github:supabase:gotrue","source_url":"https://github.com/supabase/gotrue"},{"type":"has_code","target_id":"github:supabase:storage-api","source_url":"https://github.com/supabase/storage-api"},{"type":"has_code","target_id":"github:supabase:pg_graphql","source_url":"http://github.com/supabase/pg_graphql"},{"type":"has_code","target_id":"github:supabase:postgres-meta","source_url":"https://github.com/supabase/postgres-meta"},{"type":"has_code","target_id":"github:Kong:kong","source_url":"https://github.com/Kong/kong"},{"type":"has_code","target_id":"github:postgrest:postgrest\"","source_url":"https://github.com/postgrest/postgrest\""},{"type":"has_code","target_id":"github:supabase:gotrue\"","source_url":"https://github.com/supabase/gotrue\""},{"type":"has_code","target_id":"github:supabase:realtime\"","source_url":"https://github.com/supabase/realtime\""},{"type":"has_code","target_id":"github:supabase:storage-api\"","source_url":"https://github.com/supabase/storage-api\""},{"type":"has_code","target_id":"github:supabase-community:supabase-lang\"","source_url":"https://github.com/supabase-community/supabase-lang\""},{"type":"has_code","target_id":"github:supabase-community:postgrest-lang\"","source_url":"https://github.com/supabase-community/postgrest-lang\""},{"type":"has_code","target_id":"github:supabase-community:gotrue-lang\"","source_url":"https://github.com/supabase-community/gotrue-lang\""},{"type":"has_code","target_id":"github:supabase-community:realtime-lang\"","source_url":"https://github.com/supabase-community/realtime-lang\""},{"type":"has_code","target_id":"github:supabase-community:storage-lang\"","source_url":"https://github.com/supabase-community/storage-lang\""},{"type":"has_code","target_id":"github:supabase:supabase-js\"","source_url":"https://github.com/supabase/supabase-js\""},{"type":"has_code","target_id":"github:supabase:postgrest-js\"","source_url":"https://github.com/supabase/postgrest-js\""},{"type":"has_code","target_id":"github:supabase:gotrue-js\"","source_url":"https://github.com/supabase/gotrue-js\""},{"type":"has_code","target_id":"github:supabase:realtime-js\"","source_url":"https://github.com/supabase/realtime-js\""},{"type":"has_code","target_id":"github:supabase:storage-js\"","source_url":"https://github.com/supabase/storage-js\""},{"type":"has_code","target_id":"github:supabase:functions-js\"","source_url":"https://github.com/supabase/functions-js\""},{"type":"has_code","target_id":"github:supabase:supabase-flutter\"","source_url":"https://github.com/supabase/supabase-flutter\""},{"type":"has_code","target_id":"github:supabase:postgrest-dart\"","source_url":"https://github.com/supabase/postgrest-dart\""},{"type":"has_code","target_id":"github:supabase:gotrue-dart\"","source_url":"https://github.com/supabase/gotrue-dart\""},{"type":"has_code","target_id":"github:supabase:realtime-dart\"","source_url":"https://github.com/supabase/realtime-dart\""},{"type":"has_code","target_id":"github:supabase:storage-dart\"","source_url":"https://github.com/supabase/storage-dart\""},{"type":"has_code","target_id":"github:supabase:functions-dart\"","source_url":"https://github.com/supabase/functions-dart\""},{"type":"has_code","target_id":"github:supabase:supabase-swift\"","source_url":"https://github.com/supabase/supabase-swift\""},{"type":"has_code","target_id":"github:supabase:supabase-swift","source_url":"https://github.com/supabase/supabase-swift"},{"type":"has_code","target_id":"github:supabase:supabase-swift","source_url":"https://github.com/supabase/supabase-swift"},{"type":"has_code","target_id":"github:supabase:supabase-swift","source_url":"https://github.com/supabase/supabase-swift"},{"type":"has_code","target_id":"github:supabase:supabase-swift","source_url":"https://github.com/supabase/supabase-swift"},{"type":"has_code","target_id":"github:supabase:supabase-swift","source_url":"https://github.com/supabase/supabase-swift"},{"type":"has_code","target_id":"github:supabase:supabase-py\"","source_url":"https://github.com/supabase/supabase-py\""},{"type":"has_code","target_id":"github:supabase:postgrest-py\"","source_url":"https://github.com/supabase/postgrest-py\""},{"type":"has_code","target_id":"github:supabase:gotrue-py\"","source_url":"https://github.com/supabase/gotrue-py\""},{"type":"has_code","target_id":"github:supabase:realtime-py\"","source_url":"https://github.com/supabase/realtime-py\""},{"type":"has_code","target_id":"github:supabase:storage-py\"","source_url":"https://github.com/supabase/storage-py\""},{"type":"has_code","target_id":"github:supabase:functions-py\"","source_url":"https://github.com/supabase/functions-py\""},{"type":"has_code","target_id":"github:supabase-community:supabase-csharp\"","source_url":"https://github.com/supabase-community/supabase-csharp\""},{"type":"has_code","target_id":"github:supabase-community:postgrest-csharp\"","source_url":"https://github.com/supabase-community/postgrest-csharp\""},{"type":"has_code","target_id":"github:supabase-community:gotrue-csharp\"","source_url":"https://github.com/supabase-community/gotrue-csharp\""},{"type":"has_code","target_id":"github:supabase-community:realtime-csharp\"","source_url":"https://github.com/supabase-community/realtime-csharp\""},{"type":"has_code","target_id":"github:supabase-community:storage-csharp\"","source_url":"https://github.com/supabase-community/storage-csharp\""},{"type":"has_code","target_id":"github:supabase-community:functions-csharp\"","source_url":"https://github.com/supabase-community/functions-csharp\""},{"type":"has_code","target_id":"github:supabase-community:postgrest-go\"","source_url":"https://github.com/supabase-community/postgrest-go\""},{"type":"has_code","target_id":"github:supabase-community:gotrue-go\"","source_url":"https://github.com/supabase-community/gotrue-go\""},{"type":"has_code","target_id":"github:supabase-community:storage-go\"","source_url":"https://github.com/supabase-community/storage-go\""},{"type":"has_code","target_id":"github:supabase-community:functions-go\"","source_url":"https://github.com/supabase-community/functions-go\""},{"type":"has_code","target_id":"github:supabase-community:gotrue-java\"","source_url":"https://github.com/supabase-community/gotrue-java\""},{"type":"has_code","target_id":"github:supabase-community:storage-java\"","source_url":"https://github.com/supabase-community/storage-java\""},{"type":"has_code","target_id":"github:supabase-community:supabase-kt\"","source_url":"https://github.com/supabase-community/supabase-kt\""},{"type":"has_code","target_id":"github:supabase-community:supabase-kt","source_url":"https://github.com/supabase-community/supabase-kt"},{"type":"has_code","target_id":"github:supabase-community:supabase-kt","source_url":"https://github.com/supabase-community/supabase-kt"},{"type":"has_code","target_id":"github:supabase-community:supabase-kt","source_url":"https://github.com/supabase-community/supabase-kt"},{"type":"has_code","target_id":"github:supabase-community:supabase-kt","source_url":"https://github.com/supabase-community/supabase-kt"},{"type":"has_code","target_id":"github:supabase-community:supabase-kt","source_url":"https://github.com/supabase-community/supabase-kt"},{"type":"has_code","target_id":"github:supabase-community:supabase-rb\"","source_url":"https://github.com/supabase-community/supabase-rb\""},{"type":"has_code","target_id":"github:supabase-community:postgrest-rb\"","source_url":"https://github.com/supabase-community/postgrest-rb\""},{"type":"has_code","target_id":"github:supabase-community:postgrest-rs\"","source_url":"https://github.com/supabase-community/postgrest-rs\""},{"type":"has_code","target_id":"github:supabase-community:godot-engine.supabase\"","source_url":"https://github.com/supabase-community/godot-engine.supabase\""},{"type":"has_code","target_id":"github:supabase:supabase","source_url":"https://github.com/supabase/supabase"}]', NULL, 'Apache-2.0', 'approved', 80, '73eba0077e93cf2f01244f6827578648', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-supabase-supabase from https://github.com/supabase.png
Image converted to WebP: data/images/github-supabase-supabase.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-punkpeye-awesome-mcp-servers', 'github--punkpeye--awesome-mcp-servers', 'awesome-mcp-servers', 'punkpeye', '> [!IMPORTANT] > Read The State of MCP in 2025 report. A curated list of awesome Model Context Protocol (MCP) servers. * What is MCP? * Clients * Tutorials * Community * Legend * Server Implementations * Frameworks * Tips & Tricks MCP is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, datab...', '["ai","mcp"]', 'other', 76279, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/punkpeye/awesome-mcp-servers","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '# Awesome MCP Servers [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n\n[![‡πÑ‡∏ó‡∏¢](https://img.shields.io/badge/Thai-Click-blue)](README-th.md)\n[![English](https://img.shields.io/badge/English-Click-yellow)](README.md)\n[![ÁπÅÈ´î‰∏≠Êñá](https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-ÈªûÊìäÊü•Áúã-orange)](README-zh_TW.md)\n[![ÁÆÄ‰Ωì‰∏≠Êñá](https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-ÁÇπÂáªÊü•Áúã-orange)](README-zh.md)\n[![Êó•Êú¨Ë™û](https://img.shields.io/badge/Êó•Êú¨Ë™û-„ÇØ„É™„ÉÉ„ÇØ-Èùí)](README-ja.md)\n[![ÌïúÍµ≠Ïñ¥](https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-ÌÅ¥Î¶≠-yellow)](README-ko.md)\n[![Portugu√™s Brasileiro](https://img.shields.io/badge/Portugu√™s_Brasileiro-Clique-green)](README-pt_BR.md)\n[![Discord](https://img.shields.io/discord/1312302100125843476?logo=discord&label=discord)](https://glama.ai/mcp/discord)\n[![Subreddit subscribers](https://img.shields.io/reddit/subreddit-subscribers/mcp?style=flat&logo=reddit&label=subreddit)](https://www.reddit.com/r/mcp/)\n\n> [!IMPORTANT]\n> Read [The State of MCP in 2025](https://glama.ai/blog/2025-12-07-the-state-of-mcp-in-2025) report.\n\nA curated list of awesome Model Context Protocol (MCP) servers.\n\n* [What is MCP?](#what-is-mcp)\n* [Clients](#clients)\n* [Tutorials](#tutorials)\n* [Community](#community)\n* [Legend](#legend)\n* [Server Implementations](#server-implementations)\n* [Frameworks](#frameworks)\n* [Tips & Tricks](#tips-and-tricks)\n\n## What is MCP?\n\n[MCP](https://modelcontextprotocol.io/) is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, database connections, API integrations, and other contextual services.\n\n## Clients\n\nCheckout [awesome-mcp-clients](https://github.com/punkpeye/awesome-mcp-clients/) and [glama.ai/mcp/clients](https://glama.ai/mcp/clients).\n\n> [!TIP]\n> [Glama Chat](https://glama.ai/chat) is a multi-modal AI client with MCP support & [AI gateway](https://glama.ai/gateway).\n\n## Tutorials\n\n* [Model Context Protocol (MCP) Quickstart](https://glama.ai/blog/2024-11-25-model-context-protocol-quickstart)\n* [Setup Claude Desktop App to Use a SQLite Database](https://youtu.be/wxCCzo9dGj0)\n\n## Community\n\n* [r/mcp Reddit](https://www.reddit.com/r/mcp)\n* [Discord Server](https://glama.ai/mcp/discord)\n\n## Legend\n\n* üéñÔ∏è ‚Äì official implementation\n* programming language\n  * üêç ‚Äì Python codebase\n  * üìá ‚Äì TypeScript (or JavaScript) codebase\n  * üèéÔ∏è ‚Äì Go codebase\n  * ü¶Ä ‚Äì Rust codebase\n  * #Ô∏è‚É£ - C# Codebase\n  * ‚òï - Java codebase\n  * üåä ‚Äì C/C++ codebase\n  * üíé - Ruby codebase\n\n* scope\n  * ‚òÅÔ∏è - Cloud Service\n  * üè† - Local Service\n  * üìü - Embedded Systems\n* operating system\n  * üçé ‚Äì For macOS\n  * ü™ü ‚Äì For Windows\n  * üêß - For Linux\n\n> [!NOTE]\n> Confused about Local üè† vs Cloud ‚òÅÔ∏è?\n> * Use local when MCP server is talking to a locally installed software, e.g. taking control over Chrome browser.\n> * Use cloud when MCP server is talking to remote APIs, e.g. weather API.\n\n## Server Implementations\n\n> [!NOTE]\n> We now have a [web-based directory](https://glama.ai/mcp/servers) that is synced with the repository.\n\n* üîó - [Aggregators](#aggregators)\n* üé® - [Art & Culture](#art-and-culture)\n* üìê - [Architecture & Design](#architecture-and-design)\n* üìÇ - [Browser Automation](#browser-automation)\n* üß¨ - [Biology Medicine and Bioinformatics](#bio)\n* ‚òÅÔ∏è - [Cloud Platforms](#cloud-platforms)\n* üë®‚Äçüíª - [Code Execution](#code-execution)\n* ü§ñ - [Coding Agents](#coding-agents)\n* üñ•Ô∏è - [Command Line](#command-line)\n* üí¨ - [Communication](#communication)\n* üë§ - [Customer Data Platforms](#customer-data-platforms)\n* üóÑÔ∏è - [Databases](#databases)\n* üìä - [Data Platforms](#data-platforms)\n* üöö - [Delivery](#delivery)\n* üõ†Ô∏è - [Developer Tools](#developer-tools)\n* üßÆ - [Data Science Tools](#data-science-tools)\n* üìü - [Embedded system](#embedded-system)\n* üìÇ - [File Systems](#file-systems)\n* üí∞ - [Finance & Fintech](#finance--fintech)\n* üéÆ - [Gaming](#gaming)\n* üß† - [Knowledge & Memory](#knowledge--memory)\n* ‚öñÔ∏è - [Legal](#legal)\n* üó∫Ô∏è - [Location Services](#location-services)\n* üéØ - [Marketing](#marketing)\n* üìä - [Monitoring](#monitoring)\n* üé• - [Multimedia Process](#multimedia-process)\n* üî¨ - [Research](#research)\n* üîé - [Search & Data Extraction](#search)\n* üîí - [Security](#security)\n* üåê - [Social Media](#social-media)\n* üèÉ - [Sports](#sports)\n* üéß - [Support & Service Management](#support-and-service-management)\n* üåé - [Translation Services](#translation-services)\n* üéß - [Text-to-Speech](#text-to-speech)\n* üöÜ - [Travel & Transportation](#travel-and-transportation)\n* üîÑ - [Version Control](#version-control)\n* üè¢ - [Workplace & Productivity](#workplace-and-productivity)\n* üõ†Ô∏è - [Other Tools and Integrations](#other-tools-and-integrations)\n\n\n### üîó <a name="aggregators"></a>Aggregators\n\nServers for accessing many apps and tools through a single MCP server.\n\n- [1mcp/agent](https://github.com/1mcp-app/agent) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - A unified Model Context Protocol server implementation that aggregates multiple MCP servers into one.\n- [askbudi/roundtable](https://github.com/askbudi/roundtable) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - Meta-MCP server that unifies multiple AI coding assistants (Codex, Claude Code, Cursor, Gemini) through intelligent auto-discovery and standardized MCP interface, providing zero-configuration access to the entire AI coding ecosystem.\n- [duaraghav8/MCPJungle](https://github.com/duaraghav8/MCPJungle) üèéÔ∏è üè† - Self-hosted MCP Server registry for enterprise AI Agents\n- [glenngillen/mcpmcp-server](https://github.com/glenngillen/mcpmcp-server) ‚òÅÔ∏è üìá üçé ü™ü üêß - A list of MCP servers so you can ask your client which servers you can use to improve your daily workflow.\n- [hamflx/imagen3-mcp](https://github.com/hamflx/imagen3-mcp) üìá üè† ü™ü üçé üêß - A powerful image generation tool using Google''s Imagen 3.0 API through MCP. Generate high-quality images from text prompts with advanced photography, artistic, and photorealistic controls.\n- [julien040/anyquery](https://github.com/julien040/anyquery) üèéÔ∏è üè† ‚òÅÔ∏è - Query more than 40 apps with one binary using SQL. It can also connect to your PostgreSQL, MySQL, or SQLite compatible database. Local-first and private by design.\n- [juspay/neurolink](https://github.com/juspay/neurolink) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - Making enterprise AI infrastructure universally accessible. Edge-first platform unifying 12 providers and 100+ models with multi-agent orchestration, HITL workflows, guardrails middleware, and context summarization.\n- [K-Dense-AI/claude-skills-mcp](https://github.com/K-Dense-AI/claude-skills-mcp) üêç ‚òÅÔ∏è üè† üçé ü™ü üêß - Intelligent search capabilities to let every model and client use [Claude Agent Skills](https://www.anthropic.com/news/skills) like native.\n- [metatool-ai/metatool-app](https://github.com/metatool-ai/metatool-app) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - MetaMCP is the one unified middleware MCP server that manages your MCP connections with GUI.\n- [mindsdb/mindsdb](https://github.com/mindsdb/mindsdb) - Connect and unify data across various platforms and databases with [MindsDB as a single MCP server](https://docs.mindsdb.com/mcp/overview).\n- [portel-dev/ncp](https://github.com/portel-dev/ncp) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - NCP orchestrates your entire MCP ecosystem through intelligent discovery, eliminating token overhead while maintaining 98.2% accuracy.\n- [particlefuture/MCPDiscovery](https://github.com/particlefuture/MCPDiscovery) - MCP of MCPs. A central hub for MCP servers. Helps you discover available MCP servers and learn how to install and use them.\n- [PipedreamHQ/pipedream](https://github.com/PipedreamHQ/pipedream/tree/master/modelcontextprotocol) ‚òÅÔ∏è üè† - Connect with 2,500 APIs with 8,000+ prebuilt tools, and manage servers for your users, in your own app.\n- [sitbon/magg](https://github.com/sitbon/magg) üçé ü™ü üêß ‚òÅÔ∏è üè† üêç - Magg: A meta-MCP server that acts as a universal hub, allowing LLMs to autonomously discover, install, and orchestrate multiple MCP servers - essentially giving AI assistants the power to extend their own capabilities on-demand.\n- [thinkchainai/mcpbundles](https://github.com/thinkchainai/mcpbundles) - MCP Bundles: Create custom bundles of tools and connect providers with OAuth or API keys. Use one MCP server across thousands of integrations, with programmatic tool calling and MCP UI for managing bundles and credentials.\n- [SureScaleAI/openai-gpt-image-mcp](https://github.com/SureScaleAI/openai-gpt-image-mcp) üìá ‚òÅÔ∏è - OpenAI GPT image generation/editing MCP server.\n- [sxhxliang/mcp-access-point](https://github.com/sxhxliang/mcp-access-point) üìá ‚òÅÔ∏è üè† üçé ü™ü üêß - Turn a web service into an MCP server in one click without making any code changes.\n- [TheLunarCompany/lunar#mcpx](https://github.com/TheLunarCompany/lunar/tree/main/mcpx) üìá üè†  ‚òÅÔ∏è üçé ü™ü üêß - MCPX is a production-ready, open-source gateway to manage MCP servers at scale‚Äîcentralize tool discovery, access controls, call prioritization, and usage tracking to simplify agent workflows.\n- [tigranbs/mcgravity](https://github.com/tigranbs/mcgravity) üìá üè† - A proxy tool for composing multiple MCP servers into one unified endpoint. Scale your AI tools by load balancing requests across multiple MCP servers, similar to how Nginx works for web servers.\n- [VeriTeknik/pluggedin-mcp-proxy](https://github.com/VeriTeknik/pluggedin-mcp-proxy)  üìá üè† - A comprehensive proxy server that combines multiple MCP servers into a single interface with extensive visibility features. It provides discovery and management of tools, prompts, resources, and templates across servers, plus a playground for debugging when building MCP servers.\n- [WayStation-ai/mcp](https://github.com/waystation-ai/mcp) ‚òÅÔ∏è üçé ü™ü - Seamlessly and securely connect Claude Desktop and other MCP hosts to your favorite apps (Notion, Slack, Monday, Airtable, etc.). Takes less than 90 secs.\n- [wegotdocs/open-mcp](https://github.com/wegotdocs/open-mcp) üìá üè† üçé ü™ü üêß - Turn a web API into an MCP server in 10 seconds and add it to the open source registry: https://open-mcp.org\n- [Data-Everything/mcp-server-templates](https://github.com/Data-Everything/mcp-server-templates) üìá üè† üçé ü™ü üêß - One server. All tools. A unified MCP platform that connects many apps, tools, and services behind one powerful interface‚Äîideal for local devs or production agents.\n- [YangLiangwei/PersonalizationMCP](https://github.com/YangLiangwei/PersonalizationMCP) üêç ‚òÅÔ∏è üè† üçé ü™ü üêß - Comprehensive personal data aggregation MCP server with Steam, YouTube, Bilibili, Spotify, Reddit and other platforms integrations. Features OAuth2 authentication, automatic token management, and 90+ tools for gaming, music, video, and social platform data access.\n\n### üöÄ <a name="aerospace-and-astrodynamics"></a>Aerospace & Astrodynamics\n\n- [IO-Aerospace-software-community/mcp-server](https://github.com/IO-Aerospace-software-engineering/mcp-server) #Ô∏è‚É£ ‚òÅÔ∏è/üè† üêß - IO Aerospace MCP Server: a .NET-based MCP server for aerospace & astrodynamics ‚Äî ephemeris, orbital conversions, DSS tools, time conversions, and unit/math utilities. Supports STDIO and SSE transports; Docker and native .NET deployment documented.\n\n### üé® <a name="art-and-culture"></a>Art & Culture\n\nAccess and explore art collections, cultural heritage, and museum databases. Enables AI models to search and analyze artistic and cultural content.\n\n- [drakonkat/wizzy-mcp-tmdb](https://github.com/drakonkat/wizzy-mcp-tmdb) üìá ‚òÅÔ∏è - A MCP server for The Movie Database API that enables AI assistants to search and retrieve movie, TV show, and person information.\n- [8enSmith/mcp-open-library](https://github.com/8enSmith/mcp-open-library) üìá ‚òÅÔ∏è - A MCP server for the Open Library API that enables AI assistants to search for book information.\n- [abhiemj/manim-mcp-server](https://github.com/abhiemj/manim-mcp-server) üêç üè† ü™ü üêß - A local MCP server that generates animations using Manim.\n- [ahujasid/blender-mcp](https://github.com/ahujasid/blender-mcp) üêç - MCP server for working with Blender\n- [burningion/video-editing-mcp](https://github.com/burningion/video-editing-mcp) üêç - Add, Analyze, Search, and Generate Video Edits from your Video Jungle Collection\n- [cantian-ai/bazi-mcp](https://github.com/cantian-ai/bazi-mcp) üìá üè† ‚òÅÔ∏è üçé ü™ü - Provides comprehensive and accurate Bazi (Chinese Astrology) charting and analysis\n- [cswkim/discogs-mcp-server](https://github.com/cswkim/discogs-mcp-server) üìá ‚òÅÔ∏è - MCP server to interact with the Discogs API\n- [diivi/aseprite-mcp](https://github.com/diivi/aseprite-mcp) üêç üè† - MCP server using the Aseprite API to create pixel art\n- [djalal/quran-mcp-server](https://github.com/djalal/quran-mcp-server) üìá ‚òÅÔ∏è MCP server to interact with Quran.com corpus via the official REST API v4.\n- [raveenb/fal-mcp-server](https://github.com/raveenb/fal-mcp-server) üêç ‚òÅÔ∏è - Generate AI images, videos, and music using Fal.ai models (FLUX, Stable Diffusion, MusicGen) directly in Claude Desktop\n- [GenWaveLLC/svgmaker-mcp](https://github.com/GenWaveLLC/svgmaker-mcp) üìá ‚òÅÔ∏è - Provides AI-driven SVG generation and editing via natural language, with real-time updates and secure file handling.\n- [mikechao/metmuseum-mcp](https://github.com/mikechao/metmuseum-mcp) üìá ‚òÅÔ∏è - Metropolitan Museum of Art Collection API integration to search and display artworks in the collection.\n- [molanojustin/smithsonian-mcp](https://github.com/molanojustin/smithsonian-mcp) üêç ‚òÅÔ∏è - MCP server that provides AI assistants with access to the Smithsonian Institution''s Open Access collections.  \n- [OctoEverywhere/mcp](https://github.com/OctoEverywhere/mcp) #Ô∏è‚É£ ‚òÅÔ∏è - A 3D printer MCP server that allows for getting live printer state, webcam snapshots, and printer control.\n- [omni-mcp/isaac-sim-mcp](https://github.com/omni-mcp/isaac-sim-mcp) üìá ‚òÅÔ∏è - A MCP Server and an extension enables natural language control of NVIDIA Isaac Sim, Lab, OpenUSD and etc.\n- [PatrickPalmer/MayaMCP](https://github.com/PatrickPalmer/MayaMCP) üêç üè† - MCP server for Autodesk Maya\n- [peek-travel/mcp-intro](https://github.com/peek-travel/mcp-intro) ‚òÅÔ∏è üçé ü™ü üêß - Remote MCP Server for discovering and planning experiences, at home and on vacation\n- [r-huijts/oorlogsbronnen-mcp](https://github.com/r-huijts/oorlogsbronnen-mcp) üìá ‚òÅÔ∏è - Oorlogsbronnen (War Sources) API integration for accessing historical WWII records, photographs, and documents from the Netherlands (1940-1945)\n- [r-huijts/rijksmuseum-mcp](https://github.com/r-huijts/rijksmuseum-mcp) üìá ‚òÅÔ∏è - Rijksmuseum API integration for artwork search, details, and collections\n- [samuelgursky/davinci-resolve-mcp](https://github.com/samuelgursky/davinci-resolve-mcp) üêç - MCP server integration for DaVinci Resolve providing powerful tools for video editing, color grading, media management, and project control\n- [yuna0x0/anilist-mcp](https://github.com/yuna0x0/anilist-mcp) üìá ‚òÅÔ∏è - A MCP server integrating AniList API for anime and manga information\n\n\n### üìê <a name="architecture-and-design"></a>Architecture & Design\n\nDesign and visualize software architecture, system diagrams, and technical documentation. Enables AI models to generate professional diagrams and architectural documentation.\n\n- [Narasimhaponnada/mermaid-mcp](https://github.com/Narasimhaponnada/mermaid-mcp) üìá ‚òÅÔ∏è üçé ü™ü üêß - AI-powered Mermaid diagram generation with 22+ diagram types including flowcharts, sequence diagrams, class diagrams, ER diagrams, architecture diagrams, state machines, and more. Features 50+ pre-built templates, advanced layout engines, SVG/PNG/PDF exports, and seamless integration with GitHub Copilot, Claude, and any MCP-compatible client. Install via NPM: `npm install -g @narasimhaponnada/mermaid-mcp-server`\n\n### <a name="bio"></a>Biology, Medicine and Bioinformatics\n\n- [dnaerys/onekgp-mcp](https://github.com/dnaerys/onekgp-mcp) ‚òï ‚òÅÔ∏è - natural language access to 1000 Genomes Project dataset\n- [genomoncology/biomcp](https://github.com/genomoncology/biomcp) üêç ‚òÅÔ∏è - Biomedical research MCP server providing access to PubMed, ClinicalTrials.gov, and MyVariant.info.\n- [hlydecker/ucsc-genome-mcp](https://github.com/hlydecker/ucsc-genome-mcp) üêç ‚òÅÔ∏è - MCP server to interact with the UCSC Genome Browser API, letting you find genomes, chromosomes, and more.\n- [longevity-genie/biothings-mcp](https://github.com/longevity-genie/biothings-mcp) üêç üè† ‚òÅÔ∏è - MCP server to interact with the BioThings API, including genes, genetic variants, drugs, and taxonomic information.\n- [longevity-genie/gget-mcp](https://github.com/longevity-genie/gget-mcp) üêç üè† ‚òÅÔ∏è - MCP server providing a powerful bioinformatics toolkit for genomics queries and analysis, wrapping the popular `gget` library.\n- [longevity-genie/opengenes-mcp](https://github.com/longevity-genie/opengenes-mcp) üéñÔ∏è üêç üè† ‚òÅÔ∏è - MCP server for a queryable database for aging and longevity research from the OpenGenes project.\n- [longevity-genie/synergy-age-mcp](https://github.com/longevity-genie/synergy-age-mcp) üéñÔ∏è üêç üè† ‚òÅÔ∏è - MCP server for the SynergyAge database of synergistic and antagonistic genetic interactions in longevity.\n- [the-momentum/fhir-mcp-server](https://github.com/the-momentum/fhir-mcp-server) üêç üè† ‚òÅÔ∏è - MCP Server that connects AI agents to FHIR servers. One example use case is querying patient history in natural language.\n- [wso2/fhir-mcp-server](https://github.com/wso2/fhir-mcp-server) üêç üè† ‚òÅÔ∏è - Model Context Protocol server for Fast Healthcare Interoperability Resources (FHIR) APIs. Provides seamless integration with FHIR servers, enabling AI assistants to search, retrieve, create, update, and analyze clinical healthcare data with SMART-on-FHIR authentication support.\n- [JamesANZ/medical-mcp](https://github.com/JamesANZ/medical-mcp) üìá üè† - An MCP server that provides access to medical information, drug databases, and healthcare resources. Enables AI assistants to query medical data, drug interactions, and clinical guidelines.\n- [the-momentum/apple-health-mcp-server](https://github.com/the-momentum/apple-health-mcp-server) üêç üè† üçé ü™ü üêß - An MCP server that provides access to exported data from Apple Health. Data analytics included.\n- [OHNLP/omop_mcp](https://github.com/OHNLP/omop_mcp) üêç üè† ‚òÅÔ∏è - Map clinical terminology to OMOP concepts using LLMs for healthcare data standardization and interoperability.\n\n### üìÇ <a name="browser-automation"></a>Browser Automation\n\nWeb content access and automation capabilities. Enables searching, scraping, and processing web content in AI-friendly formats.\n\n- [BB-fat/browser-use-rs](https://github.com/BB-fat/browser-use-rs) ü¶Ä Lightweight browser automation MCP server in Rust with zero dependencies.\n- [34892002/bilibili-mcp-js](https://github.com/34892002/bilibili-mcp-js) üìá üè† - A MCP server that supports searching for Bilibili content. Provides LangChain integration examples and test scripts.\n- [agent-infra/mcp-server-browser](https://github.com/bytedance/UI-TARS-desktop/tree/main/packages/agent-infra/mcp-servers/browser) üìá üè† - Browser automation capabilities using Puppeteer, both support local and remote browser connection.\n- [automatalabs/mcp-server-playwright](https://github.com/Automata-Labs-team/MCP-Server-Playwright) üêç - An MCP server for browser automation using Playwright\n- [blackwhite084/playwright-plus-python-mcp](https://github.com/blackwhite084/playwright-plus-python-mcp) üêç - An MCP python server using Playwright for browser automation,more suitable for llm\n- [browserbase/mcp-server-browserbase](https://github.com/browserbase/mcp-server-browserbase) üéñÔ∏è üìá - Automate browser interactions in the cloud (e.g. web navigation, data extraction, form filling, and more)\n- [browsermcp/mcp](https://github.com/browsermcp/mcp) üìá üè† - Automate your local Chrome browser\n- [co-browser/browser-use-mcp-server](https://github.com/co-browser/browser-use-mcp-server) üêç - browser-use packaged as an MCP server with SSE transport. includes a dockerfile to run chromium in docker + a vnc server.\n- [eat-pray-ai/yutu](https://github.com/eat-pray-ai/yutu) üèéÔ∏è üè† üçé üêß ü™ü - A fully functional MCP server and CLI for YouTube to automate YouTube operation\n- [executeautomation/playwright-mcp-server](https://github.com/executeautomation/mcp-playwright) üìá - An MCP server using Playwright for browser automation and webscrapping\n- [eyalzh/browser-control-mcp](https://github.com/eyalzh/browser-control-mcp) üìá üè† - An MCP server paired with a browser extension that enables LLM clients to control the user''s browser (Firefox).\n- [freema/firefox-devtools-mcp](https://github.com/freema/firefox-devtools-mcp) üìá üè† - Firefox browser automation via WebDriver BiDi for testing, scraping, and browser control. Supports snapshot/UID-based interactions, network monitoring, console capture, and screenshots.\n- [fradser/mcp-server-apple-reminders](https://github.com/FradSer/mcp-server-apple-reminders) üìá üè† üçé - An MCP server for interacting with Apple Reminders on macOS\n- [getrupt/ashra-mcp](https://github.com/getrupt/ashra-mcp) üìá üè† - Extract structured data from any website. Just prompt and get JSON.\n- [kimtaeyoon83/mcp-server-youtube-transcript](https://github.com/kimtaeyoon83/mcp-server-youtube-transcript) üìá ‚òÅÔ∏è - Fetch YouTube subtitles and transcripts for AI analysis\n- [kimtth/mcp-aoai-web-browsing](https://github.com/kimtth/mcp-aoai-web-browsing) üêç üè† - A `minimal` server/client MCP implementation using Azure OpenAI and Playwright.\n- [lightpanda-io/gomcp](https://github.com/lightpanda-io/gomcp) üèé üè†/‚òÅÔ∏è üêß/üçé - An MCP server in Go for Lightpanda, the ultra fast headless browser designed for web automation\n- [microsoft/playwright-mcp](https://github.com/microsoft/playwright-mcp) - Official Microsoft Playwright MCP server, enabling LLMs to interact with web pages through structured accessibility snapshots\n- [modelcontextprotocol/server-puppeteer](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/puppeteer) üìá üè† - Browser automation for web scraping and interaction\n- [ndthanhdev/mcp-browser-kit](https://github.com/ndthanhdev/mcp-browser-kit) üìá üè† - An MCP Server that enables AI assistants to interact with your local browsers.\n- [operative_sh/web-eval-agent](https://github.com/Operative-Sh/web-eval-agent) üêç üè† üçé - An MCP Server that autonomously debugs web applications with browser-use browser agents\n- [olostep/olostep-mcp-server](https://github.com/olostep/olostep-mcp-server) üìá ‚òÅÔ∏è - Web scraping, crawling, and search API. Extract content in Markdown/JSON, batch process 10k URLs, and get AI-powered answers with citations.\n- [pskill9/web-search](https://github.com/pskill9/web-search) üìá üè† - An MCP server that enables free web searching using Google search results, with no API keys required.\n- [PhungXuanAnh/selenium-mcp-server](https://github.com/PhungXuanAnh/selenium-mcp-server) üêç üè† üçé ü™ü üêß - A Model Context Protocol server providing web automation capabilities through Selenium WebDriver\n- [recursechat/mcp-server-apple-shortcuts](https://github.com/recursechat/mcp-server-apple-shortcuts) üìá üè† üçé - An MCP Server Integration with Apple Shortcuts\n- [xspadex/bilibili-mcp](https://github.com/xspadex/bilibili-mcp.git) üìá üè† - A FastMCP-based tool that fetches Bilibili''s trending videos and exposes them via a standard MCP interface.\n- [imprvhub/mcp-browser-agent](https://github.com/imprvhub/mcp-browser-agent) üìá üè† - A Model Context Protocol (MCP) integration that provides Claude Desktop with autonomous browser automation capabilities.\n\n### ‚òÅÔ∏è <a name="cloud-platforms"></a>Cloud Platforms\n\nCloud platform service integration. Enables management and interaction with cloud infrastructure and services.\n\n- [4everland/4everland-hosting-mcp](https://github.com/4everland/4everland-hosting-mcp) üéñÔ∏è üìá üè† üçé üêß - An MCP server implementation for 4EVERLAND Hosting enabling instant deployment of AI-generated code to decentralized storage networks like Greenfield, IPFS, and Arweave.\n- [aashari/mcp-server-aws-sso](https://github.com/aashari/mcp-server-aws-sso) üìá ‚òÅÔ∏è üè† - AWS Single Sign-On (SSO) integration enabling AI systems to securely interact with AWS resources by initiating SSO login, listing accounts/roles, and executing AWS CLI commands using temporary credentials.\n- [alexbakers/mcp-ipfs](https://github.com/alexbakers/mcp-ipfs) üìá ‚òÅÔ∏è - upload and manipulation of IPFS storage\n- [alexei-led/aws-mcp-server](https://github.com/alexei-led/aws-mcp-server) üêç ‚òÅÔ∏è - A lightweight but powerful server that enables AI assistants to execute AWS CLI commands, use Unix pipes, and apply prompt templates for common AWS tasks in a safe Docker environment with multi-architecture support\n- [alexei-led/k8s-mcp-server](https://github.com/alexei-led/k8s-mcp-server) üêç - A lightweight yet robust server that empowers AI assistants to securely execute Kubernetes CLI commands (`kubectl`, `helm`, `istioctl`, and `argocd`) using Unix pipes in a safe Docker environment with multi-architecture support.\n- [aliyun/alibaba-cloud-ops-mcp-server](https://github.com/aliyun/alibaba-cloud-ops-mcp-server) üéñÔ∏è üêç ‚òÅÔ∏è - A MCP server that enables AI assistants to operation resources on Alibaba Cloud, supporting ECS, Cloud Monitor, OOS and widely used cloud products.\n- [awslabs/mcp](https://github.com/awslabs/mcp) üéñÔ∏è ‚òÅÔ∏è - AWS MCP servers for seamless integration with AWS services and resources.\n- [localstack/localstack-mcp-server](https://github.com/localstack/localstack-mcp-server) üéñÔ∏è üìá üè† - A MCP server for LocalStack to manage local AWS environments, including lifecycle operations, infra deployments, log analysis, fault injection, and state management.\n- [bright8192/esxi-mcp-server](https://github.com/bright8192/esxi-mcp-server) üêç ‚òÅÔ∏è - A VMware ESXi/vCenter management server based on MCP (Model Control Protocol), providing simple REST API interfaces for virtual machine management.\n- [cloudflare/mcp-server-cloudflare](https://github.com/cloudflare/mcp-server-cloudflare) üéñÔ∏è üìá ‚òÅÔ∏è - Integration with Cloudflare services including Workers, KV, R2, and D1\n- [cyclops-ui/mcp-cyclops](https://github.com/cyclops-ui/mcp-cyclops) üéñÔ∏è üèéÔ∏è ‚òÅÔ∏è - An MCP server that allows AI agents to manage Kubernetes resources through Cyclops abstraction\n- [elementfm/mcp](https://gitlab.com/elementfm/mcp) üéñÔ∏è üêç üìá üè† ‚òÅÔ∏è - Open source podcast hosting platform\n- [erikhoward/adls-mcp-server](https://github.com/erikhoward/adls-mcp-server) üêç ‚òÅÔ∏è/üè† - MCP Server for Azure Data Lake Storage. It can perform manage containers, read/write/upload/download operations on container files and manage file metadata.\n- [espressif/esp-rainmaker-mcp](https://github.com/espressif/esp-rainmaker-mcp) üéñÔ∏è üêç üè† ‚òÅÔ∏è üìü - Official Espressif MCP Server to manage and control ESP RainMaker Devices.\n- [flux159/mcp-server-kubernetes](https://github.com/Flux159/mcp-server-kubernetes) üìá ‚òÅÔ∏è/üè† - Typescript implementation of Kubernetes cluster operations for pods, deployments, services.\n- [hardik-id/azure-resource-graph-mcp-server](https://github.com/hardik-id/azure-resource-graph-mcp-server) üìá ‚òÅÔ∏è/üè† - A Model Context Protocol server for querying and analyzing Azure resources at scale using Azure Resource Graph, enabling AI assistants to explore and monitor Azure infrastructure.\n- [jdubois/azure-cli-mcp](https://github.com/jdubois/azure-cli-mcp) - A wrapper around the Azure CLI command line that allows you to talk directly to Azure\n- [johnneerdael/netskope-mcp](https://github.com/johnneerdael/netskope-mcp) üîí ‚òÅÔ∏è - An MCP to give access to all Netskope Private Access components within a Netskope Private Access environments including detailed setup information and LLM examples on usage.\n- [kestra-io/mcp-server-python](https://github.com/kestra-io/mcp-server-python) üêç ‚òÅÔ∏è - Implementation of MCP server for [Kestra](https://kestra.io) workflow orchestration platform.\n- [liveblocks/liveblocks-mcp-server](https://github.com/liveblocks/liveblocks-mcp-server) üéñÔ∏è üìá ‚òÅÔ∏è - Create, modify, and delete different aspects of [Liveblocks](https://liveblocks.io) such as rooms, threads, comments, notifications, and more. Additionally, it has read access to Storage and Yjs.\n- [manusa/Kubernetes MCP Server](https://github.com/manusa/kubernetes-mcp-server) üèéÔ∏è üè† A - powerful Kubernetes MCP server with additional support for OpenShift. Besides providing CRUD operations for **any** Kubernetes resource, this server provides specialized tools to interact with your cluster.\n- [Nebula-Block-Data/nebulablock-mcp-server](https://github.com/Nebula-Block-Data/nebulablock-mcp-server) üìá üè† - integrates with the fastmcp library to expose the full range of NebulaBlock API functionalities as accessible tools\n- [nwiizo/tfmcp](https://github.com/nwiizo/tfmcp) - ü¶Ä üè† - A Terraform MCP server allowing AI assistants to manage and operate Terraform environments, enabling reading configurations, analyzing plans, applying configurations, and managing Terraform state.\n- [openstack-kr/python-openstackmcp-server](https://github.com/openstack-kr/python-openstackmcp-server) üêç ‚òÅÔ∏è - OpenStack MCP server for cloud infrastructure management based on openstacksdk.\n- [pibblokto/cert-manager-mcp-server](https://github.com/pibblokto/cert-manager-mcp-server) üêç üçé/üêß ‚òÅÔ∏è - mcp server for [cert-manager](https://github.com/cert-manager/cert-manager) management and troubleshooting\n- [portainer/portainer-mcp](https://github.com/portainer/portainer-mcp) üèéÔ∏è ‚òÅÔ∏è/üè† - A powerful MCP server that enables AI assistants to seamlessly interact with Portainer instances, providing natural language access to container management, deployment operations, and infrastructure monitoring capabilities.\n- [pulumi/mcp-server](https://github.com/pulumi/mcp-server) üéñÔ∏è üìá üè† - MCP server for interacting with Pulumi using the Pulumi Automation API and Pulumi Cloud API. Enables MCP clients to perform Pulumi operations like retrieving package information, previewing changes, deploying updates, and retrieving stack outputs programmatically.\n- [pythonanywhere/pythonanywhere-mcp-server](https://github.com/pythonanywhere/pythonanywhere-mcp-server) üêç üè† - MCP server implementation for PythonAnywhere cloud platform.\n- [qiniu/qiniu-mcp-server](https://github.com/qiniu/qiniu-mcp-server) üêç ‚òÅÔ∏è - A MCP built on Qiniu Cloud products, supporting access to Qiniu Cloud Storage, media processing services, etc.\n- [redis/mcp-redis-cloud](https://github.com/redis/mcp-redis-cloud) üìá ‚òÅÔ∏è - Manage your Redis Cloud resources effortlessly using natural language. Create databases, monitor subscriptions, and configure cloud deployments with simple commands.\n- [reza-gholizade/k8s-mcp-server](https://github.com/reza-gholizade/k8s-mcp-server) üèéÔ∏è ‚òÅÔ∏è/üè† - A Kubernetes Model Context Protocol (MCP) server that provides tools for interacting with Kubernetes clusters through a standardized interface, including API resource discovery, resource management, pod logs, metrics, and events.\n- [rohitg00/kubectl-mcp-server](https://github.com/rohitg00/kubectl-mcp-server) üêç ‚òÅÔ∏è/üè† - A Model Context Protocol (MCP) server for Kubernetes that enables AI assistants like Claude, Cursor, and others to interact with Kubernetes clusters through natural language.\n- [rrmistry/tilt-mcp](https://github.com/rrmistry/tilt-mcp) üêç üè† üçé ü™ü üêß - A Model Context Protocol server that integrates with Tilt to provide programmatic access to Tilt resources, logs, and management operations for Kubernetes development environments.\n- [silenceper/mcp-k8s](https://github.com/silenceper/mcp-k8s) üèéÔ∏è ‚òÅÔ∏è/üè† - MCP-K8S is an AI-driven Kubernetes resource management tool that allows users to operate any resources in Kubernetes clusters through natural language interaction, including native resources (like Deployment, Service) and custom resources (CRD). No need to memorize complex commands - just describe your needs, and AI will accurately execute the corresponding cluster operations, greatly enhancing the usability of Kubernetes.\n- [StacklokLabs/mkp](https://github.com/StacklokLabs/mkp) üèéÔ∏è ‚òÅÔ∏è - MKP is a Model Context Protocol (MCP) server for Kubernetes that allows LLM-powered applications to interact with Kubernetes clusters. It provides tools for listing and applying Kubernetes resources through the MCP protocol.\n- [StacklokLabs/ocireg-mcp](https://github.com/StacklokLabs/ocireg-mcp) üèéÔ∏è ‚òÅÔ∏è - An SSE-based MCP server that allows LLM-powered applications to interact with OCI registries. It provides tools for retrieving information about container images, listing tags, and more.\n- [strowk/mcp-k8s-go](https://github.com/strowk/mcp-k8s-go) üèéÔ∏è ‚òÅÔ∏è/üè† - Kubernetes cluster operations through MCP\n- [thunderboltsid/mcp-nutanix](https://github.com/thunderboltsid/mcp-nutanix) üèéÔ∏è üè†/‚òÅÔ∏è - Go-based MCP Server for interfacing with Nutanix Prism Central resources.\n- [trilogy-group/aws-pricing-mcp](https://github.com/trilogy-group/aws-pricing-mcp) üèéÔ∏è ‚òÅÔ∏è/üè† - Get up-to-date EC2 pricing information with one call. Fast. Powered by a pre-parsed AWS pricing catalogue.\n- [VmLia/books-mcp-server](https://github.com/VmLia/books-mcp-server) üìá ‚òÅÔ∏è - This is an MCP server used for querying books, and it can be applied in common MCP clients, such as Cherry Studio.\n- [weibaohui/k8m](https://github.com/weibaohui/k8m) üèéÔ∏è ‚òÅÔ∏è/üè† - Provides MCP multi-cluster Kubernetes management and operations, featuring a management interface, logging, and nearly 50 built-in tools covering common DevOps and development scenarios. Supports both standard and CRD resources.\n- [weibaohui/kom](https://github.com/weibaohui/kom) üèéÔ∏è ‚òÅÔ∏è/üè† - Provides MCP multi-cluster Kubernetes management and operations. It can be integrated as an SDK into your own project and includes nearly 50 built-in tools covering common DevOps and development scenarios. Supports both standard and CRD resources.\n- [wenhuwang/mcp-k8s-eye](https://github.com/wenhuwang/mcp-k8s-eye) üèéÔ∏è ‚òÅÔ∏è/üè† - MCP Server for kubernetes management, and analyze your cluster, application health\n- [elevy99927/devops-mcp-webui](https://github.com/elevy99927/devops-mcp-webui) üêç ‚òÅÔ∏è/üè† - MCP Server for Kubernetes integrated with Open-WebUI, bridging the gap between DevOps and non-technical teams. Supports `kubectl` and `helm` operations through natural-language commands.\n\n### üë®‚Äçüíª <a name="code-execution"></a>Code Execution\n\nCode execution servers. Allow LLMs to execute code in a secure environment, e.g. for coding agents.\n\n- [alfonsograziano/node-code-sandbox-mcp](https://github.com/alfonsograziano/node-code-sandbox-mcp) üìá üè† ‚Äì A Node.js MCP server that spins up isolated Docker-based sandboxes for executing JavaScript snippets with on-the-fly npm dependency installation and clean teardown\n- [ckanthony/openapi-mcp](https://github.com/ckanthony/openapi-mcp) üèéÔ∏è ‚òÅÔ∏è - OpenAPI-MCP: Dockerized MCP Server to allow your AI agent to access any API with existing api docs.\n- [gwbischof/outsource-mcp](https://github.com/gwbischof/outsource-mcp) üêç ‚òÅÔ∏è - Give your AI assistant its own AI assistants. For example: "Could you ask openai to generate an image of a dog?"\n- [hileamlakB/PRIMS](https://github.com/hileamlakB/PRIMS) üêç üè† ‚Äì A Python Runtime Interpreter MCP Server that executes user-submitted code in an isolated environment.\n- [ouvreboite/openapi-to-mcp](https://github.com/ouvreboite/openapi-to-mcp) #Ô∏è‚É£ ‚òÅÔ∏è - Lightweight MCP server to access any API using their OpenAPI specification. Supports OAuth2 and full JSON schema parameters and request body.\n- [pydantic/pydantic-ai/mcp-run-python](https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python) üêç üè† - Run Python code in a secure sandbox via MCP tool calls\n- [r33drichards/mcp-js](https://github.com/r33drichards/mcp-js) ü¶Ä üè† üêß üçé - A Javascript code execution sandbox that uses v8 to isolate code to run AI generated javascript locally without fear. Supports heap snapshotting for persistent sessions.\n- [yepcode/mcp-server-js](https://github.com/yepcode/mcp-server-js) üéñÔ∏è üìá ‚òÅÔ∏è - Execute any LLM-generated code in a secure and scalable sandbox environment and create your own MCP tools using JavaScript or Python, with full support for NPM and PyPI packages\n- [dagger/container-use](https://github.com/dagger/container-use) üèéÔ∏è üè† üêß üçé ü™ü - Containerized environments for coding agents. Multiple agents can work independently, isolated in fresh containers and git branches. No conflicts, many experiments. Full execution history, terminal access to agent environments, git workflow. Any agent/model/infra stack.\n\n### ü§ñ <a name="coding-agents"></a>Coding Agents\n\nFull coding agents that enable LLMs to read, edit, and execute code and solve general programming tasks completely autonomously.\n\n- [shashankss1205/codegraphcontext](https://github.com/Shashankss1205/CodeGraphContext) üêç üè† üçé ü™ü üêß An MCP server that indexes local code into a graph database to provide context to AI assistants with a graphical code visualizations for humans.\n- [doggybee/mcp-server-leetcode](https://github.com/doggybee/mcp-server-leetcode) üìá ‚òÅÔ∏è - An MCP server that enables AI models to search, retrieve, and solve LeetCode problems. Supports metadata filtering, user profiles, submissions, and contest data access.\n- [ezyang/codemcp](https://github.com/ezyang/codemcp) üêç üè† - Coding agent with basic read, write and command line tools.\n- [gabrielmaialva33/winx-code-agent](https://github.com/gabrielmaialva33/winx-code-agent) ü¶Ä üè† - A high-performance Rust reimplementation of WCGW for code agents, providing shell execution and advanced file management capabilities for LLMs via MCP.\n- [jinzcdev/leetcode-mcp-server](https://github.com/jinzcdev/leetcode-mcp-server) üìá ‚òÅÔ∏è - MCP server enabling automated access to **LeetCode**''s programming problems, solutions, submissions and public data with optional authentication for user-specific features (e.g., notes), supporting both `leetcode.com` (global) and `leetcode.cn` (China) sites.\n- [juehang/vscode-mcp-server](https://github.com/juehang/vscode-mcp-server) üìá üè† - A MCP Server that allows AI such as Claude to read from the directory structure in a VS Code workspace, see problems picked up by linter(s) and the language server, read code files, and make edits.\n- [micl2e2/code-to-tree](https://github.com/micl2e2/code-to-tree) üåä üè† üìü üêß ü™ü üçé - A single-binary MCP server that converts source code into AST, regardless of language.\n- [oraios/serena](https://github.com/oraios/serena) üêç üè† - A fully-featured coding agent that relies on symbolic code operations by using language servers.\n- [pdavis68/RepoMapper](https://github.com.mcas.ms/pdavis68/RepoMapper) üêß ü™ü üçé - An MCP server (and command-line tool) to provide a dynamic map of chat-related files from the repository with their function prototypes and related files in order of relevance. Based on the "Repo Map" functionality in Aider.chat\n- [rinadelph/Agent-MCP](https://github.com/rinadelph/Agent-MCP) üêç üè† - A framework for creating multi-agent systems using MCP for coordinated AI collaboration, featuring task management, shared context, and RAG capabilities.\n- [sim-xia/blind-auditor](https://github.com/Sim-xia/Blind-Auditor) - üêç üè† üçé ü™ü üêß A zero-cost MCP server that forces AI to self-correct generation messages using prompt injection, independent self-audition and context isolation.\n- [stippi/code-assistant](https://github.com/stippi/code-assistant) ü¶Ä üè† - Coding agent with basic list, read, replace_in_file, write, execute_command and web search tools. Supports multiple projects concurrently.\n- [tiianhk/MaxMSP-MCP-Server](https://github.com/tiianhk/MaxMSP-MCP-Server) üêç üè† üéµ üé• - A coding agent for Max (Max/MSP/Jitter), which is a visual programming language for music and multimedia.\n- [nesquikm/mcp-rubber-duck](https://github.com/nesquikm/mcp-rubber-duck) üìá üè† ‚òÅÔ∏è - An MCP server that bridges to multiple OpenAI-compatible LLMs - your AI rubber duck debugging panel for explaining problems to various AI "ducks" and getting different perspectives\n- [askbudi/roundtable](https://github.com/askbudi/roundtable) üêç üè† - Zero-configuration MCP server that unifies multiple AI coding assistants (Claude Code, Cursor, Codex) through intelligent auto-discovery and standardized interface. Essential infrastructure for autonomous agent development and multi-AI collaboration workflows.\n- [VertexStudio/developer](https://github.com/VertexStudio/developer) ü¶Ä üè† üçé ü™ü üêß - Comprehensive developer tools for file editing, shell command execution, and screen capture capabilities\n- [x51xxx/codex-mcp-tool](https://github.com/x51xxx/codex-mcp-tool) üìá ‚òÅÔ∏è - MCP server that connects your IDE or AI assistant to Codex CLI for code analysis and editing with support for multiple models (gpt-5-codex, o3, codex-1)\n- [x51xxx/copilot-mcp-server](https://github.com/x51xxx/copilot-mcp-server) üìá ‚òÅÔ∏è - MCP server that connects your IDE or AI assistant to GitHub Copilot CLI for code analysis, review, and batch processing\n- [wende/cicada](https://github.com/wende/cicada) üêç üè† üçé ü™ü üêß - Code Intelligence for Elixir: module search, function tracking, and PR attribution through tree-sitter AST parsing\n\n### üñ•Ô∏è <a name="command-line"></a>Command Line\n\nRun commands, capture output and otherwise interact with shells and command line tools.\n\n- [automateyournetwork/pyATS_MCP](https://github.com/automateyournetwork/pyATS_MCP) - Cisco pyATS server enabling structured, model-driven interaction with network devices.\n- [aymericzip/intlayer](https://github.com/aymericzip/intlayer) üìá ‚òÅÔ∏è üè† - A MCP Server that enhance your IDE with AI-powered assistance for Intlayer i18n / CMS tool: smart CLI access, access to the docs.\n- [blakerouse/ssh-mcp](https://github.com/blakerouse/ssh-mcp) üèéÔ∏è üè† üçé ü™ü üêß - MCP server exposing SSH control for Linux and Windows servers. Allows long running commands and the ability to perform commands on multiple hosts at the same time.\n- [ferrislucas/iterm-mcp](https://github.com/ferrislucas/iterm-mcp) üñ•Ô∏è üõ†Ô∏è üí¨ - A Model Context Protocol server that provides access to iTerm. You can run commands and ask questions about what you see in the iTerm terminal.\n- [g0t4/mcp-server-commands](https://github.com/g0t4/mcp-server-commands) üìá üè† - Run any command with `run_command` and `run_script` tools.\n- [maxim-saplin/mcp_safe_local_python_executor](https://github.com/maxim-saplin/mcp_safe_local_python_executor) - Safe Python interpreter based on HF Smolagents `LocalPythonExecutor`\n- [misiektoja/kill-process-mcp](https://github.com/misiektoja/kill-process-mcp) üêç üè† üçé ü™ü üêß - List and terminate OS processes via natural language queries\n- [MladenSU/cli-mcp-server](https://github.com/MladenSU/cli-mcp-server) üêç üè† - Command line interface with secure execution and customizable security policies\n- [OthmaneBlial/term_mcp_deepseek](https://github.com/OthmaneBlial/term_mcp_deepseek) üêç üè† - A DeepSeek MCP-like Server for Terminal\n- [ooples/mcp-console-automation](https://github.com/ooples/mcp-console-automation) üìá üè† üçé ü™ü üêß - Production-ready MCP server for AI-driven console automation and monitoring. 40 tools for session management, SSH, testing, monitoring, and background jobs. Like Playwright for terminal applications.\n- [sonirico/mcp-shell](https://github.com/sonirico/mcp-shell) - üèéÔ∏è üè† üçé ü™ü üêß Give hands to AI. MCP server to run shell commands securely, auditably, and on demand on isolated environments like docker.\n- [louis030195/terminator-mcp-agent](https://github.com/mediar-ai/terminator/tree/main/terminator-mcp-agent) ü¶Ä üìá üè† üçé ü™ü üêß - Desktop GUI automation using accessibility APIs. Control Windows, macOS, and Linux applications without vision models or screenshots. Supports workflow recording, structured data extraction, and browser DOM inspection.\n- [tufantunc/ssh-mcp](https://github.com/tufantunc/ssh-mcp) üìá üè† üêß ü™ü - MCP server exposing SSH control for Linux and Windows servers via Model Context Protocol. Securely execute remote shell commands with password or SSH key authentication.\n- [tumf/mcp-shell-server](https://github.com/tumf/mcp-shell-server) - A secure shell command execution server implementing the Model Context Protocol (MCP)\n- [wonderwhy-er/DesktopCommanderMCP](https://github.com/wonderwhy-er/DesktopCommanderMCP) üìá üè† üçé ü™ü üêß - A swiss-army-knife that can manage/execute programs and read/write/search/edit code and text files.\n- [nihalxkumar/arch-mcp](https://github.com/nihalxkumar/arch-mcp) üêç üè† üêß - Arch Linux MCP Server to the Arch Linux ecosystem of the Arch Wiki, AUR, and official repositories for AI-assisted Arch Linux usage on Arch and non-Arch systems. Features include searching Arch Wiki and AUR, getting package info, checking for updates, installing packages securely, and analyzing PKGBUILDs.\n\n### üí¨ <a name="communication"></a>Communication\n\nIntegration with communication platforms for message management and channel operations. Enables AI models to interact with team communication tools.\n\n- [AbdelStark/nostr-mcp](https://github.com/AbdelStark/nostr-mcp) ‚òÅÔ∏è - A Nostr MCP server that allows to interact with Nostr, enabling posting notes, and more.\n- [adhikasp/mcp-twikit](https://github.com/adhikasp/mcp-twikit) üêç ‚òÅÔ∏è - Interact with Twitter search and timeline\n- [agentmail-toolkit/mcp](https://github.com/agentmail-to/agentmail-toolkit/tree/main/mcp) üêç üí¨ - An MCP server to create inboxes on the fly to send, receive, and take actions on email. We aren''t AI agents for email, but email for AI Agents.\n- [areweai/tsgram-mcp](https://github.com/areweai/tsgram-mcp) - TSgram: Telegram + Claude with local workspace access on your phone in typescript. Read, write, and vibe code on the go!\n- [arpitbatra123/mcp-googletasks](https://github.com/arpitbatra123/mcp-googletasks) üìá ‚òÅÔ∏è - An MCP server to interface with the Google Tasks API\n- [Cactusinhand/mcp_server_notify](https://github.com/Cactusinhand/mcp_server_notify) üêç üè† - A MCP server that send desktop notifications with sound effect when agent tasks are completed.\n- [trycourier/courier-mcp](https://github.com/trycourier/courier-mcp) üéñÔ∏è üí¨ ‚òÅÔ∏è üõ†Ô∏è üìá ü§ñ - Build multi-channel notifications into your product, send messages, update lists, invoke automations, all without leaving your AI coding space. \n- [PhononX/cv-mcp-server](https://github.com/PhononX/cv-mcp-server) üéñÔ∏è üìá üè† ‚òÅÔ∏è üçé ü™ü üêß - MCP Server that connects AI Agents to [Carbon Voice](https://getcarbon.app). Create, manage, and interact with voice messages, conversations, direct messages, folders, voice memos, AI actions and more in [Carbon Voice](https://getcarbon.app).\n- [carterlasalle/mac_messages_mcp](https://github.com/carterlasalle/mac_messages_mcp) üè† üçé üöÄ - An MCP server that securely interfaces with your iMessage database via the Model Context Protocol (MCP), allowing LLMs to query and analyze iMessage conversations. It includes robust phone number validation, attachment processing, contact management, group chat handling, and full support for sending and receiving messages.\n- [chaindead/telegram-mcp](https://github.com/chaindead/telegram-mcp) üèéÔ∏è üè† - Telegram API integration for accessing user data, managing dialogs (chats, channels, groups), retrieving messages, and handling read status\n- [chigwell/telegram-mcp](https://github.com/chigwell/telegram-mcp) üêç üè† - Telegram API integration for accessing user data, managing dialogs (chats, channels, groups), retrieving messages, sending messages and handling read status.\n- [Danielpeter-99/calcom-mcp](https://github.com/Danielpeter-99/calcom-mcp) üêç üè† - MCP server for Calcom. Manage event types, create bookings, and access Cal.com scheduling data through LLMs.\n- [discourse/discourse-mcp](https://github.com/discourse/discourse-mcp) üéñÔ∏è üíé ‚òÅÔ∏è üè† üí¨ üçé ü™ü üêß - Official Discourse MCP server for forum integration. Search topics, read posts, manage categories and tags, discover users, and interact with Discourse communities.\n- [elie222/inbox-zero](https://github.com/elie222/inbox-zero/tree/main/apps/mcp-server) üêç ‚òÅÔ∏è - An MCP server for Inbox Zero. Adds functionality on top of Gmail like finding out which emails you need to reply to or need to follow up on.\n- [gerkensm/callcenter.js-mcp](https://github.com/gerkensm/callcenter.js-mcp) üìá ‚òÅÔ∏è - An MCP server to make phone calls using VoIP/SIP and OpenAI''s Realtime API and observe the transcript.\n- [gitmotion/ntfy-me-mcp](https://github.com/gitmotion/ntfy-me-mcp) üìá ‚òÅÔ∏è üè† - An ntfy MCP server for sending/fetching ntfy notifications to your self-hosted ntfy server from AI Agents üì§ (supports secure token auth & more - use with npx or docker!)\n- [gotoolkits/wecombot](https://github.com/gotoolkits/mcp-wecombot-server.git) üöÄ ‚òÅÔ∏è - An MCP server application that sends various types of messages to the WeCom group robot.\n- [hannesrudolph/imessage-query-fastmcp-mcp-server](https://github.com/hannesrudolph/imessage-query-fastmcp-mcp-server) üêç üè† üçé - An MCP server that provides safe access to your iMessage database through Model Context Protocol (MCP), enabling LLMs to query and analyze iMessage conversations with proper phone number validation and attachment handling\n- [i-am-bee/acp-mcp](https://github.com/i-am-bee/acp-mcp) üêç üí¨ - An MCP server acting as an adapter into the [ACP](https://agentcommunicationprotocol.dev) ecosystem. Seamlessly exposes ACP agents to MCP clients, bridging the communication gap between the two protocols.\n- [InditexTech/mcp-teams-server](https://github.com/InditexTech/mcp-teams-server) üêç ‚òÅÔ∏è - MCP server that integrates Microsoft Teams messaging (read, post, mention, list members and threads)\n- [Infobip/mcp](https://github.com/infobip/mcp) üéñÔ∏è ‚òÅÔ∏è - Official Infobip MCP server for integrating Infobip global cloud communication platform. It equips AI agents with communication superpowers, allowing them to send and receive SMS and RCS messages, interact with WhatsApp and Viber, automate communication workflows, and manage customer data, all in a production-ready environment.\n- [jagan-shanmugam/mattermost-mcp-host](https://github.com/jagan-shanmugam/mattermost-mcp-host) üêç üè† - A MCP server along with MCP host that provides access to Mattermost teams, channels and messages. MCP host is integrated as a bot in Mattermost with access to MCP servers that can be configured.\n- [jaipandya/producthunt-mcp-server](https://github.com/jaipandya/producthunt-mcp-server) üêç üè† - MCP server for Product Hunt. Interact with trending posts, comments, collections, users, and more.\n- [joinly-ai/joinly](https://github.com/joinly-ai/joinly) üêç‚òÅÔ∏è - MCP server to interact with browser-based meeting platforms (Zoom, Teams, Google Meet). Enables AI agents to send bots to online meetings, gather live transcripts, speak text, and send messages in the meeting chat.\n- [keturiosakys/bluesky-context-server](https://github.com/keturiosakys/bluesky-context-server) üìá ‚òÅÔ∏è - Bluesky instance integration for querying and interaction\n- [khan2a/telephony-mcp-server](https://github.com/khan2a/telephony-mcp-server) üêç üí¨ - MCP Telephony server for automating voice calls with Speech-to-Text and Speech Recognition to summarize call conversations. Send and receive SMS, detect voicemail, and integrate with Vonage APIs for advanced telephony workflows.\n- [korotovsky/slack-mcp-server](https://github.com/korotovsky/slack-mcp-server) üìá ‚òÅÔ∏è - The most powerful MCP server for Slack Workspaces.\n- [lharries/whatsapp-mcp](https://github.com/lharries/whatsapp-mcp) üêç üèéÔ∏è - An MCP server for searching your personal WhatsApp messages, contacts and sending messages to individuals or groups\n- [line/line-bot-mcp-server](https://github.com/line/line-bot-mcp-server) üéñ üìá ‚òÅÔ∏è - MCP Server for Integrating LINE Official Account\n- [madbonez/caldav-mcp](https://github.com/madbonez/caldav-mcp) üêç ‚òÅÔ∏è - Universal MCP server for CalDAV protocol integration. Works with any CalDAV-compatible calendar server including Yandex Calendar, Google Calendar (via CalDAV), Nextcloud, ownCloud, Apple iCloud, and others. Supports creating events with recurrence, categories, priority, attendees, reminders, searching events, and retrieving events by UID.\n- [OverQuotaAI/chatterboxio-mcp-server](https://github.com/OverQuotaAI/chatterboxio-mcp-server) üìá ‚òÅÔ∏è - MCP server implementation for ChatterBox.io, enabling AI agents to send bots to online meetings (Zoom, Google Meet) and obtain transcripts and recordings.\n- [wyattjoh/imessage-mcp](https://github.com/wyattjoh/imessage-mcp) üìá üè† üçé - A Model Context Protocol server for reading iMessage data from macOS.\n- [sawa-zen/vrchat-mcp](https://github.com/sawa-zen/vrchat-mcp) - üìá üè† This is an MCP server for interacting with the VRChat API. You can retrieve information about friends, worlds, avatars, and more in VRChat.\n- [softeria/ms-365-mcp-server](https://github.com/softeria/ms-365-mcp-server) üìá ‚òÅÔ∏è - MCP server that connects to Microsoft Office and the whole Microsoft 365 suite using Graph API (including Outlook, mail, files, Excel, calendar)\n- [saseq/discord-mcp](https://github.com/SaseQ/discord-mcp) ‚òï üìá üè† üí¨ - A MCP server for the Discord integration. Enable your AI assistants to seamlessly interact with Discord. Enhance your Discord experience with powerful automation capabilities.\n- [teddyzxcv/ntfy-mcp](https://github.com/teddyzxcv/ntfy-mcp) - The MCP server that keeps you informed by sending the notification on phone using ntfy\n- [userad/didlogic_mcp](https://github.com/UserAd/didlogic_mcp) üêç ‚òÅÔ∏è - An MCP server for [DIDLogic](https://didlogic.com). Adds functionality to manage SIP endpoints, numbers and destinations.\n- [YCloud-Developers/ycloud-whatsapp-mcp-server](https://github.com/YCloud-Developers/ycloud-whatsapp-mcp-server) üìá üè† - MCP server for WhatsApp Business Platform by YCloud.\n- [zcaceres/gtasks-mcp](https://github.com/zcaceres/gtasks-mcp) üìá ‚òÅÔ∏è - An MCP server to Manage Google Tasks\n- [ztxtxwd/open-feishu-mcp-server](https://github.com/ztxtxwd/open-feishu-mcp-server) üìá ‚òÅÔ∏è üè† - A Model Context Protocol (MCP) server with built-in Feishu OAuth authentication, supporting remote connections and providing comprehensive Feishu document management tools including block creation, content updates, and advanced features.\n\n\n### üë§ <a name="customer-data-platforms"></a>Customer Data Platforms\n\nProvides access to customer profiles inside of customer data platforms\n\n- [antv/mcp-server-chart](https://github.com/antvis/mcp-server-chart) üéñÔ∏è üìá ‚òÅÔ∏è - A Model Context Protocol server for generating visual charts using [AntV](https://github.com/antvis).\n- [hustcc/mcp-echarts](https://github.com/hustcc/mcp-echarts) üìá üè† - Generate visual charts using [Apache ECharts](https://echarts.apache.org) with AI MCP dynamically.\n- [hustcc/mcp-mermaid](https://github.com/hustcc/mcp-mermaid) üìá üè† - Generate [mermaid](https://mermaid.js.org/) diagram and chart with AI MCP dynamically.\n- [iaptic/mcp-server-iaptic](https://github.com/iaptic/mcp-server-iaptic) üéñÔ∏è üìá ‚òÅÔ∏è - Connect with [iaptic](https://www.iaptic.com) to ask about your Customer Purchases, Transaction data and App Revenue statistics.\n- [OpenDataMCP/OpenDataMCP](https://github.com/OpenDataMCP/OpenDataMCP) üêç ‚òÅÔ∏è - Connect any Open Data to any LLM with Model Context Protocol.\n- [sergehuber/inoyu-mcp-unomi-server](https://github.com/sergehuber/inoyu-mcp-unomi-server) üìá ‚òÅÔ∏è - An MCP server to access and updates profiles on an Apache Unomi CDP server.\n- [tinybirdco/mcp-tinybird](https://github.com/tinybirdco/mcp-tinybird) üêç ‚òÅÔ∏è - An MCP server to interact with a Tinybird Workspace from any MCP client.\n\n### üóÑÔ∏è <a name="databases"></a>Databases\n\nSecure database access with schema inspection capabilities. Enables querying and analyzing data with configurable security controls including read-only access.\n\n- [Aiven-Open/mcp-aiven](https://github.com/Aiven-Open/mcp-aiven) - üêç ‚òÅÔ∏è üéñÔ∏è -  Navigate your [Aiven projects](https://go.aiven.io/mcp-server) and interact with the PostgreSQL¬Æ, Apache Kafka¬Æ, ClickHouse¬Æ and OpenSearch¬Æ services\n- [alexanderzuev/supabase-mcp-server](https://github.com/alexander-zuev/supabase-mcp-server) - Supabase MCP Server with support for SQL query execution and database exploration tools\n- [aliyun/alibabacloud-tablestore-mcp-server](https://github.com/aliyun/alibabacloud-tablestore-mcp-server) ‚òï üêç ‚òÅÔ∏è - MCP service for Tablestore, features include adding documents, semantic search for documents based on vectors and scalars, RAG-friendly, and serverless.\n- [amineelkouhen/mcp-cockroachdb](https://github.com/amineelkouhen/mcp-cockroachdb) üêç ‚òÅÔ∏è - A Model Context Protocol server for managing, monitoring, and querying data in [CockroachDB](https://cockroachlabs.com).\n- [benborla29/mcp-server-mysql](https://github.com/benborla/mcp-server-mysql) ‚òÅÔ∏è üè† - MySQL database integration in NodeJS with configurable access controls and schema inspection\n- [bram2w/baserow](https://github.com/bram2w/baserow) - Baserow database integration with table search, list, and row create, read, update, and delete capabilities.\n- [c4pt0r/mcp-server-tidb](https://github.com/c4pt0r/mcp-server-tidb) üêç ‚òÅÔ∏è - TiDB database integration with schema inspection and query capabilities\n- [Canner/wren-engine](https://github.com/Canner/wren-engine) üêç ü¶Ä üè† - The Semantic Engine for Model Context Protocol(MCP) Clients and AI Agents\n- [centralmind/gateway](https://github.com/centralmind/gateway) üèéÔ∏è üè† üçé ü™ü - MCP and MCP SSE Server that automatically generate API based on database schema and data. Supports PostgreSQL, Clickhouse, MySQL, Snowflake, BigQuery, Supabase\n- [ChristianHinge/dicom-mcp](https://github.com/ChristianHinge/dicom-mcp) üêç ‚òÅÔ∏è üè† - DICOM integration to query, read, and move medical images and reports from PACS and other DICOM compliant systems.\n- [chroma-core/chroma-mcp](https://github.com/chroma-core/chroma-mcp) üéñÔ∏è üêç ‚òÅÔ∏è üè† - Chroma MCP server to access local and cloud Chroma instances for retrieval capabilities\n- [ClickHouse/mcp-clickhouse](https://github.com/ClickHouse/mcp-clickhouse) üêç ‚òÅÔ∏è - ClickHouse database integration with schema inspection and query capabilities\n- [confluentinc/mcp-confluent](https://github.com/confluentinc/mcp-confluent) üêç ‚òÅÔ∏è - Confluent integration to interact with Confluent Kafka and Confluent Cloud REST APIs.\n- [Couchbase-Ecosystem/mcp-server-couchbase](https://github.com/Couchbase-Ecosystem/mcp-server-couchbase) üéñÔ∏è üêç ‚òÅÔ∏è üè† - Couchbase MCP server provides unfied access to both Capella cloud and self-managed clusters for document operations, SQL++ queries and natural language data analysis.\n- [cr7258/elasticsearch-mcp-server](https://github.com/cr7258/elasticsearch-mcp-server) üêç üè† - MCP Server implementation that provides Elasticsearch interaction\n- [crystaldba/postgres-mcp](https://github.com/crystaldba/postgres-mcp) üêç üè† - All-in-one MCP server for Postgres development and operations, with tools for performance analysis, tuning, and health checks\n- [Dataring-engineering/mcp-server-trino](https://github.com/Dataring-engineering/mcp-server-trino) üêç ‚òÅÔ∏è - Trino MCP Server to query and access data from Trino Clusters.\n- [davewind/mysql-mcp-server](https://github.com/dave-wind/mysql-mcp-server) üèéÔ∏è üè† A ‚Äì¬†user-friendly read-only mysql mcp server for cursor and n8n...\n- [designcomputer/mysql_mcp_server](https://github.com/designcomputer/mysql_mcp_server) üêç üè† - MySQL database integration with configurable access controls, schema inspection, and comprehensive security guidelines\n- [domdomegg/airtable-mcp-server](https://github.com/domdomegg/airtable-mcp-server) üìá üè† - Airtable database integration with schema inspection, read and write capabilities\n- [edwinbernadus/nocodb-mcp-server](https://github.com/edwinbernadus/nocodb-mcp-server) üìá ‚òÅÔ∏è - Nocodb database integration, read and write capabilities\n- [ergut/mcp-bigquery-server](https://github.com/ergut/mcp-bigquery-server) üìá ‚òÅÔ∏è - Server implementation for Google BigQuery integration that enables direct BigQuery database access and querying capabilities\n- [f4ww4z/mcp-mysql-server](https://github.com/f4ww4z/mcp-mysql-server) üìá üè† - Node.js-based MySQL database integration that provides secure MySQL database operations\n- [ferrants/memvid-mcp-server](https://github.com/ferrants/memvid-mcp-server) üêç üè† - Python Streamable HTTP Server you can run locally to interact with [memvid](https://github.com/Olow304/memvid) storage and semantic search.\n- [fireproof-storage/mcp-database-server](https://github.com/fireproof-storage/mcp-database-server) üìá ‚òÅÔ∏è - Fireproof ledger database with multi-user sync\n- [freema/mcp-gsheets](https://github.com/freema/mcp-gsheets) üìá ‚òÅÔ∏è - MCP server for Google Sheets API integration with comprehensive reading, writing, formatting, and sheet management capabilities.\n- [FreePeak/db-mcp-server](https://github.com/FreePeak/db-mcp-server) üèéÔ∏è üè† ‚Äì A high-performance multi-database MCP server built with Golang, supporting MySQL & PostgreSQL (NoSQL coming soon). Includes built-in tools for query execution, transaction management, schema exploration, query building, and performance analysis, with seamless Cursor integration for enhanced database workflows.\n- [furey/mongodb-lens](https://github.com/furey/mongodb-lens) üìá üè† - MongoDB Lens: Full Featured MCP Server for MongoDB Databases\n- [gannonh/firebase-mcp](https://github.com/gannonh/firebase-mcp) üî• ‚õÖÔ∏è - Firebase services including Auth, Firestore and Storage.\n- [get-convex/convex-backend](https://stack.convex.dev/convex-mcp-server) üìá ‚òÅÔ∏è - Convex database integration to introspect tables, functions, and run oneoff queries ([Source](https://github.com/get-convex/convex-backend/blob/main/npm-packages/convex/src/cli/mcp.ts))\n- [gigamori/mcp-run-sql-connectorx](https://github.com/gigamori/mcp-run-sql-connectorx) üêç ‚òÅÔ∏è üè† üçé ü™ü üêß - An MCP server that executes SQL via ConnectorX and streams the result to a CSV or Parquet file. Supports PostgreSQL, MariaDB, BigQuery, RedShift, MS SQL Server, etc.\n- [googleapis/genai-toolbox](https://github.com/googleapis/genai-toolbox) üèéÔ∏è ‚òÅÔ∏è - Open source MCP server specializing in easy, fast, and secure tools for Databases.\n- [GreptimeTeam/greptimedb-mcp-server](https://github.com/GreptimeTeam/greptimedb-mcp-server) üêç üè† - MCP Server for querying GreptimeDB.\n- [hannesrudolph/sqlite-explorer-fastmcp-mcp-server](https://github.com/hannesrudolph/sqlite-explorer-fastmcp-mcp-server) üêç üè† - An MCP server that provides safe, read-only access to SQLite databases through Model Context Protocol (MCP). This server is built with the FastMCP framework, which enables LLMs to explore and query SQLite databases with built-in safety features and query validation.\n- [henilcalagiya/google-sheets-mcp](https://github.com/henilcalagiya/google-sheets-mcp) üêç üè† - Your AI Assistant''s Gateway to Google Sheets! 25 powerful tools for seamless Google Sheets automation via MCP.\n- [hydrolix/mcp-hydrolix](https://github.com/hydrolix/mcp-hydrolix) üéñÔ∏è üêç ‚òÅÔ∏è - Hydrolix time-series datalake integration providing schema exploration and query capabilities to LLM-based workflows.\n- [idoru/influxdb-mcp-server](https://github.com/idoru/influxdb-mcp-server) üìá ‚òÅÔ∏è üè† - Run queries against InfluxDB OSS API v2.\n- [InfluxData/influxdb3_mcp_server](https://github.com/influxdata/influxdb3_mcp_server) üéñÔ∏è üìá üè† ‚òÅÔ∏è - Official MCP server for InfluxDB 3 Core/Enterprise/Cloud Dedicated\n- [isaacwasserman/mcp-snowflake-server](https://github.com/isaacwasserman/mcp-snowflake-server) üêç ‚òÅÔ∏è - Snowflake integration implementing read and (optional) write operations as well as insight tracking\n- [iunera/druid-mcp-server](https://github.com/iunera/druid-mcp-server) ‚òï ‚òÅÔ∏è üè† - Comprehensive MCP server for Apache Druid that provides extensive tools, resources, and prompts for managing and analyzing Druid clusters.\n- [yannbrrd/simple_snowflake_mcp](https://github.com/YannBrrd/simple_snowflake_mcp) üêç ‚òÅÔ∏è - Simple Snowflake MCP server that works behind a corporate proxy. Read and write (optional) operations\n- [joshuarileydev/supabase-mcp-server](https://github.com/joshuarileydev/supabase) - Supabase MCP Server for managing and creating projects and organisations in Supabase\n- [jovezhong/mcp-timeplus](https://github.com/jovezhong/mcp-timeplus) üêç ‚òÅÔ∏è - MCP server for Apache Kafka and Timeplus. Able to list Kafka topics, poll Kafka messages, save Kafka data locally and query streaming data with SQL via Timeplus\n- [jparkerweb/mcp-sqlite](https://github.com/jparkerweb/mcp-sqlite) üìá üè† - Model Context Protocol (MCP) server that provides comprehensive SQLite database interaction capabilities.\n- [KashiwaByte/vikingdb-mcp-server](https://github.com/KashiwaByte/vikingdb-mcp-server) üêç ‚òÅÔ∏è - VikingDB integration with collection and index introduction, vector store and search capabilities.\n- [kiliczsh/mcp-mongo-server](https://github.com/kiliczsh/mcp-mongo-server) üìá üè† - A Model Context Protocol Server for MongoDB\n- [ktanaka101/mcp-server-duckdb](https://github.com/ktanaka101/mcp-server-duckdb) üêç üè† - DuckDB database integration with schema inspection and query capabilities\n- [LucasHild/mcp-server-bigquery](https://github.com/LucasHild/mcp-server-bigquery) üêç ‚òÅÔ∏è - BigQuery database integration with schema inspection and query capabilities\n- [memgraph/mcp-memgraph](https://github.com/memgraph/ai-toolkit/tree/main/integrations/mcp-memgraph) üêç üè† - Memgraph MCP Server - includes a tool to run a query against Memgraph and a schema resource.\n- [montumodi/mongodb-atlas-mcp-server](https://github.com/montumodi/mongodb-atlas-mcp-server) üìá ‚òÅÔ∏è ü™ü üçé üêß - A Model Context Protocol (MCP) that provides access to the MongoDB Atlas API. This server wraps the `mongodb-atlas-api-client` package to expose MongoDB Atlas functionality through MCP tools.\n- [modelcontextprotocol/server-postgres](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/postgres) üìá üè† - PostgreSQL database integration with schema inspection and query capabilities\n- [modelcontextprotocol/server-sqlite](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/sqlite) üêç üè† - SQLite database operations with built-in analysis features\n- [neo4j-contrib/mcp-neo4j](https://github.com/neo4j-contrib/mcp-neo4j) üêç üè† - Model Context Protocol with Neo4j (Run queries, Knowledge Graph Memory, Manaage Neo4j Aura Instances)\n- [neondatabase/mcp-server-neon](https://github.com/neondatabase/mcp-server-neon) üìá ‚òÅÔ∏è ‚Äî An MCP Server for creating and managing Postgres databases using Neon Serverless Postgres\n- [niledatabase/nile-mcp-server](https://github.com/niledatabase/nile-mcp-server) MCP server for Nile''s Postgres platform - Manage and query Postgres databases, tenants, users, auth using LLMs\n- [openlink/mcp-server-jdbc](https://github.com/OpenLinkSoftware/mcp-jdbc-server) üêç üè† - An MCP server for generic Database Management System (DBMS) Connectivity via the Java Database Connectivity (JDBC) protocol\n- [openlink/mcp-server-odbc](https://github.com/OpenLinkSoftware/mcp-odbc-server) üêç üè† - An MCP server for generic Database Management System (DBMS) Connectivity via the Open Database Connectivity (ODBC) protocol\n- [openlink/mcp-server-sqlalchemy](https://github.com/OpenLinkSoftware/mcp-sqlalchemy-server) üêç üè† - An MCP server for generic Database Management System (DBMS) Connectivity via SQLAlchemy using Python ODBC (pyodbc)\n- [pab1it0/adx-mcp-server](https://github.com/pab1it0/adx-mcp-server) üêç ‚òÅÔ∏è - Query and analyze Azure Data Explorer databases\n- [pab1it0/prometheus-mcp-server](https://github.com/pab1it0/prometheus-mcp-server) üêç ‚òÅÔ∏è -  Query and analyze Prometheus, open-source monitoring system.\n- [prisma/mcp](https://github.com/prisma/mcp) üìá ‚òÅÔ∏è üè† - Gives LLMs the ability to manage Prisma Postgres databases (e.g. spin up new databases and run migrations or queries).\n- [qdrant/mcp-server-qdrant](https://github.com/qdrant/mcp-server-qdrant) üêç üè† - A Qdrant MCP server\n- [QuantGeekDev/mongo-mcp](https://github.com/QuantGeekDev/mongo-mcp) üìá üè† - MongoDB integration that enables LLMs to interact directly with databases.\n- [quarkiverse/mcp-server-jdbc](https://github.com/quarkiverse/quarkus-mcp-servers/tree/main/jdbc) ‚òï üè† - Connect to any JDBC-compatible database and query, insert, update, delete, and more.\n- [rashidazarang/airtable-mcp](https://github.com/rashidazarang/airtable-mcp) üêç ‚òÅÔ∏è - Connect AI tools directly to Airtable. Query, create, update, and delete records using natural language. Features include base management, table operations, schema manipulation, record filtering, and data migration through a standardized MCP interface.\n- [redis/mcp-redis](https://github.com/redis/mcp-redis) üêç üè† - The Redis official MCP Server offers an interface to manage and search data in Redis.\n\n- [runekaagaard/mcp-alchemy](https://github.com/runekaagaard/mcp-alchemy) üêç üè† - Universal SQLAlchemy-based database integration supporting PostgreSQL, MySQL, MariaDB, SQLite, Oracle, MS SQL Server and many more databases. Features schema and relationship inspection, and large dataset analysis capabilities.\n- [wenerme/wener-mssql-mcp](https://github.com/wenerme/wode/tree/develop/packages/wener-mssql-mcp) üìá üè† - MSSQL database integration with schema inspection and query capabilities\n- [s2-streamstore/s2-sdk-typescript](https://github.com/s2-streamstore/s2-sdk-typescript) üéñÔ∏è üìá ‚òÅÔ∏è - Official MCP server for the S2.dev serverless stream platform.\n- [schemacrawler/SchemaCrawler-MCP-Server-Usage](https://github.com/schemacrawler/SchemaCrawler-MCP-Server-Usage) üéñÔ∏è ‚òï ‚Äì Connect to any relational database, and be able to get valid SQL, and ask questions like what does a certain column prefix mean.\n- [sirmews/mcp-pinecone](https://github.com/sirmews/mcp-pinecone) üêç ‚òÅÔ∏è - Pinecone integration with vector search capabilities\n- [skysqlinc/skysql-mcp](https://github.com/skysqlinc/skysql-mcp) üéñÔ∏è ‚òÅÔ∏è - Serverless MariaDB Cloud DB MCP server. Tools to launch, delete, execute SQL and work with DB level AI agents for accurate text-2-sql and conversations.\n- [Snowflake-Labs/mcp](https://github.com/Snowflake-Labs/mcp) üêç ‚òÅÔ∏è - Open-source MCP server for Snowflake from official Snowflake-Labs supports prompting Cortex Agents, querying structured & unstructured data, object management, SQL execution, semantic view querying, and more. RBAC, fine-grained CRUD controls, and all authentication methods supported.\n- [subnetmarco/pgmcp](https://github.com/subnetmarco/pgmcp) üèéÔ∏è üè† - Natural language PostgreSQL queries with automatic streaming, read-only safety, and universal database compatibility.\n- [pgtuner_mcp](https://github.com/isdaniel/pgtuner_mcp) üêçüóÑÔ∏è - provides AI-powered PostgreSQL performance tuning capabilities.\n- [supabase-community/supabase-mcp](https://github.com/supabase-community/supabase-mcp) üéñÔ∏è üìá ‚òÅÔ∏è - Official Supabase MCP server to connect AI assistants directly with your Supabase project and allows them to perform tasks like managing tables, fetching config, and querying data.\n- [TheRaLabs/legion-mcp](https://github.com/TheRaLabs/legion-mcp) üêç üè† Universal database MCP server supporting multiple database types including PostgreSQL, Redshift, CockroachDB, MySQL, RDS MySQL, Microsoft SQL Server, BigQuery, Oracle DB, and SQLite.\n- [tradercjz/dolphindb-mcp-server](https://github.com/tradercjz/dolphindb-mcp-server) üêç ‚òÅÔ∏è - TDolphinDB database integration with schema inspection and query capabilities\n- [tuannvm/mcp-trino](https://github.com/tuannvm/mcp-trino) üèéÔ∏è ‚òÅÔ∏è - A Go implementation of a Model Context Protocol (MCP) server for Trino\n- [VictoriaMetrics-Community/mcp-victorialogs](https://github.com/VictoriaMetrics-Community/mcp-victorialogs) üéñÔ∏è üèéÔ∏è üè† - Provides comprehensive integration with your [VictoriaLogs instance APIs](https://docs.victoriametrics.com/victorialogs/querying/#http-api) and [documentation](https://docs.victoriametrics.com/victorialogs/) for working with logs, investigating and debugging tasks related to your VictoriaLogs instances.\n- [weaviate/mcp-server-weaviate](https://github.com/weaviate/mcp-server-weaviate) üêç üìá ‚òÅÔ∏è - An MCP Server to connect to your Weaviate collections as a knowledge base as well as using Weaviate as a chat memory store.\n- [wenb1n-dev/mysql_mcp_server_pro](https://github.com/wenb1n-dev/mysql_mcp_server_pro)  üêç üè† - Supports SSE, STDIO; not only limited to MySQL''s CRUD functionality; also includes database exception analysis capabilities; controls database permissions based on roles; and makes it easy for developers to extend tools with customization\n- [wenb1n-dev/SmartDB_MCP](https://github.com/wenb1n-dev/SmartDB_MCP)  üêç üè† - A universal database MCP server supporting simultaneous connections to multiple databases. It provides tools for database operations, health analysis, SQL optimization, and more. Compatible with mainstream databases including MySQL, PostgreSQL, SQL Server, MariaDB, Dameng, and Oracle. Supports Streamable HTTP, SSE, and STDIO; integrates OAuth 2.0; and is designed for easy customization and extension by developers.\n- [xexr/mcp-libsql](https://github.com/Xexr/mcp-libsql) üìá üè† ‚òÅÔ∏è - Production-ready MCP server for libSQL databases with comprehensive security and management tools.\n- [XGenerationLab/xiyan_mcp_server](https://github.com/XGenerationLab/xiyan_mcp_server) üìá ‚òÅÔ∏è ‚Äî An MCP server that supports fetching data from a database using natural language queries, powered by XiyanSQL as the text-to-SQL LLM.\n- [xing5/mcp-google-sheets](https://github.com/xing5/mcp-google-sheets) üêç ‚òÅÔ∏è - A Model Context Protocol server for interacting with Google Sheets. This server provides tools to create, read, update, and manage spreadsheets through the Google Sheets API.\n- [ydb/ydb-mcp](https://github.com/ydb-platform/ydb-mcp) üéñÔ∏è üêç ‚òÅÔ∏è - MCP server for interacting with [YDB](https://ydb.tech) databases\n- [yincongcyincong/VictoriaMetrics-mcp-server](https://github.com/yincongcyincong/VictoriaMetrics-mcp-server) üêç üè† - An MCP server for interacting with VictoriaMetrics database.\n- [Zhwt/go-mcp-mysql](https://github.com/Zhwt/go-mcp-mysql) üèéÔ∏è üè† ‚Äì Easy to use, zero dependency MySQL MCP server built with Golang with configurable readonly mode and schema inspection.\n- [zilliztech/mcp-server-milvus](https://github.com/zilliztech/mcp-server-milvus) üêç üè† ‚òÅÔ∏è - MCP Server for Milvus / Zilliz, making it possible to interact with your database.\n\n### üìä <a name="data-platforms"></a>Data Platforms\n\nData Platforms for data integration, transformation and pipeline orchestration.\n\n- [aywengo/kafka-schema-reg-mcp](https://github.com/aywengo/kafka-schema-reg-mcp) üêç ‚òÅÔ∏è üè† üçé ü™ü üêß - Comprehensive Kafka Schema Registry MCP server with 48 tools for multi-registry management, schema migration, and enterprise features.\n- [dbt-labs/dbt-mcp](https://github.com/dbt-labs/dbt-mcp) üéñÔ∏è üêç üè† ‚òÅÔ∏è - Official MCP server for [dbt (data build tool)](https://www.getdbt.com/product/what-is-dbt) providing integration with dbt Core/Cloud CLI, project metadata discovery, model information, and semantic layer querying capabilities.\n- [flowcore/mcp-flowcore-platform](https://github.com/flowcore-io/mcp-flowcore-platform) üéñÔ∏è üìá ‚òÅÔ∏è üè† - Interact with Flowcore to perform actions, ingest data, and analyse, cross reference and utilise any data in your data cores, or in public data cores; all with human language.\n- [JordiNei/mcp-databricks-server](https://github.com/JordiNeil/mcp-databricks-server) üêç ‚òÅÔ∏è - Connect to Databricks API, allowing LLMs to run SQL queries, list jobs, and get job status.\n- [jwaxman19/qlik-mcp](https://github.com/jwaxman19/qlik-mcp) üìá ‚òÅÔ∏è - MCP Server for Qlik Cloud API that enables querying applications, sheets, and extracting data from visualizations with comprehensive authentication and rate limiting support.\n- [keboola/keboola-mcp-server](https://github.com/keboola/keboola-mcp-server) üêç - interact with Keboola Connection Data Platform. This server provides tools for listing and accessing data from Keboola Storage API.\n- [mattijsdp/dbt-docs-mcp](https://github.com/mattijsdp/dbt-docs-mcp) üêç üè† - MCP server for dbt-core (OSS) users as the official dbt MCP only supports dbt Cloud. Supports project metadata, model and column-level lineage and dbt documentation.\n- [yashshingvi/databricks-genie-MCP](https://github.com/yashshingvi/databricks-genie-MCP) üêç ‚òÅÔ∏è - A server that connects to the Databricks Genie API, allowing LLMs to ask natural language questions, run SQL queries, and interact with Databricks conversational agents.\n- [alkemiai/alkemi-mcp](https://github.com/alkemi-ai/alkemi-mcp) üìá ‚òÅÔ∏è - MCP Server for natural language querying of Snowflake, Google BigQuery, and DataBricks Data Products through Alkemi.ai.\n- [avisangle/method-crm-mcp](https://github.com/avisangle/method-crm-mcp) üêç ‚òÅÔ∏è üè† üçé ü™ü üêß - Production-ready MCP server for Method CRM API integration with 20 comprehensive tools for tables, files, users, events, and API key management. Features rate limiting, retry logic, and dual transport support (stdio/HTTP).\n- [paracetamol951/caisse-enregistreuse-mcp-server](https://github.com/paracetamol951/caisse-enregistreuse-mcp-server) üè† üêß üçé ‚òÅÔ∏è - Allows you to automate or monitor business operations, sales recorder, POS software, CRM.\n\n\n### üíª <a name="developer-tools"></a>Developer Tools\n\nTools and integrations that enhance the development workflow and environment management.\n\n- [21st-dev/Magic-MCP](https://github.com/21st-dev/magic-mcp) - Create crafted UI components inspired by the best 21st.dev design engineers.\n- [louis030195/gptzero-mcp](https://github.com/louis030195/gptzero-mcp) üìá ‚òÅÔ∏è üçé ü™ü üêß - AI detection for text content with GPTZero API. Detect AI-generated text, get confidence scores, multilingual support (French/Spanish), and detailed probability breakdowns.\n- [aashari/mcp-server-atlassian-bitbucket](https://github.com/aashari/mcp-server-atlassian-bitbucket) üìá ‚òÅÔ∏è - Atlassian Bitbucket Cloud integration. Enables AI systems to interact with repositories, pull requests, workspaces, and code in real time.\n- [aashari/mcp-server-atlassian-confluence](https://github.com/aashari/mcp-server-atlassian-confluence) üìá ‚òÅÔ∏è - Atlassian Confluence Cloud integration. Enables AI systems to interact with Confluence spaces, pages, and content with automatic ADF to Markdown conversion.\n- [aashari/mcp-server-atlassian-jira](https://github.com/aashari/mcp-server-atlassian-jira) üìá ‚òÅÔ∏è - Atlassian Jira Cloud integration. Enables AI systems to interact with Jira projects, issues, comments, and related development information in real time.\n- [abrinsmead/mindpilot-mcp](https://github.com/abrinsmead/mindpilot-mcp) üìá üè† - Visualizes code, architecture and other concepts as mermaid diagrams in a locally hosted web app. Just ask your agent to "show me this in a diagram".\n- [admica/FileScopeMCP](https://github.com/admica/FileScopeMCP) üêç üìá ü¶Ä - Analyzes your codebase identifying important files based on dependency relationships. Generates diagrams and importance scores, helping AI assistants understand the codebase.\n- [agent-hanju/char-index-mcp](https://github.com/agent-hanju/char-index-mcp) üêç üè† ‚òÅÔ∏è üçé ü™ü üêß - Precise character-level string indexing for LLMs. Provides tools for finding, extracting, and manipulating text by exact character position to solve position-based operations.\n- [akramIOT/MCP_AI_SOC_Sher](https://github.com/akramIOT/MCP_AI_SOC_Sher)  üêç ‚òÅÔ∏è üìá - MCP Server to do dynamic AI SOC Security Threat analysis for a  Text2SQL  AI Agent.\n- [alimo7amed93/webhook-tester-mcp](https://github.com/alimo7amed93/webhook-tester-mcp)  üêç ‚òÅÔ∏è ‚Äì A FastMCP-based server for interacting with webhook-test.com. Enables users to create, retrieve, and delete webhooks locally using Claude.\n- [ambar/simctl-mcp](https://github.com/ambar/simctl-mcp) üìá üè† üçé A MCP server implementation for iOS Simulator control.\n- [api7/apisix-mcp](https://github.com/api7/apisix-mcp) üéñÔ∏è üìá üè† MCP Server that support for querying and managing all resource in [Apache APISIX](https://github.com/apache/apisix).\n- [ArchAI-Labs/fastmcp-sonarqube-metrics](https://github.com/ArchAI-Labs/fastmcp-sonarqube-metrics) üêç üè† ü™ü üêß üçé -  A Model Context Protocol (MCP) server that provides a set of tools for retrieving information about SonarQube projects like metrics (actual and historical), issues, health status.\n- [artmann/package-registry-mcp](https://github.com/artmann/package-registry-mcp) üè† üìá üçé ü™ü üêß - MCP server for searching and getting up-to-date information about NPM, Cargo, PyPi, and NuGet packages.\n- [wyattjoh/jsr-mcp](https://github.com/wyattjoh/jsr-mcp) üìá ‚òÅÔ∏è - Model Context Protocol server for the JSR (JavaScript Registry)\n- [augmnt/augments-mcp-server](https://github.com/augmnt/augments-mcp-server) üìá ‚òÅÔ∏è üè† - Transform Claude Code with intelligent, real-time access to 90+ framework documentation sources. Get accurate, up-to-date code generation that follows current best practices for React, Next.js, Laravel, FastAPI, Tailwind CSS, and more.\n- [automation-ai-labs/mcp-link](https://github.com/automation-ai-labs/mcp-link) üèéÔ∏è üè† - Seamlessly Integrate Any API with AI Agents (with OpenAPI Schema)\n- [avisangle/jenkins-mcp-server](https://github.com/avisangle/jenkins-mcp-server) üêç üè† üçé ü™ü üêß - Enterprise-grade Jenkins CI/CD integration with multi-tier caching, pipeline monitoring, artifact management, and batch operations. Features 21 MCP tools for job management, build status tracking, and queue management with CSRF protection and 2FA support.\n- [axliupore/mcp-code-runner](https://github.com/axliupore/mcp-code-runner) üìá üè† - An MCP server for running code locally via Docker and supporting multiple programming languages.\n- [azer/react-analyzer-mcp](https://github.com/azer/react-analyzer-mcp) üìá üè† - Analyze React code locally, generate docs / llm.txt for whole project at once\n- [bitrise-io/bitrise-mcp](https://github.com/bitrise-io/bitrise-mcp) üéñÔ∏è üêç ‚òÅÔ∏è üçé ü™ü üêß - MCP Server for the [Bitrise](https://bitrise.io) API, enabling app management, build operations, artifact management and more.\n- [buildkite/buildkite-mcp-server](https://github.com/buildkite/buildkite-mcp-server) üéñÔ∏è üèéÔ∏è üè† ‚òÅÔ∏è üçé ü™ü üêß - Official MCP server for Buildkite. Create new pipelines, diagnose and fix failures, trigger builds, monitor job queues, and more.\n- [Chunkydotdev/bldbl-mcp](https://github.com/chunkydotdev/bldbl-mcp) üìá ‚òÅÔ∏è üçé ü™ü üêß - Official MCP server for Buildable AI-powered development platform [bldbl.dev](https://bldbl.dev). Enables AI assistants to manage tasks, track progress, get project context, and collaborate with humans on software projects.\n- [CircleCI/mcp-server-circleci](https://github.com/CircleCI-Public/mcp-server-circleci) üìá ‚òÅÔ∏è Enable AI Agents to fix build failures from CircleCI.\n- [Wolfe-Jam/claude-faf-mcp](https://github.com/Wolfe-Jam/claude-faf-mcp) üìá üè† - First & only persistent project context MCP. Provides .faf (Foundational AI-context Format) Project DNA with 33+ tools, Podium scoring (0-100%), and format-driven architecture. Official Anthropic Registry. 10k+ npm downloads.\n- [cjo4m06/mcp-shrimp-task-manager](https://github.com/cjo4m06/mcp-shrimp-task-manager) üìá ‚òÅÔ∏è üè† ‚Äì A programming-focused task management system that boosts coding agents like Cursor AI with advanced task memory, self-reflection, and dependency management. [ShrimpTaskManager](https://cjo4m06.github.io/mcp-shrimp-task-manager)\n- [ckanthony/gin-mcp](https://github.com/ckanthony/gin-mcp) üèéÔ∏è ‚òÅÔ∏è üìü ü™ü üêß üçé - A zero-configuration Go library to automatically expose existing Gin web framework APIs as MCP tools.\n- [BrunoKrugel/echo-mcp](https://github.com/BrunoKrugel/echo-mcp) üèéÔ∏è ‚òÅÔ∏è üìü ü™ü üêß üçé - A zero-configuration Go library to automatically expose any existing Echo web framework APIs as MCP tools.\n- [ckreiling/mcp-server-docker](https://github.com/ckreiling/mcp-server-docker) üêç üè† - Integrate with Docker to manage containers, images, volumes, and networks.\n- [CodeLogicIncEngineering/codelogic-mcp-server](https://github.com/CodeLogicIncEngineering/codelogic-mcp-server) üéñÔ∏è üêç ‚òÅÔ∏è üçé ü™ü üêß - Official MCP server for CodeLogic, providing access to code dependency analytics, architectural risk analysis, and impact assessment tools.\n- [Comet-ML/Opik-MCP](https://github.com/comet-ml/opik-mcp) üéñÔ∏è üìá ‚òÅÔ∏è üè† - Use natural language to explore LLM observability, traces, and monitoring data captured by Opik.\n- [ConfigCat/mcp-server](https://github.com/configcat/mcp-server) üéñÔ∏è üìá ‚òÅÔ∏è - MCP server for interacting with ConfigCat feature flag platform. Supports managing feature flags, configs, environments, products and organizations.\n- [cqfn/aibolit-mcp-server](https://github.com/cqfn/aibolit-mcp-server) ‚òï - Helping Your AI Agent Identify Hotspots for Refactoring; Help AI Understand How to ''Make Code Better''\n- [currents-dev/currents-mcp](https://github.com/currents-dev/currents-mcp) üéñÔ∏è üìá ‚òÅÔ∏è Enable AI Agents to fix Playwright test failures reported to [Currents](https://currents.dev).\n- [davidan90/time-node-mcp](https://github.com/davidan90/time-node-mcp) üìá üè† - Timezone-aware date and time operations with support for IANA timezones, timezone conversion, and Daylight Saving Time handling.\n- [davidlin2k/pox-mcp-server](https://github.com/davidlin2k/pox-mcp-server) üêç üè† - MCP server for the POX SDN controller to provides network control and management capabilities.\n- [delano/postman-mcp-server](https://github.com/delano/postman-mcp-server) üìá ‚òÅÔ∏è - Interact with [Postman API](https://www.postman.com/postman/postman-public-workspace/)\n- [deploy-mcp/deploy-mcp](https://github.com/alexpota/deploy-mcp) üìá ‚òÅÔ∏è üè† - Universal deployment tracker for AI assistants with live status badges and deployment monitoring\n- [docker/hub-mcp](https://github.com/docker/hub-mcp) üéñÔ∏è üìá ‚òÅÔ∏è üè† - Official MCP server to interact with Docker Hub, providing access to repositories, hub search and Docker Hardened Images\n- [V0v1kkk/DotNetMetadataMcpServer](https://github.com/V0v1kkk/DotNetMetadataMcpServer) #Ô∏è‚É£ üè† üçé ü™ü üêß - Provides AI agents with detailed type information from .NET projects including assembly exploration, namespace discovery, type reflection, and NuGet integration\n- [endorhq/cli](https://github.com/endorhq/cli) üìá ‚òÅÔ∏è üè† ü™ü üêß üçé - Endor lets your AI agents run services like MariaDB, Postgres, Redis, Memcached, Alpine, or Valkey in isolated sandboxes. Get pre-configured applications that boot in less than 5 seconds.\n- [eyaltoledano/claude-task-master](https://github.com/eyaltoledano/claude-task-master) üìá ‚òÅÔ∏è üè† - AI-powered task management system for AI-driven development. Features PRD parsing, task expansion, multi-provider support (Claude, OpenAI, Gemini, Perplexity, xAI), and selective tool loading for optimized context usage.\n- [etsd-tech/mcp-pointer](https://github.com/etsd-tech/mcp-pointer) üìá üè† üçé ü™ü üêß - Visual DOM element selector for agentic coding tools. Chrome extension + MCP server bridge for Claude Code, Cursor, Windsurf etc. Option+Click to capture elements.\n- [flipt-io/mcp-server-flipt](https://github.com/flipt-io/mcp-server-flipt) üìá üè† - Enable AI assistants to interact with your feature flags in [Flipt](https://flipt.io).\n- [freema/mcp-design-system-extractor](https://github.com/freema/mcp-design-system-extractor) üìá üè† - Extracts component information from Storybook design systems. Provides HTML, styles, props, dependencies, theme tokens and component metadata for AI-powered design system analysis.\n- [gitkraken/gk-cli](https://github.com/gitkraken/gk-cli) üéñÔ∏è üèéÔ∏è üè† ‚òÅÔ∏è üçé ü™ü üêß - A CLI for interacting with GitKraken APIs. Includes an MCP server via `gk mcp` that not only wraps GitKraken APIs, but also Jira, GitHub, GitLab, and more. Works with local tools and remote services.\n- [GLips/Figma-Context-MCP](https://github.com/GLips/Figma-Context-MCP) üìá üè† - Provide coding agents direct access to Figma data to help them one-shot design implementation.\n- [mhmzdev/Figma-Flutter-MCP](https://github.com/mhmzdev/Figma-Flutter-MCP) üìá üè† - Provide coding agents direct access to Figma data to help them write Flutter code for building apps including assets exports, widgets maintenance and full screens implementations.\n- [gofireflyio/firefly-mcp](https://github.com/gofireflyio/firefly-mcp) üéñÔ∏è üìá ‚òÅÔ∏è - Integrates, discovers, manages, and codifies cloud resources with [Firefly](https://firefly.ai).\n- [gorosun/unified-diff-mcp](https://github.com/gorosun/unified-diff-mcp) üìá üè† - Generate and visualize unified diff comparisons with beautiful HTML/PNG output, supporting side-by-side and line-by-line views for filesystem dry-run integration\n- [Govcraft/rust-docs-mcp-server](https://github.com/Govcraft/rust-docs-mcp-server) ü¶Ä üè† - Provides up-to-date documentation context for a specific Rust crate to LLMs via an MCP tool, using semantic search (embeddings) and LLM summarization.\n- [PromptExecution/cratedocs-mcp](https://github.com/promptexecution/cratedocs-mcp) ü¶Ä üè† - Outputs short-form Rust crate derived traits,interfaces, etc. from AST (uses same api as rust-analyzer), output limits (token estimation) & crate docs w/regex stripping.\n- [HainanZhao/mcp-gitlab-jira](https://github.com/HainanZhao/mcp-gitlab-jira) üìá ‚òÅÔ∏è üè† - Unified MCP server for GitLab and Jira: manage projects, merge requests, files, releases and tickets with AI agents.\n- [haris-musa/excel-mcp-server](https://github.com/haris-musa/excel-mcp-server) üêç üè† - An Excel manipulation server providing workbook creation, data operations, formatting, and advanced features (charts, pivot tables, formulae).\n- [sbroenne/mcp-server-excel](https://github.com/sbroenne/mcp-server-excel) #Ô∏è‚É£ üè† ü™ü - Full-featured Excel MCP server. 173 operations: Power Query, DAX, VBA, PivotTables, Tables, Charts, ranges, formatting. 100% Excel compatibility - uses Excel app instead of creating .xlsx files. Windows only.\n- [hechtcarmel/jetbrains-debugger-mcp-plugin](https://github.com/hechtcarmel/jetbrains-debugger-mcp-plugin) ‚òï üè† - A JetBrains IDE plugin that exposes an MCP server, giving AI coding assistants full programmatic control over the debugger.\n- [hechtcarmel/jetbrains-index-mcp-plugin](https://github.com/hechtcarmel/jetbrains-index-mcp-plugin) ‚òï üè† - A JetBrains IDE plugin that exposes an MCP server, enabling AI coding assistants to leverage the IDE''s indexing and refactoring capabilities (rename, safe delete, find references, call hierarchy, type hierarchy, diagnostics and more).\n- [higress-group/higress-ops-mcp-server](https://github.com/higress-group/higress-ops-mcp-server) üêç üè† - MCP server that provides comprehensive tools for managing [Higress](https://github.com/alibaba/higress) gateway configurations and operations.\n- [hijaz/postmancer](https://github.com/hijaz/postmancer) üìá üè† - A MCP server for replacing Rest Clients like Postman/Insomnia, by allowing your LLM to maintain and use api collections.\n- [hloiseaufcms/mcp-gopls](https://github.com/hloiseaufcms/mcp-gopls) üèéÔ∏è üè† - A MCP server for interacting with [Go''s Language Server Protocol (gopls)](https://github.com/golang/tools/tree/master/gopls) and benefit from advanced Go code analysis features.\n- [hungthai1401/bruno-mcp](https://github.com/hungthai1401/bruno-mcp) üìá üè† - A MCP server for interacting with [Bruno API Client](https://www.usebruno.com/).\n- [hyperb1iss/droidmind](https://github.com/hyperb1iss/droidmind) üêç üè† - Control Android devices with AI through MCP, enabling device control, debugging, system analysis, and UI automation with a comprehensive security framework.\n- [Hypersequent/qasphere-mcp](https://github.com/Hypersequent/qasphere-mcp) üéñÔ∏è üìá ‚òÅÔ∏è - Integration with [QA Sphere](https://qasphere.com/) test management system, enabling LLMs to discover, summarize, and interact with test cases directly from AI-powered IDEs\n- [idosal/git-mcp](https://github.com/idosal/git-mcp) üìá ‚òÅÔ∏è - [gitmcp.io](https://gitmcp.io/) is a generic remote MCP server to connect to ANY [GitHub](https://www.github.com) repository or project for documentation\n- [IlyaGulya/gradle-mcp-server](https://github.com/IlyaGulya/gradle-mcp-server) üè† - Gradle integration using the Gradle Tooling API to inspect projects, execute tasks, and run tests with per-test result reporting\n- [promptexecution/just-mcp](https://github.com/promptexecution/just-mcp) ü¶Ä üè† - Justfile integration that enables LLMs to execute any CLI or script commands with parameters safely and easily, with environment variable support and comprehensive testing.\n- [InditexTech/mcp-server-simulator-ios-idb](https://github.com/InditexTech/mcp-server-simulator-ios-idb) üìá üè† üçé - A Model Context Protocol (MCP) server that enables LLMs to interact with iOS simulators (iPhone, iPad, etc.) through natural language commands.\n- [InhiblabCore/mcp-image-compression](https://github.com/InhiblabCore/mcp-image-compression) üêç üè† - MCP server for local compression of various image formats.\n- [InsForge/insforge-mcp](https://github.com/InsForge/insforge-mcp) üìá ‚òÅÔ∏è - AI-native backend-as-a-service platform enabling AI agents to build and manage full-stack applications. Provides Auth, Database (PostgreSQL), Storage, and Functions as production-grade infrastructure, reducing MVP development time from weeks to hours.\n- [Inspizzz/jetbrains-datalore-mcp](https://github.com/inspizzz/jetbrains-datalore-mcp) üêç ‚òÅÔ∏è - MCP server for interacting with cloud deployments of Jetbrains Datalore platform. Fully incorporated Datalore API ( run, run interactively, get run data, fetch files )\n- [ios-simulator-mcp](https://github.com/joshuayoes/ios-simulator-mcp) üìá üè† üçé - A Model Context Protocol (MCP) server for interacting with iOS simulators. This server allows you to interact with iOS simulators by getting information about them, controlling UI interactions, and inspecting UI elements.\n- [isaacphi/mcp-language-server](https://github.com/isaacphi/mcp-language-server) üèéÔ∏è üè† - MCP Language Server helps MCP enabled clients navigate codebases more easily by giving them access to semantic tools like get definition, references, rename, and diagnostics.\n- [IvanAmador/vercel-ai-docs-mcp](https://github.com/IvanAmador/vercel-ai-docs-mcp) üìá üè† - A Model Context Protocol (MCP) server that provides AI-powered search and querying capabilities for the Vercel AI SDK documentation.\n- [j4c0bs/mcp-server-sql-analyzer](https://github.com/j4c0bs/mcp-server-sql-analyzer) üêç - MCP server that provides SQL analysis, linting, and dialect conversion using [SQLGlot](https://github.com/tobymao/sqlglot)\n- [janreges/ai-distiller-mcp](https://github.com/janreges/ai-distiller) üèéÔ∏è üè† - Extracts essential code structure from large codebases into AI-digestible format, helping AI agents write code that correctly uses existing APIs on the first attempt.\n- [jasonjmcghee/claude-debugs-for-you](https://github.com/jasonjmcghee/claude-debugs-for-you) üìá üè† - An MCP Server and VS Code Extension which enables (language agnostic) automatic debugging via breakpoints and expression evaluation.\n- [jetbrains/mcpProxy](https://github.com/JetBrains/mcpProxy) üéñÔ∏è üìá üè† - Connect to JetBrains IDE\n- [Jktfe/serveMyAPI](https://github.com/Jktfe/serveMyAPI) üìá üè† üçé - A personal MCP (Model Context Protocol) server for securely storing and accessing API keys across projects using the macOS Keychain.\n- [jordandalton/restcsv-mcp-server](https://github.com/JordanDalton/RestCsvMcpServer) üìá ‚òÅÔ∏è - An MCP server for CSV files.\n- [joshuarileydev/app-store-connect-mcp-server](https://github.com/JoshuaRileyDev/app-store-connect-mcp-server) üìá üè† - An MCP server to communicate with the App Store Connect API for iOS Developers\n- [joshuarileydev/simulator-mcp-server](https://github.com/JoshuaRileyDev/simulator-mcp-server) üìá üè† - An MCP server to control iOS Simulators\n- [Jpisnice/shadcn-ui-mcp-server](https://github.com/Jpisnice/shadcn-ui-mcp-server) üìá üè† - MCP server that gives AI assistants seamless access to shadcn/ui v4 components, blocks, demos, and metadata.\n- [jsdelivr/globalping-mcp-server](https://github.com/jsdelivr/globalping-mcp-server) üéñÔ∏è üìá ‚òÅÔ∏è - The Globalping MCP server provides users and LLMs access to run network tools like ping, traceroute, mtr, HTTP and DNS resolve from thousands of locations around the world.\n- [kadykov/mcp-openapi-schema-explorer](https://github.com/kadykov/mcp-openapi-schema-explorer) üìá ‚òÅÔ∏è üè† - Token-efficient access to OpenAPI/Swagger specs via MCP Resources.\n- [lamemind/mcp-server-multiverse](https://github.com/lamemind/mcp-server-multiverse) üìá üè† üõ†Ô∏è - A middleware server that enables multiple isolated instances of the same MCP servers to coexist independently with unique namespaces and configurations.\n- [langfuse/mcp-server-langfuse](https://github.com/langfuse/mcp-server-langfuse) üêç üè† - MCP server to access and manage LLM application prompts created with [Langfuse]([https://langfuse.com/](https://langfuse.com/docs/prompts/get-started)) Prompt Management.\n- [JamesANZ/system-prompts-mcp-server](https://github.com/JamesANZ/system-prompts-mcp-server) üìá üè† üçé ü™ü üêß - Exposes a large catalog of coding assistant prompts as MCP tools with model-aware suggestions and persona activation to emulate agents like Cursor or Devin.\n- [linw1995/nvim-mcp](https://github.com/linw1995/nvim-mcp) ü¶Ä üè† üçé ü™ü üêß  -  A MCP server to interact with Neovim\n- [lpigeon/ros-mcp-server](https://github.com/lpig', '{"language":null,"stars":76279,"forks":6457,"watchers":76279,"open_issues":127,"topics":["ai","mcp"],"default_branch":"main","size_kb":5343,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:punkpeye:awesome-mcp-clients","source_url":"https://github.com/punkpeye/awesome-mcp-clients"},{"type":"has_code","target_id":"github:1mcp-app:agent","source_url":"https://github.com/1mcp-app/agent"},{"type":"has_code","target_id":"github:askbudi:roundtable","source_url":"https://github.com/askbudi/roundtable"},{"type":"has_code","target_id":"github:duaraghav8:MCPJungle","source_url":"https://github.com/duaraghav8/MCPJungle"},{"type":"has_code","target_id":"github:glenngillen:mcpmcp-server","source_url":"https://github.com/glenngillen/mcpmcp-server"},{"type":"has_code","target_id":"github:hamflx:imagen3-mcp","source_url":"https://github.com/hamflx/imagen3-mcp"},{"type":"has_code","target_id":"github:julien040:anyquery","source_url":"https://github.com/julien040/anyquery"},{"type":"has_code","target_id":"github:juspay:neurolink","source_url":"https://github.com/juspay/neurolink"},{"type":"has_code","target_id":"github:K-Dense-AI:claude-skills-mcp","source_url":"https://github.com/K-Dense-AI/claude-skills-mcp"},{"type":"has_code","target_id":"github:metatool-ai:metatool-app","source_url":"https://github.com/metatool-ai/metatool-app"},{"type":"has_code","target_id":"github:mindsdb:mindsdb","source_url":"https://github.com/mindsdb/mindsdb"},{"type":"has_code","target_id":"github:portel-dev:ncp","source_url":"https://github.com/portel-dev/ncp"},{"type":"has_code","target_id":"github:particlefuture:MCPDiscovery","source_url":"https://github.com/particlefuture/MCPDiscovery"},{"type":"has_code","target_id":"github:PipedreamHQ:pipedream","source_url":"https://github.com/PipedreamHQ/pipedream"},{"type":"has_code","target_id":"github:sitbon:magg","source_url":"https://github.com/sitbon/magg"},{"type":"has_code","target_id":"github:thinkchainai:mcpbundles","source_url":"https://github.com/thinkchainai/mcpbundles"},{"type":"has_code","target_id":"github:SureScaleAI:openai-gpt-image-mcp","source_url":"https://github.com/SureScaleAI/openai-gpt-image-mcp"},{"type":"has_code","target_id":"github:sxhxliang:mcp-access-point","source_url":"https://github.com/sxhxliang/mcp-access-point"},{"type":"has_code","target_id":"github:TheLunarCompany:lunar","source_url":"https://github.com/TheLunarCompany/lunar"},{"type":"has_code","target_id":"github:tigranbs:mcgravity","source_url":"https://github.com/tigranbs/mcgravity"},{"type":"has_code","target_id":"github:VeriTeknik:pluggedin-mcp-proxy","source_url":"https://github.com/VeriTeknik/pluggedin-mcp-proxy"},{"type":"has_code","target_id":"github:waystation-ai:mcp","source_url":"https://github.com/waystation-ai/mcp"},{"type":"has_code","target_id":"github:wegotdocs:open-mcp","source_url":"https://github.com/wegotdocs/open-mcp"},{"type":"has_code","target_id":"github:Data-Everything:mcp-server-templates","source_url":"https://github.com/Data-Everything/mcp-server-templates"},{"type":"has_code","target_id":"github:YangLiangwei:PersonalizationMCP","source_url":"https://github.com/YangLiangwei/PersonalizationMCP"},{"type":"has_code","target_id":"github:IO-Aerospace-software-engineering:mcp-server","source_url":"https://github.com/IO-Aerospace-software-engineering/mcp-server"},{"type":"has_code","target_id":"github:drakonkat:wizzy-mcp-tmdb","source_url":"https://github.com/drakonkat/wizzy-mcp-tmdb"},{"type":"has_code","target_id":"github:8enSmith:mcp-open-library","source_url":"https://github.com/8enSmith/mcp-open-library"},{"type":"has_code","target_id":"github:abhiemj:manim-mcp-server","source_url":"https://github.com/abhiemj/manim-mcp-server"},{"type":"has_code","target_id":"github:ahujasid:blender-mcp","source_url":"https://github.com/ahujasid/blender-mcp"},{"type":"has_code","target_id":"github:burningion:video-editing-mcp","source_url":"https://github.com/burningion/video-editing-mcp"},{"type":"has_code","target_id":"github:cantian-ai:bazi-mcp","source_url":"https://github.com/cantian-ai/bazi-mcp"},{"type":"has_code","target_id":"github:cswkim:discogs-mcp-server","source_url":"https://github.com/cswkim/discogs-mcp-server"},{"type":"has_code","target_id":"github:diivi:aseprite-mcp","source_url":"https://github.com/diivi/aseprite-mcp"},{"type":"has_code","target_id":"github:djalal:quran-mcp-server","source_url":"https://github.com/djalal/quran-mcp-server"},{"type":"has_code","target_id":"github:raveenb:fal-mcp-server","source_url":"https://github.com/raveenb/fal-mcp-server"},{"type":"has_code","target_id":"github:GenWaveLLC:svgmaker-mcp","source_url":"https://github.com/GenWaveLLC/svgmaker-mcp"},{"type":"has_code","target_id":"github:mikechao:metmuseum-mcp","source_url":"https://github.com/mikechao/metmuseum-mcp"},{"type":"has_code","target_id":"github:molanojustin:smithsonian-mcp","source_url":"https://github.com/molanojustin/smithsonian-mcp"},{"type":"has_code","target_id":"github:OctoEverywhere:mcp","source_url":"https://github.com/OctoEverywhere/mcp"},{"type":"has_code","target_id":"github:omni-mcp:isaac-sim-mcp","source_url":"https://github.com/omni-mcp/isaac-sim-mcp"},{"type":"has_code","target_id":"github:PatrickPalmer:MayaMCP","source_url":"https://github.com/PatrickPalmer/MayaMCP"},{"type":"has_code","target_id":"github:peek-travel:mcp-intro","source_url":"https://github.com/peek-travel/mcp-intro"},{"type":"has_code","target_id":"github:r-huijts:oorlogsbronnen-mcp","source_url":"https://github.com/r-huijts/oorlogsbronnen-mcp"},{"type":"has_code","target_id":"github:r-huijts:rijksmuseum-mcp","source_url":"https://github.com/r-huijts/rijksmuseum-mcp"},{"type":"has_code","target_id":"github:samuelgursky:davinci-resolve-mcp","source_url":"https://github.com/samuelgursky/davinci-resolve-mcp"},{"type":"has_code","target_id":"github:yuna0x0:anilist-mcp","source_url":"https://github.com/yuna0x0/anilist-mcp"},{"type":"has_code","target_id":"github:Narasimhaponnada:mermaid-mcp","source_url":"https://github.com/Narasimhaponnada/mermaid-mcp"},{"type":"has_code","target_id":"github:dnaerys:onekgp-mcp","source_url":"https://github.com/dnaerys/onekgp-mcp"},{"type":"has_code","target_id":"github:genomoncology:biomcp","source_url":"https://github.com/genomoncology/biomcp"},{"type":"has_code","target_id":"github:hlydecker:ucsc-genome-mcp","source_url":"https://github.com/hlydecker/ucsc-genome-mcp"},{"type":"has_code","target_id":"github:longevity-genie:biothings-mcp","source_url":"https://github.com/longevity-genie/biothings-mcp"},{"type":"has_code","target_id":"github:longevity-genie:gget-mcp","source_url":"https://github.com/longevity-genie/gget-mcp"},{"type":"has_code","target_id":"github:longevity-genie:opengenes-mcp","source_url":"https://github.com/longevity-genie/opengenes-mcp"},{"type":"has_code","target_id":"github:longevity-genie:synergy-age-mcp","source_url":"https://github.com/longevity-genie/synergy-age-mcp"},{"type":"has_code","target_id":"github:the-momentum:fhir-mcp-server","source_url":"https://github.com/the-momentum/fhir-mcp-server"},{"type":"has_code","target_id":"github:wso2:fhir-mcp-server","source_url":"https://github.com/wso2/fhir-mcp-server"},{"type":"has_code","target_id":"github:JamesANZ:medical-mcp","source_url":"https://github.com/JamesANZ/medical-mcp"},{"type":"has_code","target_id":"github:the-momentum:apple-health-mcp-server","source_url":"https://github.com/the-momentum/apple-health-mcp-server"},{"type":"has_code","target_id":"github:OHNLP:omop_mcp","source_url":"https://github.com/OHNLP/omop_mcp"},{"type":"has_code","target_id":"github:BB-fat:browser-use-rs","source_url":"https://github.com/BB-fat/browser-use-rs"},{"type":"has_code","target_id":"github:34892002:bilibili-mcp-js","source_url":"https://github.com/34892002/bilibili-mcp-js"},{"type":"has_code","target_id":"github:bytedance:UI-TARS-desktop","source_url":"https://github.com/bytedance/UI-TARS-desktop"},{"type":"has_code","target_id":"github:Automata-Labs-team:MCP-Server-Playwright","source_url":"https://github.com/Automata-Labs-team/MCP-Server-Playwright"},{"type":"has_code","target_id":"github:blackwhite084:playwright-plus-python-mcp","source_url":"https://github.com/blackwhite084/playwright-plus-python-mcp"},{"type":"has_code","target_id":"github:browserbase:mcp-server-browserbase","source_url":"https://github.com/browserbase/mcp-server-browserbase"},{"type":"has_code","target_id":"github:browsermcp:mcp","source_url":"https://github.com/browsermcp/mcp"},{"type":"has_code","target_id":"github:co-browser:browser-use-mcp-server","source_url":"https://github.com/co-browser/browser-use-mcp-server"},{"type":"has_code","target_id":"github:eat-pray-ai:yutu","source_url":"https://github.com/eat-pray-ai/yutu"},{"type":"has_code","target_id":"github:executeautomation:mcp-playwright","source_url":"https://github.com/executeautomation/mcp-playwright"},{"type":"has_code","target_id":"github:eyalzh:browser-control-mcp","source_url":"https://github.com/eyalzh/browser-control-mcp"},{"type":"has_code","target_id":"github:freema:firefox-devtools-mcp","source_url":"https://github.com/freema/firefox-devtools-mcp"},{"type":"has_code","target_id":"github:FradSer:mcp-server-apple-reminders","source_url":"https://github.com/FradSer/mcp-server-apple-reminders"},{"type":"has_code","target_id":"github:getrupt:ashra-mcp","source_url":"https://github.com/getrupt/ashra-mcp"},{"type":"has_code","target_id":"github:kimtaeyoon83:mcp-server-youtube-transcript","source_url":"https://github.com/kimtaeyoon83/mcp-server-youtube-transcript"},{"type":"has_code","target_id":"github:kimtth:mcp-aoai-web-browsing","source_url":"https://github.com/kimtth/mcp-aoai-web-browsing"},{"type":"has_code","target_id":"github:lightpanda-io:gomcp","source_url":"https://github.com/lightpanda-io/gomcp"},{"type":"has_code","target_id":"github:microsoft:playwright-mcp","source_url":"https://github.com/microsoft/playwright-mcp"},{"type":"has_code","target_id":"github:modelcontextprotocol:servers-archived","source_url":"https://github.com/modelcontextprotocol/servers-archived"},{"type":"has_code","target_id":"github:ndthanhdev:mcp-browser-kit","source_url":"https://github.com/ndthanhdev/mcp-browser-kit"},{"type":"has_code","target_id":"github:Operative-Sh:web-eval-agent","source_url":"https://github.com/Operative-Sh/web-eval-agent"},{"type":"has_code","target_id":"github:olostep:olostep-mcp-server","source_url":"https://github.com/olostep/olostep-mcp-server"},{"type":"has_code","target_id":"github:pskill9:web-search","source_url":"https://github.com/pskill9/web-search"},{"type":"has_code","target_id":"github:PhungXuanAnh:selenium-mcp-server","source_url":"https://github.com/PhungXuanAnh/selenium-mcp-server"},{"type":"has_code","target_id":"github:recursechat:mcp-server-apple-shortcuts","source_url":"https://github.com/recursechat/mcp-server-apple-shortcuts"},{"type":"has_code","target_id":"github:xspadex:bilibili-mcp.git","source_url":"https://github.com/xspadex/bilibili-mcp.git"},{"type":"has_code","target_id":"github:imprvhub:mcp-browser-agent","source_url":"https://github.com/imprvhub/mcp-browser-agent"},{"type":"has_code","target_id":"github:4everland:4everland-hosting-mcp","source_url":"https://github.com/4everland/4everland-hosting-mcp"},{"type":"has_code","target_id":"github:aashari:mcp-server-aws-sso","source_url":"https://github.com/aashari/mcp-server-aws-sso"},{"type":"has_code","target_id":"github:alexbakers:mcp-ipfs","source_url":"https://github.com/alexbakers/mcp-ipfs"},{"type":"has_code","target_id":"github:alexei-led:aws-mcp-server","source_url":"https://github.com/alexei-led/aws-mcp-server"},{"type":"has_code","target_id":"github:alexei-led:k8s-mcp-server","source_url":"https://github.com/alexei-led/k8s-mcp-server"},{"type":"has_code","target_id":"github:aliyun:alibaba-cloud-ops-mcp-server","source_url":"https://github.com/aliyun/alibaba-cloud-ops-mcp-server"},{"type":"has_code","target_id":"github:awslabs:mcp","source_url":"https://github.com/awslabs/mcp"},{"type":"has_code","target_id":"github:localstack:localstack-mcp-server","source_url":"https://github.com/localstack/localstack-mcp-server"},{"type":"has_code","target_id":"github:bright8192:esxi-mcp-server","source_url":"https://github.com/bright8192/esxi-mcp-server"},{"type":"has_code","target_id":"github:cloudflare:mcp-server-cloudflare","source_url":"https://github.com/cloudflare/mcp-server-cloudflare"},{"type":"has_code","target_id":"github:cyclops-ui:mcp-cyclops","source_url":"https://github.com/cyclops-ui/mcp-cyclops"},{"type":"has_code","target_id":"github:erikhoward:adls-mcp-server","source_url":"https://github.com/erikhoward/adls-mcp-server"},{"type":"has_code","target_id":"github:espressif:esp-rainmaker-mcp","source_url":"https://github.com/espressif/esp-rainmaker-mcp"},{"type":"has_code","target_id":"github:Flux159:mcp-server-kubernetes","source_url":"https://github.com/Flux159/mcp-server-kubernetes"},{"type":"has_code","target_id":"github:hardik-id:azure-resource-graph-mcp-server","source_url":"https://github.com/hardik-id/azure-resource-graph-mcp-server"},{"type":"has_code","target_id":"github:jdubois:azure-cli-mcp","source_url":"https://github.com/jdubois/azure-cli-mcp"},{"type":"has_code","target_id":"github:johnneerdael:netskope-mcp","source_url":"https://github.com/johnneerdael/netskope-mcp"},{"type":"has_code","target_id":"github:kestra-io:mcp-server-python","source_url":"https://github.com/kestra-io/mcp-server-python"},{"type":"has_code","target_id":"github:liveblocks:liveblocks-mcp-server","source_url":"https://github.com/liveblocks/liveblocks-mcp-server"},{"type":"has_code","target_id":"github:manusa:kubernetes-mcp-server","source_url":"https://github.com/manusa/kubernetes-mcp-server"},{"type":"has_code","target_id":"github:Nebula-Block-Data:nebulablock-mcp-server","source_url":"https://github.com/Nebula-Block-Data/nebulablock-mcp-server"},{"type":"has_code","target_id":"github:nwiizo:tfmcp","source_url":"https://github.com/nwiizo/tfmcp"},{"type":"has_code","target_id":"github:openstack-kr:python-openstackmcp-server","source_url":"https://github.com/openstack-kr/python-openstackmcp-server"},{"type":"has_code","target_id":"github:pibblokto:cert-manager-mcp-server","source_url":"https://github.com/pibblokto/cert-manager-mcp-server"},{"type":"has_code","target_id":"github:cert-manager:cert-manager","source_url":"https://github.com/cert-manager/cert-manager"},{"type":"has_code","target_id":"github:portainer:portainer-mcp","source_url":"https://github.com/portainer/portainer-mcp"},{"type":"has_code","target_id":"github:pulumi:mcp-server","source_url":"https://github.com/pulumi/mcp-server"},{"type":"has_code","target_id":"github:pythonanywhere:pythonanywhere-mcp-server","source_url":"https://github.com/pythonanywhere/pythonanywhere-mcp-server"},{"type":"has_code","target_id":"github:qiniu:qiniu-mcp-server","source_url":"https://github.com/qiniu/qiniu-mcp-server"},{"type":"has_code","target_id":"github:redis:mcp-redis-cloud","source_url":"https://github.com/redis/mcp-redis-cloud"},{"type":"has_code","target_id":"github:reza-gholizade:k8s-mcp-server","source_url":"https://github.com/reza-gholizade/k8s-mcp-server"},{"type":"has_code","target_id":"github:rohitg00:kubectl-mcp-server","source_url":"https://github.com/rohitg00/kubectl-mcp-server"},{"type":"has_code","target_id":"github:rrmistry:tilt-mcp","source_url":"https://github.com/rrmistry/tilt-mcp"},{"type":"has_code","target_id":"github:silenceper:mcp-k8s","source_url":"https://github.com/silenceper/mcp-k8s"},{"type":"has_code","target_id":"github:StacklokLabs:mkp","source_url":"https://github.com/StacklokLabs/mkp"},{"type":"has_code","target_id":"github:StacklokLabs:ocireg-mcp","source_url":"https://github.com/StacklokLabs/ocireg-mcp"},{"type":"has_code","target_id":"github:strowk:mcp-k8s-go","source_url":"https://github.com/strowk/mcp-k8s-go"},{"type":"has_code","target_id":"github:thunderboltsid:mcp-nutanix","source_url":"https://github.com/thunderboltsid/mcp-nutanix"},{"type":"has_code","target_id":"github:trilogy-group:aws-pricing-mcp","source_url":"https://github.com/trilogy-group/aws-pricing-mcp"},{"type":"has_code","target_id":"github:VmLia:books-mcp-server","source_url":"https://github.com/VmLia/books-mcp-server"},{"type":"has_code","target_id":"github:weibaohui:k8m","source_url":"https://github.com/weibaohui/k8m"},{"type":"has_code","target_id":"github:weibaohui:kom","source_url":"https://github.com/weibaohui/kom"},{"type":"has_code","target_id":"github:wenhuwang:mcp-k8s-eye","source_url":"https://github.com/wenhuwang/mcp-k8s-eye"},{"type":"has_code","target_id":"github:elevy99927:devops-mcp-webui","source_url":"https://github.com/elevy99927/devops-mcp-webui"},{"type":"has_code","target_id":"github:alfonsograziano:node-code-sandbox-mcp","source_url":"https://github.com/alfonsograziano/node-code-sandbox-mcp"},{"type":"has_code","target_id":"github:ckanthony:openapi-mcp","source_url":"https://github.com/ckanthony/openapi-mcp"},{"type":"has_code","target_id":"github:gwbischof:outsource-mcp","source_url":"https://github.com/gwbischof/outsource-mcp"},{"type":"has_code","target_id":"github:hileamlakB:PRIMS","source_url":"https://github.com/hileamlakB/PRIMS"},{"type":"has_code","target_id":"github:ouvreboite:openapi-to-mcp","source_url":"https://github.com/ouvreboite/openapi-to-mcp"},{"type":"has_code","target_id":"github:pydantic:pydantic-ai","source_url":"https://github.com/pydantic/pydantic-ai"},{"type":"has_code","target_id":"github:r33drichards:mcp-js","source_url":"https://github.com/r33drichards/mcp-js"},{"type":"has_code","target_id":"github:yepcode:mcp-server-js","source_url":"https://github.com/yepcode/mcp-server-js"},{"type":"has_code","target_id":"github:dagger:container-use","source_url":"https://github.com/dagger/container-use"},{"type":"has_code","target_id":"github:Shashankss1205:CodeGraphContext","source_url":"https://github.com/Shashankss1205/CodeGraphContext"},{"type":"has_code","target_id":"github:doggybee:mcp-server-leetcode","source_url":"https://github.com/doggybee/mcp-server-leetcode"},{"type":"has_code","target_id":"github:ezyang:codemcp","source_url":"https://github.com/ezyang/codemcp"},{"type":"has_code","target_id":"github:gabrielmaialva33:winx-code-agent","source_url":"https://github.com/gabrielmaialva33/winx-code-agent"},{"type":"has_code","target_id":"github:jinzcdev:leetcode-mcp-server","source_url":"https://github.com/jinzcdev/leetcode-mcp-server"},{"type":"has_code","target_id":"github:juehang:vscode-mcp-server","source_url":"https://github.com/juehang/vscode-mcp-server"},{"type":"has_code","target_id":"github:micl2e2:code-to-tree","source_url":"https://github.com/micl2e2/code-to-tree"},{"type":"has_code","target_id":"github:oraios:serena","source_url":"https://github.com/oraios/serena"},{"type":"has_code","target_id":"github:rinadelph:Agent-MCP","source_url":"https://github.com/rinadelph/Agent-MCP"},{"type":"has_code","target_id":"github:Sim-xia:Blind-Auditor","source_url":"https://github.com/Sim-xia/Blind-Auditor"},{"type":"has_code","target_id":"github:stippi:code-assistant","source_url":"https://github.com/stippi/code-assistant"},{"type":"has_code","target_id":"github:tiianhk:MaxMSP-MCP-Server","source_url":"https://github.com/tiianhk/MaxMSP-MCP-Server"},{"type":"has_code","target_id":"github:nesquikm:mcp-rubber-duck","source_url":"https://github.com/nesquikm/mcp-rubber-duck"},{"type":"has_code","target_id":"github:askbudi:roundtable","source_url":"https://github.com/askbudi/roundtable"},{"type":"has_code","target_id":"github:VertexStudio:developer","source_url":"https://github.com/VertexStudio/developer"},{"type":"has_code","target_id":"github:x51xxx:codex-mcp-tool","source_url":"https://github.com/x51xxx/codex-mcp-tool"},{"type":"has_code","target_id":"github:x51xxx:copilot-mcp-server","source_url":"https://github.com/x51xxx/copilot-mcp-server"},{"type":"has_code","target_id":"github:wende:cicada","source_url":"https://github.com/wende/cicada"},{"type":"has_code","target_id":"github:automateyournetwork:pyATS_MCP","source_url":"https://github.com/automateyournetwork/pyATS_MCP"},{"type":"has_code","target_id":"github:aymericzip:intlayer","source_url":"https://github.com/aymericzip/intlayer"},{"type":"has_code","target_id":"github:blakerouse:ssh-mcp","source_url":"https://github.com/blakerouse/ssh-mcp"},{"type":"has_code","target_id":"github:ferrislucas:iterm-mcp","source_url":"https://github.com/ferrislucas/iterm-mcp"},{"type":"has_code","target_id":"github:g0t4:mcp-server-commands","source_url":"https://github.com/g0t4/mcp-server-commands"},{"type":"has_code","target_id":"github:maxim-saplin:mcp_safe_local_python_executor","source_url":"https://github.com/maxim-saplin/mcp_safe_local_python_executor"},{"type":"has_code","target_id":"github:misiektoja:kill-process-mcp","source_url":"https://github.com/misiektoja/kill-process-mcp"},{"type":"has_code","target_id":"github:MladenSU:cli-mcp-server","source_url":"https://github.com/MladenSU/cli-mcp-server"},{"type":"has_code","target_id":"github:OthmaneBlial:term_mcp_deepseek","source_url":"https://github.com/OthmaneBlial/term_mcp_deepseek"},{"type":"has_code","target_id":"github:ooples:mcp-console-automation","source_url":"https://github.com/ooples/mcp-console-automation"},{"type":"has_code","target_id":"github:sonirico:mcp-shell","source_url":"https://github.com/sonirico/mcp-shell"},{"type":"has_code","target_id":"github:mediar-ai:terminator","source_url":"https://github.com/mediar-ai/terminator"},{"type":"has_code","target_id":"github:tufantunc:ssh-mcp","source_url":"https://github.com/tufantunc/ssh-mcp"},{"type":"has_code","target_id":"github:tumf:mcp-shell-server","source_url":"https://github.com/tumf/mcp-shell-server"},{"type":"has_code","target_id":"github:wonderwhy-er:DesktopCommanderMCP","source_url":"https://github.com/wonderwhy-er/DesktopCommanderMCP"},{"type":"has_code","target_id":"github:nihalxkumar:arch-mcp","source_url":"https://github.com/nihalxkumar/arch-mcp"},{"type":"has_code","target_id":"github:AbdelStark:nostr-mcp","source_url":"https://github.com/AbdelStark/nostr-mcp"},{"type":"has_code","target_id":"github:adhikasp:mcp-twikit","source_url":"https://github.com/adhikasp/mcp-twikit"},{"type":"has_code","target_id":"github:agentmail-to:agentmail-toolkit","source_url":"https://github.com/agentmail-to/agentmail-toolkit"},{"type":"has_code","target_id":"github:areweai:tsgram-mcp","source_url":"https://github.com/areweai/tsgram-mcp"},{"type":"has_code","target_id":"github:arpitbatra123:mcp-googletasks","source_url":"https://github.com/arpitbatra123/mcp-googletasks"},{"type":"has_code","target_id":"github:Cactusinhand:mcp_server_notify","source_url":"https://github.com/Cactusinhand/mcp_server_notify"},{"type":"has_code","target_id":"github:trycourier:courier-mcp","source_url":"https://github.com/trycourier/courier-mcp"},{"type":"has_code","target_id":"github:PhononX:cv-mcp-server","source_url":"https://github.com/PhononX/cv-mcp-server"},{"type":"has_code","target_id":"github:carterlasalle:mac_messages_mcp","source_url":"https://github.com/carterlasalle/mac_messages_mcp"},{"type":"has_code","target_id":"github:chaindead:telegram-mcp","source_url":"https://github.com/chaindead/telegram-mcp"},{"type":"has_code","target_id":"github:chigwell:telegram-mcp","source_url":"https://github.com/chigwell/telegram-mcp"},{"type":"has_code","target_id":"github:Danielpeter-99:calcom-mcp","source_url":"https://github.com/Danielpeter-99/calcom-mcp"},{"type":"has_code","target_id":"github:discourse:discourse-mcp","source_url":"https://github.com/discourse/discourse-mcp"},{"type":"has_code","target_id":"github:elie222:inbox-zero","source_url":"https://github.com/elie222/inbox-zero"},{"type":"has_code","target_id":"github:gerkensm:callcenter.js-mcp","source_url":"https://github.com/gerkensm/callcenter.js-mcp"},{"type":"has_code","target_id":"github:gitmotion:ntfy-me-mcp","source_url":"https://github.com/gitmotion/ntfy-me-mcp"},{"type":"has_code","target_id":"github:gotoolkits:mcp-wecombot-server.git","source_url":"https://github.com/gotoolkits/mcp-wecombot-server.git"},{"type":"has_code","target_id":"github:hannesrudolph:imessage-query-fastmcp-mcp-server","source_url":"https://github.com/hannesrudolph/imessage-query-fastmcp-mcp-server"},{"type":"has_code","target_id":"github:i-am-bee:acp-mcp","source_url":"https://github.com/i-am-bee/acp-mcp"},{"type":"has_code","target_id":"github:InditexTech:mcp-teams-server","source_url":"https://github.com/InditexTech/mcp-teams-server"},{"type":"has_code","target_id":"github:infobip:mcp","source_url":"https://github.com/infobip/mcp"},{"type":"has_code","target_id":"github:jagan-shanmugam:mattermost-mcp-host","source_url":"https://github.com/jagan-shanmugam/mattermost-mcp-host"},{"type":"has_code","target_id":"github:jaipandya:producthunt-mcp-server","source_url":"https://github.com/jaipandya/producthunt-mcp-server"},{"type":"has_code","target_id":"github:joinly-ai:joinly","source_url":"https://github.com/joinly-ai/joinly"},{"type":"has_code","target_id":"github:keturiosakys:bluesky-context-server","source_url":"https://github.com/keturiosakys/bluesky-context-server"},{"type":"has_code","target_id":"github:khan2a:telephony-mcp-server","source_url":"https://github.com/khan2a/telephony-mcp-server"},{"type":"has_code","target_id":"github:korotovsky:slack-mcp-server","source_url":"https://github.com/korotovsky/slack-mcp-server"},{"type":"has_code","target_id":"github:lharries:whatsapp-mcp","source_url":"https://github.com/lharries/whatsapp-mcp"},{"type":"has_code","target_id":"github:line:line-bot-mcp-server","source_url":"https://github.com/line/line-bot-mcp-server"},{"type":"has_code","target_id":"github:madbonez:caldav-mcp","source_url":"https://github.com/madbonez/caldav-mcp"},{"type":"has_code","target_id":"github:OverQuotaAI:chatterboxio-mcp-server","source_url":"https://github.com/OverQuotaAI/chatterboxio-mcp-server"},{"type":"has_code","target_id":"github:wyattjoh:imessage-mcp","source_url":"https://github.com/wyattjoh/imessage-mcp"},{"type":"has_code","target_id":"github:sawa-zen:vrchat-mcp","source_url":"https://github.com/sawa-zen/vrchat-mcp"},{"type":"has_code","target_id":"github:softeria:ms-365-mcp-server","source_url":"https://github.com/softeria/ms-365-mcp-server"},{"type":"has_code","target_id":"github:SaseQ:discord-mcp","source_url":"https://github.com/SaseQ/discord-mcp"},{"type":"has_code","target_id":"github:teddyzxcv:ntfy-mcp","source_url":"https://github.com/teddyzxcv/ntfy-mcp"},{"type":"has_code","target_id":"github:UserAd:didlogic_mcp","source_url":"https://github.com/UserAd/didlogic_mcp"},{"type":"has_code","target_id":"github:YCloud-Developers:ycloud-whatsapp-mcp-server","source_url":"https://github.com/YCloud-Developers/ycloud-whatsapp-mcp-server"},{"type":"has_code","target_id":"github:zcaceres:gtasks-mcp","source_url":"https://github.com/zcaceres/gtasks-mcp"},{"type":"has_code","target_id":"github:ztxtxwd:open-feishu-mcp-server","source_url":"https://github.com/ztxtxwd/open-feishu-mcp-server"},{"type":"has_code","target_id":"github:antvis:mcp-server-chart","source_url":"https://github.com/antvis/mcp-server-chart"},{"type":"has_code","target_id":"github:hustcc:mcp-echarts","source_url":"https://github.com/hustcc/mcp-echarts"},{"type":"has_code","target_id":"github:hustcc:mcp-mermaid","source_url":"https://github.com/hustcc/mcp-mermaid"},{"type":"has_code","target_id":"github:iaptic:mcp-server-iaptic","source_url":"https://github.com/iaptic/mcp-server-iaptic"},{"type":"has_code","target_id":"github:OpenDataMCP:OpenDataMCP","source_url":"https://github.com/OpenDataMCP/OpenDataMCP"},{"type":"has_code","target_id":"github:sergehuber:inoyu-mcp-unomi-server","source_url":"https://github.com/sergehuber/inoyu-mcp-unomi-server"},{"type":"has_code","target_id":"github:tinybirdco:mcp-tinybird","source_url":"https://github.com/tinybirdco/mcp-tinybird"},{"type":"has_code","target_id":"github:Aiven-Open:mcp-aiven","source_url":"https://github.com/Aiven-Open/mcp-aiven"},{"type":"has_code","target_id":"github:alexander-zuev:supabase-mcp-server","source_url":"https://github.com/alexander-zuev/supabase-mcp-server"},{"type":"has_code","target_id":"github:aliyun:alibabacloud-tablestore-mcp-server","source_url":"https://github.com/aliyun/alibabacloud-tablestore-mcp-server"},{"type":"has_code","target_id":"github:amineelkouhen:mcp-cockroachdb","source_url":"https://github.com/amineelkouhen/mcp-cockroachdb"},{"type":"has_code","target_id":"github:benborla:mcp-server-mysql","source_url":"https://github.com/benborla/mcp-server-mysql"},{"type":"has_code","target_id":"github:bram2w:baserow","source_url":"https://github.com/bram2w/baserow"},{"type":"has_code","target_id":"github:c4pt0r:mcp-server-tidb","source_url":"https://github.com/c4pt0r/mcp-server-tidb"},{"type":"has_code","target_id":"github:Canner:wren-engine","source_url":"https://github.com/Canner/wren-engine"},{"type":"has_code","target_id":"github:centralmind:gateway","source_url":"https://github.com/centralmind/gateway"},{"type":"has_code","target_id":"github:ChristianHinge:dicom-mcp","source_url":"https://github.com/ChristianHinge/dicom-mcp"},{"type":"has_code","target_id":"github:chroma-core:chroma-mcp","source_url":"https://github.com/chroma-core/chroma-mcp"},{"type":"has_code","target_id":"github:ClickHouse:mcp-clickhouse","source_url":"https://github.com/ClickHouse/mcp-clickhouse"},{"type":"has_code","target_id":"github:confluentinc:mcp-confluent","source_url":"https://github.com/confluentinc/mcp-confluent"},{"type":"has_code","target_id":"github:Couchbase-Ecosystem:mcp-server-couchbase","source_url":"https://github.com/Couchbase-Ecosystem/mcp-server-couchbase"},{"type":"has_code","target_id":"github:cr7258:elasticsearch-mcp-server","source_url":"https://github.com/cr7258/elasticsearch-mcp-server"},{"type":"has_code","target_id":"github:crystaldba:postgres-mcp","source_url":"https://github.com/crystaldba/postgres-mcp"},{"type":"has_code","target_id":"github:Dataring-engineering:mcp-server-trino","source_url":"https://github.com/Dataring-engineering/mcp-server-trino"},{"type":"has_code","target_id":"github:dave-wind:mysql-mcp-server","source_url":"https://github.com/dave-wind/mysql-mcp-server"},{"type":"has_code","target_id":"github:designcomputer:mysql_mcp_server","source_url":"https://github.com/designcomputer/mysql_mcp_server"},{"type":"has_code","target_id":"github:domdomegg:airtable-mcp-server","source_url":"https://github.com/domdomegg/airtable-mcp-server"},{"type":"has_code","target_id":"github:edwinbernadus:nocodb-mcp-server","source_url":"https://github.com/edwinbernadus/nocodb-mcp-server"},{"type":"has_code","target_id":"github:ergut:mcp-bigquery-server","source_url":"https://github.com/ergut/mcp-bigquery-server"},{"type":"has_code","target_id":"github:f4ww4z:mcp-mysql-server","source_url":"https://github.com/f4ww4z/mcp-mysql-server"},{"type":"has_code","target_id":"github:ferrants:memvid-mcp-server","source_url":"https://github.com/ferrants/memvid-mcp-server"},{"type":"has_code","target_id":"github:Olow304:memvid","source_url":"https://github.com/Olow304/memvid"},{"type":"has_code","target_id":"github:fireproof-storage:mcp-database-server","source_url":"https://github.com/fireproof-storage/mcp-database-server"},{"type":"has_code","target_id":"github:freema:mcp-gsheets","source_url":"https://github.com/freema/mcp-gsheets"},{"type":"has_code","target_id":"github:FreePeak:db-mcp-server","source_url":"https://github.com/FreePeak/db-mcp-server"},{"type":"has_code","target_id":"github:furey:mongodb-lens","source_url":"https://github.com/furey/mongodb-lens"},{"type":"has_code","target_id":"github:gannonh:firebase-mcp","source_url":"https://github.com/gannonh/firebase-mcp"},{"type":"has_code","target_id":"github:get-convex:convex-backend","source_url":"https://github.com/get-convex/convex-backend"},{"type":"has_code","target_id":"github:gigamori:mcp-run-sql-connectorx","source_url":"https://github.com/gigamori/mcp-run-sql-connectorx"},{"type":"has_code","target_id":"github:googleapis:genai-toolbox","source_url":"https://github.com/googleapis/genai-toolbox"},{"type":"has_code","target_id":"github:GreptimeTeam:greptimedb-mcp-server","source_url":"https://github.com/GreptimeTeam/greptimedb-mcp-server"},{"type":"has_code","target_id":"github:hannesrudolph:sqlite-explorer-fastmcp-mcp-server","source_url":"https://github.com/hannesrudolph/sqlite-explorer-fastmcp-mcp-server"},{"type":"has_code","target_id":"github:henilcalagiya:google-sheets-mcp","source_url":"https://github.com/henilcalagiya/google-sheets-mcp"},{"type":"has_code","target_id":"github:hydrolix:mcp-hydrolix","source_url":"https://github.com/hydrolix/mcp-hydrolix"},{"type":"has_code","target_id":"github:idoru:influxdb-mcp-server","source_url":"https://github.com/idoru/influxdb-mcp-server"},{"type":"has_code","target_id":"github:influxdata:influxdb3_mcp_server","source_url":"https://github.com/influxdata/influxdb3_mcp_server"},{"type":"has_code","target_id":"github:isaacwasserman:mcp-snowflake-server","source_url":"https://github.com/isaacwasserman/mcp-snowflake-server"},{"type":"has_code","target_id":"github:iunera:druid-mcp-server","source_url":"https://github.com/iunera/druid-mcp-server"},{"type":"has_code","target_id":"github:YannBrrd:simple_snowflake_mcp","source_url":"https://github.com/YannBrrd/simple_snowflake_mcp"},{"type":"has_code","target_id":"github:joshuarileydev:supabase","source_url":"https://github.com/joshuarileydev/supabase"},{"type":"has_code","target_id":"github:jovezhong:mcp-timeplus","source_url":"https://github.com/jovezhong/mcp-timeplus"},{"type":"has_code","target_id":"github:jparkerweb:mcp-sqlite","source_url":"https://github.com/jparkerweb/mcp-sqlite"},{"type":"has_code","target_id":"github:KashiwaByte:vikingdb-mcp-server","source_url":"https://github.com/KashiwaByte/vikingdb-mcp-server"},{"type":"has_code","target_id":"github:kiliczsh:mcp-mongo-server","source_url":"https://github.com/kiliczsh/mcp-mongo-server"},{"type":"has_code","target_id":"github:ktanaka101:mcp-server-duckdb","source_url":"https://github.com/ktanaka101/mcp-server-duckdb"},{"type":"has_code","target_id":"github:LucasHild:mcp-server-bigquery","source_url":"https://github.com/LucasHild/mcp-server-bigquery"},{"type":"has_code","target_id":"github:memgraph:ai-toolkit","source_url":"https://github.com/memgraph/ai-toolkit"},{"type":"has_code","target_id":"github:montumodi:mongodb-atlas-mcp-server","source_url":"https://github.com/montumodi/mongodb-atlas-mcp-server"},{"type":"has_code","target_id":"github:modelcontextprotocol:servers-archived","source_url":"https://github.com/modelcontextprotocol/servers-archived"},{"type":"has_code","target_id":"github:modelcontextprotocol:servers-archived","source_url":"https://github.com/modelcontextprotocol/servers-archived"},{"type":"has_code","target_id":"github:neo4j-contrib:mcp-neo4j","source_url":"https://github.com/neo4j-contrib/mcp-neo4j"},{"type":"has_code","target_id":"github:neondatabase:mcp-server-neon","source_url":"https://github.com/neondatabase/mcp-server-neon"},{"type":"has_code","target_id":"github:niledatabase:nile-mcp-server","source_url":"https://github.com/niledatabase/nile-mcp-server"},{"type":"has_code","target_id":"github:OpenLinkSoftware:mcp-jdbc-server","source_url":"https://github.com/OpenLinkSoftware/mcp-jdbc-server"},{"type":"has_code","target_id":"github:OpenLinkSoftware:mcp-odbc-server","source_url":"https://github.com/OpenLinkSoftware/mcp-odbc-server"},{"type":"has_code","target_id":"github:OpenLinkSoftware:mcp-sqlalchemy-server","source_url":"https://github.com/OpenLinkSoftware/mcp-sqlalchemy-server"},{"type":"has_code","target_id":"github:pab1it0:adx-mcp-server","source_url":"https://github.com/pab1it0/adx-mcp-server"},{"type":"has_code","target_id":"github:pab1it0:prometheus-mcp-server","source_url":"https://github.com/pab1it0/prometheus-mcp-server"},{"type":"has_code","target_id":"github:prisma:mcp","source_url":"https://github.com/prisma/mcp"},{"type":"has_code","target_id":"github:qdrant:mcp-server-qdrant","source_url":"https://github.com/qdrant/mcp-server-qdrant"},{"type":"has_code","target_id":"github:QuantGeekDev:mongo-mcp","source_url":"https://github.com/QuantGeekDev/mongo-mcp"},{"type":"has_code","target_id":"github:quarkiverse:quarkus-mcp-servers","source_url":"https://github.com/quarkiverse/quarkus-mcp-servers"},{"type":"has_code","target_id":"github:rashidazarang:airtable-mcp","source_url":"https://github.com/rashidazarang/airtable-mcp"},{"type":"has_code","target_id":"github:redis:mcp-redis","source_url":"https://github.com/redis/mcp-redis"},{"type":"has_code","target_id":"github:runekaagaard:mcp-alchemy","source_url":"https://github.com/runekaagaard/mcp-alchemy"},{"type":"has_code","target_id":"github:wenerme:wode","source_url":"https://github.com/wenerme/wode"},{"type":"has_code","target_id":"github:s2-streamstore:s2-sdk-typescript","source_url":"https://github.com/s2-streamstore/s2-sdk-typescript"},{"type":"has_code","target_id":"github:schemacrawler:SchemaCrawler-MCP-Server-Usage","source_url":"https://github.com/schemacrawler/SchemaCrawler-MCP-Server-Usage"},{"type":"has_code","target_id":"github:sirmews:mcp-pinecone","source_url":"https://github.com/sirmews/mcp-pinecone"},{"type":"has_code","target_id":"github:skysqlinc:skysql-mcp","source_url":"https://github.com/skysqlinc/skysql-mcp"},{"type":"has_code","target_id":"github:Snowflake-Labs:mcp","source_url":"https://github.com/Snowflake-Labs/mcp"},{"type":"has_code","target_id":"github:subnetmarco:pgmcp","source_url":"https://github.com/subnetmarco/pgmcp"},{"type":"has_code","target_id":"github:isdaniel:pgtuner_mcp","source_url":"https://github.com/isdaniel/pgtuner_mcp"},{"type":"has_code","target_id":"github:supabase-community:supabase-mcp","source_url":"https://github.com/supabase-community/supabase-mcp"},{"type":"has_code","target_id":"github:TheRaLabs:legion-mcp","source_url":"https://github.com/TheRaLabs/legion-mcp"},{"type":"has_code","target_id":"github:tradercjz:dolphindb-mcp-server","source_url":"https://github.com/tradercjz/dolphindb-mcp-server"},{"type":"has_code","target_id":"github:tuannvm:mcp-trino","source_url":"https://github.com/tuannvm/mcp-trino"},{"type":"has_code","target_id":"github:VictoriaMetrics-Community:mcp-victorialogs","source_url":"https://github.com/VictoriaMetrics-Community/mcp-victorialogs"},{"type":"has_code","target_id":"github:weaviate:mcp-server-weaviate","source_url":"https://github.com/weaviate/mcp-server-weaviate"},{"type":"has_code","target_id":"github:wenb1n-dev:mysql_mcp_server_pro","source_url":"https://github.com/wenb1n-dev/mysql_mcp_server_pro"},{"type":"has_code","target_id":"github:wenb1n-dev:SmartDB_MCP","source_url":"https://github.com/wenb1n-dev/SmartDB_MCP"},{"type":"has_code","target_id":"github:Xexr:mcp-libsql","source_url":"https://github.com/Xexr/mcp-libsql"},{"type":"has_code","target_id":"github:XGenerationLab:xiyan_mcp_server","source_url":"https://github.com/XGenerationLab/xiyan_mcp_server"},{"type":"has_code","target_id":"github:xing5:mcp-google-sheets","source_url":"https://github.com/xing5/mcp-google-sheets"},{"type":"has_code","target_id":"github:ydb-platform:ydb-mcp","source_url":"https://github.com/ydb-platform/ydb-mcp"},{"type":"has_code","target_id":"github:yincongcyincong:VictoriaMetrics-mcp-server","source_url":"https://github.com/yincongcyincong/VictoriaMetrics-mcp-server"},{"type":"has_code","target_id":"github:Zhwt:go-mcp-mysql","source_url":"https://github.com/Zhwt/go-mcp-mysql"},{"type":"has_code","target_id":"github:zilliztech:mcp-server-milvus","source_url":"https://github.com/zilliztech/mcp-server-milvus"},{"type":"has_code","target_id":"github:aywengo:kafka-schema-reg-mcp","source_url":"https://github.com/aywengo/kafka-schema-reg-mcp"},{"type":"has_code","target_id":"github:dbt-labs:dbt-mcp","source_url":"https://github.com/dbt-labs/dbt-mcp"},{"type":"has_code","target_id":"github:flowcore-io:mcp-flowcore-platform","source_url":"https://github.com/flowcore-io/mcp-flowcore-platform"},{"type":"has_code","target_id":"github:JordiNeil:mcp-databricks-server","source_url":"https://github.com/JordiNeil/mcp-databricks-server"},{"type":"has_code","target_id":"github:jwaxman19:qlik-mcp","source_url":"https://github.com/jwaxman19/qlik-mcp"},{"type":"has_code","target_id":"github:keboola:keboola-mcp-server","source_url":"https://github.com/keboola/keboola-mcp-server"},{"type":"has_code","target_id":"github:mattijsdp:dbt-docs-mcp","source_url":"https://github.com/mattijsdp/dbt-docs-mcp"},{"type":"has_code","target_id":"github:yashshingvi:databricks-genie-MCP","source_url":"https://github.com/yashshingvi/databricks-genie-MCP"},{"type":"has_code","target_id":"github:alkemi-ai:alkemi-mcp","source_url":"https://github.com/alkemi-ai/alkemi-mcp"},{"type":"has_code","target_id":"github:avisangle:method-crm-mcp","source_url":"https://github.com/avisangle/method-crm-mcp"},{"type":"has_code","target_id":"github:paracetamol951:caisse-enregistreuse-mcp-server","source_url":"https://github.com/paracetamol951/caisse-enregistreuse-mcp-server"},{"type":"has_code","target_id":"github:21st-dev:magic-mcp","source_url":"https://github.com/21st-dev/magic-mcp"},{"type":"has_code","target_id":"github:louis030195:gptzero-mcp","source_url":"https://github.com/louis030195/gptzero-mcp"},{"type":"has_code","target_id":"github:aashari:mcp-server-atlassian-bitbucket","source_url":"https://github.com/aashari/mcp-server-atlassian-bitbucket"},{"type":"has_code","target_id":"github:aashari:mcp-server-atlassian-confluence","source_url":"https://github.com/aashari/mcp-server-atlassian-confluence"},{"type":"has_code","target_id":"github:aashari:mcp-server-atlassian-jira","source_url":"https://github.com/aashari/mcp-server-atlassian-jira"},{"type":"has_code","target_id":"github:abrinsmead:mindpilot-mcp","source_url":"https://github.com/abrinsmead/mindpilot-mcp"},{"type":"has_code","target_id":"github:admica:FileScopeMCP","source_url":"https://github.com/admica/FileScopeMCP"},{"type":"has_code","target_id":"github:agent-hanju:char-index-mcp","source_url":"https://github.com/agent-hanju/char-index-mcp"},{"type":"has_code","target_id":"github:akramIOT:MCP_AI_SOC_Sher","source_url":"https://github.com/akramIOT/MCP_AI_SOC_Sher"},{"type":"has_code","target_id":"github:alimo7amed93:webhook-tester-mcp","source_url":"https://github.com/alimo7amed93/webhook-tester-mcp"},{"type":"has_code","target_id":"github:ambar:simctl-mcp","source_url":"https://github.com/ambar/simctl-mcp"},{"type":"has_code","target_id":"github:api7:apisix-mcp","source_url":"https://github.com/api7/apisix-mcp"},{"type":"has_code","target_id":"github:apache:apisix","source_url":"https://github.com/apache/apisix"},{"type":"has_code","target_id":"github:ArchAI-Labs:fastmcp-sonarqube-metrics","source_url":"https://github.com/ArchAI-Labs/fastmcp-sonarqube-metrics"},{"type":"has_code","target_id":"github:artmann:package-registry-mcp","source_url":"https://github.com/artmann/package-registry-mcp"},{"type":"has_code","target_id":"github:wyattjoh:jsr-mcp","source_url":"https://github.com/wyattjoh/jsr-mcp"},{"type":"has_code","target_id":"github:augmnt:augments-mcp-server","source_url":"https://github.com/augmnt/augments-mcp-server"},{"type":"has_code","target_id":"github:automation-ai-labs:mcp-link","source_url":"https://github.com/automation-ai-labs/mcp-link"},{"type":"has_code","target_id":"github:avisangle:jenkins-mcp-server","source_url":"https://github.com/avisangle/jenkins-mcp-server"},{"type":"has_code","target_id":"github:axliupore:mcp-code-runner","source_url":"https://github.com/axliupore/mcp-code-runner"},{"type":"has_code","target_id":"github:azer:react-analyzer-mcp","source_url":"https://github.com/azer/react-analyzer-mcp"},{"type":"has_code","target_id":"github:bitrise-io:bitrise-mcp","source_url":"https://github.com/bitrise-io/bitrise-mcp"},{"type":"has_code","target_id":"github:buildkite:buildkite-mcp-server","source_url":"https://github.com/buildkite/buildkite-mcp-server"},{"type":"has_code","target_id":"github:chunkydotdev:bldbl-mcp","source_url":"https://github.com/chunkydotdev/bldbl-mcp"},{"type":"has_code","target_id":"github:CircleCI-Public:mcp-server-circleci","source_url":"https://github.com/CircleCI-Public/mcp-server-circleci"},{"type":"has_code","target_id":"github:Wolfe-Jam:claude-faf-mcp","source_url":"https://github.com/Wolfe-Jam/claude-faf-mcp"},{"type":"has_code","target_id":"github:cjo4m06:mcp-shrimp-task-manager","source_url":"https://github.com/cjo4m06/mcp-shrimp-task-manager"},{"type":"has_code","target_id":"github:ckanthony:gin-mcp","source_url":"https://github.com/ckanthony/gin-mcp"},{"type":"has_code","target_id":"github:BrunoKrugel:echo-mcp","source_url":"https://github.com/BrunoKrugel/echo-mcp"},{"type":"has_code","target_id":"github:ckreiling:mcp-server-docker","source_url":"https://github.com/ckreiling/mcp-server-docker"},{"type":"has_code","target_id":"github:CodeLogicIncEngineering:codelogic-mcp-server","source_url":"https://github.com/CodeLogicIncEngineering/codelogic-mcp-server"},{"type":"has_code","target_id":"github:comet-ml:opik-mcp","source_url":"https://github.com/comet-ml/opik-mcp"},{"type":"has_code","target_id":"github:configcat:mcp-server","source_url":"https://github.com/configcat/mcp-server"},{"type":"has_code","target_id":"github:cqfn:aibolit-mcp-server","source_url":"https://github.com/cqfn/aibolit-mcp-server"},{"type":"has_code","target_id":"github:currents-dev:currents-mcp","source_url":"https://github.com/currents-dev/currents-mcp"},{"type":"has_code","target_id":"github:davidan90:time-node-mcp","source_url":"https://github.com/davidan90/time-node-mcp"},{"type":"has_code","target_id":"github:davidlin2k:pox-mcp-server","source_url":"https://github.com/davidlin2k/pox-mcp-server"},{"type":"has_code","target_id":"github:delano:postman-mcp-server","source_url":"https://github.com/delano/postman-mcp-server"},{"type":"has_code","target_id":"github:alexpota:deploy-mcp","source_url":"https://github.com/alexpota/deploy-mcp"},{"type":"has_code","target_id":"github:docker:hub-mcp","source_url":"https://github.com/docker/hub-mcp"},{"type":"has_code","target_id":"github:V0v1kkk:DotNetMetadataMcpServer","source_url":"https://github.com/V0v1kkk/DotNetMetadataMcpServer"},{"type":"has_code","target_id":"github:endorhq:cli","source_url":"https://github.com/endorhq/cli"},{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master","source_url":"https://github.com/eyaltoledano/claude-task-master"},{"type":"has_code","target_id":"github:etsd-tech:mcp-pointer","source_url":"https://github.com/etsd-tech/mcp-pointer"},{"type":"has_code","target_id":"github:flipt-io:mcp-server-flipt","source_url":"https://github.com/flipt-io/mcp-server-flipt"},{"type":"has_code","target_id":"github:freema:mcp-design-system-extractor","source_url":"https://github.com/freema/mcp-design-system-extractor"},{"type":"has_code","target_id":"github:gitkraken:gk-cli","source_url":"https://github.com/gitkraken/gk-cli"},{"type":"has_code","target_id":"github:GLips:Figma-Context-MCP","source_url":"https://github.com/GLips/Figma-Context-MCP"},{"type":"has_code","target_id":"github:mhmzdev:Figma-Flutter-MCP","source_url":"https://github.com/mhmzdev/Figma-Flutter-MCP"},{"type":"has_code","target_id":"github:gofireflyio:firefly-mcp","source_url":"https://github.com/gofireflyio/firefly-mcp"},{"type":"has_code","target_id":"github:gorosun:unified-diff-mcp","source_url":"https://github.com/gorosun/unified-diff-mcp"},{"type":"has_code","target_id":"github:Govcraft:rust-docs-mcp-server","source_url":"https://github.com/Govcraft/rust-docs-mcp-server"},{"type":"has_code","target_id":"github:promptexecution:cratedocs-mcp","source_url":"https://github.com/promptexecution/cratedocs-mcp"},{"type":"has_code","target_id":"github:HainanZhao:mcp-gitlab-jira","source_url":"https://github.com/HainanZhao/mcp-gitlab-jira"},{"type":"has_code","target_id":"github:haris-musa:excel-mcp-server","source_url":"https://github.com/haris-musa/excel-mcp-server"},{"type":"has_code","target_id":"github:sbroenne:mcp-server-excel","source_url":"https://github.com/sbroenne/mcp-server-excel"},{"type":"has_code","target_id":"github:hechtcarmel:jetbrains-debugger-mcp-plugin","source_url":"https://github.com/hechtcarmel/jetbrains-debugger-mcp-plugin"},{"type":"has_code","target_id":"github:hechtcarmel:jetbrains-index-mcp-plugin","source_url":"https://github.com/hechtcarmel/jetbrains-index-mcp-plugin"},{"type":"has_code","target_id":"github:higress-group:higress-ops-mcp-server","source_url":"https://github.com/higress-group/higress-ops-mcp-server"},{"type":"has_code","target_id":"github:alibaba:higress","source_url":"https://github.com/alibaba/higress"},{"type":"has_code","target_id":"github:hijaz:postmancer","source_url":"https://github.com/hijaz/postmancer"},{"type":"has_code","target_id":"github:hloiseaufcms:mcp-gopls","source_url":"https://github.com/hloiseaufcms/mcp-gopls"},{"type":"has_code","target_id":"github:golang:tools","source_url":"https://github.com/golang/tools"},{"type":"has_code","target_id":"github:hungthai1401:bruno-mcp","source_url":"https://github.com/hungthai1401/bruno-mcp"},{"type":"has_code","target_id":"github:hyperb1iss:droidmind","source_url":"https://github.com/hyperb1iss/droidmind"},{"type":"has_code","target_id":"github:Hypersequent:qasphere-mcp","source_url":"https://github.com/Hypersequent/qasphere-mcp"},{"type":"has_code","target_id":"github:idosal:git-mcp","source_url":"https://github.com/idosal/git-mcp"},{"type":"has_code","target_id":"github:IlyaGulya:gradle-mcp-server","source_url":"https://github.com/IlyaGulya/gradle-mcp-server"},{"type":"has_code","target_id":"github:promptexecution:just-mcp","source_url":"https://github.com/promptexecution/just-mcp"},{"type":"has_code","target_id":"github:InditexTech:mcp-server-simulator-ios-idb","source_url":"https://github.com/InditexTech/mcp-server-simulator-ios-idb"},{"type":"has_code","target_id":"github:InhiblabCore:mcp-image-compression","source_url":"https://github.com/InhiblabCore/mcp-image-compression"},{"type":"has_code","target_id":"github:InsForge:insforge-mcp","source_url":"https://github.com/InsForge/insforge-mcp"},{"type":"has_code","target_id":"github:inspizzz:jetbrains-datalore-mcp","source_url":"https://github.com/inspizzz/jetbrains-datalore-mcp"},{"type":"has_code","target_id":"github:joshuayoes:ios-simulator-mcp","source_url":"https://github.com/joshuayoes/ios-simulator-mcp"},{"type":"has_code","target_id":"github:isaacphi:mcp-language-server","source_url":"https://github.com/isaacphi/mcp-language-server"},{"type":"has_code","target_id":"github:IvanAmador:vercel-ai-docs-mcp","source_url":"https://github.com/IvanAmador/vercel-ai-docs-mcp"},{"type":"has_code","target_id":"github:j4c0bs:mcp-server-sql-analyzer","source_url":"https://github.com/j4c0bs/mcp-server-sql-analyzer"},{"type":"has_code","target_id":"github:tobymao:sqlglot","source_url":"https://github.com/tobymao/sqlglot"},{"type":"has_code","target_id":"github:janreges:ai-distiller","source_url":"https://github.com/janreges/ai-distiller"},{"type":"has_code","target_id":"github:jasonjmcghee:claude-debugs-for-you","source_url":"https://github.com/jasonjmcghee/claude-debugs-for-you"},{"type":"has_code","target_id":"github:JetBrains:mcpProxy","source_url":"https://github.com/JetBrains/mcpProxy"},{"type":"has_code","target_id":"github:Jktfe:serveMyAPI","source_url":"https://github.com/Jktfe/serveMyAPI"},{"type":"has_code","target_id":"github:JordanDalton:RestCsvMcpServer","source_url":"https://github.com/JordanDalton/RestCsvMcpServer"},{"type":"has_code","target_id":"github:JoshuaRileyDev:app-store-connect-mcp-server","source_url":"https://github.com/JoshuaRileyDev/app-store-connect-mcp-server"},{"type":"has_code","target_id":"github:JoshuaRileyDev:simulator-mcp-server","source_url":"https://github.com/JoshuaRileyDev/simulator-mcp-server"},{"type":"has_code","target_id":"github:Jpisnice:shadcn-ui-mcp-server","source_url":"https://github.com/Jpisnice/shadcn-ui-mcp-server"},{"type":"has_code","target_id":"github:jsdelivr:globalping-mcp-server","source_url":"https://github.com/jsdelivr/globalping-mcp-server"},{"type":"has_code","target_id":"github:kadykov:mcp-openapi-schema-explorer","source_url":"https://github.com/kadykov/mcp-openapi-schema-explorer"},{"type":"has_code","target_id":"github:lamemind:mcp-server-multiverse","source_url":"https://github.com/lamemind/mcp-server-multiverse"},{"type":"has_code","target_id":"github:langfuse:mcp-server-langfuse","source_url":"https://github.com/langfuse/mcp-server-langfuse"},{"type":"has_code","target_id":"github:JamesANZ:system-prompts-mcp-server","source_url":"https://github.com/JamesANZ/system-prompts-mcp-server"},{"type":"has_code","target_id":"github:linw1995:nvim-mcp","source_url":"https://github.com/linw1995/nvim-mcp"},{"type":"has_code","target_id":"github:lpigeon:ros-mcp-server","source_url":"https://github.com/lpigeon/ros-mcp-server"},{"type":"has_code","target_id":"github:lpigeon:unitree-go2-mcp-server","source_url":"https://github.com/lpigeon/unitree-go2-mcp-server"},{"type":"has_code","target_id":"github:ukkit:memcord","source_url":"https://github.com/ukkit/memcord"},{"type":"has_code","target_id":"github:mattjegan:swarmia-mcp","source_url":"https://github.com/mattjegan/swarmia-mcp"},{"type":"has_code","target_id":"github:mobile-next:mobile-mcp","source_url":"https://github.com/mobile-next/mobile-mcp"},{"type":"has_code","target_id":"github:mrexodia:user-feedback-mcp","source_url":"https://github.com/mrexodia/user-feedback-mcp"},{"type":"has_code","target_id":"github:mumez:pharo-smalltalk-interop-mcp-server","source_url":"https://github.com/mumez/pharo-smalltalk-interop-mcp-server"},{"type":"has_code","target_id":"github:narumiruna:gitingest-mcp","source_url":"https://github.com/narumiruna/gitingest-mcp"},{"type":"has_code","target_id":"github:cyclotruc:gitingest","source_url":"https://github.com/cyclotruc/gitingest"},{"type":"has_code","target_id":"github:neilberkman:editorconfig_mcp","source_url":"https://github.com/neilberkman/editorconfig_mcp"},{"type":"has_code","target_id":"github:OctoMind-dev:octomind-mcp","source_url":"https://github.com/OctoMind-dev/octomind-mcp"},{"type":"has_code","target_id":"github:OpenZeppelin:contracts-wizard","source_url":"https://github.com/OpenZeppelin/contracts-wizard"},{"type":"has_code","target_id":"github:bgauryy:octocode-mcp","source_url":"https://github.com/bgauryy/octocode-mcp"},{"type":"has_code","target_id":"github:opslevel:opslevel-mcp","source_url":"https://github.com/opslevel/opslevel-mcp"},{"type":"has_code","target_id":"github:ooples:token-optimizer-mcp","source_url":"https://github.com/ooples/token-optimizer-mcp"}]', NULL, 'MIT', 'approved', 80, '03f814126c385248441b1eec8af13603', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-punkpeye-awesome-mcp-servers from https://github.com/punkpeye.png
Image converted to WebP: data/images/github-punkpeye-awesome-mcp-servers.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-hacksider-Deep-Live-Cam', 'github--hacksider--deep-live-cam', 'Deep-Live-Cam', 'hacksider', '<h1 align="center">Deep-Live-Cam</h1> <p align="center"> Real-time face swap and video deepfake with a single click and only a single image. </p> <p align="center"> <a href="https://trendshift.io/repositories/11395" target="_blank"><img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a> </p> <p align="center"> <img src="media/demo.gif" alt="Demo GIF" width="800"> </p> This deep...', '["ai","ai-deep-fake","ai-face","ai-webcam","artificial-intelligence","deep-fake","deepfake","deepfake-webcam","faceswap","fake-webcam","gan","real-time-deepfake","realtime","realtime-deepfake","realtime-face-changer","video-deepfake","webcam","webcamera","python"]', 'other', 76185, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/hacksider/Deep-Live-Cam","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<h1 align="center">Deep-Live-Cam</h1>\n\n<p align="center">\n  Real-time face swap and video deepfake with a single click and only a single image.\n</p>\n\n<p align="center">\n<a href="https://trendshift.io/repositories/11395" target="_blank"><img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>\n</p>\n\n<p align="center">\n  <img src="media/demo.gif" alt="Demo GIF" width="800">\n</p>\n\n##  Disclaimer\n\nThis deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.\n\nWe are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.\n\n- Ethical Use: Users are expected to use this software responsibly and legally. If using a real person''s face, obtain their consent and clearly label any output as a deepfake when sharing online.\n\n- Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.\n\n- Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.\n\n- User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.\n\nBy using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.\n\nUsers are expected to use this software responsibly and legally. If using a real person''s face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.\n\n## Exclusive v2.3d Quick Start - Pre-built (Windows/Mac Silicon)\n\n  <a href="https://deeplivecam.net/index.php/quickstart"> <img src="media/Download.png" width="285" height="77" />\n\n##### This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you''ll receive special priority support.\n \n###### These Pre-builts are perfect for non-technical users or those who don''t have time to, or can''t manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually. \n\n## TLDR; Live Deepfake in just 3 Clicks\n![easysteps](https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6)\n1. Select a face\n2. Select which camera to use\n3. Press live!\n\n## Features & Uses - Everything is in real-time\n\n### Mouth Mask\n\n**Retain your original mouth for accurate movement using Mouth Mask**\n\n<p align="center">\n  <img src="media/ludwig.gif" alt="resizable-gif">\n</p>\n\n### Face Mapping\n\n**Use different faces on multiple subjects simultaneously**\n\n<p align="center">\n  <img src="media/streamers.gif" alt="face_mapping_source">\n</p>\n\n### Your Movie, Your Face\n\n**Watch movies with any face in real-time**\n\n<p align="center">\n  <img src="media/movie.gif" alt="movie">\n</p>\n\n### Live Show\n\n**Run Live shows and performances**\n\n<p align="center">\n  <img src="media/live_show.gif" alt="show">\n</p>\n\n### Memes\n\n**Create Your Most Viral Meme Yet**\n\n<p align="center">\n  <img src="media/meme.gif" alt="show" width="450"> \n  <br>\n  <sub>Created using Many Faces feature in Deep-Live-Cam</sub>\n</p>\n\n### Omegle\n\n**Surprise people on Omegle**\n\n<p align="center">\n  <video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls></video>\n</p>\n\n## Installation (Manual)\n\n**Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.**\n\n<details>\n<summary>Click to see the process</summary>\n\n### Installation\n\nThis is more likely to work on your computer but will be slower as it utilizes the CPU.\n\n**1. Set up Your Platform**\n\n-   Python (3.11 recommended)\n-   pip\n-   git\n-   [ffmpeg](https://www.youtube.com/watch?v=OlNWCpFdVMA) - ```iex (irm ffmpeg.tc.ht)```\n-   [Visual Studio 2022 Runtimes (Windows)](https://visualstudio.microsoft.com/visual-cpp-build-tools/)\n\n**2. Clone the Repository**\n\n```bash\ngit clone https://github.com/hacksider/Deep-Live-Cam.git\ncd Deep-Live-Cam\n```\n\n**3. Download the Models**\n\n1. [GFPGANv1.4](https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth)\n2. [inswapper\_128\_fp16.onnx](https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx)\n\nPlace these files in the "**models**" folder.\n\n**4. Install Dependencies**\n\nWe highly recommend using a `venv` to avoid issues.\n\n\nFor Windows:\n```bash\npython -m venv venv\nvenv\Scripts\activate\npip install -r requirements.txt\n```\nFor Linux:\n```bash\n# Ensure you use the installed Python 3.10\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n**For macOS:**\n\nApple Silicon (M1/M2/M3) requires specific setup:\n\n```bash\n# Install Python 3.11 (specific version is important)\nbrew install python@3.11\n\n# Install tkinter package (required for the GUI)\nbrew install python-tk@3.10\n\n# Create and activate virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n** In case something goes wrong and you need to reinstall the virtual environment **\n\n```bash\n# Deactivate the virtual environment\nrm -rf venv\n\n# Reinstall the virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# install the dependencies again\npip install -r requirements.txt\n\n# gfpgan and basicsrs issue fix\npip install git+https://github.com/xinntao/BasicSR.git@master\npip uninstall gfpgan -y\npip install git+https://github.com/TencentARC/GFPGAN.git@master\n```\n\n**Run:** If you don''t have a GPU, you can run Deep-Live-Cam using `python run.py`. Note that initial execution will download models (~300MB).\n\n### GPU Acceleration\n\n**CUDA Execution Provider (Nvidia)**\n\n1. Install [CUDA Toolkit 12.8.0](https://developer.nvidia.com/cuda-12-8-0-download-archive)\n2. Install [cuDNN v8.9.7 for CUDA 12.x](https://developer.nvidia.com/rdp/cudnn-archive) (required for onnxruntime-gpu):\n   - Download cuDNN v8.9.7 for CUDA 12.x\n   - Make sure the cuDNN bin directory is in your system PATH\n3. Install dependencies:\n\n```bash\npip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\npip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime-gpu==1.21.0\n```\n\n3. Usage:\n\n```bash\npython run.py --execution-provider cuda\n```\n\n**CoreML Execution Provider (Apple Silicon)**\n\nApple Silicon (M1/M2/M3) specific installation:\n\n1. Make sure you''ve completed the macOS setup above using Python 3.10.\n2. Install dependencies:\n\n```bash\npip uninstall onnxruntime onnxruntime-silicon\npip install onnxruntime-silicon==1.13.1\n```\n\n3. Usage (important: specify Python 3.10):\n\n```bash\npython3.10 run.py --execution-provider coreml\n```\n\n**Important Notes for macOS:**\n- You **must** use Python 3.10, not newer versions like 3.11 or 3.13\n- Always run with `python3.10` command not just `python` if you have multiple Python versions installed\n- If you get error about `_tkinter` missing, reinstall the tkinter package: `brew reinstall python-tk@3.10`\n- If you get model loading errors, check that your models are in the correct folder\n- If you encounter conflicts with other Python versions, consider uninstalling them:\n  ```bash\n  # List all installed Python versions\n  brew list | grep python\n  \n  # Uninstall conflicting versions if needed\n  brew uninstall --ignore-dependencies python@3.11 python@3.13\n  \n  # Keep only Python 3.11\n  brew cleanup\n  ```\n\n**CoreML Execution Provider (Apple Legacy)**\n\n1. Install dependencies:\n\n```bash\npip uninstall onnxruntime onnxruntime-coreml\npip install onnxruntime-coreml==1.21.0\n```\n\n2. Usage:\n\n```bash\npython run.py --execution-provider coreml\n```\n\n**DirectML Execution Provider (Windows)**\n\n1. Install dependencies:\n\n```bash\npip uninstall onnxruntime onnxruntime-directml\npip install onnxruntime-directml==1.21.0\n```\n\n2. Usage:\n\n```bash\npython run.py --execution-provider directml\n```\n\n**OpenVINO‚Ñ¢ Execution Provider (Intel)**\n\n1. Install dependencies:\n\n```bash\npip uninstall onnxruntime onnxruntime-openvino\npip install onnxruntime-openvino==1.21.0\n```\n\n2. Usage:\n\n```bash\npython run.py --execution-provider openvino\n```\n</details>\n\n## Usage\n\n**1. Image/Video Mode**\n\n-   Execute `python run.py`.\n-   Choose a source face image and a target image/video.\n-   Click "Start".\n-   The output will be saved in a directory named after the target video.\n\n**2. Webcam Mode**\n\n-   Execute `python run.py`.\n-   Select a source face image.\n-   Click "Live".\n-   Wait for the preview to appear (10-30 seconds).\n-   Use a screen capture tool like OBS to stream.\n-   To change the face, select a new source image.\n\n## Command Line Arguments (Unmaintained)\n\n```\noptions:\n  -h, --help                                               show this help message and exit\n  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image\n  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video\n  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory\n  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)\n  --keep-fps                                               keep original fps\n  --keep-audio                                             keep original audio\n  --keep-frames                                            keep temporary frames\n  --many-faces                                             process every face\n  --map-faces                                              map source target faces\n  --mouth-mask                                             mask the mouth region\n  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder\n  --video-quality [0-51]                                   adjust output video quality\n  --live-mirror                                            the live camera display as you see it in the front-facing camera frame\n  --live-resizable                                         the live camera frame is resizable\n  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB\n  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)\n  --execution-threads EXECUTION_THREADS                    number of execution threads\n  -v, --version                                            show program''s version number and exit\n```\n\nLooking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.\n\n## Press\n\n**We are always open to criticism and are ready to improve, that''s why we didn''t cherry-pick anything.**\n\n - [*"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"*](https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/) - Ars Technica\n - [*"Thanks Deep Live Cam, shapeshifters are among us now"*](https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/) - Dataconomy\n - [*"This free AI tool lets you become anyone during video-calls"*](https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story) - NewsBytes\n - [*"OK, this viral AI live stream software is truly terrifying"*](https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying) - Creative Bloq\n - [*"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"*](https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/) - PetaPixel\n - [*"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"*](https://www.techeblog.com/deep-live-cam-ai-transform-face/) - TechEBlog\n - [*"An AI tool that "makes you look like anyone" during a video call is going viral online"*](https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/) - Telegrafi\n - [*"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"*](https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts) - Emerge\n - [*"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"*](https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/) - Digital Music News\n - [*"This real-time webcam deepfake tool raises alarms about the future of identity theft"*](https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/) - DIYPhotography\n - [*"That''s Crazy, Oh God. That''s Fucking Freaky Dude... That''s So Wild Dude"*](https://www.youtube.com/watch?time_continue=1074&v=py4Tc-Y8BcY) - SomeOrdinaryGamers\n - [*"Alright look look look, now look chat, we can do any face we want to look like chat"*](https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&t=2686) - IShowSpeed\n - [*"They do a pretty good job matching poses, expression and even the lighting"*](https://www.youtube.com/watch?v=wnCghLjqv3s&t=551s) - TechLinked (LTT)\n - [*"Als Sean Connery an der Redaktionskonferenz teilnahm"*](https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html) - Golem.de (German)\n - [*"What the F***! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! "*](https://youtu.be/JbUPRmXRUtE?t=3964) - IShowSpeed\n\n\n## Credits\n\n-   [ffmpeg](https://ffmpeg.org/): for making video-related operations easy\n-   [Henry](https://github.com/henryruhs): One of the major contributor in this repo\n-   [deepinsight](https://github.com/deepinsight): for their [insightface](https://github.com/deepinsight/insightface) project which provided a well-made library and models. Please be reminded that the [use of the model is for non-commercial research purposes only](https://github.com/deepinsight/insightface?tab=readme-ov-file#license).\n-   [havok2-htwo](https://github.com/havok2-htwo): for sharing the code for webcam\n-   [GosuDRM](https://github.com/GosuDRM): for the open version of roop\n-   [pereiraroland26](https://github.com/pereiraroland26): Multiple faces support\n-   [vic4key](https://github.com/vic4key): For supporting/contributing to this project\n-   [kier007](https://github.com/kier007): for improving the user experience\n-   [qitianai](https://github.com/qitianai): for multi-lingual support\n-   and [all developers](https://github.com/hacksider/Deep-Live-Cam/graphs/contributors) behind libraries used in this project.\n-   Footnote: Please be informed that the base author of the code is [s0md3v](https://github.com/s0md3v/roop)\n-   All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è\n\n[![Stargazers](https://reporoster.com/stars/hacksider/Deep-Live-Cam)](https://github.com/hacksider/Deep-Live-Cam/stargazers)\n\n## Contributions\n\n![Alt](https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg "Repobeats analytics image")\n\n## Stars to the Moon üöÄ\n\n<a href="https://star-history.com/#hacksider/deep-live-cam&Date">\n <picture>\n   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&type=Date&theme=dark" />\n   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&type=Date" />\n   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&type=Date" />\n </picture>\n</a>\n', '{"language":"Python","stars":76185,"forks":11098,"watchers":76185,"open_issues":92,"topics":["ai","ai-deep-fake","ai-face","ai-webcam","artificial-intelligence","deep-fake","deepfake","deepfake-webcam","faceswap","fake-webcam","gan","real-time-deepfake","realtime","realtime-deepfake","realtime-face-changer","video-deepfake","webcam","webcamera"],"default_branch":"main","size_kb":155912,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:hacksider:Deep-Live-Cam.git","source_url":"https://github.com/hacksider/Deep-Live-Cam.git"},{"type":"has_code","target_id":"github:xinntao:BasicSR.git@master","source_url":"https://github.com/xinntao/BasicSR.git@master"},{"type":"has_code","target_id":"github:TencentARC:GFPGAN.git@master","source_url":"https://github.com/TencentARC/GFPGAN.git@master"},{"type":"has_code","target_id":"github:deepinsight:insightface","source_url":"https://github.com/deepinsight/insightface"},{"type":"has_code","target_id":"github:deepinsight:insightface","source_url":"https://github.com/deepinsight/insightface?tab=readme-ov-file#license"},{"type":"has_code","target_id":"github:hacksider:Deep-Live-Cam","source_url":"https://github.com/hacksider/Deep-Live-Cam"},{"type":"has_code","target_id":"github:s0md3v:roop","source_url":"https://github.com/s0md3v/roop"},{"type":"has_code","target_id":"github:hacksider:Deep-Live-Cam","source_url":"https://github.com/hacksider/Deep-Live-Cam"}]', NULL, 'AGPL-3.0', 'approved', 80, '611f900575dab550638ce8becde79100', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-hacksider-Deep-Live-Cam from https://github.com/hacksider.png
Image converted to WebP: data/images/github-hacksider-Deep-Live-Cam.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-firecrawl-firecrawl', 'github--firecrawl--firecrawl', 'firecrawl', 'firecrawl', '<h3 align="center"> <a name="readme-top"></a> <img src="https://raw.githubusercontent.com/firecrawl/firecrawl/main/img/firecrawl_logo.png" height="200" > </h3> <div align="center"> <a href="https://github.com/firecrawl/firecrawl/blob/main/LICENSE"> <img src="https://img.shields.io/github/license/firecrawl/firecrawl" alt="License"> </a> <a href="https://pepy.tech/project/firecrawl-py"> <img src="https://static.pepy.tech/badge/firecrawl-py" alt="Downloads"> </a> <a href="https://GitHub.com/fire...', '["ai","ai-agents","ai-crawler","ai-scraping","ai-search","crawler","data-extraction","html-to-markdown","llm","markdown","scraper","scraping","web-crawler","web-data","web-data-extraction","web-scraper","web-scraping","web-search","webscraping","typescript"]', 'other', 69325, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/firecrawl/firecrawl","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<h3 align="center">\n  <a name="readme-top"></a>\n  <img\n    src="https://raw.githubusercontent.com/firecrawl/firecrawl/main/img/firecrawl_logo.png"\n    height="200"\n  >\n</h3>\n<div align="center">\n    <a href="https://github.com/firecrawl/firecrawl/blob/main/LICENSE">\n  <img src="https://img.shields.io/github/license/firecrawl/firecrawl" alt="License">\n</a>\n    <a href="https://pepy.tech/project/firecrawl-py">\n  <img src="https://static.pepy.tech/badge/firecrawl-py" alt="Downloads">\n</a>\n<a href="https://GitHub.com/firecrawl/firecrawl/graphs/contributors">\n  <img src="https://img.shields.io/github/contributors/firecrawl/firecrawl.svg" alt="GitHub Contributors">\n</a>\n<a href="https://firecrawl.dev">\n  <img src="https://img.shields.io/badge/Visit-firecrawl.dev-orange" alt="Visit firecrawl.dev">\n</a>\n</div>\n<div>\n  <p align="center">\n    <a href="https://twitter.com/firecrawl_dev">\n      <img src="https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&logo=x&logoColor=white" alt="Follow on X" />\n    </a>\n    <a href="https://www.linkedin.com/company/104100957">\n      <img src="https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="Follow on LinkedIn" />\n    </a>\n    <a href="https://discord.com/invite/gSmWdAkdwd">\n      <img src="https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white" alt="Join our Discord" />\n    </a>\n  </p>\n</div>\n\n# üî• Firecrawl\n\nEmpower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.\n\n_This repository is in development, and we‚Äôre still integrating custom modules into the mono repo. It''s not fully ready for self-hosted deployment yet, but you can run it locally._\n\n## What is Firecrawl?\n\n[Firecrawl](https://firecrawl.dev?ref=github) is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our [documentation](https://docs.firecrawl.dev).\n\nLooking for our MCP? Check out the [repo here](https://github.com/firecrawl/firecrawl-mcp-server).\n\n_Pst. hey, you, join our stargazers :)_\n\n<a href="https://github.com/firecrawl/firecrawl">\n  <img src="https://img.shields.io/github/stars/firecrawl/firecrawl.svg?style=social&label=Star&maxAge=2592000" alt="GitHub stars">\n</a>\n\n## How to use it?\n\nWe provide an easy to use API with our hosted version. You can find the playground and documentation [here](https://firecrawl.dev/playground). You can also self host the backend if you''d like.\n\nCheck out the following resources to get started:\n- [x] **API**: [Documentation](https://docs.firecrawl.dev/api-reference/introduction)\n- [x] **SDKs**: [Python](https://docs.firecrawl.dev/sdks/python), [Node](https://docs.firecrawl.dev/sdks/node)\n- [x] **LLM Frameworks**: [Langchain (python)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/), [Langchain (js)](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl), [Llama Index](https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader), [Crew.ai](https://docs.crewai.com/), [Composio](https://composio.dev/tools/firecrawl/all), [PraisonAI](https://docs.praison.ai/firecrawl/), [Superinterface](https://superinterface.ai/docs/assistants/functions/firecrawl), [Vectorize](https://docs.vectorize.io/integrations/source-connectors/firecrawl)\n- [x] **Low-code Frameworks**: [Dify](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl), [Langflow](https://docs.langflow.org/), [Flowise AI](https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl), [Cargo](https://docs.getcargo.io/integration/firecrawl), [Pipedream](https://pipedream.com/apps/firecrawl/)\n- [x] **Community SDKs**: [Go](https://docs.firecrawl.dev/sdks/go), [Rust](https://docs.firecrawl.dev/sdks/rust)\n- [x] **Others**: [Zapier](https://zapier.com/apps/firecrawl/integrations), [Pabbly Connect](https://www.pabbly.com/connect/integrations/firecrawl/)\n- [ ] Want an SDK or Integration? Let us know by opening an issue.\n\nTo run locally, refer to guide [here](https://github.com/firecrawl/firecrawl/blob/main/CONTRIBUTING.md).\n\n### API Key\n\nTo use the API, you need to sign up on [Firecrawl](https://firecrawl.dev) and get an API key.\n\n### Features\n\n- [**Scrape**](#scraping): scrapes a URL and get its content in LLM-ready format (markdown, structured data via [LLM Extract](#llm-extraction-beta), screenshot, html)\n- [**Crawl**](#crawling): scrapes all the URLs of a web page and return content in LLM-ready format\n- [**Map**](#map): input a website and get all the website urls - extremely fast\n- [**Search**](#search): search the web and get full content from results\n- [**Extract**](#extract): get structured data from single page, multiple pages or entire websites with AI.\n\n### Powerful Capabilities\n- **LLM-ready formats**: markdown, structured data, screenshot, HTML, links, metadata\n- **The hard stuff**: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration\n- **Customizability**: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...\n- **Media parsing**: pdfs, docx, images\n- **Reliability first**: designed to get the data you need - no matter how hard it is\n- **Actions**: click, scroll, input, wait and more before extracting data\n- **Batching**: scrape thousands of URLs at the same time with a new async endpoint\n- **Change Tracking**: monitor and detect changes in website content over time\n\nYou can find all of Firecrawl''s capabilities and how to use them in our [documentation](https://docs.firecrawl.dev)\n\n### Crawling\n\nUsed to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/crawl \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer fc-YOUR_API_KEY'' \\n    -d ''{\n      "url": "https://docs.firecrawl.dev",\n      "limit": 10,\n      "scrapeOptions": {\n        "formats": ["markdown", "html"]\n      }\n    }''\n```\n\nReturns a crawl job id and the url to check the status of the crawl.\n\n```json\n{\n  "success": true,\n  "id": "123-456-789",\n  "url": "https://api.firecrawl.dev/v2/crawl/123-456-789"\n}\n```\n\n### Check Crawl Job\n\nUsed to check the status of a crawl job and get its result.\n\n```bash\ncurl -X GET https://api.firecrawl.dev/v2/crawl/123-456-789 \\n  -H ''Content-Type: application/json'' \\n  -H ''Authorization: Bearer YOUR_API_KEY''\n```\n\n```json\n{\n  "status": "completed",\n  "total": 36,\n  "creditsUsed": 36,\n  "expiresAt": "2024-00-00T00:00:00.000Z",\n  "data": [\n    {\n      "markdown": "[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...",\n      "html": "<!DOCTYPE html><html lang=\"en\" class=\"js-focus-visible lg:[--scroll-mt:9.5rem]\" data-js-focus-visible=\"\">...",\n      "metadata": {\n        "title": "Build a ''Chat with website'' using Groq Llama 3 | Firecrawl",\n        "language": "en",\n        "sourceURL": "https://docs.firecrawl.dev/learn/rag-llama3",\n        "description": "Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a ''Chat with your website'' bot.",\n        "ogLocaleAlternate": [],\n        "statusCode": 200\n      }\n    }\n  ]\n}\n```\n\n### Scraping\n\nUsed to scrape a URL and get its content in the specified formats.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/scrape \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "url": "https://docs.firecrawl.dev",\n      "formats" : ["markdown", "html"]\n    }''\n```\n\nResponse:\n\n```json\n{\n  "success": true,\n  "data": {\n    "markdown": "Launch Week I is here! [See our Day 2 Release üöÄ](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[üí• Get 2 months free...",\n    "html": "<!DOCTYPE html><html lang=\"en\" class=\"light\" style=\"color-scheme: light;\"><body class=\"__variable_36bd41 __variable_d7dc5d font-inter ...",\n    "metadata": {\n      "title": "Home - Firecrawl",\n      "description": "Firecrawl crawls and converts any website into clean markdown.",\n      "language": "en",\n      "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",\n      "robots": "follow, index",\n      "ogTitle": "Firecrawl",\n      "ogDescription": "Turn any website into LLM-ready data.",\n      "ogUrl": "https://www.firecrawl.dev/",\n      "ogImage": "https://www.firecrawl.dev/og.png?123",\n      "ogLocaleAlternate": [],\n      "ogSiteName": "Firecrawl",\n      "sourceURL": "https://firecrawl.dev",\n      "statusCode": 200\n    }\n  }\n}\n```\n\n### Map\n\nUsed to map a URL and get urls of the website. This returns most links present on the website.\n\n```bash cURL\ncurl -X POST https://api.firecrawl.dev/v2/map \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "url": "https://firecrawl.dev"\n    }''\n```\n\nResponse:\n\n```json\n{\n  "success": true,\n  "links": [\n    { "url": "https://firecrawl.dev", "title": "Firecrawl", "description": "Firecrawl is a tool that allows you to crawl a website and get the data you need." },\n    { "url": "https://www.firecrawl.dev/pricing", "title": "Firecrawl Pricing", "description": "Firecrawl Pricing" },\n    { "url": "https://www.firecrawl.dev/blog", "title": "Firecrawl Blog", "description": "Firecrawl Blog" },\n    { "url": "https://www.firecrawl.dev/playground", "title": "Firecrawl Playground", "description": "Firecrawl Playground" },\n    { "url": "https://www.firecrawl.dev/smart-crawl", "title": "Firecrawl Smart Crawl", "description": "Firecrawl Smart Crawl" }\n  ]\n}\n```\n\n#### Map with search\n\nMap with `search` param allows you to search for specific urls inside a website.\n\n```bash cURL\ncurl -X POST https://api.firecrawl.dev/v2/map \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "url": "https://firecrawl.dev",\n      "search": "docs"\n    }''\n```\n\nResponse will be an ordered list from the most relevant to the least relevant.\n\n```json\n{\n  "success": true,\n  "links": [\n    { "url": "https://docs.firecrawl.dev", "title": "Firecrawl Docs", "description": "Firecrawl Docs" },\n    { "url": "https://docs.firecrawl.dev/sdks/python", "title": "Firecrawl Python SDK", "description": "Firecrawl Python SDK" },\n    { "url": "https://docs.firecrawl.dev/learn/rag-llama3", "title": "Firecrawl RAG Llama 3", "description": "Firecrawl RAG Llama 3" }\n  ]\n}\n```\n\n### Search\n\nSearch the web and get full content from results\n\nFirecrawl‚Äôs search API allows you to perform web searches and optionally scrape the search results in one operation.\n\n- Choose specific output formats (markdown, HTML, links, screenshots)\n- Search the web with customizable parameters (language, country, etc.)\n- Optionally retrieve content from search results in various formats\n- Control the number of results and set timeouts\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/search \\n  -H "Content-Type: application/json" \\n  -H "Authorization: Bearer fc-YOUR_API_KEY" \\n  -d ''{\n    "query": "what is firecrawl?",\n    "limit": 5\n  }''\n```\n\n#### Response\n\n```json\n{\n  "success": true,\n  "data": [\n    {\n      "url": "https://firecrawl.dev",\n      "title": "Firecrawl | Home Page",\n      "description": "Turn websites into LLM-ready data with Firecrawl"\n    },\n    {\n      "url": "https://docs.firecrawl.dev",\n      "title": "Documentation | Firecrawl",\n      "description": "Learn how to use Firecrawl in your own applications"\n    }\n  ]\n}\n```\n\n#### With content scraping\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/search \\n  -H "Content-Type: application/json" \\n  -H "Authorization: Bearer fc-YOUR_API_KEY" \\n  -d ''{\n    "query": "what is firecrawl?",\n    "limit": 5,\n    "scrapeOptions": {\n      "formats": ["markdown", "links"]\n    }\n  }''\n```\n\n### Extract (Beta)\n\nGet structured data from entire websites with a prompt and/or a schema.\n\nYou can extract structured data from one or multiple URLs, including wildcards:\n\nSingle Page:\nExample: https://firecrawl.dev/some-page\n\nMultiple Pages / Full Domain\nExample: https://firecrawl.dev/*\n\nWhen you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/extract \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "urls": [\n        "https://firecrawl.dev/*", \n        "https://docs.firecrawl.dev/", \n        "https://www.ycombinator.com/companies"\n      ],\n      "prompt": "Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.",\n      "schema": {\n        "type": "object",\n        "properties": {\n          "company_mission": {\n            "type": "string"\n          },\n          "is_open_source": {\n            "type": "boolean"\n          },\n          "is_in_yc": {\n            "type": "boolean"\n          }\n        },\n        "required": [\n          "company_mission",\n          "is_open_source",\n          "is_in_yc"\n        ]\n      }\n    }''\n```\n\n```json\n{\n  "success": true,\n  "id": "44aa536d-f1cb-4706-ab87-ed0386685740",\n  "urlTrace": []\n}\n```\n\nIf you are using the sdks, it will auto pull the response for you:\n\n```json\n{\n  "success": true,\n  "data": {\n    "company_mission": "Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.",\n    "supports_sso": false,\n    "is_open_source": true,\n    "is_in_yc": true\n  }\n}\n```\n\n### LLM Extraction (Beta)\n\nUsed to extract structured data from scraped pages.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/scrape \\n  -H ''Content-Type: application/json'' \\n  -H ''Authorization: Bearer YOUR_API_KEY'' \\n  -d ''{\n    "url": "https://www.mendable.ai/",\n    "formats": [\n      {\n        "type": "json",\n        "schema": {\n          "type": "object",\n          "properties": {\n            "company_mission": { "type": "string" },\n            "supports_sso": { "type": "boolean" },\n            "is_open_source": { "type": "boolean" },\n            "is_in_yc": { "type": "boolean" }\n          }\n        }\n      }\n    ]\n  }''\n```\n\n```json\n{\n  "success": true,\n  "data": {\n    "content": "Raw Content",\n    "metadata": {\n      "title": "Mendable",\n      "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",\n      "robots": "follow, index",\n      "ogTitle": "Mendable",\n      "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",\n      "ogUrl": "https://mendable.ai/",\n      "ogImage": "https://mendable.ai/mendable_new_og1.png",\n      "ogLocaleAlternate": [],\n      "ogSiteName": "Mendable",\n      "sourceURL": "https://mendable.ai/"\n    },\n    "json": {\n      "company_mission": "Train a secure AI on your technical resources that answers customer and employee questions so your team doesn''t have to",\n      "supports_sso": true,\n      "is_open_source": false,\n      "is_in_yc": true\n    }\n  }\n}\n```\n\n### Extracting without a schema (New)\n\nYou can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/scrape \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "url": "https://docs.firecrawl.dev/",\n      "formats": [\n        {\n          "type": "json",\n          "prompt": "Extract the company mission from the page."\n        }\n      ]\n    }''\n```\n\n### Interacting with the page with Actions (Cloud-only)\n\nFirecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.\n\nHere is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/scrape \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n        "url": "google.com",\n        "formats": ["markdown"],\n        "actions": [\n            {"type": "wait", "milliseconds": 2000},\n            {"type": "click", "selector": "textarea[title=\"Search\"]"},\n            {"type": "wait", "milliseconds": 2000},\n            {"type": "write", "text": "firecrawl"},\n            {"type": "wait", "milliseconds": 2000},\n            {"type": "press", "key": "ENTER"},\n            {"type": "wait", "milliseconds": 3000},\n            {"type": "click", "selector": "h3"},\n            {"type": "wait", "milliseconds": 3000},\n            {"type": "screenshot"}\n        ]\n    }''\n```\n\n### Batch Scraping Multiple URLs (New)\n\nYou can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.\n\n```bash\ncurl -X POST https://api.firecrawl.dev/v2/batch/scrape \\n    -H ''Content-Type: application/json'' \\n    -H ''Authorization: Bearer YOUR_API_KEY'' \\n    -d ''{\n      "urls": ["https://docs.firecrawl.dev", "https://docs.firecrawl.dev/sdks/overview"],\n      "formats" : ["markdown", "html"]\n    }''\n```\n\n\n\n## Using Python SDK\n\n### Installing Python SDK\n\n```bash\npip install firecrawl-py\n```\n\n### Crawl a website\n\n```python\nfrom firecrawl import Firecrawl\n\nfirecrawl = Firecrawl(api_key="fc-YOUR_API_KEY")\n\n# Scrape a website (returns a Document)\ndoc = firecrawl.scrape(\n    "https://firecrawl.dev",\n    formats=["markdown", "html"],\n)\nprint(doc.markdown)\n\n# Crawl a website\nresponse = firecrawl.crawl(\n    "https://firecrawl.dev",\n    limit=100,\n    scrape_options={"formats": ["markdown", "html"]},\n    poll_interval=30,\n)\nprint(response)\n```\n\n### Extracting structured data from a URL\n\nWith LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:\n\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass Article(BaseModel):\n    title: str\n    points: int\n    by: str\n    commentsURL: str\n\nclass TopArticles(BaseModel):\n    top: List[Article] = Field(..., description="Top 5 stories")\n\n# Use JSON format with a Pydantic schema\ndoc = firecrawl.scrape(\n    "https://news.ycombinator.com",\n    formats=[{"type": "json", "schema": TopArticles}],\n)\nprint(doc.json)\n```\n\n## Using the Node SDK\n\n### Installation\n\nTo install the Firecrawl Node SDK, you can use npm:\n\n```bash\nnpm install @mendable/firecrawl-js\n```\n\n### Usage\n\n1. Get an API key from [firecrawl.dev](https://firecrawl.dev)\n2. Set the API key as an environment variable named `FIRECRAWL_API_KEY` or pass it as a parameter to the `Firecrawl` class.\n\n```js\nimport Firecrawl from ''@mendable/firecrawl-js'';\n\nconst firecrawl = new Firecrawl({ apiKey: ''fc-YOUR_API_KEY'' });\n\n// Scrape a website\nconst doc = await firecrawl.scrape(''https://firecrawl.dev'', {\n  formats: [''markdown'', ''html''],\n});\nconsole.log(doc);\n\n// Crawl a website\nconst response = await firecrawl.crawl(''https://firecrawl.dev'', {\n  limit: 100,\n  scrapeOptions: { formats: [''markdown'', ''html''] },\n});\nconsole.log(response);\n```\n\n\n### Extracting structured data from a URL\n\nWith LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:\n\n```js\nimport Firecrawl from ''@mendable/firecrawl-js'';\nimport { z } from ''zod'';\n\nconst firecrawl = new Firecrawl({ apiKey: ''fc-YOUR_API_KEY'' });\n\n// Define schema to extract contents into\nconst schema = z.object({\n  top: z\n    .array(\n      z.object({\n        title: z.string(),\n        points: z.number(),\n        by: z.string(),\n        commentsURL: z.string(),\n      })\n    )\n    .length(5)\n    .describe(''Top 5 stories on Hacker News''),\n});\n\n// Use the v2 extract API with direct Zod schema support\nconst extractRes = await firecrawl.extract({\n  urls: [''https://news.ycombinator.com''],\n  schema,\n  prompt: ''Extract the top 5 stories'',\n});\n\nconsole.log(extractRes);\n```\n\n## Open Source vs Cloud Offering\n\nFirecrawl is open source available under the AGPL-3.0 license. \n\nTo deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.\n\nFirecrawl Cloud is available at [firecrawl.dev](https://firecrawl.dev) and offers a range of features that are not available in the open source version:\n\n![Open Source vs Cloud Offering](https://raw.githubusercontent.com/firecrawl/firecrawl/main/img/open-source-cloud.png)\n\n\n## Contributing\n\nWe love contributions! Please read our [contributing guide](CONTRIBUTING.md) before submitting a pull request. If you''d like to self-host, refer to the [self-hosting guide](SELF_HOST.md).\n\n_It is the sole responsibility of the end users to respect websites'' policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites'' robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions._\n\n## Contributors\n\n<a href="https://github.com/firecrawl/firecrawl/graphs/contributors">\n  <img alt="contributors" src="https://contrib.rocks/image?repo=firecrawl/firecrawl"/>\n</a>\n\n## License Disclaimer\n\nThis project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.\n\nPlease note:\n\n- The AGPL-3.0 license applies to all parts of the project unless otherwise specified.\n- The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.\n- When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.\n\nFor more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.\n\n\n<p align="right" style="font-size: 14px; color: #555; margin-top: 20px;">\n    <a href="#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;">\n        ‚Üë Back to Top ‚Üë\n    </a>\n</p>\n', '{"language":"TypeScript","stars":69325,"forks":5437,"watchers":69325,"open_issues":132,"topics":["ai","ai-agents","ai-crawler","ai-scraping","ai-search","crawler","data-extraction","html-to-markdown","llm","markdown","scraper","scraping","web-crawler","web-data","web-data-extraction","web-scraper","web-scraping","web-search","webscraping"],"default_branch":"main","size_kb":80176,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:firecrawl:firecrawl","source_url":"https://github.com/firecrawl/firecrawl"},{"type":"has_code","target_id":"github:firecrawl:firecrawl-mcp-server","source_url":"https://github.com/firecrawl/firecrawl-mcp-server"},{"type":"has_code","target_id":"github:firecrawl:firecrawl\">","source_url":"https://github.com/firecrawl/firecrawl\">"},{"type":"has_code","target_id":"github:firecrawl:firecrawl","source_url":"https://github.com/firecrawl/firecrawl"},{"type":"has_code","target_id":"github:firecrawl:firecrawl","source_url":"https://github.com/firecrawl/firecrawl"}]', NULL, 'AGPL-3.0', 'approved', 80, '7e7fb4a3b13aba51d270dcb47e2a72f9', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-firecrawl-firecrawl from https://github.com/firecrawl.png
Image converted to WebP: data/images/github-firecrawl-firecrawl.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-lobehub-lobe-chat', 'github--lobehub--lobe-chat', 'lobe-chat', 'lobehub', '> \[!NOTE] > > **Version Information** > > - **v1.x** (Stable): Available on the [](https://github.com/lobehub/lobe-chat/tree/main) branch > - **v2.x** (In Development): Currently being actively developed on the [](https://github.com/lobehub/lobe-chat/tree/next) branch üî• <div align="center"><a name="readme-top"></a> [![][image-banner]][vercel-link] An open-source, modern design ChatGPT/LLMs UI/framework.<br/> Supports speech synthesis, multi-modal, and extensible ([function call][docs-functi...', '["agent","ai","artifacts","chat","chatgpt","claude","deepseek","deepseek-r1","function-calling","gemini","gpt","knowledge-base","mcp","nextjs","ollama","openai","rag","typescript"]', 'other', 68749, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/lobehub/lobe-chat","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '> \[!NOTE]\n>\n> **Version Information**\n>\n> - **v1.x** (Stable): Available on the [`main`](https://github.com/lobehub/lobe-chat/tree/main) branch\n> - **v2.x** (In Development): Currently being actively developed on the [`next`](https://github.com/lobehub/lobe-chat/tree/next) branch üî•\n\n<div align="center"><a name="readme-top"></a>\n\n[![][image-banner]][vercel-link]\n\n# Lobe Chat\n\nAn open-source, modern design ChatGPT/LLMs UI/framework.<br/>\nSupports speech synthesis, multi-modal, and extensible ([function call][docs-function-call]) plugin system.<br/>\nOne-click **FREE** deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.\n\n**English** ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md) ¬∑ [Official Site][official-site] ¬∑ [Changelog][changelog] ¬∑ [Documents][docs] ¬∑ [Blog][blog] ¬∑ [Feedback][github-issues-link]\n\n<!-- SHIELD GROUP -->\n\n[![][github-release-shield]][github-release-link]\n[![][docker-release-shield]][docker-release-link]\n[![][vercel-shield]][vercel-link]\n[![][discord-shield]][discord-link]<br/>\n[![][codecov-shield]][codecov-link]\n[![][github-action-test-shield]][github-action-test-link]\n[![][github-action-release-shield]][github-action-release-link]\n[![][github-releasedate-shield]][github-releasedate-link]<br/>\n[![][github-contributors-shield]][github-contributors-link]\n[![][github-forks-shield]][github-forks-link]\n[![][github-stars-shield]][github-stars-link]\n[![][github-issues-shield]][github-issues-link]\n[![][github-license-shield]][github-license-link]<br>\n[![][sponsor-shield]][sponsor-link]\n\n**Share LobeChat Repository**\n\n[![][share-x-shield]][share-x-link]\n[![][share-telegram-shield]][share-telegram-link]\n[![][share-whatsapp-shield]][share-whatsapp-link]\n[![][share-reddit-shield]][share-reddit-link]\n[![][share-weibo-shield]][share-weibo-link]\n[![][share-mastodon-shield]][share-mastodon-link]\n[![][share-linkedin-shield]][share-linkedin-link]\n\n<sup>Pioneering the new age of thinking and creating. Built for you, the Super Individual.</sup>\n\n[![][github-trending-shield]][github-trending-url] <br /> <br /> <a href="https://vercel.com/oss"> <img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg" /> </a>\n\n![][image-overview]\n\n</div>\n\n<details>\n<summary><kbd>Table of contents</kbd></summary>\n\n#### TOC\n\n- [üëãüèª Getting Started & Join Our Community](#-getting-started--join-our-community)\n- [‚ú® Features](#-features)\n  - [‚ú® MCP Plugin One-Click Installation](#-mcp-plugin-one-click-installation)\n  - [üè™ MCP Marketplace](#-mcp-marketplace)\n  - [üñ•Ô∏è Desktop App](#Ô∏è-desktop-app)\n  - [üåê Smart Internet Search](#-smart-internet-search)\n  - [Chain of Thought](#chain-of-thought)\n  - [Branching Conversations](#branching-conversations)\n  - [Artifacts Support](#artifacts-support)\n  - [File Upload /Knowledge Base](#file-upload-knowledge-base)\n  - [Multi-Model Service Provider Support](#multi-model-service-provider-support)\n  - [Local Large Language Model (LLM) Support](#local-large-language-model-llm-support)\n  - [Model Visual Recognition](#model-visual-recognition)\n  - [TTS & STT Voice Conversation](#tts--stt-voice-conversation)\n  - [Text to Image Generation](#text-to-image-generation)\n  - [Plugin System (Function Calling)](#plugin-system-function-calling)\n  - [Agent Market (GPTs)](#agent-market-gpts)\n  - [Support Local / Remote Database](#support-local--remote-database)\n  - [Support Multi-User Management](#support-multi-user-management)\n  - [Progressive Web App (PWA)](#progressive-web-app-pwa)\n  - [Mobile Device Adaptation](#mobile-device-adaptation)\n  - [Custom Themes](#custom-themes)\n  - [`*` What''s more](#-whats-more)\n- [‚ö°Ô∏è Performance](#Ô∏è-performance)\n- [üõ≥ Self Hosting](#-self-hosting)\n  - [`A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud](#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud)\n  - [`B` Deploying with Docker](#b-deploying-with-docker)\n  - [Environment Variable](#environment-variable)\n- [üì¶ Ecosystem](#-ecosystem)\n- [üß© Plugins](#-plugins)\n- [‚å®Ô∏è Local Development](#Ô∏è-local-development)\n- [ü§ù Contributing](#-contributing)\n- [‚ù§Ô∏è Sponsor](#Ô∏è-sponsor)\n- [üîó More Products](#-more-products)\n\n####\n\n<br/>\n\n</details>\n\n## üëãüèª Getting Started & Join Our Community\n\nWe are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC.\nBy adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.\n\nWhether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any [issues][issues-link] encountered.\n\n| [![][vercel-shield-badge]][vercel-link]   | No installation or registration necessary! Visit our website to experience it firsthand.                           |\n| :---------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |\n| [![][discord-shield-badge]][discord-link] | Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub. |\n\n> \[!IMPORTANT]\n>\n> **Star Us**, You will receive all release notifications from GitHub without any delay \~ ‚≠êÔ∏è\n\n[![][image-star]][github-stars-link]\n\n<details>\n  <summary><kbd>Star History</kbd></summary>\n  <picture>\n    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&theme=dark&type=Date">\n    <img width="100%" src="https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&type=Date">\n  </picture>\n</details>\n\n## ‚ú® Features\n\nTransform your AI experience with LobeChat''s powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.\n\n![][image-feat-mcp]\n\n### ‚ú® MCP Plugin One-Click Installation\n\n**Seamlessly Connect Your AI to the World**\n\nUnlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat''s MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.\n\nTransform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.\n\n[![][back-to-top]](#readme-top)\n\n![][image-feat-mcp-market]\n\n### üè™ MCP Marketplace\n\n**Discover, Connect, Extend**\n\nBrowse a growing library of MCP plugins to expand your AI''s capabilities and streamline your workflows effortlessly. Visit [lobehub.com/mcp](https://lobehub.com/mcp) to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI''s ability to work with various tools and services.\n\nFrom productivity tools to development environments, discover new ways to extend your AI''s reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.\n\n[![][back-to-top]](#readme-top)\n\n![][image-feat-desktop]\n\n### üñ•Ô∏è Desktop App\n\n**Peak Performance, Zero Distractions**\n\nGet the full LobeChat experience without browser limitations‚Äîcomprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.\n\nExperience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.\n\n[![][back-to-top]](#readme-top)\n\n![][image-feat-web-search]\n\n### üåê Smart Internet Search\n\n**Online Knowledge On Demand**\n\nWith real-time internet access, your AI keeps up with the world‚Äînews, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.\n\nAccess live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world''s knowledge, always current and comprehensive.\n\n[![][back-to-top]](#readme-top)\n\n[![][image-feat-cot]][docs-feat-cot]\n\n### [Chain of Thought][docs-feat-cot]\n\nExperience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI''s decision-making process, allowing you to observe how conclusions are reached in real-time.\n\nBy breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI''s problem-solving approach. Whether you''re debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.\n\n[![][back-to-top]](#readme-top)\n\n[![][image-feat-branch]][docs-feat-branch]\n\n### [Branching Conversations][docs-feat-branch]\n\nIntroducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.\n\nChoose between two powerful modes:\n\n- **Continuation Mode:** Seamlessly extend your current discussion while maintaining valuable context\n- **Standalone Mode:** Start fresh with a new topic based on any previous message\n\nThis groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.\n\n[![][back-to-top]](#readme-top)\n\n[![][image-feat-artifacts]][docs-feat-artifacts]\n\n### [Artifacts Support][docs-feat-artifacts]\n\nExperience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.\n\nCreate and visualize with unprecedented flexibility:\n\n- Generate and display dynamic SVG graphics\n- Build and render interactive HTML pages in real-time\n- Produce professional documents in multiple formats\n\n[![][back-to-top]](#readme-top)\n\n[![][image-feat-knowledgebase]][docs-feat-knowledgebase]\n\n### [File Upload /Knowledge Base][docs-feat-knowledgebase]\n\nLobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.\n\n<https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175>\n\n> \[!TIP]\n>\n> Learn more on [üìò LobeChat Knowledge Base Launch ‚Äî From Now On, Every Step Counts](https://lobehub.com/blog/knowledge-base)\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-privoder]][docs-feat-provider]\n\n### [Multi-Model Service Provider Support][docs-feat-provider]\n\nIn the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.\n\nIn this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.\n\n#### Supported Model Service Providers\n\nWe have implemented support for the following model service providers:\n\n<!-- PROVIDER LIST -->\n\n<details><summary><kbd>See more providers (+-10)</kbd></summary>\n\n</details>\n\n> üìä Total providers: [<kbd>**0**</kbd>](https://lobechat.com/discover/providers)\n\n <!-- PROVIDER LIST -->\n\nAt the same time, we are also planning to support more model service providers. If you would like LobeChat to support your favorite service provider, feel free to join our [üí¨ community discussion](https://github.com/lobehub/lobe-chat/discussions/1284).\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-local]][docs-feat-local]\n\n### [Local Large Language Model (LLM) Support][docs-feat-local]\n\nTo meet the specific needs of users, LobeChat also supports the use of local models based on [Ollama](https://ollama.ai), allowing users to flexibly use their own or third-party models.\n\n> \[!TIP]\n>\n> Learn more about [üìò Using Ollama in LobeChat][docs-usage-ollama] by checking it out.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-vision]][docs-feat-vision]\n\n### [Model Visual Recognition][docs-feat-vision]\n\nLobeChat now supports OpenAI''s latest [`gpt-4-vision`](https://platform.openai.com/docs/guides/vision) model with visual recognition capabilities,\na multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box,\nand the agent will be able to recognize the content of the images and engage in intelligent conversation based on this,\ncreating smarter and more diversified chat scenarios.\n\nThis feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements.\nWhether it''s sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-tts]][docs-feat-tts]\n\n### [TTS & STT Voice Conversation][docs-feat-tts]\n\nLobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs,\nallowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.\n\nMoreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy.\nIn LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds.\nUsers can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-t2i]][docs-feat-t2i]\n\n### [Text to Image Generation][docs-feat-t2i]\n\nWith support for the latest text-to-image generation technology, LobeChat now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as [`DALL-E 3`](https://openai.com/dall-e-3), [`MidJourney`](https://www.midjourney.com/), and [`Pollinations`](https://pollinations.ai/), the agents are now equipped to transform your ideas into images.\n\nThis enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-plugin]][docs-feat-plugin]\n\n### [Plugin System (Function Calling)][docs-feat-plugin]\n\nThe plugin ecosystem of LobeChat is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeChat assistant.\n\n<video controls src="https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2" muted="false"></video>\n\nBy utilizing plugins, LobeChat assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.\n\nIn addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.\n\n> \[!TIP]\n>\n> Learn more about [üìò Plugin Usage][docs-usage-plugin] by checking it out.\n\n<!-- PLUGIN LIST -->\n\n| Recent Submits                                                                                                              | Description                                                                                                                               |\n| --------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n| [AladinBooks](https://lobechat.com/discover/plugin/AladinSearchBooks)<br/><sup>By **azurewebsites** on **2025-12-08**</sup> | Search for books on Aladin.<br/>`book` `search`                                                                                           |\n| [PortfolioMeta](https://lobechat.com/discover/plugin/StockData)<br/><sup>By **portfoliometa** on **2025-11-28**</sup>       | Analyze stocks and get comprehensive real-time investment data and analytics.<br/>`stock`                                                 |\n| [SEO](https://lobechat.com/discover/plugin/SEO)<br/><sup>By **orrenprunckun** on **2025-11-14**</sup>                       | Enter any URL and keyword and get an On-Page SEO analysis & insights!<br/>`seo`                                                           |\n| [Shopping tools](https://lobechat.com/discover/plugin/ShoppingTools)<br/><sup>By **shoppingtools** on **2025-10-27**</sup>  | Search for products on eBay & AliExpress, find eBay events & coupons. Get prompt examples.<br/>`shopping` `e-bay` `ali-express` `coupons` |\n\n> üìä Total plugins: [<kbd>**41**</kbd>](https://lobechat.com/discover/plugins)\n\n <!-- PLUGIN LIST -->\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-agent]][docs-feat-agent]\n\n### [Agent Market (GPTs)][docs-feat-agent]\n\nIn LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents,\nwhich not only play an important role in work scenarios but also offer great convenience in learning processes.\nOur marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.\n\n> \[!TIP]\n>\n> By [ü§ñ/üè™ Submit Agents][submit-agents-link], you can easily submit your agent creations to our platform.\n> Importantly, LobeChat has established a sophisticated automated internationalization (i18n) workflow,\n> capable of seamlessly translating your agent into multiple language versions.\n> This means that no matter what language your users speak, they can experience your agent without barriers.\n\n> \[!IMPORTANT]\n>\n> We welcome all users to join this growing ecosystem and participate in the iteration and optimization of agents.\n> Together, we can create more interesting, practical, and innovative agents, further enriching the diversity and practicality of the agent offerings.\n\n<!-- AGENT LIST -->\n\n| Recent Submits                                                                                                                                                                 | Description                                                                                                                                                                                                              |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| [Turtle Soup Host](https://lobechat.com/discover/assistant/lateral-thinking-puzzle)<br/><sup>By **[CSY2022](https://github.com/CSY2022)** on **2025-06-19**</sup>              | A turtle soup host needs to provide the scenario, the complete story (truth of the event), and the key point (the condition for guessing correctly).<br/>`turtle-soup` `reasoning` `interaction` `puzzle` `role-playing` |\n| [Gourmet Reviewerüçü](https://lobechat.com/discover/assistant/food-reviewer)<br/><sup>By **[renhai-lab](https://github.com/renhai-lab)** on **2025-06-17**</sup>                | Food critique expert<br/>`gourmet` `review` `writing`                                                                                                                                                                    |\n| [Academic Writing Assistant](https://lobechat.com/discover/assistant/academic-writing-assistant)<br/><sup>By **[swarfte](https://github.com/swarfte)** on **2025-06-17**</sup> | Expert in academic research paper writing and formal documentation<br/>`academic-writing` `research` `formal-style`                                                                                                      |\n| [Minecraft Senior Developer](https://lobechat.com/discover/assistant/java-development)<br/><sup>By **[iamyuuk](https://github.com/iamyuuk)** on **2025-06-17**</sup>           | Expert in advanced Java development and Minecraft mod and server plugin development<br/>`development` `programming` `minecraft` `java`                                                                                   |\n\n> üìä Total agents: [<kbd>**505**</kbd> ](https://lobechat.com/discover/assistants)\n\n <!-- AGENT LIST -->\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-database]][docs-feat-database]\n\n### [Support Local / Remote Database][docs-feat-database]\n\nLobeChat supports the use of both server-side and local databases. Depending on your needs, you can choose the appropriate deployment solution:\n\n- **Local database**: suitable for users who want more control over their data and privacy protection. LobeChat uses CRDT (Conflict-Free Replicated Data Type) technology to achieve multi-device synchronization. This is an experimental feature aimed at providing a seamless data synchronization experience.\n- **Server-side database**: suitable for users who want a more convenient user experience. LobeChat supports PostgreSQL as a server-side database. For detailed documentation on how to configure the server-side database, please visit [Configure Server-side Database](https://lobehub.com/docs/self-hosting/advanced/server-database).\n\nRegardless of which database you choose, LobeChat can provide you with an excellent user experience.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-auth]][docs-feat-auth]\n\n### [Support Multi-User Management][docs-feat-auth]\n\nLobeChat supports multi-user management and provides two main user authentication and management solutions to meet different needs:\n\n- **next-auth**: LobeChat integrates `next-auth`, a flexible and powerful identity verification library that supports multiple authentication methods, including OAuth, email login, credential login, etc. With `next-auth`, you can easily implement user registration, login, session management, social login, and other functions to ensure the security and privacy of user data.\n\n- [**Clerk**](https://go.clerk.com/exgqLG0): For users who need more advanced user management features, LobeChat also supports `Clerk`, a modern user management platform. `Clerk` provides richer functions, such as multi-factor authentication (MFA), user profile management, login activity monitoring, etc. With `Clerk`, you can get higher security and flexibility, and easily cope with complex user management needs.\n\nRegardless of which user management solution you choose, LobeChat can provide you with an excellent user experience and powerful functional support.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-pwa]][docs-feat-pwa]\n\n### [Progressive Web App (PWA)][docs-feat-pwa]\n\nWe deeply understand the importance of providing a seamless experience for users in today''s multi-device environment.\nTherefore, we have adopted Progressive Web Application ([PWA](https://support.google.com/chrome/answer/9658361)) technology,\na modern web technology that elevates web applications to an experience close to that of native apps.\n\nThrough PWA, LobeChat can offer a highly optimized user experience on both desktop and mobile devices while maintaining high-performance characteristics.\nVisually and in terms of feel, we have also meticulously designed the interface to ensure it is indistinguishable from native apps,\nproviding smooth animations, responsive layouts, and adapting to different device screen resolutions.\n\n> \[!NOTE]\n>\n> If you are unfamiliar with the installation process of PWA, you can add LobeChat as your desktop application (also applicable to mobile devices) by following these steps:\n>\n> - Launch the Chrome or Edge browser on your computer.\n> - Visit the LobeChat webpage.\n> - In the upper right corner of the address bar, click on the <kbd>Install</kbd> icon.\n> - Follow the instructions on the screen to complete the PWA Installation.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-mobile]][docs-feat-mobile]\n\n### [Mobile Device Adaptation][docs-feat-mobile]\n\nWe have carried out a series of optimization designs for mobile devices to enhance the user''s mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n[![][image-feat-theme]][docs-feat-theme]\n\n### [Custom Themes][docs-feat-theme]\n\nAs a design-engineering-oriented application, LobeChat places great emphasis on users'' personalized experiences,\nhence introducing flexible and diverse theme modes, including a light mode for daytime and a dark mode for nighttime.\nBeyond switching theme modes, a range of color customization options allow users to adjust the application''s theme colors according to their preferences.\nWhether it''s a desire for a sober dark blue, a lively peach pink, or a professional gray-white, users can find their style of color choices in LobeChat.\n\n> \[!TIP]\n>\n> The default configuration can intelligently recognize the user''s system color mode and automatically switch themes to ensure a consistent visual experience with the operating system.\n> For users who like to manually control details, LobeChat also offers intuitive setting options and a choice between chat bubble mode and document mode for conversation scenarios.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n### `*` What''s more\n\nBeside these features, LobeChat also have much better basic technique underground:\n\n- [x] üí® **Quick Deployment**: Using the Vercel platform or docker image, you can deploy with just one click and complete the process within 1 minute without any complex configuration.\n- [x] üåê **Custom Domain**: If users have their own domain, they can bind it to the platform for quick access to the dialogue agent from anywhere.\n- [x] üîí **Privacy Protection**: All data is stored locally in the user''s browser, ensuring user privacy.\n- [x] üíé **Exquisite UI Design**: With a carefully designed interface, it offers an elegant appearance and smooth interaction. It supports light and dark themes and is mobile-friendly. PWA support provides a more native-like experience.\n- [x] üó£Ô∏è **Smooth Conversation Experience**: Fluid responses ensure a smooth conversation experience. It fully supports Markdown rendering, including code highlighting, LaTex formulas, Mermaid flowcharts, and more.\n\n> ‚ú® more features will be added when LobeChat evolve.\n\n---\n\n> \[!NOTE]\n>\n> You can find our upcoming [Roadmap][github-project-link] plans in the Projects section.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## ‚ö°Ô∏è Performance\n\n> \[!NOTE]\n>\n> The complete list of reports can be found in the [üìò Lighthouse Reports][docs-lighthouse]\n\n|                   Desktop                   |                   Mobile                   |\n| :-----------------------------------------: | :----------------------------------------: |\n|              ![][chat-desktop]              |              ![][chat-mobile]              |\n| [üìë Lighthouse Report][chat-desktop-report] | [üìë Lighthouse Report][chat-mobile-report] |\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## üõ≥ Self Hosting\n\nLobeChat provides Self-Hosted Version with Vercel, Alibaba Cloud, and [Docker Image][docker-release-link]. This allows you to deploy your own chatbot within a few minutes without any prior knowledge.\n\n> \[!TIP]\n>\n> Learn more about [üìò Build your own LobeChat][docs-self-hosting] by checking it out.\n\n### `A` Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud\n\n"If you want to deploy this service yourself on Vercel, Zeabur or Alibaba Cloud, you can follow these steps:\n\n- Prepare your [OpenAI API Key](https://platform.openai.com/account/api-keys).\n- Click the button below to start deployment: Log in directly with your GitHub account, and remember to fill in the `OPENAI_API_KEY`(required) and `ACCESS_CODE` (recommended) on the environment variable section.\n- After deployment, you can start using it.\n- Bind a custom domain (optional): The DNS of the domain assigned by Vercel is polluted in some areas; binding a custom domain can connect directly.\n\n<div align="center">\n\n|           Deploy with Vercel            |                     Deploy with Zeabur                      |                     Deploy with Sealos                      |                       Deploy with RepoCloud                       |                         Deploy with Alibaba Cloud                         |\n| :-------------------------------------: | :---------------------------------------------------------: | :---------------------------------------------------------: | :---------------------------------------------------------------: | :-----------------------------------------------------------------------: |\n| [![][deploy-button-image]][deploy-link] | [![][deploy-on-zeabur-button-image]][deploy-on-zeabur-link] | [![][deploy-on-sealos-button-image]][deploy-on-sealos-link] | [![][deploy-on-repocloud-button-image]][deploy-on-repocloud-link] | [![][deploy-on-alibaba-cloud-button-image]][deploy-on-alibaba-cloud-link] |\n\n</div>\n\n#### After Fork\n\nAfter fork, only retain the upstream sync action and disable other actions in your repository on GitHub.\n\n#### Keep Updated\n\nIf you have deployed your own project following the one-click deployment steps in the README, you might encounter constant prompts indicating "updates available." This is because Vercel defaults to creating a new project instead of forking this one, resulting in an inability to detect updates accurately.\n\n> \[!TIP]\n>\n> We suggest you redeploy using the following steps, [üìò Auto Sync With Latest][docs-upstream-sync]\n\n<br/>\n\n### `B` Deploying with Docker\n\n[![][docker-release-shield]][docker-release-link]\n[![][docker-size-shield]][docker-size-link]\n[![][docker-pulls-shield]][docker-pulls-link]\n\nWe provide a Docker image for deploying the LobeChat service on your own private device. Use the following command to start the LobeChat service:\n\n1. create a folder to for storage files\n\n```fish\n$ mkdir lobe-chat-db && cd lobe-chat-db\n```\n\n2. init the LobeChat infrastructure\n\n```fish\nbash <(curl -fsSL https://lobe.li/setup.sh)\n```\n\n3. Start the LobeChat service\n\n```fish\ndocker compose up -d\n```\n\n> \[!NOTE]\n>\n> For detailed instructions on deploying with Docker, please refer to the [üìò Docker Deployment Guide][docs-docker]\n\n<br/>\n\n### Environment Variable\n\nThis project provides some additional configuration items set with environment variables:\n\n| Environment Variable | Required | Description                                                                                                                                                               | Example                                                                                                              |\n| -------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n| `OPENAI_API_KEY`     | Yes      | This is the API key you apply on the OpenAI account page                                                                                                                  | `sk-xxxxxx...xxxxxx`                                                                                                 |\n| `OPENAI_PROXY_URL`   | No       | If you manually configure the OpenAI interface proxy, you can use this configuration item to override the default OpenAI API request base URL                             | `https://api.chatanywhere.cn` or `https://aihubmix.com/v1` <br/>The default value is<br/>`https://api.openai.com/v1` |\n| `ACCESS_CODE`        | No       | Add a password to access this service; you can set a long password to avoid leaking. If this value contains a comma, it is a password array.                              | `awCTe)re_r74` or `rtrt_ewee3@09!` or `code1,code2,code3`                                                            |\n| `OPENAI_MODEL_LIST`  | No       | Used to control the model list. Use `+` to add a model, `-` to hide a model, and `model_name=display_name` to customize the display name of a model, separated by commas. | `qwen-7b-chat,+glm-6b,-gpt-3.5-turbo`                                                                                |\n\n> \[!NOTE]\n>\n> The complete list of environment variables can be found in the [üìò Environment Variables][docs-env-var]\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## üì¶ Ecosystem\n\n| NPM                               | Repository                              | Description                                                                                           | Version                                   |\n| --------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------------------------------- | ----------------------------------------- |\n| [@lobehub/ui][lobe-ui-link]       | [lobehub/lobe-ui][lobe-ui-github]       | Open-source UI component library dedicated to building AIGC web applications.                         | [![][lobe-ui-shield]][lobe-ui-link]       |\n| [@lobehub/icons][lobe-icons-link] | [lobehub/lobe-icons][lobe-icons-github] | Popular AI / LLM Model Brand SVG Logo and Icon Collection.                                            | [![][lobe-icons-shield]][lobe-icons-link] |\n| [@lobehub/tts][lobe-tts-link]     | [lobehub/lobe-tts][lobe-tts-github]     | High-quality & reliable TTS/STT React Hooks library                                                   | [![][lobe-tts-shield]][lobe-tts-link]     |\n| [@lobehub/lint][lobe-lint-link]   | [lobehub/lobe-lint][lobe-lint-github]   | Configurations for ESlint, Stylelint, Commitlint, Prettier, Remark, and Semantic Release for LobeHub. | [![][lobe-lint-shield]][lobe-lint-link]   |\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## üß© Plugins\n\nPlugins provide a means to extend the [Function Calling][docs-function-call] capabilities of LobeChat. They can be used to introduce new function calls and even new ways to render message results. If you are interested in plugin development, please refer to our [üìò Plugin Development Guide][docs-plugin-dev] in the Wiki.\n\n- [lobe-chat-plugins][lobe-chat-plugins]: This is the plugin index for LobeChat. It accesses index.json from this repository to display a list of available plugins for LobeChat to the user.\n- [chat-plugin-template][chat-plugin-template]: This is the plugin template for LobeChat plugin development.\n- [@lobehub/chat-plugin-sdk][chat-plugin-sdk]: The LobeChat Plugin SDK assists you in creating exceptional chat plugins for Lobe Chat.\n- [@lobehub/chat-plugins-gateway][chat-plugins-gateway]: The LobeChat Plugins Gateway is a backend service that provides a gateway for LobeChat plugins. We deploy this service using Vercel. The primary API POST /api/v1/runner is deployed as an Edge Function.\n\n> \[!NOTE]\n>\n> The plugin system is currently undergoing major development. You can learn more in the following issues:\n>\n> - [x] [**Plugin Phase 1**](https://github.com/lobehub/lobe-chat/issues/73): Implement separation of the plugin from the main body, split the plugin into an independent repository for maintenance, and realize dynamic loading of the plugin.\n> - [x] [**Plugin Phase 2**](https://github.com/lobehub/lobe-chat/issues/97): The security and stability of the plugin''s use, more accurately presenting abnormal states, the maintainability of the plugin architecture, and developer-friendly.\n> - [x] [**Plugin Phase 3**](https://github.com/lobehub/lobe-chat/issues/149): Higher-level and more comprehensive customization capabilities, support for plugin authentication, and examples.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## ‚å®Ô∏è Local Development\n\nYou can use GitHub Codespaces for online development:\n\n[![][codespaces-shield]][codespaces-link]\n\nOr clone it for local development:\n\n```fish\n$ git clone https://github.com/lobehub/lobe-chat.git\n$ cd lobe-chat\n$ pnpm install\n$ pnpm dev\n```\n\nIf you would like to learn more details, please feel free to look at our [üìò Development Guide][docs-dev-guide].\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## ü§ù Contributing\n\nContributions of all types are more than welcome; if you are interested in contributing code, feel free to check out our GitHub [Issues][github-issues-link] and [Projects][github-project-link] to get stuck in to show us what you''re made of.\n\n> \[!TIP]\n>\n> We are creating a technology-driven forum, fostering knowledge interaction and the exchange of ideas that may culminate in mutual inspiration and collaborative innovation.\n>\n> Help us make LobeChat better. Welcome to provide product design feedback, user experience discussions directly to us.\n>\n> **Principal Maintainers:** [@arvinxx](https://github.com/arvinxx) [@canisminor1990](https://github.com/canisminor1990)\n\n[![][pr-welcome-shield]][pr-welcome-link]\n[![][submit-agents-shield]][submit-agents-link]\n[![][submit-plugin-shield]][submit-plugin-link]\n\n<a href="https://github.com/lobehub/lobe-chat/graphs/contributors" target="_blank">\n  <table>\n    <tr>\n      <th colspan="2">\n        <br><img src="https://contrib.rocks/image?repo=lobehub/lobe-chat"><br><br>\n      </th>\n    </tr>\n    <tr>\n      <td>\n        <picture>\n          <source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=2x3&color_scheme=dark">\n          <img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=2x3&color_scheme=light">\n        </picture>\n      </td>\n      <td rowspan="2">\n        <picture>\n          <source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=4x7&color_scheme=dark">\n          <img src="https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=4x7&color_scheme=light">\n        </picture>\n      </td>\n    </tr>\n    <tr>\n      <td>\n        <picture>\n          <source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=2x3&color_scheme=dark">\n          <img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&period=past_28_days&owner_id=131470832&repo_ids=643445235&image_size=2x3&color_scheme=light">\n        </picture>\n      </td>\n    </tr>\n  </table>\n</a>\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## ‚ù§Ô∏è Sponsor\n\nEvery bit counts and your one-time donation sparkles in our galaxy of support! You''re a shooting star, making a swift and bright impact on our journey. Thank you for believing in us ‚Äì your generosity guides us toward our mission, one brilliant flash at a time.\n\n<a href="https://opencollective.com/lobehub" target="_blank">\n  <picture>\n    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/lobehub/.github/blob/main/static/sponsor-dark.png?raw=true">\n    <img  src="https://github.com/lobehub/.github/blob/main/static/sponsor-light.png?raw=true">\n  </picture>\n</a>\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n## üîó More Products\n\n- **[üÖ∞Ô∏è Lobe SD Theme][lobe-theme]:** Modern theme for Stable Diffusion WebUI, exquisite interface design, highly customizable UI, and efficiency-boosting features.\n- **[‚õµÔ∏è Lobe Midjourney WebUI][lobe-midjourney-webui]:** WebUI for Midjourney, leverages AI to quickly generate a wide array of rich and diverse images from text prompts, sparking creativity and enhancing conversations.\n- **[üåè Lobe i18n][lobe-i18n] :** Lobe i18n is an automation tool for the i18n (internationalization) translation process, powered by ChatGPT. It supports features such as automatic splitting of large files, incremental updates, and customization options for the OpenAI model, API proxy, and temperature.\n- **[üíå Lobe Commit][lobe-commit]:** Lobe Commit is a CLI tool that leverages Langchain/ChatGPT to generate Gitmoji-based commit messages.\n\n<div align="right">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\n<details><summary><h4>üìù License</h4></summary>\n\n[![][fossa-license-shield]][fossa-license-link]\n\n</details>\n\nCopyright ¬© 2025 [LobeHub][profile-link]. <br />\nThis project is [LobeHub Community License](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square\n[blog]: https://lobehub.com/blog\n[changelog]: https://lobehub.com/changelog\n[chat-desktop]: https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/desktop/pagespeed.svg\n[chat-desktop-report]: https://lobehub.github.io/lobe-chat/lighthouse/chat/desktop/chat_preview_lobehub_com_chat.html\n[chat-mobile]: https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/mobile/pagespeed.svg\n[chat-mobile-report]: https://lobehub.github.io/lobe-chat/lighthouse/chat/mobile/chat_preview_lobehub_com_chat.html\n[chat-plugin-sdk]: https://github.com/lobehub/chat-plugin-sdk\n[chat-plugin-template]: https://github.com/lobehub/chat-plugin-template\n[chat-plugins-gateway]: https://github.com/lobehub/chat-plugins-gateway\n[codecov-link]: https://codecov.io/gh/lobehub/lobe-chat\n[codecov-shield]: https://img.shields.io/codecov/c/github/lobehub/lobe-chat?labelColor=black&style=flat-square&logo=codecov&logoColor=white\n[codespaces-link]: https://codespaces.new/lobehub/lobe-chat\n[codespaces-shield]: https://github.com/codespaces/badge.svg\n[deploy-button-image]: https://vercel.com/button\n[deploy-link]: https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&env=OPENAI_API_KEY,ACCESS_CODE&envDescription=Find%20your%20OpenAI%20API%20Key%20by%20click%20the%20right%20Learn%20More%20button.%20%7C%20Access%20Code%20can%20protect%20your%20website&envLink=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys&project-name=lobe-chat&repository-name=lobe-chat\n[deploy-on-alibaba-cloud-button-image]: https://service-info-public.oss-cn-hangzhou.aliyuncs.com/computenest-en.svg\n[deploy-on-alibaba-cloud-link]: https://computenest.console.aliyun.com/service/instance/create/default?type=user&ServiceName=LobeChat%E7%A4%BE%E5%8C%BA%E7%89%88\n[deploy-on-repocloud-button-image]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[deploy-on-repocloud-link]: https://repocloud.io/details/?app_id=248\n[deploy-on-sealos-button-image]: https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg\n[deploy-on-sealos-link]: https://template.usw.sealos.io/deploy?templateName=lobe-chat-db\n[deploy-on-zeabur-button-image]: https://zeabur.com/button.svg\n[deploy-on-zeabur-link]: https://zeabur.com/templates/VZGGTI\n[discord-link]: https://discord.gg/AYFPHvv2jT\n[discord-shield]: https://img.shields.io/discord/1127171173982154893?color=5865F2&label=discord&labelColor=black&logo=discord&logoColor=white&style=flat-square\n[discord-shield-badge]: https://img.shields.io/discord/1127171173982154893?color=5865F2&label=discord&labelColor=black&logo=discord&logoColor=white&style=for-the-badge\n[docker-pulls-link]: https://hub.docker.com/r/lobehub/lobe-chat-database\n[docker-pulls-shield]: https://img.shields.io/docker/pulls/lobehub/lobe-chat?color=45cc11&labelColor=black&style=flat-square&sort=semver\n[docker-release-link]: https://hub.docker.com/r/lobehub/lobe-chat-database\n[docker-release-shield]: https://img.shields.io/docker/v/lobehub/lobe-chat-database?color=369eff&label=docker&labelColor=black&logo=docker&logoColor=white&style=flat-square&sort=semver\n[docker-size-link]: https://hub.docker.com/r/lobehub/lobe-chat-database\n[docker-size-shield]: https://img.shields.io/docker/image-size/lobehub/lobe-chat-database?color=369eff&labelColor=black&style=flat-square&sort=semver\n[docs]: https://lobehub.com/docs/usage/start\n[docs-dev-guide]: https://github.com/lobehub/lobe-chat/wiki/index\n[docs-docker]: https://lobehub.com/docs/self-hosting/server-database/docker-compose\n[docs-env-var]: https://lobehub.com/docs/self-hosting/environment-variables\n[docs-feat-agent]: https://lobehub.com/docs/usage/features/agent-market\n[docs-feat-artifacts]: https://lobehub.com/docs/usage/features/artifacts\n[docs-feat-auth]: https://lobehub.com/docs/usage/features/auth\n[docs-feat-branch]: https://lobehub.com/docs/usage/features/branching-conversations\n[docs-feat-cot]: https://lobehub.com/docs/usage/features/cot\n[docs-feat-database]: https://lobehub.com/docs/usage/features/database\n[docs-feat-knowledgebase]: https://lobehub.com/blog/knowledge-base\n[docs-feat-local]: https://lobehub.com/docs/usage/features/local-llm\n[docs-feat-mobile]: https://lobehub.com/docs/usage/features/mobile\n[docs-feat-plugin]: https://lobehub.com/docs/usage/features/plugin-system\n[docs-feat-provider]: https://lobehub.com/docs/usage/features/multi-ai-providers\n[docs-feat-pwa]: https://lobehub.com/docs/usage/features/pwa\n[docs-feat-t2i]: https://lobehub.com/docs/usage/features/text-to-image\n[docs-feat-theme]: https://lobehub.com/docs/usage/features/theme\n[docs-feat-tts]: https://lobehub.com/docs/usage/features/tts\n[docs-feat-vision]: https://lobehub.com/docs/usage/features/vision\n[docs-function-call]: https://lobehub.com/blog/openai-function-call\n[docs-lighthouse]: https://github.com/lobehub/lobe-chat/wiki/Lighthouse\n[docs-plugin-dev]: https://lobehub.com/docs/usage/plugins/development\n[docs-self-hosting]: https://lobehub.com/docs/self-hosting/start\n[docs-upstream-sync]: https://lobehub.com/docs/self-hosting/advanced/upstream-sync\n[docs-usage-ollama]: https://lobehub.com/docs/usage/providers/ollama\n[docs-usage-plugin]: https://lobehub.com/docs/usage/plugins/basic\n[fossa-license-link]: https://app.fossa.com/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat\n[fossa-license-shield]: https://app.fossa.com/api/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat.svg?type=large\n[github-action-release-link]: https://github.com/actions/workflows/lobehub/lobe-chat/release.yml\n[github-action-release-shield]: https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/release.yml?label=release&labelColor=black&logo=githubactions&logoColor=white&style=flat-square\n[github-action-test-link]: https://github.com/actions/workflows/lobehub/lobe-chat/test.yml\n[github-action-test-shield]: https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/test.yml?label=test&labelColor=black&logo=githubactions&logoColor=white&style=flat-square\n[github-contributors-link]: https://github.com/lobehub/lobe-chat/graphs/contributors\n[github-contributors-shield]: https://img.shields.io/github/contributors/lobehub/lobe-chat?color=c4f042&labelColor=black&style=flat-square\n[github-forks-link]: https://github.com/lobehub/lobe-chat/network/members\n[github-forks-shield]: https://img.shields.io/github/forks/lobehub/lobe-chat?color=8ae8ff&labelColor=black&style=flat-square\n[github-issues-link]: https://github.com/lobehub/lobe-chat/issues\n[github-issues-shield]: https://img.shields.io/github/issues/lobehub/lobe-chat?color=ff80eb&labelColor=black&style=flat-square\n[github-license-link]: https://github.com/lobehub/lobe-chat/blob/main/LICENSE\n[github-license-shield]: https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&style=flat-square\n[github-project-link]: https://github.com/lobehub/lobe-chat/projects\n[github-release-link]: https://github.com/lobehub/lobe-chat/releases\n[github-release-shield]: https://img.shields.io/github/v/release/lobehub/lobe-chat?color=369eff&labelColor=black&logo=github&style=flat-square\n[github-releasedate-link]: https://github.com/lobehub/lobe-chat/releases\n[github-releasedate-shield]: https://img.shields.io/github/release-date/lobehub/lobe-chat?labelColor=black&style=flat-square\n[github-stars-link]: https://github.com/lobehub/lobe-chat/stargazers\n[github-stars-shield]: https://img.shields.io/github/stars/lobehub/lobe-chat?color=ffcb47&labelColor=black&style=flat-square\n[github-trending-shield]: https://trendshift.io/api/badge/repositories/2256\n[github-trending-url]: https://trendshift.io/repositories/2256\n[image-banner]: https://github.com/user-attachments/assets/6f293c7f-47b4-47eb-9202-fe68a942d35b\n[image-feat-agent]: https://github.com/user-attachments/assets/b3ab6e35-4fbc-468d-af10-e3e0c687350f\n[image-feat-artifacts]: https://github.com/user-attachments/assets/7f95fad6-b210-4e6e-84a0-7f39e96f3a00\n[image-feat-auth]: https://github.com/user-attachments/assets/80bb232e-19d1-4f97-98d6-e291f3585e6d\n[image-feat-branch]: https://github.com/user-attachments/assets/92f72082-02bd-4835-9c54-b089aad7fd41\n[image-feat-cot]: https://github.com/user-attachments/assets/f74f1139-d115-4e9c-8c43-040a53797a5e\n[image-feat-database]: https://github.com/user-attachments/assets/f1697c8b-d1fb-4dac-ba05-153c6295d91d\n[image-feat-desktop]: https://github.com/user-attachments/assets/a7bac8d3-ea96-4000-bb39-fadc9b610f96\n[image-feat-knowledgebase]: https://github.com/user-attachments/assets/7da7a3b2-92fd-4630-9f4e-8560c74955ae\n[image-feat-local]: https://github.com/user-attachments/assets/1239da50-d832-4632-a7ef-bd754c0f3850\n[image-feat-mcp]: https://github.com/user-attachments/assets/1be85d36-3975-4413-931f-27e05e440995\n[image-feat-mcp-market]: https://github.com/user-attachments/assets/bb114f9f-24c5-4000-a984-c10d187da5a0\n[image-feat-mobile]: https://github.com/user-attachments/assets/32cf43c4-96bd-4a4c-bfb6-59acde6fe380\n[image-feat-plugin]: https://github.com/user-attachments/assets/66a891ac-01b6-4e3f-b978-2eb07b489b1b\n[image-feat-privoder]: https://github.com/user-attachments/assets/e553e407-42de-4919-977d-7dbfcf44a821\n[image-feat-pwa]: https://github.com/user-attachments/assets/9647f70f-b71b-43b6-9564-7cdd12d1c24d\n[image-feat-t2i]: https://github.com/user-attachments/assets/708274a7-2458-494b-a6ec-b73dfa1fa7c2\n[image-feat-theme]: https://github.com/user-attachments/assets/b47c39f1-806f-492b-8fcb-b0fa973937c1\n[image-feat-tts]: https://github.com/user-attachments/assets/50189597-2cc3-4002-b4c8-756a52ad5c0a\n[image-feat-vision]: https://github.com/user-attachments/assets/18574a1f-46c2-4cbc-af2c-35a86e128a07\n[image-feat-web-search]: https://github.com/user-attachments/assets/cfdc48ac-b5f8-4a00-acee-db8f2eba09ad\n[image-overview]: https://github.com/user-attachments/assets/dbfaa84a-2c82-4dd9-815c-5be616f264a4\n[image-star]: https://github.com/user-attachments/assets/c3b482e7-cef5-4e94-bef9-226900ecfaab\n[issues-link]: https://img.shields.io/github/issues/lobehub/lobe-chat.svg?style=flat\n[lobe-chat-plugins]: https://github.com/lobehub/lobe-chat-plugins\n[lobe-commit]: https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-commit\n[lobe-i18n]: https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-i18n\n[lobe-icons-github]: https://github.com/lobehub/lobe-icons\n[lobe-icons-link]: https://www.npmjs.com/package/@lobehub/icons\n[lobe-icons-shield]: https://img.shields.io/npm/v/@lobehub/icons?color=369eff&labelColor=black&logo=npm&logoColor=white&style=flat-square\n[lobe-lint-github]: https://github.com/lobehub/lobe-lint\n[lobe-lint-link]: https://www.npmjs.com/package/@lobehub/lint\n[lobe-lint-shield]: https://img.shields.io/npm/v/@lobehub/lint?color=369eff&labelColor=black&logo=npm&logoColor=white&style=flat-square\n[lobe-midjourney-webui]: https://github.com/lobehub/lobe-midjourney-webui\n[lobe-theme]: https://github.com/lobehub/sd-webui-lobe-theme\n[lobe-tts-github]: https://github.com/lobehub/lobe-tts\n[lobe-tts-link]: https://www.npmjs.com/package/@lobehub/tts\n[lobe-tts-shield]: https://img.shields.io/npm/v/@lobehub/tts?color=369eff&labelColor=black&logo=npm&logoColor=white&style=flat-square\n[lobe-ui-github]: https://github.com/lobehub/lobe-ui\n[lobe-ui-link]: https://www.npmjs.com/package/@lobehub/ui\n[lobe-ui-shield]: https://img.shields.io/npm/v/@lobehub/ui?color=369eff&labelColor=black&logo=npm&logoColor=white&style=flat-square\n[official-site]: https://lobehub.com\n[pr-welcome-link]: https://github.com/lobehub/lobe-chat/pulls\n[pr-welcome-shield]: https://img.shields.io/badge/ü§Ø_pr_welcome-%E2%86%92-ffcb47?labelColor=black&style=for-the-badge\n[profile-link]: https://github.com/lobehub\n[share-linkedin-link]: https://linkedin.com/feed\n[share-linkedin-shield]: https://img.shields.io/badge/-share%20on%20linkedin-black?labelColor=black&logo=linkedin&logoColor=white&style=flat-square\n[share-mastodon-link]: https://mastodon.social/share?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source,%20extensible%20%28Function%20Calling%29,%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https://github.com/lobehub/lobe-chat%20#chatbot%20#chatGPT%20#openAI\n[share-mastodon-shield]: https://img.shields.io/badge/-share%20on%20mastodon-black?labelColor=black&logo=mastodon&logoColor=white&style=flat-square\n[share-reddit-link]: https://www.reddit.com/submit?title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat\n[share-reddit-shield]: https://img.shields.io/badge/-share%20on%20reddit-black?labelColor=black&logo=reddit&logoColor=white&style=flat-square\n[share-telegram-link]: https://t.me/share/url"?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat\n[share-telegram-shield]: https://img.shields.io/badge/-share%20on%20telegram-black?labelColor=black&logo=telegram&logoColor=white&style=flat-square\n[share-weibo-link]: http://service.weibo.com/share/share.php?sharesource=weibo&title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat\n[share-weibo-shield]: https://img.shields.io/badge/-share%20on%20weibo-black?labelColor=black&logo=sinaweibo&logoColor=white&style=flat-square\n[share-whatsapp-link]: https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat%20%23chatbot%20%23chatGPT%20%23openAI\n[share-whatsapp-shield]: https://img.shields.io/badge/-share%20on%20whatsapp-black?labelColor=black&logo=whatsapp&logoColor=white&style=flat-square\n[share-x-link]: https://x.com/intent/tweet?hashtags=chatbot%2CchatGPT%2CopenAI&text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.&url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat\n[share-x-shield]: https://img.shields.io/badge/-share%20on%20x-black?labelColor=black&logo=x&logoColor=white&style=flat-square\n[sponsor-link]: https://opencollective.com/lobehub ''Become ‚ù§Ô∏è LobeHub Sponsor''\n[sponsor-shield]: https://img.shields.io/badge/-Sponsor%20LobeHub-f04f88?logo=opencollective&logoColor=white&style=flat-square\n[submit-agents-link]: https://github.com/lobehub/lobe-chat-agents\n[submit-agents-shield]: https://img.shields.io/badge/ü§ñ/üè™_submit_agent-%E2%86%92-c4f042?labelColor=black&style=for-the-badge\n[submit-plugin-link]: https://github.com/lobehub/lobe-chat-plugins\n[submit-plugin-shield]: https://img.shields.io/badge/üß©/üè™_submit_plugin-%E2%86%92-95f3d9?labelColor=black&style=for-the-badge\n[vercel-link]: https://chat-preview.lobehub.com\n[vercel-shield]: https://img.shields.io/badge/vercel-online-55b467?labelColor=black&logo=vercel&style=flat-square\n[vercel-shield-badge]: https://img.shields.io/badge/TRY%20LOBECHAT-ONLINE-55b467?labelColor=black&logo=vercel&style=for-the-badge\n', '{"language":"TypeScript","stars":68749,"forks":14181,"watchers":68749,"open_issues":1057,"topics":["agent","ai","artifacts","chat","chatgpt","claude","deepseek","deepseek-r1","function-calling","gemini","gpt","knowledge-base","mcp","nextjs","ollama","openai","rag"],"default_branch":"next","size_kb":585695,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat.git","source_url":"https://github.com/lobehub/lobe-chat.git"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:.github","source_url":"https://github.com/lobehub/.github"},{"type":"has_code","target_id":"github:lobehub:.github","source_url":"https://github.com/lobehub/.github"},{"type":"has_code","target_id":"github:lobehub:chat-plugin-sdk","source_url":"https://github.com/lobehub/chat-plugin-sdk"},{"type":"has_code","target_id":"github:lobehub:chat-plugin-template","source_url":"https://github.com/lobehub/chat-plugin-template"},{"type":"has_code","target_id":"github:lobehub:chat-plugins-gateway","source_url":"https://github.com/lobehub/chat-plugins-gateway"},{"type":"has_code","target_id":"github:codespaces:badge.svg","source_url":"https://github.com/codespaces/badge.svg"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:actions:workflows","source_url":"https://github.com/actions/workflows"},{"type":"has_code","target_id":"github:actions:workflows","source_url":"https://github.com/actions/workflows"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:lobehub:lobe-chat-plugins","source_url":"https://github.com/lobehub/lobe-chat-plugins"},{"type":"has_code","target_id":"github:lobehub:lobe-commit","source_url":"https://github.com/lobehub/lobe-commit"},{"type":"has_code","target_id":"github:lobehub:lobe-commit","source_url":"https://github.com/lobehub/lobe-commit"},{"type":"has_code","target_id":"github:lobehub:lobe-icons","source_url":"https://github.com/lobehub/lobe-icons"},{"type":"has_code","target_id":"github:lobehub:lobe-lint","source_url":"https://github.com/lobehub/lobe-lint"},{"type":"has_code","target_id":"github:lobehub:lobe-midjourney-webui","source_url":"https://github.com/lobehub/lobe-midjourney-webui"},{"type":"has_code","target_id":"github:lobehub:sd-webui-lobe-theme","source_url":"https://github.com/lobehub/sd-webui-lobe-theme"},{"type":"has_code","target_id":"github:lobehub:lobe-tts","source_url":"https://github.com/lobehub/lobe-tts"},{"type":"has_code","target_id":"github:lobehub:lobe-ui","source_url":"https://github.com/lobehub/lobe-ui"},{"type":"has_code","target_id":"github:lobehub:lobe-chat","source_url":"https://github.com/lobehub/lobe-chat"},{"type":"has_code","target_id":"github:lobehub:lobe-chat%20","source_url":"https://github.com/lobehub/lobe-chat%20#chatbot%20#chatGPT%20#openAI"},{"type":"has_code","target_id":"github:lobehub:lobe-chat-agents","source_url":"https://github.com/lobehub/lobe-chat-agents"},{"type":"has_code","target_id":"github:lobehub:lobe-chat-plugins","source_url":"https://github.com/lobehub/lobe-chat-plugins"}]', NULL, 'NOASSERTION', 'approved', 80, '7f944629051a27d1bedb99ea72287649', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-lobehub-lobe-chat from https://github.com/lobehub.png
Image converted to WebP: data/images/github-lobehub-lobe-chat.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-hiyouga-LLaMA-Factory', 'github--hiyouga--llama-factory', 'LLaMA-Factory', 'hiyouga', '!# LLaMA Factory <div align="center" markdown="1"> | <div style="text-align: center;"><a href="https://warp.dev/llama-factory"><img alt="Warp sponsorship" width="400" src="assets/sponsors/warp.jpg"></a><br><a href="https://warp.dev/llama-factory" style="font-size:larger;">Warp, the agentic terminal for developers</a><br><a href="https://warp.dev/llama-factory">Available for MacOS, Linux, & Windows</a> | <a href="https://serpapi.com"><img alt="SerpAPI sponsorship" width="250" src="assets/spons...', '["agent","ai","deepseek","fine-tuning","gemma","gpt","instruction-tuning","large-language-models","llama","llama3","llm","lora","moe","nlp","peft","qlora","quantization","qwen","rlhf","transformers","python"]', 'other', 63676, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/hiyouga/LLaMA-Factory","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'model', '![# LLaMA Factory](assets/logo.png)\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)\n[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)\n[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)\n[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)\n[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)\n[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)\n[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)\n\n[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)\n[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)\n[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)\n[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/en/)\n\n[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)\n[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)\n[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)\n[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)\n[![Open in Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)\n[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)\n[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)\n\n### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.\n\n<div align="center" markdown="1">\n\n### Supporters ‚ù§Ô∏è\n\n| <div style="text-align: center;"><a href="https://warp.dev/llama-factory"><img alt="Warp sponsorship" width="400" src="assets/sponsors/warp.jpg"></a><br><a href="https://warp.dev/llama-factory" style="font-size:larger;">Warp, the agentic terminal for developers</a><br><a href="https://warp.dev/llama-factory">Available for MacOS, Linux, & Windows</a> | <a href="https://serpapi.com"><img alt="SerpAPI sponsorship" width="250" src="assets/sponsors/serpapi.svg"> </a> |\n| ---- | ---- |\n\n----\n\n### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n\n![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)\n\n</div>\n\nüëã Join our [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg), [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg), [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg), [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg) user group.\n\n\[ English | [‰∏≠Êñá](README_zh.md) \]\n\n**Fine-tuning a large language model can be easy as...**\n\nhttps://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e\n\nStart local training:\n- Please refer to [usage](#getting-started)\n\nStart cloud training:\n- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing\n- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory\n- **LLaMA Factory Online**: https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory\n- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory\n\nRead technical notes:\n- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/\n- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html\n- **Official Blog**: https://blog.llamafactory.net/en/\n- **Official Course**: https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory\n\n> [!NOTE]\n> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.\n\n## Table of Contents\n\n- [Features](#features)\n- [Blogs](#blogs)\n- [Changelog](#changelog)\n- [Supported Models](#supported-models)\n- [Supported Training Approaches](#supported-training-approaches)\n- [Provided Datasets](#provided-datasets)\n- [Requirement](#requirement)\n- [Getting Started](#getting-started)\n  - [Installation](#installation)\n  - [Data Preparation](#data-preparation)\n  - [Quickstart](#quickstart)\n  - [Fine-Tuning with LLaMA Board GUI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n  - [LLaMA Factory Online](#llama-factory-online)\n  - [Build Docker](#build-docker)\n  - [Deploy with OpenAI-style API and vLLM](#deploy-with-openai-style-api-and-vllm)\n  - [Download from ModelScope Hub](#download-from-modelscope-hub)\n  - [Download from Modelers Hub](#download-from-modelers-hub)\n  - [Use W&B Logger](#use-wb-logger)\n  - [Use SwanLab Logger](#use-swanlab-logger)\n- [Projects using LLaMA Factory](#projects-using-llama-factory)\n- [License](#license)\n- [Citation](#citation)\n- [Acknowledgement](#acknowledgement)\n\n## Features\n\n- **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.\n- **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.\n- **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n- **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), [Muon](https://github.com/KellerJordan/Muon), [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.\n- **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [KTransformers](https://github.com/kvcache-ai/ktransformers/), RoPE scaling, NEFTune and rsLoRA.\n- **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.\n- **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, [SwanLab](https://github.com/SwanHubX/SwanLab), etc.\n- **Faster inference**: OpenAI-style API, Gradio UI and CLI with [vLLM worker](https://github.com/vllm-project/vllm) or [SGLang worker](https://github.com/sgl-project/sglang).\n\n### Day-N Support for Fine-Tuning Cutting-Edge Models\n\n| Support Date | Model Name                                                           |\n| ------------ | -------------------------------------------------------------------- |\n| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |\n| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |\n\n## Blogs\n\n> [!TIP]\n> Now we have a dedicated blog for LLaMA Factory!\n>\n> Website: https://blog.llamafactory.net/en/\n\n- üí° [KTransformers Fine-Tuning √ó LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/) (English)\n- üí° [Easy Dataset √ó LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g) (English)\n- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory) (Chinese)\n- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/) (Chinese)\n- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/) (English)\n\n<details><summary>All Blogs</summary>\n\n- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory) (Chinese)\n- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b) (Chinese)\n- [A One-Stop Code-Free Model Fine-Tuning \& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/) (Chinese)\n- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl) (Chinese)\n- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory) (Chinese)\n\n</details>\n\n## Changelog\n\n[25/10/26] We support Megatron-core training backend with [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter). See [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237) to get started.\n\n[25/08/22] We supported **[OFT](https://arxiv.org/abs/2306.07280)** and **[OFTv2](https://arxiv.org/abs/2506.19847)**. See [examples](examples/README.md) for usage.\n\n[25/08/20] We supported fine-tuning the **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** models. See [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) to get started.\n\n[25/08/06] We supported fine-tuning the **[GPT-OSS](https://github.com/openai/gpt-oss)** models. See [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) to get started.\n\n<details><summary>Full Changelog</summary>\n\n[25/07/02] We supported fine-tuning the **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** model.\n\n[25/04/28] We supported fine-tuning the **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** model family.\n\n[25/04/21] We supported the **[Muon](https://github.com/KellerJordan/Muon)** optimizer. See [examples](examples/README.md) for usage. Thank [@tianshijing](https://github.com/tianshijing)''s PR.\n\n[25/04/16] We supported fine-tuning the **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** model. See [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) to get started.\n\n[25/04/14] We supported fine-tuning the **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** and **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** models.\n\n[25/04/06] We supported fine-tuning the **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** model. See [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) to get started.\n\n[25/03/31] We supported fine-tuning the **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** model. See [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) to get started.\n\n[25/03/15] We supported **[SGLang](https://github.com/sgl-project/sglang)** as inference backend. Try `infer_backend: sglang` to accelerate inference.\n\n[25/03/12] We supported fine-tuning the **[Gemma 3](https://huggingface.co/blog/gemma3)** model.\n\n[25/02/24] Announcing **[EasyR1](https://github.com/hiyouga/EasyR1)**, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.\n\n[25/02/11] We supported saving the **[Ollama](https://github.com/ollama/ollama)** modelfile when exporting the model checkpoints. See [examples](examples/README.md) for usage.\n\n[25/02/05] We supported fine-tuning the **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** and **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** on audio understanding tasks.\n\n[25/01/31] We supported fine-tuning the **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** and **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** models.\n\n[25/01/15] We supported **[APOLLO](https://arxiv.org/abs/2412.05270)** optimizer. See [examples](examples/README.md) for usage.\n\n[25/01/14] We supported fine-tuning the **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** and **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** models. Thank [@BUAADreamer](https://github.com/BUAADreamer)''s PR.\n\n[25/01/14] We supported fine-tuning the **[InternLM 3](https://huggingface.co/collections/internlm/)** models. Thank [@hhaAndroid](https://github.com/hhaAndroid)''s PR.\n\n[25/01/10] We supported fine-tuning the **[Phi-4](https://huggingface.co/microsoft/phi-4)** model.\n\n[24/12/21] We supported using **[SwanLab](https://github.com/SwanHubX/SwanLab)** for experiment tracking and visualization. See [this section](#use-swanlab-logger) for details.\n\n[24/11/27] We supported fine-tuning the **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** model and the **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** dataset.\n\n[24/10/09] We supported downloading pre-trained models and datasets from the **[Modelers Hub](https://modelers.cn/models)**. See [this tutorial](#download-from-modelers-hub) for usage.\n\n[24/09/19] We supported fine-tuning the **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** models.\n\n[24/08/30] We supported fine-tuning the **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** models. Thank [@simonJJJ](https://github.com/simonJJJ)''s PR.\n\n[24/08/27] We supported **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**. Try `enable_liger_kernel: true` for efficient training.\n\n[24/08/09] We supported **[Adam-mini](https://github.com/zyushun/Adam-mini)** optimizer. See [examples](examples/README.md) for usage. Thank [@relic-yuexi](https://github.com/relic-yuexi)''s PR.\n\n[24/07/04] We supported [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing). Use `neat_packing: true` to activate it. Thank [@chuan298](https://github.com/chuan298)''s PR.\n\n[24/06/16] We supported **[PiSSA](https://arxiv.org/abs/2404.02948)** algorithm. See [examples](examples/README.md) for usage.\n\n[24/06/07] We supported fine-tuning the **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** and **[GLM-4](https://github.com/THUDM/GLM-4)** models.\n\n[24/05/26] We supported **[SimPO](https://arxiv.org/abs/2405.14734)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/20] We supported fine-tuning the **PaliGemma** series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with `paligemma` template for chat completion.\n\n[24/05/18] We supported **[KTO](https://arxiv.org/abs/2402.01306)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/14] We supported training and inference on the Ascend NPU devices. Check [installation](#installation) section for details.\n\n[24/04/26] We supported fine-tuning the **LLaVA-1.5** multimodal LLMs. See [examples](examples/README.md) for usage.\n\n[24/04/22] We provided a **[Colab notebook](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)** for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) and [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese) for details.\n\n[24/04/21] We supported **[Mixture-of-Depths](https://arxiv.org/abs/2404.02258)** according to [AstraMindAI''s implementation](https://github.com/astramind-ai/Mixture-of-depths). See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[BAdam](https://arxiv.org/abs/2404.02827)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[unsloth](https://github.com/unslothai/unsloth)**''s long-sequence training (Llama-2-7B-56k within 24GB). It achieves **117%** speed and **50%** memory compared with FlashAttention-2, more benchmarks can be found in [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison).\n\n[24/03/31] We supported **[ORPO](https://arxiv.org/abs/2403.07691)**. See [examples](examples/README.md) for usage.\n\n[24/03/21] Our paper "[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)" is available at arXiv!\n\n[24/03/20] We supported **FSDP+QLoRA** that fine-tunes a 70B model on 2x24GB GPUs. See [examples](examples/README.md) for usage.\n\n[24/03/13] We supported **[LoRA+](https://arxiv.org/abs/2402.12354)**. See [examples](examples/README.md) for usage.\n\n[24/03/07] We supported **[GaLore](https://arxiv.org/abs/2403.03507)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/03/07] We integrated **[vLLM](https://github.com/vllm-project/vllm)** for faster and concurrent inference. Try `infer_backend: vllm` to enjoy **270%** inference speed.\n\n[24/02/28] We supported weight-decomposed LoRA (**[DoRA](https://arxiv.org/abs/2402.09353)**). Try `use_dora: true` to activate DoRA training.\n\n[24/02/15] We supported **block expansion** proposed by [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro). See [examples](examples/README.md) for usage.\n\n[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this [blog post](https://qwenlm.github.io/blog/qwen1.5/) for details.\n\n[24/01/18] We supported **agent tuning** for most models, equipping model with tool using abilities by fine-tuning with `dataset: glaive_toolcall_en`.\n\n[23/12/23] We supported **[unsloth](https://github.com/unslothai/unsloth)**''s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try `use_unsloth: true` argument to activate unsloth patch. It achieves **170%** speed in our benchmark, check [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison) for details.\n\n[23/12/12] We supported fine-tuning the latest MoE model **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)** in our framework. See hardware requirement [here](#hardware-requirement).\n\n[23/12/01] We supported downloading pre-trained models and datasets from the **[ModelScope Hub](https://modelscope.cn/models)**. See [this tutorial](#download-from-modelscope-hub) for usage.\n\n[23/10/21] We supported **[NEFTune](https://arxiv.org/abs/2310.05914)** trick for fine-tuning. Try `neftune_noise_alpha: 5` argument to activate NEFTune.\n\n[23/09/27] We supported **$S^2$-Attn** proposed by [LongLoRA](https://github.com/dvlab-research/LongLoRA) for the LLaMA models. Try `shift_attn: true` argument to enable shift short attention.\n\n[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See [examples](examples/README.md) for usage.\n\n[23/09/10] We supported **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**. Try `flash_attn: fa2` argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.\n\n[23/08/12] We supported **RoPE scaling** to extend the context length of the LLaMA models. Try `rope_scaling: linear` argument in training and `rope_scaling: dynamic` argument at inference to extrapolate the position embeddings.\n\n[23/08/11] We supported **[DPO training](https://arxiv.org/abs/2305.18290)** for instruction-tuned models. See [examples](examples/README.md) for usage.\n\n[23/07/31] We supported **dataset streaming**. Try `streaming: true` and `max_steps: 10000` arguments to load your dataset in streaming mode.\n\n[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ([LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)) for details.\n\n[23/07/18] We developed an **all-in-one Web UI** for training, evaluation and inference. Try `train_web.py` to fine-tune models in your Web browser. Thank [@KanadeSiina](https://github.com/KanadeSiina) and [@codemayq](https://github.com/codemayq) for their efforts in the development.\n\n[23/07/09] We released **[FastEdit](https://github.com/hiyouga/FastEdit)** ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow [FastEdit](https://github.com/hiyouga/FastEdit) if you are interested.\n\n[23/06/29] We provided a **reproducible example** of training a chat model using instruction-following datasets, see [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft) for details.\n\n[23/06/22] We aligned the [demo API](src/api_demo.py) with the [OpenAI''s](https://platform.openai.com/docs/api-reference/chat) format where you can insert the fine-tuned model in **arbitrary ChatGPT-based applications**.\n\n[23/06/03] We supported quantized training and inference (aka **[QLoRA](https://github.com/artidoro/qlora)**). See [examples](examples/README.md) for usage.\n\n</details>\n\n> [!TIP]\n> If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.\n\n## Supported Models\n\n| Model                                                             | Model size                       | Template             |\n| ----------------------------------------------------------------- | -------------------------------- | -------------------- |\n| [Baichuan 2](https://huggingface.co/baichuan-inc)                 | 7B/13B                           | baichuan2            |\n| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |\n| [ChatGLM3](https://huggingface.co/THUDM)                          | 6B                               | chatglm3             |\n| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |\n| [DeepSeek (Code/MoE)](https://huggingface.co/deepseek-ai)         | 7B/16B/67B/236B                  | deepseek             |\n| [DeepSeek 2.5/3](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |\n| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |\n| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |\n| [Falcon](https://huggingface.co/tiiuae)                           | 7B/11B/40B/180B                  | falcon               |\n| [Falcon-H1](https://huggingface.co/tiiuae)                        | 0.5B/1.5B/3B/7B/34B              | falcon_h1            |\n| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |\n| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |\n| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |\n| [GLM-4.1V](https://huggingface.co/zai-org)                        | 9B                               | glm4v                |\n| [GLM-4.5/GLM-4.5V](https://huggingface.co/zai-org)                | 106B/355B                        | glm4_moe/glm4v_moe   |\n| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |\n| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt                  |\n| [Granite 3.0-3.3](https://huggingface.co/ibm-granite)             | 1B/2B/3B/8B                      | granite3             |\n| [Granite 4](https://huggingface.co/ibm-granite)                   | 7B                               | granite4             |\n| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |\n| [Index](https://huggingface.co/IndexTeam)                         | 1.9B                             | index                |\n| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |\n| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |\n| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |\n| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |\n| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |\n| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |\n| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |\n| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |\n| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |\n| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |\n| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |\n| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |\n| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |\n| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B                               | mimo                 |\n| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |\n| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |\n| [Ministral/Mistral-Nemo](https://huggingface.co/mistralai)        | 8B/12B                           | ministral            |\n| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |\n| [Mistral Small](https://huggingface.co/mistralai)                 | 24B                              | mistral_small        |\n| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |\n| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |\n| [Phi-1.5/Phi-2](https://huggingface.co/microsoft)                 | 1.3B/2.7B                        | -                    |\n| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |\n| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |\n| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |\n| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |\n| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |\n| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |\n| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |\n| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |\n| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |\n| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |\n| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |\n| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |\n| [Skywork o1](https://huggingface.co/Skywork)                      | 8B                               | skywork_o1           |\n| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |\n| [TeleChat2](https://huggingface.co/Tele-AI)                       | 3B/7B/35B/115B                   | telechat2            |\n| [XVERSE](https://huggingface.co/xverse)                           | 7B/13B/65B                       | xverse               |\n| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |\n| [Yi-VL](https://huggingface.co/01-ai)                             | 6B/34B                           | yi_vl                |\n| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |\n\n> [!NOTE]\n> For the "base" models, the `template` argument can be chosen from `default`, `alpaca`, `vicuna` etc. But make sure to use the **corresponding template** for the "instruct/chat" models.\n>\n> If the model has both reasoning and non-reasoning versions, please use the `_nothink` suffix to distinguish between them. For example, `qwen3` and `qwen3_nothink`.\n>\n> Remember to use the **SAME** template in training and inference.\n>\n> \*: You should install the `transformers` from main branch and use `DISABLE_VERSION_CHECK=1` to skip version check.\n>\n> \*\*: You need to install a specific version of `transformers` to use the corresponding model.\n\nPlease refer to [constants.py](src/llamafactory/extras/constants.py) for a full list of models we supported.\n\nYou also can add a custom chat template to [template.py](src/llamafactory/data/template.py).\n\n## Supported Training Approaches\n\n| Approach               |     Full-tuning    |    Freeze-tuning   |       LoRA         |       QLoRA        |        OFT         |        QOFT        |\n| ---------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |\n| Pre-Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Supervised Fine-Tuning | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Reward Modeling        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| PPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| DPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| KTO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| ORPO Training          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| SimPO Training         | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n\n> [!TIP]\n> The implementation details of PPO can be found in [this blog](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html).\n\n## Provided Datasets\n\n<details><summary>Pre-training datasets</summary>\n\n- [Wiki Demo (en)](data/wiki_demo.txt)\n- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)\n- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)\n- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)\n- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)\n- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)\n- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)\n- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)\n- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)\n- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)\n- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)\n- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)\n- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)\n- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)\n- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)\n- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)\n\n</details>\n\n<details><summary>Supervised fine-tuning datasets</summary>\n\n- [Identity (en&zh)](data/identity.json)\n- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)\n- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)\n- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)\n- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)\n- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)\n- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)\n- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)\n- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)\n- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)\n- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)\n- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)\n- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)\n- [UltraChat (en)](https://github.com/thunlp/UltraChat)\n- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)\n- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)\n- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)\n- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)\n- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)\n- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)\n- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)\n- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)\n- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)\n- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)\n- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)\n- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)\n- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)\n- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)\n- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)\n- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)\n- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)\n- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)\n- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)\n- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)\n- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)\n- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)\n- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)\n- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)\n- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)\n- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)\n- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)\n- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)\n- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)\n- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)\n- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)\n- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)\n- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)\n- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)\n- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)\n- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)\n- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)\n- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)\n- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)\n\n</details>\n\n<details><summary>Preference datasets</summary>\n\n- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)\n- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)\n- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)\n- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)\n- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)\n- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)\n- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)\n- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)\n- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)\n\n</details>\n\nSome datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.\n\n```bash\npip install "huggingface_hub<1.0.0"\nhuggingface-cli login\n```\n\n## Requirement\n\n| Mandatory    | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| python       | 3.9     | 3.10      |\n| torch        | 2.0.0   | 2.6.0     |\n| torchvision  | 0.15.0  | 0.21.0    |\n| transformers | 4.49.0  | 4.50.0    |\n| datasets     | 2.16.0  | 3.2.0     |\n| accelerate   | 0.34.0  | 1.2.1     |\n| peft         | 0.14.0  | 0.15.1    |\n| trl          | 0.8.6   | 0.9.6     |\n\n| Optional     | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| CUDA         | 11.6    | 12.2      |\n| deepspeed    | 0.10.0  | 0.16.4    |\n| bitsandbytes | 0.39.0  | 0.43.1    |\n| vllm         | 0.4.3   | 0.8.2     |\n| flash-attn   | 2.5.6   | 2.7.2     |\n\n### Hardware Requirement\n\n\* *estimated*\n\n| Method                              | Bits |   7B  |  14B  |  30B  |   70B  |   `x`B  |\n| ----------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |\n| Full (`bf16` or `fp16`)             |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |\n| Full (`pure_bf16`)                  |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |\n| Freeze/LoRA/GaLore/APOLLO/BAdam/OFT |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |\n| QLoRA / QOFT                        |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |\n| QLoRA / QOFT                        |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |\n| QLoRA / QOFT                        |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |\n\n## Getting Started\n\n### Installation\n\n> [!IMPORTANT]\n> Installation is mandatory.\n\n#### Install from Source\n\n```bash\ngit clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\npip install -e ".[torch,metrics]" --no-build-isolation\n```\n\nExtra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev\n\n#### Install from Docker Image\n\n```bash\ndocker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest\n```\n\nThis image is built on Ubuntu 22.04 (x86\_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.\n\nFind the pre-built images: https://hub.docker.com/r/hiyouga/llamafactory/tags\n\nPlease refer to [build docker](#build-docker) to build the image yourself.\n\n<details><summary>Setting up a virtual environment with <b>uv</b></summary>\n\nCreate an isolated Python environment with [uv](https://github.com/astral-sh/uv):\n\n```bash\nuv sync --extra torch --extra metrics --prerelease=allow\n```\n\nRun LLaMA-Factory in the isolated environment:\n\n```bash\nuv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml\n```\n\n</details>\n\n<details><summary>For Windows users</summary>\n\n#### Install PyTorch\n\nYou need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the [official website](https://pytorch.org/get-started/locally/) and the following command to install PyTorch with CUDA support:\n\n```bash\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\npython -c "import torch; print(torch.cuda.is_available())"\n```\n\nIf you see `True` then you have successfully installed PyTorch with CUDA support.\n\nTry `dataloader_num_workers: 0` if you encounter `Can''t pickle local object` error.\n\n#### Install BitsAndBytes\n\nIf you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of `bitsandbytes` library, which supports CUDA 11.1 to 12.2, please select the appropriate [release version](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels) based on your CUDA version.\n\n```bash\npip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl\n```\n\n#### Install Flash Attention-2\n\nTo enable FlashAttention-2 on the Windows platform, please use the script from [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) to compile and install it by yourself.\n\n</details>\n\n<details><summary>For Ascend NPU users</summary>\n\nTo install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: `pip install -e ".[torch-npu,metrics]"`. Additionally, you need to install the **[Ascend CANN Toolkit and Kernels](https://www.hiascend.com/developer/download/community/result?module=cann)**. Please follow the [installation tutorial](https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html) or use the following commands:\n\n```bash\n# replace the url according to your CANN version and devices\n# install CANN Toolkit\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run\nbash Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run --install\n\n# install CANN Kernels\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run\nbash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run --install\n\n# set env variables\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n| Requirement  | Minimum | Recommend      |\n| ------------ | ------- | -------------- |\n| CANN         | 8.0.RC1 | 8.0.0.alpha002 |\n| torch        | 2.1.0   | 2.4.0          |\n| torch-npu    | 2.1.0   | 2.4.0.post2    |\n| deepspeed    | 0.13.2  | 0.13.2         |\n| vllm-ascend  | -       | 0.7.3          |\n\nRemember to use `ASCEND_RT_VISIBLE_DEVICES` instead of `CUDA_VISIBLE_DEVICES` to specify the device to use.\n\nIf you cannot infer model on NPU devices, try setting `do_sample: false` in the configurations.\n\nDownload the pre-built Docker images: [32GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html) | [64GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html)\n\n#### Install BitsAndBytes\n\nTo use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:\n\n1. Manually compile bitsandbytes: Refer to [the installation documentation](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU) for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.\n\n```bash\n# Install bitsandbytes from source\n# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch\ngit clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git\ncd bitsandbytes/\n\n# Install dependencies\npip install -r requirements-dev.txt\n\n# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference\napt-get install -y build-essential cmake\n\n# Compile & install  \ncmake -DCOMPUTE_BACKEND=npu -S .\nmake\npip install .\n```\n\n2. Install transformers from the main branch.\n\n```bash\ngit clone -b main https://github.com/huggingface/transformers.git\ncd transformers\npip install .\n```\n\n3. Set `double_quantization: false` in the configuration. You can refer to the [example](examples/train_qlora/llama3_lora_sft_bnb_npu.yaml).\n\n</details>\n\n### Data Preparation\n\nPlease refer to [data/README.md](data/README.md) for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.\n\n> [!NOTE]\n> Please update `data/dataset_info.json` to use your custom dataset.\n\nYou can also use **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**, **[DataFlow](https://github.com/OpenDCAI/DataFlow)** and **[GraphGen](https://github.com/open-sciencelab/GraphGen)** to create synthetic data for fine-tuning.\n\n### Quickstart\n\nUse the following 3 commands to run LoRA **fine-tuning**, **inference** and **merging** of the Llama3-8B-Instruct model, respectively.\n\n```bash\nllamafactory-cli train examples/train_lora/llama3_lora_sft.yaml\nllamafactory-cli chat examples/inference/llama3_lora_sft.yaml\nllamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml\n```\n\nSee [examples/README.md](examples/README.md) for advanced usage (including distributed training).\n\n> [!TIP]\n> Use `llamafactory-cli help` to show help information.\n>\n> Read [FAQs](https://github.com/hiyouga/LLaMA-Factory/issues/4614) first if you encounter any problems.\n\n### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))\n\n```bash\nllamafactory-cli webui\n```\n\n### LLaMA Factory Online\n\nRead our [documentation](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory).\n\n### Build Docker\n\nFor CUDA users:\n\n```bash\ncd docker/docker-cuda/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ncd docker/docker-npu/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ncd docker/docker-rocm/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\n<details><summary>Build without Docker Compose</summary>\n\nFor CUDA users:\n\n```bash\ndocker build -f ./docker/docker-cuda/Dockerfile \\n    --build-arg PIP_INDEX=https://pypi.org/simple \\n    --build-arg EXTRAS=metrics \\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host --gpus=all \\n    -p 7860:7860 \\n    -p 8000:8000 \\n    --name llamafactory \\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ndocker build -f ./docker/docker-npu/Dockerfile \\n    --build-arg PIP_INDEX=https://pypi.org/simple \\n    --build-arg EXTRAS=torch-npu,metrics \\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\n    -v /usr/local/dcmi:/usr/local/dcmi \\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\n    -v /etc/ascend_install.info:/etc/ascend_install.info \\n    -p 7860:7860 \\n    -p 8000:8000 \\n    --device /dev/davinci0 \\n    --device /dev/davinci_manager \\n    --device /dev/devmm_svm \\n    --device /dev/hisi_hdc \\n    --name llamafactory \\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ndocker build -f ./docker/docker-rocm/Dockerfile \\n    --build-arg PIP_INDEX=https://pypi.org/simple \\n    --build-arg EXTRAS=metrics \\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\n    -p 7860:7860 \\n    -p 8000:8000 \\n    --device /dev/kfd \\n    --device /dev/dri \\n    --name llamafactory \\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\n</details>\n\n<details><summary>Use Docker volumes</summary>\n\nYou can uncomment `VOLUME [ "/root/.cache/huggingface", "/app/shared_data", "/app/output" ]` in the Dockerfile to use data volumes.\n\nWhen building the Docker image, use `-v ./hf_cache:/root/.cache/huggingface` argument to mount the local directory to the container. The following data volumes are available.\n\n- `hf_cache`: Utilize Hugging Face cache on the host machine.\n- `shared_data`: The directionary to store datasets on the host machine.\n- `output`: Set export dir to this location so that the merged result can be accessed directly on the host machine.\n\n</details>\n\n### Deploy with OpenAI-style API and vLLM\n\n```bash\nAPI_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true\n```\n\n> [!TIP]\n> Visit [this page](https://platform.openai.com/docs/api-reference/chat/create) for API document.\n>\n> Examples: [Image understanding](scripts/api_example/test_image.py) | [Function calling](scripts/api_example/test_toolcall.py)\n\n### Download from ModelScope Hub\n\nIf you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.\n\n```bash\nexport USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the ModelScope Hub as the `model_name_or_path`. You can find a full list of model IDs at [ModelScope Hub](https://modelscope.cn/models), e.g., `LLM-Research/Meta-Llama-3-8B-Instruct`.\n\n### Download from Modelers Hub\n\nYou can also use Modelers Hub to download models and datasets.\n\n```bash\nexport USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the Modelers Hub as the `model_name_or_path`. You can find a full list of model IDs at [Modelers Hub](https://modelers.cn/models), e.g., `TeleAI/TeleChat-7B-pt`.\n\n### Use W&B Logger\n\nTo use [Weights & Biases](https://wandb.ai) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nreport_to: wandb\nrun_name: test_run # optional\n```\n\nSet `WANDB_API_KEY` to [your key](https://wandb.ai/authorize) when launching training tasks to log in with your W&B account.\n\n### Use SwanLab Logger\n\nTo use [SwanLab](https://github.com/SwanHubX/SwanLab) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nuse_swanlab: true\nswanlab_run_name: test_run # optional\n```\n\nWhen launching training tasks, you can log in to SwanLab in three ways:\n\n1. Add `swanlab_api_key=<your_api_key>` to the yaml file, and set it to your [API key](https://swanlab.cn/settings).\n2. Set the environment variable `SWANLAB_API_KEY` to your [API key](https://swanlab.cn/settings).\n3. Use the `swanlab login` command to complete the login.\n\n## Projects using LLaMA Factory\n\nIf you have a project that should be incorporated, please contact via email or create a pull request.\n\n<details><summary>Click to show</summary>\n\n1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)\n1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)\n1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)\n1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)\n1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)\n1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)\n1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)\n1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)\n1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)\n1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)\n1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)\n1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)\n1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)\n1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)\n1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)\n1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)\n1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)\n1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)\n1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)\n1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)\n1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)\n1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)\n1. Zhang et al. EDT: Improving Large Language Models'' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)\n1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)\n1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)\n1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)\n1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)\n1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)\n1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)\n1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)\n1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)\n1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)\n1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)\n1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)\n1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)\n1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)\n1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)\n1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)\n1. Dammu et al. "They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)\n1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)\n1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)\n1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)\n1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)\n1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)\n1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)\n1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)\n1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)\n1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)\n1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)\n1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)\n1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)\n1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)\n1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)\n1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)\n1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)\n1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)\n1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)\n1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)\n1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)\n1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)\n1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)\n1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh''s Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)\n1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)\n1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)\n1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)\n1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)\n1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)\n1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)\n1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)\n1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)\n1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)\n1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)\n1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)\n1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)\n1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)\n1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)\n1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)\n1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)\n1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)\n1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)\n1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)\n1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)\n1. Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. [[paper]](https://aclanthology.org/2024.findings-acl.830.pdf)\n1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.\n1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.\n1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.\n1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.\n1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.\n1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**: A large language model specialized in generate metadata for stable diffusion. [[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)\n1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.\n1. **[AutoRE](https://github.com/THUDM/AutoRE)**: A document-level relation extraction system based on large language models.\n1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.\n1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.\n1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [[blog]](https://zhuanlan.zhihu.com/p/987727357)\n1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**: A modified library that supports long sequence SFT & DPO using ring attention.\n1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**: An o1-like model fine-tuned by NovaSky AI with very small cost.\n1. **[WeClone](https://github.com/xming521/WeClone)**: One-stop solution for creating your digital avatar from chat logs.\n1. **[EmoLLM](https://github.com/SmartFlowAI/EmoLLM)**: A project about large language models (LLMs) and mental health.\n</details>\n\n## License\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n\nPlease follow the model licenses to use the corresponding model weights: [Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)\n\n## Citation\n\nIf this work is helpful, please kindly cite as:\n\n```bibtex\n@inproceedings{zheng2024llamafactory,\n  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},\n  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},\n  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},\n  address={Bangkok, Thailand},\n  publisher={Association for Computational Linguistics},\n  year={2024},\n  url={http://arxiv.org/abs/2403.13372}\n}\n```\n\n## Acknowledgement\n\nThis repo benefits from [PEFT](https://github.com/huggingface/peft), [TRL](https://github.com/huggingface/trl), [QLoRA](https://github.com/artidoro/qlora) and [FastChat](https://github.com/lm-sys/FastChat). Thanks for their wonderful works.\n\n## Star History\n\n![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)\n', '{"language":"Python","stars":63676,"forks":7698,"watchers":63676,"open_issues":811,"topics":["agent","ai","deepseek","fine-tuning","gemma","gpt","instruction-tuning","large-language-models","llama","llama3","llm","lora","moe","nlp","peft","qlora","quantization","qwen","rlhf","transformers"],"default_branch":"main","size_kb":12421,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:llamafactory-community","source_url":"https://github.com/hiyouga/llamafactory-community"},{"type":"has_code","target_id":"github:hiyouga:llamafactory-community","source_url":"https://github.com/hiyouga/llamafactory-community"},{"type":"has_code","target_id":"github:hiyouga:llamafactory-community","source_url":"https://github.com/hiyouga/llamafactory-community"},{"type":"has_code","target_id":"github:hiyouga:llamafactory-community","source_url":"https://github.com/hiyouga/llamafactory-community"},{"type":"has_code","target_id":"github:hiyouga:llamafactory-community","source_url":"https://github.com/hiyouga/llamafactory-community"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:jiaweizzhao:GaLore","source_url":"https://github.com/jiaweizzhao/GaLore"},{"type":"has_code","target_id":"github:Ledzy:BAdam","source_url":"https://github.com/Ledzy/BAdam"},{"type":"has_code","target_id":"github:zhuhanqing:APOLLO","source_url":"https://github.com/zhuhanqing/APOLLO"},{"type":"has_code","target_id":"github:zyushun:Adam-mini","source_url":"https://github.com/zyushun/Adam-mini"},{"type":"has_code","target_id":"github:KellerJordan:Muon","source_url":"https://github.com/KellerJordan/Muon"},{"type":"has_code","target_id":"github:huggingface:peft","source_url":"https://github.com/huggingface/peft"},{"type":"has_code","target_id":"github:Dao-AILab:flash-attention","source_url":"https://github.com/Dao-AILab/flash-attention"},{"type":"has_code","target_id":"github:unslothai:unsloth","source_url":"https://github.com/unslothai/unsloth"},{"type":"has_code","target_id":"github:linkedin:Liger-Kernel","source_url":"https://github.com/linkedin/Liger-Kernel"},{"type":"has_code","target_id":"github:kvcache-ai:ktransformers","source_url":"https://github.com/kvcache-ai/ktransformers"},{"type":"has_code","target_id":"github:SwanHubX:SwanLab","source_url":"https://github.com/SwanHubX/SwanLab"},{"type":"has_code","target_id":"github:vllm-project:vllm","source_url":"https://github.com/vllm-project/vllm"},{"type":"has_code","target_id":"github:sgl-project:sglang","source_url":"https://github.com/sgl-project/sglang"},{"type":"has_code","target_id":"github:alibaba:ROLL","source_url":"https://github.com/alibaba/ROLL"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:openai:gpt-oss","source_url":"https://github.com/openai/gpt-oss"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:THUDM:GLM-4.1V-Thinking","source_url":"https://github.com/THUDM/GLM-4.1V-Thinking"},{"type":"has_code","target_id":"github:KellerJordan:Muon","source_url":"https://github.com/KellerJordan/Muon"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:sgl-project:sglang","source_url":"https://github.com/sgl-project/sglang"},{"type":"has_code","target_id":"github:hiyouga:EasyR1","source_url":"https://github.com/hiyouga/EasyR1"},{"type":"has_code","target_id":"github:ollama:ollama","source_url":"https://github.com/ollama/ollama"},{"type":"has_code","target_id":"github:SwanHubX:SwanLab","source_url":"https://github.com/SwanHubX/SwanLab"},{"type":"has_code","target_id":"github:linkedin:Liger-Kernel","source_url":"https://github.com/linkedin/Liger-Kernel"},{"type":"has_code","target_id":"github:zyushun:Adam-mini","source_url":"https://github.com/zyushun/Adam-mini"},{"type":"has_code","target_id":"github:MeetKai:functionary","source_url":"https://github.com/MeetKai/functionary"},{"type":"has_code","target_id":"github:THUDM:GLM-4","source_url":"https://github.com/THUDM/GLM-4"},{"type":"has_code","target_id":"github:astramind-ai:Mixture-of-depths","source_url":"https://github.com/astramind-ai/Mixture-of-depths"},{"type":"has_code","target_id":"github:unslothai:unsloth","source_url":"https://github.com/unslothai/unsloth"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:vllm-project:vllm","source_url":"https://github.com/vllm-project/vllm"},{"type":"has_code","target_id":"github:TencentARC:LLaMA-Pro","source_url":"https://github.com/TencentARC/LLaMA-Pro"},{"type":"has_code","target_id":"github:unslothai:unsloth","source_url":"https://github.com/unslothai/unsloth"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:dvlab-research:LongLoRA","source_url":"https://github.com/dvlab-research/LongLoRA"},{"type":"has_code","target_id":"github:Dao-AILab:flash-attention","source_url":"https://github.com/Dao-AILab/flash-attention"},{"type":"has_code","target_id":"github:hiyouga:FastEdit","source_url":"https://github.com/hiyouga/FastEdit"},{"type":"has_code","target_id":"github:hiyouga:FastEdit","source_url":"https://github.com/hiyouga/FastEdit"},{"type":"has_code","target_id":"github:artidoro:qlora","source_url":"https://github.com/artidoro/qlora"},{"type":"has_code","target_id":"github:facebookresearch:llama","source_url":"https://github.com/facebookresearch/llama"},{"type":"has_code","target_id":"github:tatsu-lab:stanford_alpaca","source_url":"https://github.com/tatsu-lab/stanford_alpaca"},{"type":"has_code","target_id":"github:ymcui:Chinese-LLaMA-Alpaca-3","source_url":"https://github.com/ymcui/Chinese-LLaMA-Alpaca-3"},{"type":"has_code","target_id":"github:Instruction-Tuning-with-GPT-4:GPT-4-LLM","source_url":"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM"},{"type":"has_code","target_id":"github:thunlp:UltraChat","source_url":"https://github.com/thunlp/UltraChat"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory.git","source_url":"https://github.com/hiyouga/LLaMA-Factory.git"},{"type":"has_code","target_id":"github:astral-sh:uv","source_url":"https://github.com/astral-sh/uv"},{"type":"has_code","target_id":"github:jllllll:bitsandbytes-windows-webui","source_url":"https://github.com/jllllll/bitsandbytes-windows-webui"},{"type":"has_code","target_id":"github:jllllll:bitsandbytes-windows-webui","source_url":"https://github.com/jllllll/bitsandbytes-windows-webui"},{"type":"has_code","target_id":"github:bitsandbytes-foundation:bitsandbytes.git","source_url":"https://github.com/bitsandbytes-foundation/bitsandbytes.git"},{"type":"has_code","target_id":"github:huggingface:transformers.git","source_url":"https://github.com/huggingface/transformers.git"},{"type":"has_code","target_id":"github:ConardLi:easy-dataset","source_url":"https://github.com/ConardLi/easy-dataset"},{"type":"has_code","target_id":"github:OpenDCAI:DataFlow","source_url":"https://github.com/OpenDCAI/DataFlow"},{"type":"has_code","target_id":"github:open-sciencelab:GraphGen","source_url":"https://github.com/open-sciencelab/GraphGen"},{"type":"has_code","target_id":"github:hiyouga:LLaMA-Factory","source_url":"https://github.com/hiyouga/LLaMA-Factory"},{"type":"has_code","target_id":"github:gradio-app:gradio","source_url":"https://github.com/gradio-app/gradio"},{"type":"has_code","target_id":"github:SwanHubX:SwanLab","source_url":"https://github.com/SwanHubX/SwanLab"},{"type":"has_code","target_id":"github:Yu-Yang-Li:StarWhisper","source_url":"https://github.com/Yu-Yang-Li/StarWhisper"},{"type":"has_code","target_id":"github:FudanDISC:DISC-LawLLM","source_url":"https://github.com/FudanDISC/DISC-LawLLM"},{"type":"has_code","target_id":"github:X-D-Lab:Sunsimiao","source_url":"https://github.com/X-D-Lab/Sunsimiao"},{"type":"has_code","target_id":"github:WangRongsheng:CareGPT","source_url":"https://github.com/WangRongsheng/CareGPT"},{"type":"has_code","target_id":"github:PKU-YuanGroup:Machine-Mindset","source_url":"https://github.com/PKU-YuanGroup/Machine-Mindset"},{"type":"has_code","target_id":"github:BUAADreamer:Chinese-LLaVA-Med","source_url":"https://github.com/BUAADreamer/Chinese-LLaVA-Med"},{"type":"has_code","target_id":"github:THUDM:AutoRE","source_url":"https://github.com/THUDM/AutoRE"},{"type":"has_code","target_id":"github:NVIDIA:RTX-AI-Toolkit","source_url":"https://github.com/NVIDIA/RTX-AI-Toolkit"},{"type":"has_code","target_id":"github:LazyAGI:LazyLLM","source_url":"https://github.com/LazyAGI/LazyLLM"},{"type":"has_code","target_id":"github:NLPJCL:RAG-Retrieval","source_url":"https://github.com/NLPJCL/RAG-Retrieval"},{"type":"has_code","target_id":"github:Qihoo360:360-LLaMA-Factory","source_url":"https://github.com/Qihoo360/360-LLaMA-Factory"},{"type":"has_code","target_id":"github:xming521:WeClone","source_url":"https://github.com/xming521/WeClone"},{"type":"has_code","target_id":"github:SmartFlowAI:EmoLLM","source_url":"https://github.com/SmartFlowAI/EmoLLM"},{"type":"has_code","target_id":"github:THUDM:ChatGLM3","source_url":"https://github.com/THUDM/ChatGLM3"},{"type":"has_code","target_id":"github:deepseek-ai:DeepSeek-LLM","source_url":"https://github.com/deepseek-ai/DeepSeek-LLM"},{"type":"has_code","target_id":"github:openai:gpt-2","source_url":"https://github.com/openai/gpt-2"},{"type":"has_code","target_id":"github:InternLM:InternLM","source_url":"https://github.com/InternLM/InternLM#license"},{"type":"has_code","target_id":"github:facebookresearch:llama","source_url":"https://github.com/facebookresearch/llama"},{"type":"has_code","target_id":"github:meta-llama:llama-models","source_url":"https://github.com/meta-llama/llama-models"},{"type":"has_code","target_id":"github:OpenBMB:MiniCPM","source_url":"https://github.com/OpenBMB/MiniCPM"},{"type":"has_code","target_id":"github:QwenLM:Qwen","source_url":"https://github.com/QwenLM/Qwen"},{"type":"has_code","target_id":"github:xverse-ai:XVERSE-13B","source_url":"https://github.com/xverse-ai/XVERSE-13B"},{"type":"has_code","target_id":"github:IEIT-Yuan:Yuan-2.0","source_url":"https://github.com/IEIT-Yuan/Yuan-2.0"},{"type":"has_code","target_id":"github:huggingface:peft","source_url":"https://github.com/huggingface/peft"},{"type":"has_code","target_id":"github:huggingface:trl","source_url":"https://github.com/huggingface/trl"},{"type":"has_code","target_id":"github:artidoro:qlora","source_url":"https://github.com/artidoro/qlora"},{"type":"has_code","target_id":"github:lm-sys:FastChat","source_url":"https://github.com/lm-sys/FastChat"}]', NULL, 'Apache-2.0', 'approved', 80, 'c873bca5e0012d5e7c9bf26e25134377', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-hiyouga-LLaMA-Factory from https://github.com/hiyouga.png
Image converted to WebP: data/images/github-hiyouga-LLaMA-Factory.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-AntonOsika-gpt-engineer', 'github--antonosika--gpt-engineer', 'gpt-engineer', 'AntonOsika', '!GitHub Release The OG code genereation experimentation platform! If you are looking for the evolution that is an opinionated, managed service ‚Äì check out gptengineer.app. If you are looking for a well maintained hackable CLI for ‚Äì check out aider. gpt-engineer lets you: - Specify software in natural language - Sit back and watch as an AI writes and executes the code - Ask the AI to implement improvements For **stable** release: - For **development**: - - - - to activate the virtual environme...', '["ai","autonomous-agent","code-generation","codebase-generation","codegen","coding-assistant","gpt-4","gpt-engineer","openai","python","python"]', 'other', 55096, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/AntonOsika/gpt-engineer","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '# gpt-engineer\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/gpt-engineer-org/gpt-engineer?style=social)](https://github.com/gpt-engineer-org/gpt-engineer)\n[![Discord Follow](https://dcbadge.vercel.app/api/server/8tcDQ89Ej2?style=flat)](https://discord.gg/8tcDQ89Ej2)\n[![License](https://img.shields.io/github/license/gpt-engineer-org/gpt-engineer)](https://github.com/gpt-engineer-org/gpt-engineer/blob/main/LICENSE)\n[![GitHub Issues or Pull Requests](https://img.shields.io/github/issues/gpt-engineer-org/gpt-engineer)](https://github.com/gpt-engineer-org/gpt-engineer/issues)\n![GitHub Release](https://img.shields.io/github/v/release/gpt-engineer-org/gpt-engineer)\n[![Twitter Follow](https://img.shields.io/twitter/follow/antonosika?style=social)](https://twitter.com/antonosika)\n\nThe OG code genereation experimentation platform!\n\nIf you are looking for the evolution that is an opinionated, managed service ‚Äì check out gptengineer.app.\n\nIf you are looking for a well maintained hackable CLI for ‚Äì check out aider.\n\n\ngpt-engineer lets you:\n- Specify software in natural language\n- Sit back and watch as an AI writes and executes the code\n- Ask the AI to implement improvements\n\n## Getting Started\n\n### Install gpt-engineer\n\nFor **stable** release:\n\n- `python -m pip install gpt-engineer`\n\nFor **development**:\n- `git clone https://github.com/gpt-engineer-org/gpt-engineer.git`\n- `cd gpt-engineer`\n- `poetry install`\n- `poetry shell` to activate the virtual environment\n\nWe actively support Python 3.10 - 3.12. The last version to support Python 3.8 - 3.9 was [0.2.6](https://pypi.org/project/gpt-engineer/0.2.6/).\n\n### Setup API key\n\nChoose **one** of:\n- Export env variable (you can add this to .bashrc so that you don''t have to do it each time you start the terminal)\n    - `export OPENAI_API_KEY=[your api key]`\n- .env file:\n    - Create a copy of `.env.template` named `.env`\n    - Add your OPENAI_API_KEY in .env\n- Custom model:\n    - See [docs](https://gpt-engineer.readthedocs.io/en/latest/open_models.html), supports local model, azure, etc.\n\nCheck the [Windows README](./WINDOWS_README.md) for Windows usage.\n\n**Other ways to run:**\n- Use Docker ([instructions](docker/README.md))\n- Do everything in your browser:\n[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://github.com/gpt-engineer-org/gpt-engineer/codespaces)\n\n### Create new code (default usage)\n- Create an empty folder for your project anywhere on your computer\n- Create a file called `prompt` (no extension) inside your new folder and fill it with instructions\n- Run `gpte <project_dir>` with a relative path to your folder\n  - For example: `gpte projects/my-new-project` from the gpt-engineer directory root with your new folder in `projects/`\n\n### Improve existing code\n- Locate a folder with code which you want to improve anywhere on your computer\n- Create a file called `prompt` (no extension) inside your new folder and fill it with instructions for how you want to improve the code\n- Run `gpte <project_dir> -i` with a relative path to your folder\n  - For example: `gpte projects/my-old-project -i` from the gpt-engineer directory root with your folder in `projects/`\n\n### Benchmark custom agents\n- gpt-engineer installs the binary ''bench'', which gives you a simple interface for benchmarking your own agent implementations against popular public datasets.\n- The easiest way to get started with benchmarking is by checking out the [template](https://github.com/gpt-engineer-org/gpte-bench-template) repo, which contains detailed instructions and an agent template.\n- Currently supported benchmark:\n  - [APPS](https://github.com/hendrycks/apps)\n  - [MBPP](https://github.com/google-research/google-research/tree/master/mbpp)\n\nThe community has started work with different benchmarking initiatives, as described in [this Loom](https://www.loom.com/share/206805143fbb4302b5455a5329eaab17?sid=f689608f-8e49-44f7-b55f-4c81e9dc93e6) video.\n\n### Research\nSome of our community members have worked on different research briefs that could be taken further. See [this document](https://docs.google.com/document/d/1qmOj2DvdPc6syIAm8iISZFpfik26BYw7ZziD5c-9G0E/edit?usp=sharing) if you are interested.\n\n## Terms\nBy running gpt-engineer, you agree to our [terms](https://github.com/gpt-engineer-org/gpt-engineer/blob/main/TERMS_OF_USE.md).\n\n\n## Relation to gptengineer.app (GPT Engineer)\n[gptengineer.app](https://gptengineer.app/) is a commercial project for the automatic generation of web apps.\nIt features a UI for non-technical users connected to a git-controlled codebase.\nThe gptengineer.app team is actively supporting the open source community.\n\n\n## Features\n\n### Pre Prompts\nYou can specify the "identity" of the AI agent by overriding the `preprompts` folder with your own version of the `preprompts`. You can do so via the `--use-custom-preprompts` argument.\n\nEditing the `preprompts` is how you make the agent remember things between projects.\n\n### Vision\n\nBy default, gpt-engineer expects text input via a `prompt` file. It can also accept image inputs for vision-capable models. This can be useful for adding UX or architecture diagrams as additional context for GPT Engineer. You can do this by specifying an image directory with the `‚Äî-image_directory` flag and setting a vision-capable model in the second CLI argument.\n\nE.g. `gpte projects/example-vision gpt-4-vision-preview --prompt_file prompt/text --image_directory prompt/images -i`\n\n### Open source, local and alternative models\n\nBy default, gpt-engineer supports OpenAI Models via the OpenAI API or Azure OpenAI API, as well as Anthropic models.\n\nWith a little extra setup, you can also run with open source models like WizardCoder. See the [documentation](https://gpt-engineer.readthedocs.io/en/latest/open_models.html) for example instructions.\n\n## Mission\n\nThe gpt-engineer community mission is to **maintain tools that coding agent builders can use and facilitate collaboration in the open source community**.\n\nIf you are interested in contributing to this, we are interested in having you.\n\nIf you want to see our broader ambitions, check out the [roadmap](https://github.com/gpt-engineer-org/gpt-engineer/blob/main/ROADMAP.md), and join\n[discord](https://discord.gg/8tcDQ89Ej2)\nto learn how you can [contribute](.github/CONTRIBUTING.md) to it.\n\ngpt-engineer is [governed](https://github.com/gpt-engineer-org/gpt-engineer/blob/main/GOVERNANCE.md) by a board of long-term contributors. If you contribute routinely and have an interest in shaping the future of gpt-engineer, you will be considered for the board.\n\n## Significant contributors\n<ul style="list-style-type: none; padding: 0; display: flex; flex-wrap: wrap;"> <li style="margin-right: 10px; margin-bottom: 10px;"> <a href="https://github.com/ATheorell"> <img src="https://avatars.githubusercontent.com/u/143704446?s=64&v=4" alt="@ATheorell" width="32" height="32" style="border-radius: 50%;"> @ATheorell </a> </li> <li style="margin-right: 10px; margin-bottom: 10px;"> <a href="https://github.com/similato87"> <img src="https://avatars.githubusercontent.com/u/71301573?s=64&v=4" alt="@similato87" width="32" height="32" style="border-radius: 50%;"> @similato87 </a> </li> <li style="margin-right: 10px; margin-bottom: 10px;"> <a href="https://github.com/TheoMcCabe"> <img src="https://avatars.githubusercontent.com/u/9841960?s=64&v=4" alt="@TheoMcCabe" width="32" height="32" style="border-radius: 50%;"> @TheoMcCabe </a> </li> <li style="margin-right: 10px; margin-bottom: 10px;"> <a href="https://github.com/captivus"> <img src="https://avatars.githubusercontent.com/u/366332?s=64&v=4" alt="@captivus" width="32" height="32" style="border-radius: 50%;"> @captivus </a> </li> </ul>\n\n\n## Example\n\n\n\nhttps://github.com/gpt-engineer-org/gpt-engineer/assets/4467025/40d0a9a8-82d0-4432-9376-136df0d57c99\n', '{"language":"Python","stars":55096,"forks":7347,"watchers":55096,"open_issues":66,"topics":["ai","autonomous-agent","code-generation","codebase-generation","codegen","coding-assistant","gpt-4","gpt-engineer","openai","python"],"default_branch":"main","size_kb":20474,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer.git`","source_url":"https://github.com/gpt-engineer-org/gpt-engineer.git`"},{"type":"has_code","target_id":"github:codespaces:badge.svg","source_url":"https://github.com/codespaces/badge.svg"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpte-bench-template","source_url":"https://github.com/gpt-engineer-org/gpte-bench-template"},{"type":"has_code","target_id":"github:hendrycks:apps","source_url":"https://github.com/hendrycks/apps"},{"type":"has_code","target_id":"github:google-research:google-research","source_url":"https://github.com/google-research/google-research"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"},{"type":"has_code","target_id":"github:gpt-engineer-org:gpt-engineer","source_url":"https://github.com/gpt-engineer-org/gpt-engineer"}]', NULL, 'MIT', 'approved', 65, '0b7d284a74123b67f4b8c0b4f75df4b6', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-AntonOsika-gpt-engineer from https://github.com/AntonOsika.png
Image converted to WebP: data/images/github-AntonOsika-gpt-engineer.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-meilisearch-meilisearch', 'github--meilisearch--meilisearch', 'meilisearch', 'meilisearch', '<p align="center"> <a href="https://www.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=logo#gh-light-mode-only" target="_blank"> <img src="assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only"> </a> <a href="https://www.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=logo#gh-dark-mode-only" target="_blank"> <img src="assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only"> </a> </p> <h4 alig...', '["ai","api","app-search","database","enterprise-search","faceting","full-text-search","fuzzy-search","geosearch","hybrid-search","instantsearch","search","search-as-you-type","search-engine","semantic-search","site-search","typo-tolerance","vector-database","vector-search","vectors","rust"]', 'other', 54842, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/meilisearch/meilisearch","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center">\n  <a href="https://www.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=logo#gh-light-mode-only" target="_blank">\n    <img src="assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only">\n  </a>\n  <a href="https://www.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=logo#gh-dark-mode-only" target="_blank">\n    <img src="assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only">\n  </a>\n</p>\n\n<h4 align="center">\n  <a href="https://www.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Website</a> |\n  <a href="https://roadmap.meilisearch.com/tabs/1-under-consideration">Roadmap</a> |\n  <a href="https://www.meilisearch.com/pricing?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Meilisearch Cloud</a> |\n  <a href="https://blog.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Blog</a> |\n  <a href="https://www.meilisearch.com/docs?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Documentation</a> |\n  <a href="https://www.meilisearch.com/docs/faq?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">FAQ</a> |\n  <a href="https://discord.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Discord</a>\n</h4>\n\n<p align="center">\n  <a href="https://deps.rs/repo/github/meilisearch/meilisearch"><img src="https://deps.rs/repo/github/meilisearch/meilisearch/status.svg" alt="Dependency status"></a>\n  <a href="https://github.com/meilisearch/meilisearch/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT-informational" alt="License"></a>\n  <a href="https://github.com/meilisearch/meilisearch/queue"><img alt="Merge Queues enabled" src="https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github"></a>\n</p>\n\n<p align="center">‚ö° A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow üîç</p>\n\n[Meilisearch](https://www.meilisearch.com?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=intro) helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.\n\n<p align="center" name="demo">\n  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demo-gif#gh-light-mode-only" target="_blank">\n    <img src="assets/demo-light.gif#gh-light-mode-only" alt="A bright colored application for finding movies screening near the user">\n  </a>\n  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demo-gif#gh-dark-mode-only" target="_blank">\n    <img src="assets/demo-dark.gif#gh-dark-mode-only" alt="A dark colored application for finding movies screening near the user">\n  </a>\n</p>\n\n## üñ• Examples\n\n- [**Movies**](https://where2watch.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=organization) ‚Äî An application to help you find streaming platforms to watch movies using [hybrid search](https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos).\n- [**Flickr**](https://flickr.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=organization) ‚Äî Search and explore one hundred million Flickr images with semantic search.\n- [**Ecommerce**](https://ecommerce.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos) ‚Äî Ecommerce website using disjunctive [facets](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos), range and rating filtering, and pagination.\n- [**Songs**](https://music.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos) ‚Äî Search through 47 million of songs.\n- [**SaaS**](https://saas.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos) ‚Äî Search for contacts, deals, and companies in this [multi-tenant](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=demos) CRM application.\n\nSee the list of all our example apps in our [demos repository](https://github.com/meilisearch/demos).\n\n## ‚ú® Features\n- **Hybrid search:** Combine the best of both [semantic](https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features) & full-text search to get the most relevant results\n- **Search-as-you-type:** Find & display results in less than 50 milliseconds to provide an intuitive experience\n- **[Typo tolerance](https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** get relevant matches even when queries contain typos and misspellings\n- **[Filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features) and [faceted search](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** enhance your users'' search experience with custom filters and build a faceted search interface in a few lines of code\n- **[Sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** sort results based on price, date, or pretty much anything else your users need\n- **[Synonym support](https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** configure synonyms to include more relevant content in your search results\n- **[Geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** filter and sort documents based on geographic data\n- **[Extensive language support](https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet\n- **[Security management](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** control which users can access what data with API keys that allow fine-grained permissions handling\n- **[Multi-Tenancy](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** personalize search results for any number of application tenants\n- **Highly Customizable:** customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets\n- **[RESTful API](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=features):** integrate Meilisearch in your technical stack with our plugins and SDKs\n- **AI-ready:** works out of the box with [langchain](https://www.meilisearch.com/with/langchain) and the [model context protocol](https://github.com/meilisearch/meilisearch-mcp)\n- **Easy to install, deploy, and maintain**\n\n## üìñ Documentation\n\nYou can consult Meilisearch''s documentation at [meilisearch.com/docs](https://www.meilisearch.com/docs/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=docs).\n\n## üöÄ Getting started\n\nFor basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our [documentation](https://www.meilisearch.com/docs?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=get-started) guide.\n\n## üåç Supercharge your Meilisearch experience\n\nSay goodbye to server deployment and manual updates with [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=oss&utm_source=github&utm_medium=meilisearch). Additional features include analytics & monitoring in many regions around the world. No credit card is required.\n\n## üß∞ SDKs & integration tools\n\nInstall one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!\n\nTake a look at the complete [Meilisearch integration list](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=sdks-link).\n\n[![Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP](assets/integrations.png)](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=sdks-logos)\n\n## ‚öôÔ∏è Advanced usage\n\nExperienced users will want to keep our [API Reference](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced) close at hand.\n\nWe also offer a wide range of dedicated guides to all Meilisearch features, such as [filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced), [sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced), [geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced), [API keys](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced), and [tenant tokens](https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced).\n\nFinally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as [documents](https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced) and [indexes](https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=advanced).\n\n## üßæ Editions & Licensing\n\nMeilisearch is available in two editions:\n\n### üß™ Community Edition (CE)\n\n- Fully open source under the [MIT license](./LICENSE)\n- Core search engine with fast and relevant full-text, semantic or hybrid search\n- Free to use for anyone, including commercial usage\n\n### üè¢ Enterprise Edition (EE)\n\n- Includes advanced features such as:\n  - Sharding\n- Governed by a [commercial license](./LICENSE-EE) or the [Business Source License 1.1](https://mariadb.com/bsl11)\n- Not allowed in production without a commercial agreement with Meilisearch.\n  - You may use, modify, and distribute the Licensed Work for non-production purposes only, such as testing, development, or evaluation.\n\nWant access to Enterprise features? ‚Üí Contact us at [sales@meilisearch.com](maito:sales@meilisearch.com).\n\n## üìä Telemetry\n\nMeilisearch collects **anonymized** user data to help us improve our product. You can [deactivate this](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=telemetry#how-to-disable-data-collection) whenever you want.\n\nTo request deletion of collected data, please write to us at [privacy@meilisearch.com](mailto:privacy@meilisearch.com). Remember to include your `Instance UID` in the message, as this helps us quickly find and delete your data.\n\nIf you want to know more about the kind of data we collect and what we use it for, check the [telemetry section](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=telemetry#how-to-disable-data-collection) of our documentation.\n\n## üì´ Get in touch!\n\nMeilisearch is a search engine created by [Meili](https://www.meilisearch.com/careers), a software development company headquartered in France and with team members all over the world. Want to know more about us? [Check out our blog!](https://blog.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=contact)\n\nüóû [Subscribe to our newsletter](https://share-eu1.hsforms.com/1LN5N0x_GQgq7ss7tXmSykwfg3aq) if you don''t want to miss any updates! We promise we won''t clutter your mailbox: we only send one edition every two months.\n\nüíå Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:\n\n- For feature requests, please visit our [product repository](https://github.com/meilisearch/product/discussions)\n- Found a bug? Open an [issue](https://github.com/meilisearch/meilisearch/issues)!\n- Want to be part of our Discord community? [Join us!](https://discord.meilisearch.com/?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=contact)\n\nThank you for your support!\n\n## üë©‚Äçüíª Contributing\n\nMeilisearch is, and will always be, open-source! If you want to contribute to the project, please look at [our contribution guidelines](CONTRIBUTING.md).\n\n## üì¶ Versioning\n\nMeilisearch releases and their associated binaries are available on the project''s [releases page](https://github.com/meilisearch/meilisearch/releases).\n\nThe binaries are versioned following [SemVer conventions](https://semver.org/). To know more, read our [versioning policy](./documentation/versioning-policy.md).\n\nDifferently from the binaries, crates in this repository are not currently available on [crates.io](https://crates.io/) and do not follow [SemVer conventions](https://semver.org).\n', '{"language":"Rust","stars":54842,"forks":2290,"watchers":54842,"open_issues":276,"topics":["ai","api","app-search","database","enterprise-search","faceting","full-text-search","fuzzy-search","geosearch","hybrid-search","instantsearch","search","search-as-you-type","search-engine","semantic-search","site-search","typo-tolerance","vector-database","vector-search","vectors"],"default_branch":"main","size_kb":85322,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:meilisearch:meilisearch","source_url":"https://github.com/meilisearch/meilisearch"},{"type":"has_code","target_id":"github:meilisearch:meilisearch","source_url":"https://github.com/meilisearch/meilisearch"},{"type":"has_code","target_id":"github:meilisearch:demos","source_url":"https://github.com/meilisearch/demos"},{"type":"has_code","target_id":"github:meilisearch:meilisearch-mcp","source_url":"https://github.com/meilisearch/meilisearch-mcp"},{"type":"has_code","target_id":"github:meilisearch:product","source_url":"https://github.com/meilisearch/product"},{"type":"has_code","target_id":"github:meilisearch:meilisearch","source_url":"https://github.com/meilisearch/meilisearch"},{"type":"has_code","target_id":"github:meilisearch:meilisearch","source_url":"https://github.com/meilisearch/meilisearch"}]', NULL, 'NOASSERTION', 'approved', 80, 'b33202220af15ad8f0fe031afa0102d1', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-meilisearch-meilisearch from https://github.com/meilisearch.png
Image converted to WebP: data/images/github-meilisearch-meilisearch.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-lencx-ChatGPT', 'github--lencx--chatgpt', 'ChatGPT', 'lencx', '<p align="center"> <img width="180" src="./public/ChatGPT.png" alt="ChatGPT"> <p align="center">ChatGPT Desktop Application (Available on Mac, Windows, and Linux)</p> </p> <a href="https://www.buymeacoffee.com/lencx" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-blue.png" alt="Buy Me A Coffee" style="height: 40px !important;width: 145px !important;" ></a> --- > [!NOTE] > **If you want to experience a more powerful AI wrapper application, you can try the Noi (https:...', '["ai","app","application","chatgpt","desktop-app","gpt","gpt-3","linux","macos","notes-app","openai","rust","tauri","webview","windows","rust"]', 'other', 54349, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/lencx/ChatGPT","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center">\n  <img width="180" src="./public/ChatGPT.png" alt="ChatGPT">\n  <p align="center">ChatGPT Desktop Application (Available on Mac, Windows, and Linux)</p>\n</p>\n\n[![ChatGPT downloads](https://img.shields.io/github/downloads/lencx/ChatGPT/total.svg?style=flat-square)](https://github.com/lencx/ChatGPT/releases)\n[![chat](https://img.shields.io/badge/chat-discord-blue?style=flat&logo=discord)](https://discord.gg/aPhCRf4zZr)\n[![twitter](https://img.shields.io/badge/follow-lencx__-blue?style=flat&logo=Twitter)](https://twitter.com/lencx_)\n[![youtube](https://img.shields.io/youtube/channel/subscribers/UC__gTZL-OZKDPic7s_6Ntgg?style=social)](https://www.youtube.com/@lencx)\n\n<a href="https://www.buymeacoffee.com/lencx" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-blue.png" alt="Buy Me A Coffee" style="height: 40px !important;width: 145px !important;" ></a>\n\n---\n\n> [!NOTE]\n> **If you want to experience a more powerful AI wrapper application, you can try the Noi (https://github.com/lencx/Noi), which is a successor to the ChatGPT desktop application concept.**\n\nThank you very much for your interest in this project. OpenAI has now released the macOS version of the application, and a Windows version will be available later ([Introducing GPT-4o and more tools to ChatGPT free users](https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/)). If you prefer the official application, you can stay updated with the latest information from OpenAI.\n\nIf you want to learn about or download the previous version (v1.1.0), please click [here](https://github.com/lencx/ChatGPT/tree/release-v1.1.0).\n\nI am currently looking for some differentiating features to develop version 2.0. If you are interested in this, please stay tuned.\n\n![](./docs/static/chatgpt-v2.gif)', '{"language":"Rust","stars":54349,"forks":6198,"watchers":54349,"open_issues":893,"topics":["ai","app","application","chatgpt","desktop-app","gpt","gpt-3","linux","macos","notes-app","openai","rust","tauri","webview","windows"],"default_branch":"v2-dev","size_kb":32499,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:lencx:ChatGPT","source_url":"https://github.com/lencx/ChatGPT"},{"type":"has_code","target_id":"github:lencx:Noi","source_url":"https://github.com/lencx/Noi"},{"type":"has_code","target_id":"github:lencx:ChatGPT","source_url":"https://github.com/lencx/ChatGPT"}]', NULL, NULL, 'pending', 40, '26e808617996cc76ddbc1113b7722457', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-lencx-ChatGPT from https://github.com/lencx.png
Image converted to WebP: data/images/github-lencx-ChatGPT.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-github-spec-kit', 'github--github--spec-kit', 'spec-kit', 'github', '<div align="center"> <img src="./media/logo_large.webp" alt="Spec Kit Logo" width="200" height="200"/> <h1>üå± Spec Kit</h1> <h3><em>Build high-quality software faster.</em></h3> </div> <p align="center"> <strong>An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.</strong> </p> <p align="center"> <a href="https://github.com/github/spec-kit/actions/workflows/release.yml"><img src="https://github.com/githu...', '["ai","copilot","development","engineering","prd","spec","spec-driven","python"]', 'other', 54023, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/github/spec-kit","fetched_at":"2025-12-08T10:39:52.045Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<div align="center">\n    <img src="./media/logo_large.webp" alt="Spec Kit Logo" width="200" height="200"/>\n    <h1>üå± Spec Kit</h1>\n    <h3><em>Build high-quality software faster.</em></h3>\n</div>\n\n<p align="center">\n    <strong>An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.</strong>\n</p>\n\n<p align="center">\n    <a href="https://github.com/github/spec-kit/actions/workflows/release.yml"><img src="https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg" alt="Release"/></a>\n    <a href="https://github.com/github/spec-kit/stargazers"><img src="https://img.shields.io/github/stars/github/spec-kit?style=social" alt="GitHub stars"/></a>\n    <a href="https://github.com/github/spec-kit/blob/main/LICENSE"><img src="https://img.shields.io/github/license/github/spec-kit" alt="License"/></a>\n    <a href="https://github.github.io/spec-kit/"><img src="https://img.shields.io/badge/docs-GitHub_Pages-blue" alt="Documentation"/></a>\n</p>\n\n---\n\n## Table of Contents\n\n- [ü§î What is Spec-Driven Development?](#-what-is-spec-driven-development)\n- [‚ö° Get Started](#-get-started)\n- [üìΩÔ∏è Video Overview](#Ô∏è-video-overview)\n- [ü§ñ Supported AI Agents](#-supported-ai-agents)\n- [üîß Specify CLI Reference](#-specify-cli-reference)\n- [üìö Core Philosophy](#-core-philosophy)\n- [üåü Development Phases](#-development-phases)\n- [üéØ Experimental Goals](#-experimental-goals)\n- [üîß Prerequisites](#-prerequisites)\n- [üìñ Learn More](#-learn-more)\n- [üìã Detailed Process](#-detailed-process)\n- [üîç Troubleshooting](#-troubleshooting)\n- [üë• Maintainers](#-maintainers)\n- [üí¨ Support](#-support)\n- [üôè Acknowledgements](#-acknowledgements)\n- [üìÑ License](#-license)\n\n## ü§î What is Spec-Driven Development?\n\nSpec-Driven Development **flips the script** on traditional software development. For decades, code has been king ‚Äî specifications were just scaffolding we built and discarded once the "real work" of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.\n\n## ‚ö° Get Started\n\n### 1. Install Specify CLI\n\nChoose your preferred installation method:\n\n#### Option 1: Persistent Installation (Recommended)\n\nInstall once and use everywhere:\n\n```bash\nuv tool install specify-cli --from git+https://github.com/github/spec-kit.git\n```\n\nThen use the tool directly:\n\n```bash\n# Create new project\nspecify init <PROJECT_NAME>\n\n# Or initialize in existing project\nspecify init . --ai claude\n# or\nspecify init --here --ai claude\n\n# Check installed tools\nspecify check\n```\n\nTo upgrade Specify, see the [Upgrade Guide](./docs/upgrade.md) for detailed instructions. Quick upgrade:\n\n```bash\nuv tool install specify-cli --force --from git+https://github.com/github/spec-kit.git\n```\n\n#### Option 2: One-time Usage\n\nRun directly without installing:\n\n```bash\nuvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>\n```\n\n**Benefits of persistent installation:**\n\n- Tool stays installed and available in PATH\n- No need to create shell aliases\n- Better tool management with `uv tool list`, `uv tool upgrade`, `uv tool uninstall`\n- Cleaner shell configuration\n\n### 2. Establish project principles\n\nLaunch your AI assistant in the project directory. The `/speckit.*` commands are available in the assistant.\n\nUse the **`/speckit.constitution`** command to create your project''s governing principles and development guidelines that will guide all subsequent development.\n\n```bash\n/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements\n```\n\n### 3. Create the spec\n\nUse the **`/speckit.specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.\n\n```bash\n/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.\n```\n\n### 4. Create a technical implementation plan\n\nUse the **`/speckit.plan`** command to provide your tech stack and architecture choices.\n\n```bash\n/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.\n```\n\n### 5. Break down into tasks\n\nUse **`/speckit.tasks`** to create an actionable task list from your implementation plan.\n\n```bash\n/speckit.tasks\n```\n\n### 6. Execute implementation\n\nUse **`/speckit.implement`** to execute all tasks and build your feature according to the plan.\n\n```bash\n/speckit.implement\n```\n\nFor detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).\n\n## üìΩÔ∏è Video Overview\n\nWant to see Spec Kit in action? Watch our [video overview](https://www.youtube.com/watch?v=a9eR1xsfvHg&pp=0gcJCckJAYcqIYzv)!\n\n[![Spec Kit video header](/media/spec-kit-video-header.jpg)](https://www.youtube.com/watch?v=a9eR1xsfvHg&pp=0gcJCckJAYcqIYzv)\n\n## ü§ñ Supported AI Agents\n\n| Agent                                                                                | Support | Notes                                                                                                                                     |\n| ------------------------------------------------------------------------------------ | ------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n| [Qoder CLI](https://qoder.com/cli)                                                   | ‚úÖ      |                                                                                                                                           |\n| [Amazon Q Developer CLI](https://aws.amazon.com/developer/learning/q-developer-cli/) | ‚ö†Ô∏è      | Amazon Q Developer CLI [does not support](https://github.com/aws/amazon-q-developer-cli/issues/3064) custom arguments for slash commands. |\n| [Amp](https://ampcode.com/)                                                          | ‚úÖ      |                                                                                                                                           |\n| [Auggie CLI](https://docs.augmentcode.com/cli/overview)                              | ‚úÖ      |                                                                                                                                           |\n| [Claude Code](https://www.anthropic.com/claude-code)                                 | ‚úÖ      |                                                                                                                                           |\n| [CodeBuddy CLI](https://www.codebuddy.ai/cli)                                        | ‚úÖ      |                                                                                                                                           |\n| [Codex CLI](https://github.com/openai/codex)                                         | ‚úÖ      |                                                                                                                                           |\n| [Cursor](https://cursor.sh/)                                                         | ‚úÖ      |                                                                                                                                           |\n| [Gemini CLI](https://github.com/google-gemini/gemini-cli)                            | ‚úÖ      |                                                                                                                                           |\n| [GitHub Copilot](https://code.visualstudio.com/)                                     | ‚úÖ      |                                                                                                                                           |\n| [IBM Bob](https://www.ibm.com/products/bob)                                          | ‚úÖ      | IDE-based agent with slash command support                                                                                                |\n| [Jules](https://jules.google.com/)                                                   | ‚úÖ      |                                                                                                                                           |\n| [Kilo Code](https://github.com/Kilo-Org/kilocode)                                    | ‚úÖ      |                                                                                                                                           |\n| [opencode](https://opencode.ai/)                                                     | ‚úÖ      |                                                                                                                                           |\n| [Qwen Code](https://github.com/QwenLM/qwen-code)                                     | ‚úÖ      |                                                                                                                                           |\n| [Roo Code](https://roocode.com/)                                                     | ‚úÖ      |                                                                                                                                           |\n| [SHAI (OVHcloud)](https://github.com/ovh/shai)                                       | ‚úÖ      |                                                                                                                                           |\n| [Windsurf](https://windsurf.com/)                                                    | ‚úÖ      |                                                                                                                                           |\n\n## üîß Specify CLI Reference\n\nThe `specify` command supports the following options:\n\n### Commands\n\n| Command | Description                                                                                                                                             |\n| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `init`  | Initialize a new Specify project from the latest template                                                                                               |\n| `check` | Check for installed tools (`git`, `claude`, `gemini`, `code`/`code-insiders`, `cursor-agent`, `windsurf`, `qwen`, `opencode`, `codex`, `shai`, `qoder`) |\n\n### `specify init` Arguments & Options\n\n| Argument/Option        | Type     | Description                                                                                                                                                                                  |\n| ---------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `<project-name>`       | Argument | Name for your new project directory (optional if using `--here`, or use `.` for current directory)                                                                                           |\n| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor-agent`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, `roo`, `codebuddy`, `amp`, `shai`, `q`, `bob`, or `qoder` |\n| `--script`             | Option   | Script variant to use: `sh` (bash/zsh) or `ps` (PowerShell)                                                                                                                                  |\n| `--ignore-agent-tools` | Flag     | Skip checks for AI agent tools like Claude Code                                                                                                                                              |\n| `--no-git`             | Flag     | Skip git repository initialization                                                                                                                                                           |\n| `--here`               | Flag     | Initialize project in the current directory instead of creating a new one                                                                                                                    |\n| `--force`              | Flag     | Force merge/overwrite when initializing in current directory (skip confirmation)                                                                                                             |\n| `--skip-tls`           | Flag     | Skip SSL/TLS verification (not recommended)                                                                                                                                                  |\n| `--debug`              | Flag     | Enable detailed debug output for troubleshooting                                                                                                                                             |\n| `--github-token`       | Option   | GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)                                                                                                                    |\n\n### Examples\n\n```bash\n# Basic project initialization\nspecify init my-project\n\n# Initialize with specific AI assistant\nspecify init my-project --ai claude\n\n# Initialize with Cursor support\nspecify init my-project --ai cursor-agent\n\n# Initialize with Qoder support\nspecify init my-project --ai qoder\n\n# Initialize with Windsurf support\nspecify init my-project --ai windsurf\n\n# Initialize with Amp support\nspecify init my-project --ai amp\n\n# Initialize with SHAI support\nspecify init my-project --ai shai\n\n# Initialize with IBM Bob support\nspecify init my-project --ai bob\n\n# Initialize with PowerShell scripts (Windows/cross-platform)\nspecify init my-project --ai copilot --script ps\n\n# Initialize in current directory\nspecify init . --ai copilot\n# or use the --here flag\nspecify init --here --ai copilot\n\n# Force merge into current (non-empty) directory without confirmation\nspecify init . --force --ai copilot\n# or\nspecify init --here --force --ai copilot\n\n# Skip git initialization\nspecify init my-project --ai gemini --no-git\n\n# Enable debug output for troubleshooting\nspecify init my-project --ai claude --debug\n\n# Use GitHub token for API requests (helpful for corporate environments)\nspecify init my-project --ai claude --github-token ghp_your_token_here\n\n# Check system requirements\nspecify check\n```\n\n### Available Slash Commands\n\nAfter running `specify init`, your AI coding agent will have access to these slash commands for structured development:\n\n#### Core Commands\n\nEssential commands for the Spec-Driven Development workflow:\n\n| Command                 | Description                                                              |\n| ----------------------- | ------------------------------------------------------------------------ |\n| `/speckit.constitution` | Create or update project governing principles and development guidelines |\n| `/speckit.specify`      | Define what you want to build (requirements and user stories)            |\n| `/speckit.plan`         | Create technical implementation plans with your chosen tech stack        |\n| `/speckit.tasks`        | Generate actionable task lists for implementation                        |\n| `/speckit.implement`    | Execute all tasks to build the feature according to the plan             |\n\n#### Optional Commands\n\nAdditional commands for enhanced quality and validation:\n\n| Command              | Description                                                                                                                          |\n| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n| `/speckit.clarify`   | Clarify underspecified areas (recommended before `/speckit.plan`; formerly `/quizme`)                                                |\n| `/speckit.analyze`   | Cross-artifact consistency & coverage analysis (run after `/speckit.tasks`, before `/speckit.implement`)                             |\n| `/speckit.checklist` | Generate custom quality checklists that validate requirements completeness, clarity, and consistency (like "unit tests for English") |\n\n### Environment Variables\n\n| Variable          | Description                                                                                                                                                                                                                                                                                            |\n| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.<br/>\*\*Must be set in the context of the agent you''re working with prior to using `/speckit.plan` or follow-up commands. |\n\n## üìö Core Philosophy\n\nSpec-Driven Development is a structured process that emphasizes:\n\n- **Intent-driven development** where specifications define the "*what*" before the "*how*"\n- **Rich specification creation** using guardrails and organizational principles\n- **Multi-step refinement** rather than one-shot code generation from prompts\n- **Heavy reliance** on advanced AI model capabilities for specification interpretation\n\n## üåü Development Phases\n\n| Phase                                    | Focus                    | Key Activities                                                                                                                                                     |\n| ---------------------------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| **0-to-1 Development** ("Greenfield")    | Generate from scratch    | <ul><li>Start with high-level requirements</li><li>Generate specifications</li><li>Plan implementation steps</li><li>Build production-ready applications</li></ul> |\n| **Creative Exploration**                 | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul>                         |\n| **Iterative Enhancement** ("Brownfield") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul>                                                                |\n\n## üéØ Experimental Goals\n\nOur research and experimentation focus on:\n\n### Technology independence\n\n- Create applications using diverse technology stacks\n- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks\n\n### Enterprise constraints\n\n- Demonstrate mission-critical application development\n- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)\n- Support enterprise design systems and compliance requirements\n\n### User-centric development\n\n- Build applications for different user cohorts and preferences\n- Support various development approaches (from vibe-coding to AI-native development)\n\n### Creative & iterative processes\n\n- Validate the concept of parallel implementation exploration\n- Provide robust iterative feature development workflows\n- Extend processes to handle upgrades and modernization tasks\n\n## üîß Prerequisites\n\n- **Linux/macOS/Windows**\n- [Supported](#-supported-ai-agents) AI coding agent.\n- [uv](https://docs.astral.sh/uv/) for package management\n- [Python 3.11+](https://www.python.org/downloads/)\n- [Git](https://git-scm.com/downloads)\n\nIf you encounter issues with an agent, please open an issue so we can refine the integration.\n\n## üìñ Learn More\n\n- **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process\n- **[Detailed Walkthrough](#-detailed-process)** - Step-by-step implementation guide\n\n---\n\n## üìã Detailed Process\n\n<details>\n<summary>Click to expand the detailed step-by-step walkthrough</summary>\n\nYou can use the Specify CLI to bootstrap your project, which will bring in the required artifacts in your environment. Run:\n\n```bash\nspecify init <project_name>\n```\n\nOr initialize in the current directory:\n\n```bash\nspecify init .\n# or use the --here flag\nspecify init --here\n# Skip confirmation when the directory already has files\nspecify init . --force\n# or\nspecify init --here --force\n```\n\n![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)\n\nYou will be prompted to select the AI agent you are using. You can also proactively specify it directly in the terminal:\n\n```bash\nspecify init <project_name> --ai claude\nspecify init <project_name> --ai gemini\nspecify init <project_name> --ai copilot\n\n# Or in current directory:\nspecify init . --ai claude\nspecify init . --ai codex\n\n# or use --here flag\nspecify init --here --ai claude\nspecify init --here --ai codex\n\n# Force merge into a non-empty current directory\nspecify init . --force --ai claude\n\n# or\nspecify init --here --force --ai claude\n```\n\nThe CLI will check if you have Claude Code, Gemini CLI, Cursor CLI, Qwen CLI, opencode, Codex CLI, Qoder CLI, or Amazon Q Developer CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:\n\n```bash\nspecify init <project_name> --ai claude --ignore-agent-tools\n```\n\n### **STEP 1:** Establish project principles\n\nGo to the project folder and run your AI agent. In our example, we''re using `claude`.\n\n![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)\n\nYou will know that things are configured correctly if you see the `/speckit.constitution`, `/speckit.specify`, `/speckit.plan`, `/speckit.tasks`, and `/speckit.implement` commands available.\n\nThe first step should be establishing your project''s governing principles using the `/speckit.constitution` command. This helps ensure consistent decision-making throughout all subsequent development phases:\n\n```text\n/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements. Include governance for how these principles should guide technical decisions and implementation choices.\n```\n\nThis step creates or updates the `.specify/memory/constitution.md` file with your project''s foundational guidelines that the AI agent will reference during specification, planning, and implementation phases.\n\n### **STEP 2:** Create project specifications\n\nWith your project principles established, you can now create the functional specifications. Use the `/speckit.specify` command and then provide the concrete requirements for the project you want to develop.\n\n> [!IMPORTANT]\n> Be as explicit as possible about *what* you are trying to build and *why*. **Do not focus on the tech stack at this point**.\n\nAn example prompt:\n\n```text\nDevelop Taskify, a team productivity platform. It should allow users to create projects, add team members,\nassign tasks, comment and move tasks between boards in Kanban style. In this initial phase for this feature,\nlet''s call it "Create Taskify," let''s have multiple users but the users will be declared ahead of time, predefined.\nI want five users in two different categories, one product manager and four engineers. Let''s create three\ndifferent sample projects. Let''s have the standard Kanban columns for the status of each task, such as "To Do,"\n"In Progress," "In Review," and "Done." There will be no login for this application as this is just the very\nfirst testing thing to ensure that our basic features are set up. For each task in the UI for a task card,\nyou should be able to change the current status of the task between the different columns in the Kanban work board.\nYou should be able to leave an unlimited number of comments for a particular card. You should be able to, from that task\ncard, assign one of the valid users. When you first launch Taskify, it''s going to give you a list of the five users to pick\nfrom. There will be no password required. When you click on a user, you go into the main view, which displays the list of\nprojects. When you click on a project, you open the Kanban board for that project. You''re going to see the columns.\nYou''ll be able to drag and drop cards back and forth between different columns. You will see any cards that are\nassigned to you, the currently logged in user, in a different color from all the other ones, so you can quickly\nsee yours. You can edit any comments that you make, but you can''t edit comments that other people made. You can\ndelete any comments that you made, but you can''t delete comments anybody else made.\n```\n\nAfter this prompt is entered, you should see Claude Code kick off the planning and spec drafting process. Claude Code will also trigger some of the built-in scripts to set up the repository.\n\nOnce this step is completed, you should have a new branch created (e.g., `001-create-taskify`), as well as a new specification in the `specs/001-create-taskify` directory.\n\nThe produced specification should contain a set of user stories and functional requirements, as defined in the template.\n\nAt this stage, your project folder contents should resemble the following:\n\n```text\n‚îî‚îÄ‚îÄ .specify\n    ‚îú‚îÄ‚îÄ memory\n    ‚îÇ  ‚îî‚îÄ‚îÄ constitution.md\n    ‚îú‚îÄ‚îÄ scripts\n    ‚îÇ  ‚îú‚îÄ‚îÄ check-prerequisites.sh\n    ‚îÇ  ‚îú‚îÄ‚îÄ common.sh\n    ‚îÇ  ‚îú‚îÄ‚îÄ create-new-feature.sh\n    ‚îÇ  ‚îú‚îÄ‚îÄ setup-plan.sh\n    ‚îÇ  ‚îî‚îÄ‚îÄ update-claude-md.sh\n    ‚îú‚îÄ‚îÄ specs\n    ‚îÇ  ‚îî‚îÄ‚îÄ 001-create-taskify\n    ‚îÇ      ‚îî‚îÄ‚îÄ spec.md\n    ‚îî‚îÄ‚îÄ templates\n        ‚îú‚îÄ‚îÄ plan-template.md\n        ‚îú‚îÄ‚îÄ spec-template.md\n        ‚îî‚îÄ‚îÄ tasks-template.md\n```\n\n### **STEP 3:** Functional specification clarification (required before planning)\n\nWith the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt.\n\nYou should run the structured clarification workflow **before** creating a technical plan to reduce rework downstream.\n\nPreferred order:\n\n1. Use `/speckit.clarify` (structured) ‚Äì sequential, coverage-based questioning that records answers in a Clarifications section.\n2. Optionally follow up with ad-hoc free-form refinement if something still feels vague.\n\nIf you intentionally want to skip clarification (e.g., spike or exploratory prototype), explicitly state that so the agent doesn''t block on missing clarifications.\n\nExample free-form refinement prompt (after `/speckit.clarify` if still needed):\n\n```text\nFor each sample project or project that you create there should be a variable number of tasks between 5 and 15\ntasks for each one randomly distributed into different states of completion. Make sure that there''s at least\none task in each stage of completion.\n```\n\nYou should also ask Claude Code to validate the **Review & Acceptance Checklist**, checking off the things that are validated/pass the requirements, and leave the ones that are not unchecked. The following prompt can be used:\n\n```text\nRead the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.\n```\n\nIt''s important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.\n\n### **STEP 4:** Generate a plan\n\nYou can now be specific about the tech stack and other technical requirements. You can use the `/speckit.plan` command that is built into the project template with a prompt like this:\n\n```text\nWe are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use\nBlazor server with drag-and-drop task boards, real-time updates. There should be a REST API created with a projects API,\ntasks API, and a notifications API.\n```\n\nThe output of this step will include a number of implementation detail documents, with your directory tree resembling this:\n\n```text\n.\n‚îú‚îÄ‚îÄ CLAUDE.md\n‚îú‚îÄ‚îÄ memory\n‚îÇ  ‚îî‚îÄ‚îÄ constitution.md\n‚îú‚îÄ‚îÄ scripts\n‚îÇ  ‚îú‚îÄ‚îÄ check-prerequisites.sh\n‚îÇ  ‚îú‚îÄ‚îÄ common.sh\n‚îÇ  ‚îú‚îÄ‚îÄ create-new-feature.sh\n‚îÇ  ‚îú‚îÄ‚îÄ setup-plan.sh\n‚îÇ  ‚îî‚îÄ‚îÄ update-claude-md.sh\n‚îú‚îÄ‚îÄ specs\n‚îÇ  ‚îî‚îÄ‚îÄ 001-create-taskify\n‚îÇ      ‚îú‚îÄ‚îÄ contracts\n‚îÇ      ‚îÇ  ‚îú‚îÄ‚îÄ api-spec.json\n‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ signalr-spec.md\n‚îÇ      ‚îú‚îÄ‚îÄ data-model.md\n‚îÇ      ‚îú‚îÄ‚îÄ plan.md\n‚îÇ      ‚îú‚îÄ‚îÄ quickstart.md\n‚îÇ      ‚îú‚îÄ‚îÄ research.md\n‚îÇ      ‚îî‚îÄ‚îÄ spec.md\n‚îî‚îÄ‚îÄ templates\n    ‚îú‚îÄ‚îÄ CLAUDE-template.md\n    ‚îú‚îÄ‚îÄ plan-template.md\n    ‚îú‚îÄ‚îÄ spec-template.md\n    ‚îî‚îÄ‚îÄ tasks-template.md\n```\n\nCheck the `research.md` document to ensure that the right tech stack is used, based on your instructions. You can ask Claude Code to refine it if any of the components stand out, or even have it check the locally-installed version of the platform/framework you want to use (e.g., .NET).\n\nAdditionally, you might want to ask Claude Code to research details about the chosen tech stack if it''s something that is rapidly changing (e.g., .NET Aspire, JS frameworks), with a prompt like this:\n\n```text\nI want you to go through the implementation plan and implementation details, looking for areas that could\nbenefit from additional research as .NET Aspire is a rapidly changing library. For those areas that you identify that\nrequire further research, I want you to update the research document with additional details about the specific\nversions that we are going to be using in this Taskify application and spawn parallel research tasks to clarify\nany details using research from the web.\n```\n\nDuring this process, you might find that Claude Code gets stuck researching the wrong thing - you can help nudge it in the right direction with a prompt like this:\n\n```text\nI think we need to break this down into a series of steps. First, identify a list of tasks\nthat you would need to do during implementation that you''re not sure of or would benefit\nfrom further research. Write down a list of those tasks. And then for each one of these tasks,\nI want you to spin up a separate research task so that the net results is we are researching\nall of those very specific tasks in parallel. What I saw you doing was it looks like you were\nresearching .NET Aspire in general and I don''t think that''s gonna do much for us in this case.\nThat''s way too untargeted research. The research needs to help you solve a specific targeted question.\n```\n\n> [!NOTE]\n> Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.\n\n### **STEP 5:** Have Claude Code validate the plan\n\nWith the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:\n\n```text\nNow I want you to go and audit the implementation plan and the implementation detail files.\nRead through it with an eye on determining whether or not there is a sequence of tasks that you need\nto be doing that are obvious from reading this. Because I don''t know if there''s enough here. For example,\nwhen I look at the core implementation, it would be useful to reference the appropriate places in the implementation\ndetails where it can find the information as it walks through each step in the core implementation or in the refinement.\n```\n\nThis helps refine the implementation plan and helps you avoid potential blind spots that Claude Code missed in its planning cycle. Once the initial refinement pass is complete, ask Claude Code to go through the checklist once more before you can get to the implementation.\n\nYou can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.com/en/github-cli/github-cli) installed) to go ahead and create a pull request from your current branch to `main` with a detailed description, to make sure that the effort is properly tracked.\n\n> [!NOTE]\n> Before you have the agent implement it, it''s also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.\n\n### **STEP 6:** Generate task breakdown with /speckit.tasks\n\nWith the implementation plan validated, you can now break down the plan into specific, actionable tasks that can be executed in the correct order. Use the `/speckit.tasks` command to automatically generate a detailed task breakdown from your implementation plan:\n\n```text\n/speckit.tasks\n```\n\nThis step creates a `tasks.md` file in your feature specification directory that contains:\n\n- **Task breakdown organized by user story** - Each user story becomes a separate implementation phase with its own set of tasks\n- **Dependency management** - Tasks are ordered to respect dependencies between components (e.g., models before services, services before endpoints)\n- **Parallel execution markers** - Tasks that can run in parallel are marked with `[P]` to optimize development workflow\n- **File path specifications** - Each task includes the exact file paths where implementation should occur\n- **Test-driven development structure** - If tests are requested, test tasks are included and ordered to be written before implementation\n- **Checkpoint validation** - Each user story phase includes checkpoints to validate independent functionality\n\nThe generated tasks.md provides a clear roadmap for the `/speckit.implement` command, ensuring systematic implementation that maintains code quality and allows for incremental delivery of user stories.\n\n### **STEP 7:** Implementation\n\nOnce ready, use the `/speckit.implement` command to execute your implementation plan:\n\n```text\n/speckit.implement\n```\n\nThe `/speckit.implement` command will:\n\n- Validate that all prerequisites are in place (constitution, spec, plan, and tasks)\n- Parse the task breakdown from `tasks.md`\n- Execute tasks in the correct order, respecting dependencies and parallel execution markers\n- Follow the TDD approach defined in your task plan\n- Provide progress updates and handle errors appropriately\n\n> [!IMPORTANT]\n> The AI agent will execute local CLI commands (such as `dotnet`, `npm`, etc.) - make sure you have the required tools installed on your machine.\n\nOnce the implementation is complete, test the application and resolve any runtime errors that may not be visible in CLI logs (e.g., browser console errors). You can copy and paste such errors back to your AI agent for resolution.\n\n</details>\n\n---\n\n## üîç Troubleshooting\n\n### Git Credential Manager on Linux\n\nIf you''re having issues with Git authentication on Linux, you can install Git Credential Manager:\n\n```bash\n#!/usr/bin/env bash\nset -e\necho "Downloading Git Credential Manager v2.6.1..."\nwget https://github.com/git-ecosystem/git-credential-manager/releases/download/v2.6.1/gcm-linux_amd64.2.6.1.deb\necho "Installing Git Credential Manager..."\nsudo dpkg -i gcm-linux_amd64.2.6.1.deb\necho "Configuring Git to use GCM..."\ngit config --global credential.helper manager\necho "Cleaning up..."\nrm gcm-linux_amd64.2.6.1.deb\n```\n\n## üë• Maintainers\n\n- Den Delimarsky ([@localden](https://github.com/localden))\n- John Lam ([@jflam](https://github.com/jflam))\n\n## üí¨ Support\n\nFor support, please open a [GitHub issue](https://github.com/github/spec-kit/issues/new). We welcome bug reports, feature requests, and questions about using Spec-Driven Development.\n\n## üôè Acknowledgements\n\nThis project is heavily influenced by and based on the work and research of [John Lam](https://github.com/jflam).\n\n## üìÑ License\n\nThis project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.\n', '{"language":"Python","stars":54023,"forks":4680,"watchers":54023,"open_issues":485,"topics":["ai","copilot","development","engineering","prd","spec","spec-driven"],"default_branch":"main","size_kb":5143,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:github:spec-kit","source_url":"https://github.com/github/spec-kit"},{"type":"has_code","target_id":"github:github:spec-kit","source_url":"https://github.com/github/spec-kit"},{"type":"has_code","target_id":"github:github:spec-kit","source_url":"https://github.com/github/spec-kit"},{"type":"has_code","target_id":"github:github:spec-kit","source_url":"https://github.com/github/spec-kit"},{"type":"has_code","target_id":"github:github:spec-kit.git","source_url":"https://github.com/github/spec-kit.git"},{"type":"has_code","target_id":"github:github:spec-kit.git","source_url":"https://github.com/github/spec-kit.git"},{"type":"has_code","target_id":"github:github:spec-kit.git","source_url":"https://github.com/github/spec-kit.git"},{"type":"has_code","target_id":"github:aws:amazon-q-developer-cli","source_url":"https://github.com/aws/amazon-q-developer-cli"},{"type":"has_code","target_id":"github:openai:codex","source_url":"https://github.com/openai/codex"},{"type":"has_code","target_id":"github:google-gemini:gemini-cli","source_url":"https://github.com/google-gemini/gemini-cli"},{"type":"has_code","target_id":"github:Kilo-Org:kilocode","source_url":"https://github.com/Kilo-Org/kilocode"},{"type":"has_code","target_id":"github:QwenLM:qwen-code","source_url":"https://github.com/QwenLM/qwen-code"},{"type":"has_code","target_id":"github:ovh:shai","source_url":"https://github.com/ovh/shai"},{"type":"has_code","target_id":"github:git-ecosystem:git-credential-manager","source_url":"https://github.com/git-ecosystem/git-credential-manager"},{"type":"has_code","target_id":"github:github:spec-kit","source_url":"https://github.com/github/spec-kit"}]', NULL, 'MIT', 'approved', 80, '35483b4bafef6da143e697bf529399b2', NULL, NULL, CURRENT_TIMESTAMP);
