/* LOGS:
Downloading image for github-TabbyML-tabby from https://github.com/TabbyML.png
Image converted to WebP: data/images/github-TabbyML-tabby.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-danny-avila-LibreChat', 'github--danny-avila--librechat', 'LibreChat', 'danny-avila', '<p align="center"> <a href="https://librechat.ai"> <img src="client/public/assets/logo.svg" height="256"> </a> <h1 align="center"> <a href="https://librechat.ai">LibreChat</a> </h1> </p> <p align="center"> <a href="https://discord.librechat.ai"> <img src="https://img.shields.io/discord/1086345563026489514?label=&logo=discord&style=for-the-badge&logoWidth=20&logoColor=white&labelColor=000000&color=blueviolet"> </a> <a href="https://www.youtube.com/@LibreChat"> <img src="https://img.shields.io/...', '["ai","anthropic","artifacts","aws","azure","chatgpt","chatgpt-clone","claude","clone","deepseek","gemini","google","gpt-5","librechat","mcp","o1","openai","responses-api","vision","webui","typescript"]', 'other', 32239, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/danny-avila/LibreChat","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'model', '<p align="center">\n  <a href="https://librechat.ai">\n    <img src="client/public/assets/logo.svg" height="256">\n  </a>\n  <h1 align="center">\n    <a href="https://librechat.ai">LibreChat</a>\n  </h1>\n</p>\n\n<p align="center">\n  <a href="https://discord.librechat.ai"> \n    <img\n      src="https://img.shields.io/discord/1086345563026489514?label=&logo=discord&style=for-the-badge&logoWidth=20&logoColor=white&labelColor=000000&color=blueviolet">\n  </a>\n  <a href="https://www.youtube.com/@LibreChat"> \n    <img\n      src="https://img.shields.io/badge/YOUTUBE-red.svg?style=for-the-badge&logo=youtube&logoColor=white&labelColor=000000&logoWidth=20">\n  </a>\n  <a href="https://docs.librechat.ai"> \n    <img\n      src="https://img.shields.io/badge/DOCS-blue.svg?style=for-the-badge&logo=read-the-docs&logoColor=white&labelColor=000000&logoWidth=20">\n  </a>\n  <a aria-label="Sponsors" href="https://github.com/sponsors/danny-avila">\n    <img\n      src="https://img.shields.io/badge/SPONSORS-brightgreen.svg?style=for-the-badge&logo=github-sponsors&logoColor=white&labelColor=000000&logoWidth=20">\n  </a>\n</p>\n\n<p align="center">\n<a href="https://railway.app/template/b5k2mn?referralCode=HI9hWz">\n  <img src="https://railway.app/button.svg" alt="Deploy on Railway" height="30">\n</a>\n<a href="https://zeabur.com/templates/0X2ZY8">\n  <img src="https://zeabur.com/button.svg" alt="Deploy on Zeabur" height="30"/>\n</a>\n<a href="https://template.cloud.sealos.io/deploy?templateName=librechat">\n  <img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg" alt="Deploy on Sealos" height="30">\n</a>\n</p>\n\n<p align="center">\n  <a href="https://www.librechat.ai/docs/translation">\n    <img \n      src="https://img.shields.io/badge/dynamic/json.svg?style=for-the-badge&color=2096F3&label=locize&query=%24.translatedPercentage&url=https://api.locize.app/badgedata/4cb2598b-ed4d-469c-9b04-2ed531a8cb45&suffix=%+translated" \n      alt="Translation Progress">\n  </a>\n</p>\n\n\n# ‚ú® Features\n\n- üñ•Ô∏è **UI & Experience** inspired by ChatGPT with enhanced design and features\n\n- ü§ñ **AI Model Selection**:  \n  - Anthropic (Claude), AWS Bedrock, OpenAI, Azure OpenAI, Google, Vertex AI, OpenAI Responses API (incl. Azure)\n  - [Custom Endpoints](https://www.librechat.ai/docs/quick_start/custom_endpoints): Use any OpenAI-compatible API with LibreChat, no proxy required\n  - Compatible with [Local & Remote AI Providers](https://www.librechat.ai/docs/configuration/librechat_yaml/ai_endpoints):\n    - Ollama, groq, Cohere, Mistral AI, Apple MLX, koboldcpp, together.ai,\n    - OpenRouter, Helicone, Perplexity, ShuttleAI, Deepseek, Qwen, and more\n\n- üîß **[Code Interpreter API](https://www.librechat.ai/docs/features/code_interpreter)**: \n  - Secure, Sandboxed Execution in Python, Node.js (JS/TS), Go, C/C++, Java, PHP, Rust, and Fortran\n  - Seamless File Handling: Upload, process, and download files directly\n  - No Privacy Concerns: Fully isolated and secure execution\n\n- üî¶ **Agents & Tools Integration**:  \n  - **[LibreChat Agents](https://www.librechat.ai/docs/features/agents)**:\n    - No-Code Custom Assistants: Build specialized, AI-driven helpers\n    - Agent Marketplace: Discover and deploy community-built agents\n    - Collaborative Sharing: Share agents with specific users and groups\n    - Flexible & Extensible: Use MCP Servers, tools, file search, code execution, and more\n    - Compatible with Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, Google, Vertex AI, Responses API, and more\n    - [Model Context Protocol (MCP) Support](https://modelcontextprotocol.io/clients#librechat) for Tools\n\n- üîç **Web Search**:  \n  - Search the internet and retrieve relevant information to enhance your AI context\n  - Combines search providers, content scrapers, and result rerankers for optimal results\n  - **Customizable Jina Reranking**: Configure custom Jina API URLs for reranking services\n  - **[Learn More ‚Üí](https://www.librechat.ai/docs/features/web_search)**\n\n- ü™Ñ **Generative UI with Code Artifacts**:  \n  - [Code Artifacts](https://youtu.be/GfTj7O4gmd0?si=WJbdnemZpJzBrJo3) allow creation of React, HTML, and Mermaid diagrams directly in chat\n\n- üé® **Image Generation & Editing**\n  - Text-to-image and image-to-image with [GPT-Image-1](https://www.librechat.ai/docs/features/image_gen#1--openai-image-tools-recommended)\n  - Text-to-image with [DALL-E (3/2)](https://www.librechat.ai/docs/features/image_gen#2--dalle-legacy), [Stable Diffusion](https://www.librechat.ai/docs/features/image_gen#3--stable-diffusion-local), [Flux](https://www.librechat.ai/docs/features/image_gen#4--flux), or any [MCP server](https://www.librechat.ai/docs/features/image_gen#5--model-context-protocol-mcp)\n  - Produce stunning visuals from prompts or refine existing images with a single instruction\n\n- üíæ **Presets & Context Management**:  \n  - Create, Save, & Share Custom Presets  \n  - Switch between AI Endpoints and Presets mid-chat\n  - Edit, Resubmit, and Continue Messages with Conversation branching  \n  - Create and share prompts with specific users and groups\n  - [Fork Messages & Conversations](https://www.librechat.ai/docs/features/fork) for Advanced Context control\n\n- üí¨ **Multimodal & File Interactions**:  \n  - Upload and analyze images with Claude 3, GPT-4.5, GPT-4o, o1, Llama-Vision, and Gemini üì∏  \n  - Chat with Files using Custom Endpoints, OpenAI, Azure, Anthropic, AWS Bedrock, & Google üóÉÔ∏è\n\n- üåé **Multilingual UI**:\n  - English, ‰∏≠Êñá (ÁÆÄ‰Ωì), ‰∏≠Êñá (ÁπÅÈ´î), ÿßŸÑÿπÿ±ÿ®Ÿäÿ©, Deutsch, Espa√±ol, Fran√ßais, Italiano\n  - Polski, Portugu√™s (PT), Portugu√™s (BR), –†—É—Å—Å–∫–∏–π, Êó•Êú¨Ë™û, Svenska, ÌïúÍµ≠Ïñ¥, Ti·∫øng Vi·ªát\n  - T√ºrk√ße, Nederlands, ◊¢◊ë◊®◊ô◊™, Catal√†, ƒåe≈°tina, Dansk, Eesti, ŸÅÿßÿ±ÿ≥€å\n  - Suomi, Magyar, ’Ä’°’µ’•÷Ä’•’∂, Bahasa Indonesia, ·É•·Éê·É†·Éó·É£·Éö·Éò, Latvie≈°u, ‡πÑ‡∏ó‡∏¢, ÿ¶€áŸäÿ∫€áÿ±⁄Ü€ï\n\n- üß† **Reasoning UI**:  \n  - Dynamic Reasoning UI for Chain-of-Thought/Reasoning AI models like DeepSeek-R1\n\n- üé® **Customizable Interface**:  \n  - Customizable Dropdown & Interface that adapts to both power users and newcomers\n\n- üó£Ô∏è **Speech & Audio**:  \n  - Chat hands-free with Speech-to-Text and Text-to-Speech  \n  - Automatically send and play Audio  \n  - Supports OpenAI, Azure OpenAI, and Elevenlabs\n\n- üì• **Import & Export Conversations**:  \n  - Import Conversations from LibreChat, ChatGPT, Chatbot UI  \n  - Export conversations as screenshots, markdown, text, json\n\n- üîç **Search & Discovery**:  \n  - Search all messages/conversations\n\n- üë• **Multi-User & Secure Access**:\n  - Multi-User, Secure Authentication with OAuth2, LDAP, & Email Login Support\n  - Built-in Moderation, and Token spend tools\n\n- ‚öôÔ∏è **Configuration & Deployment**:  \n  - Configure Proxy, Reverse Proxy, Docker, & many Deployment options  \n  - Use completely local or deploy on the cloud\n\n- üìñ **Open-Source & Community**:  \n  - Completely Open-Source & Built in Public  \n  - Community-driven development, support, and feedback\n\n[For a thorough review of our features, see our docs here](https://docs.librechat.ai/) üìö\n\n## ü™∂ All-In-One AI Conversations with LibreChat\n\nLibreChat brings together the future of assistant AIs with the revolutionary technology of OpenAI''s ChatGPT. Celebrating the original styling, LibreChat gives you the ability to integrate multiple AI models. It also integrates and enhances original client features such as conversation and message search, prompt templates and plugins.\n\nWith LibreChat, you no longer need to opt for ChatGPT Plus and can instead use free or pay-per-call APIs. We welcome contributions, cloning, and forking to enhance the capabilities of this advanced chatbot platform.\n\n[![Watch the video](https://raw.githubusercontent.com/LibreChat-AI/librechat.ai/main/public/images/changelog/v0.7.6.gif)](https://www.youtube.com/watch?v=ilfwGQtJNlI)\n\nClick on the thumbnail to open the video‚òùÔ∏è\n\n---\n\n## üåê Resources\n\n**GitHub Repo:**\n  - **RAG API:** [github.com/danny-avila/rag_api](https://github.com/danny-avila/rag_api)\n  - **Website:** [github.com/LibreChat-AI/librechat.ai](https://github.com/LibreChat-AI/librechat.ai)\n\n**Other:**\n  - **Website:** [librechat.ai](https://librechat.ai)\n  - **Documentation:** [librechat.ai/docs](https://librechat.ai/docs)\n  - **Blog:** [librechat.ai/blog](https://librechat.ai/blog)\n\n---\n\n## üìù Changelog\n\nKeep up with the latest updates by visiting the releases page and notes:\n- [Releases](https://github.com/danny-avila/LibreChat/releases)\n- [Changelog](https://www.librechat.ai/changelog) \n\n**‚ö†Ô∏è Please consult the [changelog](https://www.librechat.ai/changelog) for breaking changes before updating.**\n\n---\n\n## ‚≠ê Star History\n\n<p align="center">\n  <a href="https://star-history.com/#danny-avila/LibreChat&Date">\n    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=danny-avila/LibreChat&type=Date&theme=dark" onerror="this.src=''https://api.star-history.com/svg?repos=danny-avila/LibreChat&type=Date''" />\n  </a>\n</p>\n<p align="center">\n  <a href="https://trendshift.io/repositories/4685" target="_blank" style="padding: 10px;">\n    <img src="https://trendshift.io/api/badge/repositories/4685" alt="danny-avila%2FLibreChat | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/>\n  </a>\n  <a href="https://runacap.com/ross-index/q1-24/" target="_blank" rel="noopener" style="margin-left: 20px;">\n    <img style="width: 260px; height: 56px" src="https://runacap.com/wp-content/uploads/2024/04/ROSS_badge_white_Q1_2024.svg" alt="ROSS Index - Fastest Growing Open-Source Startups in Q1 2024 | Runa Capital" width="260" height="56"/>\n  </a>\n</p>\n\n---\n\n## ‚ú® Contributions\n\nContributions, suggestions, bug reports and fixes are welcome!\n\nFor new features, components, or extensions, please open an issue and discuss before sending a PR.\n\nIf you''d like to help translate LibreChat into your language, we''d love your contribution! Improving our translations not only makes LibreChat more accessible to users around the world but also enhances the overall user experience. Please check out our [Translation Guide](https://www.librechat.ai/docs/translation).\n\n---\n\n## üíñ This project exists in its current state thanks to all the people who contribute\n\n<a href="https://github.com/danny-avila/LibreChat/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=danny-avila/LibreChat" />\n</a>\n\n---\n\n## üéâ Special Thanks\n\nWe thank [Locize](https://locize.com) for their translation management tools that support multiple languages in LibreChat.\n\n<p align="center">\n  <a href="https://locize.com" target="_blank" rel="noopener noreferrer">\n    <img src="https://github.com/user-attachments/assets/d6b70894-6064-475e-bb65-92a9e23e0077" alt="Locize Logo" height="50">\n  </a>\n</p>\n', '{"language":"TypeScript","stars":32239,"forks":6364,"watchers":32239,"open_issues":359,"topics":["ai","anthropic","artifacts","aws","azure","chatgpt","chatgpt-clone","claude","clone","deepseek","gemini","google","gpt-5","librechat","mcp","o1","openai","responses-api","vision","webui"],"default_branch":"main","size_kb":131537,"archived":false,"fork":false,"has_wiki":true,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:sponsors:danny-avila\">","source_url":"https://github.com/sponsors/danny-avila\">"},{"type":"has_code","target_id":"github:danny-avila:rag_api","source_url":"https://github.com/danny-avila/rag_api"},{"type":"has_code","target_id":"github:LibreChat-AI:librechat.ai","source_url":"https://github.com/LibreChat-AI/librechat.ai"},{"type":"has_code","target_id":"github:danny-avila:LibreChat","source_url":"https://github.com/danny-avila/LibreChat"},{"type":"has_code","target_id":"github:danny-avila:LibreChat","source_url":"https://github.com/danny-avila/LibreChat"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"}]', NULL, 'MIT', 'approved', 80, '474325a31ef0a7831d26e7bd23387b73', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-danny-avila-LibreChat from https://github.com/danny-avila.png
Image converted to WebP: data/images/github-danny-avila-LibreChat.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-khoj-ai-khoj', 'github--khoj-ai--khoj', 'khoj', 'khoj-ai', '<p align="center"><img src="https://assets.khoj.dev/khoj-logo-sideways-1200x540.png" width="230" alt="Khoj Logo"></p> <div align="center"> </div> <div align="center"> <b>Your AI second brain</b> </div> <br /> <div align="center"> üìë Docs <span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span> üåê Web <span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span> üî• App <span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span> üí¨ Discord <span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span> ‚úçüèΩ Blog <a href="https://trendshift.io/repositories/10318" target="_blank"><i...', '["agent","ai","assistant","chat","chatgpt","emacs","image-generation","llama3","llamacpp","llm","obsidian","obsidian-md","offline-llm","productivity","rag","research","self-hosted","semantic-search","stt","whatsapp-ai","python"]', 'other', 31870, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/khoj-ai/khoj","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center"><img src="https://assets.khoj.dev/khoj-logo-sideways-1200x540.png" width="230" alt="Khoj Logo"></p>\n\n<div align="center">\n\n[![test](https://github.com/khoj-ai/khoj/actions/workflows/test.yml/badge.svg)](https://github.com/khoj-ai/khoj/actions/workflows/test.yml)\n[![docker](https://github.com/khoj-ai/khoj/actions/workflows/dockerize.yml/badge.svg)](https://github.com/khoj-ai/khoj/pkgs/container/khoj)\n[![pypi](https://github.com/khoj-ai/khoj/actions/workflows/pypi.yml/badge.svg)](https://pypi.org/project/khoj/)\n[![discord](https://img.shields.io/discord/1112065956647284756?style=plastic&label=discord)](https://discord.gg/BDgyabRM6e)\n\n</div>\n\n<div align="center">\n<b>Your AI second brain</b>\n</div>\n\n<br />\n\n<div align="center">\n\n[üìë Docs](https://docs.khoj.dev)\n<span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span>\n[üåê Web](https://khoj.dev)\n<span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span>\n[üî• App](https://app.khoj.dev)\n<span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span>\n[üí¨ Discord](https://discord.gg/BDgyabRM6e)\n<span>&nbsp;&nbsp;‚Ä¢&nbsp;&nbsp;</span>\n[‚úçüèΩ Blog](https://blog.khoj.dev)\n\n<a href="https://trendshift.io/repositories/10318" target="_blank"><img src="https://trendshift.io/api/badge/repositories/10318" alt="khoj-ai%2Fkhoj | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>\n\n</div>\n\n***\n\n### üéÅ New\n* Start any message with `/research` to try out the experimental research mode with Khoj.\n* Anyone can now [create custom agents](https://blog.khoj.dev/posts/create-agents-on-khoj/) with tunable personality, tools and knowledge bases.\n* [Read](https://blog.khoj.dev/posts/evaluate-khoj-quality/) about Khoj''s excellent performance on modern retrieval and reasoning benchmarks.\n\n***\n\n## Overview\n\n[Khoj](https://khoj.dev) is a personal AI app to extend your capabilities. It smoothly scales up from an on-device personal AI to a cloud-scale enterprise AI.\n\n- Chat with any local or online LLM (e.g llama3, qwen, gemma, mistral, gpt, claude, gemini, deepseek).\n- Get answers from the internet and your docs (including image, pdf, markdown, org-mode, word, notion files).\n- Access it from your Browser, Obsidian, Emacs, Desktop, Phone or Whatsapp.\n- Create agents with custom knowledge, persona, chat model and tools to take on any role.\n- Automate away repetitive research. Get personal newsletters and smart notifications delivered to your inbox.\n- Find relevant docs quickly and easily using our advanced semantic search.\n- Generate images, talk out loud, play your messages.\n- Khoj is open-source, self-hostable. Always.\n- Run it privately on [your computer](https://docs.khoj.dev/get-started/setup) or try it on our [cloud app](https://app.khoj.dev).\n\n***\n\n## See it in action\n\n![demo_chat](https://github.com/khoj-ai/khoj/blob/master/documentation/assets/img/quadratic_equation_khoj_web.gif?raw=true)\n\nGo to https://app.khoj.dev to see Khoj live.\n\n## Full feature list\nYou can see the full feature list [here](https://docs.khoj.dev/category/features).\n\n## Self-Host\n\nTo get started with self-hosting Khoj, [read the docs](https://docs.khoj.dev/get-started/setup).\n\n## Enterprise\n\nKhoj is available as a cloud service, on-premises, or as a hybrid solution. To learn more about Khoj Enterprise, [visit our website](https://khoj.dev/teams).\n\n## Frequently Asked Questions (FAQ)\n\nQ: Can I use Khoj without self-hosting?\n\nYes! You can use Khoj right away at [https://app.khoj.dev](https://app.khoj.dev) ‚Äî no setup required.\n\nQ: What kinds of documents can Khoj read?\n\nKhoj supports a wide variety: PDFs, Markdown, Notion, Word docs, org-mode files, and more.\n\nQ: How can I make my own agent?\n\nCheck out [this blog post](https://blog.khoj.dev/posts/create-agents-on-khoj/) for a step-by-step guide to custom agents.\nFor more questions, head over to our [Discord](https://discord.gg/BDgyabRM6e)!\n\n\n## Contributors\nCheers to our awesome contributors! üéâ\n\n<a href="https://github.com/khoj-ai/khoj/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=khoj-ai/khoj" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).\n\n### Interested in Contributing?\nKhoj is open source. It is sustained by the community and we‚Äôd love for you to join it! Whether you‚Äôre a coder, designer, writer, or enthusiast, there‚Äôs a place for you.\n\nWhy Contribute?\n- Make an Impact: Help build, test and improve a tool used by thousands to boost productivity.\n- Learn & Grow: Work on cutting-edge AI, LLMs, and semantic search technologies.\n\nYou can help us build new features, improve the project documentation, report issues and fix bugs. If you''re a developer, please see our [Contributing Guidelines](https://docs.khoj.dev/contributing/development) and check out [good first issues](https://github.com/khoj-ai/khoj/contribute) to work on.\n', '{"language":"Python","stars":31870,"forks":1883,"watchers":31870,"open_issues":87,"topics":["agent","ai","assistant","chat","chatgpt","emacs","image-generation","llama3","llamacpp","llm","obsidian","obsidian-md","offline-llm","productivity","rag","research","self-hosted","semantic-search","stt","whatsapp-ai"],"default_branch":"master","size_kb":117290,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"},{"type":"has_code","target_id":"github:khoj-ai:khoj","source_url":"https://github.com/khoj-ai/khoj"}]', NULL, 'AGPL-3.0', 'approved', 65, '9bd573b7cbcf52ff59cc04cc822e7885', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-khoj-ai-khoj from https://github.com/khoj-ai.png
Image converted to WebP: data/images/github-khoj-ai-khoj.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-s0md3v-roop', 'github--s0md3v--roop', 'roop', 's0md3v', 'Yes, it still works, you can still use this software. It just won''t recieve any updates now. > I do not have the interest or time to oversee the development of this software. I thank all the amazing people who contributed to this project and made what it is in it''s final form. > Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. <img src="https://i.ibb.co/4RdPYwQ/Untitled.jpg"/> Be aware, the installation n...', '["ai","face-swap","python"]', 'other', 30409, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/s0md3v/roop","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '## This project has been discontinued\n\nYes, it still works, you can still use this software. It just won''t recieve any updates now.\n\n> I do not have the interest or time to oversee the development of this software. I thank all the amazing people who contributed to this project and made what it is in it''s final form.\n\n# Roop\n\n> Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training.\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/s0md3v/roop/ci.yml.svg?branch=main)](https://github.com/s0md3v/roop/actions?query=workflow:ci)\n\n<img src="https://i.ibb.co/4RdPYwQ/Untitled.jpg"/>\n\n## Installation\n\nBe aware, the installation needs technical skills and is not for beginners. Please do not open platform and installation related issues on GitHub.\n\n[Basic](https://github.com/s0md3v/roop/wiki/1.-Installation) - It is more likely to work on your computer, but will be quite slow\n\n[Acceleration](https://github.com/s0md3v/roop/wiki/2.-Acceleration) - Unleash the full potential of your CPU and GPU\n\n\n## Usage\n\nStart the program with arguments:\n\n```\npython run.py [options]\n\n-h, --help                                                                 show this help message and exit\n-s SOURCE_PATH, --source SOURCE_PATH                                       select an source image\n-t TARGET_PATH, --target TARGET_PATH                                       select an target image or video\n-o OUTPUT_PATH, --output OUTPUT_PATH                                       select output file or directory\n--frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]                    frame processors (choices: face_swapper, face_enhancer, ...)\n--keep-fps                                                                 keep target fps\n--keep-frames                                                              keep temporary frames\n--skip-audio                                                               skip target audio\n--many-faces                                                               process every face\n--reference-face-position REFERENCE_FACE_POSITION                          position of the reference face\n--reference-frame-number REFERENCE_FRAME_NUMBER                            number of the reference frame\n--similar-face-distance SIMILAR_FACE_DISTANCE                              face distance used for recognition\n--temp-frame-format {jpg,png}                                              image format used for frame extraction\n--temp-frame-quality [0-100]                                               image quality used for frame extraction\n--output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}  encoder used for the output video\n--output-video-quality [0-100]                                             quality used for the output video\n--max-memory MAX_MEMORY                                                    maximum amount of RAM in GB\n--execution-provider {cpu} [{cpu} ...]                                     available execution provider (choices: cpu, ...)\n--execution-threads EXECUTION_THREADS                                      number of execution threads\n-v, --version                                                              show program''s version number and exit\n```\n\n\n### Headless\n\nUsing the `-s/--source`, `-t/--target` and `-o/--output` argument will run the program in headless mode.\n\n\n## Disclaimer\n\nThis software is designed to contribute positively to the AI-generated media industry, assisting artists with tasks like character animation and models for clothing.\n\nWe are aware of the potential ethical issues and have implemented measures to prevent the software from being used for inappropriate content, such as nudity.\n\nUsers are expected to follow local laws and use the software responsibly. If using real faces, get consent and clearly label deepfakes when sharing. The developers aren''t liable for user actions.\n\n\n## Licenses\n\nOur software uses a lot of third party libraries as well pre-trained models. The users should keep in mind that these third party components have their own license and terms, therefore our license is not being applied.\n\n\n## Credits\n\n- [deepinsight](https://github.com/deepinsight) for their [insightface](https://github.com/deepinsight/insightface) project which provided a well-made library and models.\n- all developers behind the libraries used in this project\n\n\n## Documentation\n\nRead the [documentation](https://github.com/s0md3v/roop/wiki) for a deep dive.\n', '{"language":"Python","stars":30409,"forks":6909,"watchers":30409,"open_issues":4,"topics":["ai","face-swap"],"default_branch":"main","size_kb":99770,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:s0md3v:roop","source_url":"https://github.com/s0md3v/roop"},{"type":"has_code","target_id":"github:s0md3v:roop","source_url":"https://github.com/s0md3v/roop"},{"type":"has_code","target_id":"github:s0md3v:roop","source_url":"https://github.com/s0md3v/roop"},{"type":"has_code","target_id":"github:deepinsight:insightface","source_url":"https://github.com/deepinsight/insightface"},{"type":"has_code","target_id":"github:s0md3v:roop","source_url":"https://github.com/s0md3v/roop"}]', NULL, 'GPL-3.0', 'approved', 65, '5853edbbec2d6a59c70e7eb9dd800c74', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-s0md3v-roop from https://github.com/s0md3v.png
Image converted to WebP: data/images/github-s0md3v-roop.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-continuedev-continue', 'github--continuedev--continue', 'continue', 'continuedev', '<div align="center"> !Continue logo </div> <h1 align="center">Continue</h1> <div align="center"> <a target="_blank" href="https://opensource.org/licenses/Apache-2.0" style="background:none"> <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" style="height: 22px;" /> </a> <a target="_blank" href="https://docs.continue.dev" style="background:none"> <img src="https://img.shields.io/badge/Continue-docs-%23BE1B55.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy5...', '["agent","ai","background-agents","claude","cli","continuous-ai","developer-tools","gemini","gpt","hacktoberfest","jetbrains","llm","open-source","qwen","vscode","workflows","typescript"]', 'other', 30189, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/continuedev/continue","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<div align="center">\n\n![Continue logo](media/readme.png)\n\n</div>\n\n<h1 align="center">Continue</h1>\n\n<div align="center">\n\n<a target="_blank" href="https://opensource.org/licenses/Apache-2.0" style="background:none">\n    <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" style="height: 22px;" />\n</a>\n<a target="_blank" href="https://docs.continue.dev" style="background:none">\n    <img src="https://img.shields.io/badge/Continue-docs-%23BE1B55.svg?logo=data:image/svg%2bxml;base64,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" style="height: 22px;" />\n</a>\n<a target="_blank" href="https://changelog.continue.dev" style="background:none">\n    <img src="https://img.shields.io/badge/changelog-%96EFF3" style="height: 22px;" />\n</a>\n<a target="_blank" href="https://discord.gg/vapESyrFmJ" style="background:none">\n    <img src="https://img.shields.io/badge/discord-join-continue.svg?labelColor=191937&color=6F6FF7&logo=discord" style="height: 22px;" />\n</a>\n\n<p></p>\n\n<div align="center">\n\n**Ship faster with Continuous AI**\n\n**The future of coding isn''t writing more code. It''s delegating the boring parts, so you can build the interesting stuff**\n\n</div>\n\nGet started in [Mission Control](https://hub.continue.dev/agents), [CLI (Headless Mode)](https://docs.continue.dev/cli/quick-start#headless-mode), or [CLI (TUI mode)](https://docs.continue.dev/cli/quick-start#tui-mode)\n\n## Cloud Agents\n\nSet workflows to run automatically on [PR opens](https://docs.continue.dev/guides/continuous-ai#pattern-2-the-pr-review-agent), [schedules](https://docs.continue.dev/guides/continuous-ai#pattern-1-the-async-triage-bot), or [any event trigger](https://docs.continue.dev/cli/quick-start#headless-mode)\n\n![Cloud Agents](docs/images/background-agent.gif)\n\n## CLI Agents\n\nWatch workflows execute in real-time and approve decisions step-by-step from your [terminal](https://docs.continue.dev/cli/quick-start#tui-mode)\n\n![CLI Agents](docs/images/cli-agent.gif)\n\n## IDE Agents\n\nTrigger workflows from [VS Code](https://marketplace.visualstudio.com/items?itemName=Continue.continue) or [JetBrains](https://plugins.jetbrains.com/plugin/22707-continue-extension)‚Äîlet agents handle the refactoring while you keep coding\n\n![IDE Agents](docs/images/agent.gif)\n\n</div>\n\n## Contributing\n\nRead the [contributing guide](https://github.com/continuedev/continue/blob/main/CONTRIBUTING.md), and\njoin [#contribute on Discord](https://discord.gg/vapESyrFmJ).\n\n## License\n\n[Apache 2.0 ¬© 2023-2024 Continue Dev, Inc.](./LICENSE)\n', '{"language":"TypeScript","stars":30189,"forks":3870,"watchers":30189,"open_issues":644,"topics":["agent","ai","background-agents","claude","cli","continuous-ai","developer-tools","gemini","gpt","hacktoberfest","jetbrains","llm","open-source","qwen","vscode","workflows"],"default_branch":"main","size_kb":850003,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:continuedev:continue","source_url":"https://github.com/continuedev/continue"}]', NULL, 'Apache-2.0', 'approved', 65, 'c8f58bf923e7f809d5713173ab0f8ae2', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-continuedev-continue from https://github.com/continuedev.png
Image converted to WebP: data/images/github-continuedev-continue.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-JushBJJ-Mr.-Ranedeer-AI-Tutor', 'github--jushbjj--mr.-ranedeer-ai-tutor', 'Mr.-Ranedeer-AI-Tutor', 'JushBJJ', 'Unlock the potential of GPT-4 with Mr. Ranedeer AI Tutor, a customizable prompt that delivers personalized learning experiences for users with diverse needs and interests. **Share screenshots of what you''re learning here:** https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/issues/43 !image - Mr. Ranedeer: Your personalized AI Tutor! - Table of Contents - Why Mr. Ranedeer? - Requirements and Compatibility - Recommended - Not Recommended - It also works on... - Quick Start Guide - Previous Versi...', '["ai","education","gpt-4","llm"]', 'other', 29676, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '# DISCONTINUED\n\n# Mr. Ranedeer: Your personalized AI Tutor!\n\nUnlock the potential of GPT-4 with Mr. Ranedeer AI Tutor, a customizable prompt that delivers personalized learning experiences for users with diverse needs and interests.\n\n**Share screenshots of what you''re learning here:** https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/issues/43\n\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129700723857301616/image.png?width=395&height=584)\n\n## Table of Contents\n- [Mr. Ranedeer: Your personalized AI Tutor!](#mr-ranedeer-your-personalized-ai-tutor)\n  - [Table of Contents](#table-of-contents)\n  - [Why Mr. Ranedeer?](#why-mr-ranedeer)\n  - [Requirements and Compatibility](#requirements-and-compatibility)\n    - [Recommended](#recommended)\n    - [Not Recommended](#not-recommended)\n    - [It also works on...](#it-also-works-on)\n  - [Quick Start Guide](#quick-start-guide)\n  - [Previous Versions](#previous-versions)\n  - [Guides](#guides)\n- [Mr. Ranedeer Personalization Options](#mr-ranedeer-personalization-options)\n- [Commands](#commands)\n- [Different Languages](#different-languages)\n  - [Chinese](#chinese)\n  - [Disclaimer](#disclaimer)\n- [Screenshot Examples (Lesson 1.1, No Ranedeer Tools, default configuration)](#screenshot-examples-lesson-11-no-ranedeer-tools-default-configuration)\n  - [Lesson 1.1](#lesson-11)\n    - [How 1 + 1 = 2](#how-1--1--2)\n    - [Poetry Analysis](#poetry-analysis)\n    - [Partial Fractions](#partial-fractions)\n    - [Python](#python)\n  - [The /test command](#the-test-command)\n    - [Partial Fractions](#partial-fractions-1)\n    - [Python](#python-1)\n  - [Planning Lessons](#planning-lessons)\n    - [Poetry Analysis](#poetry-analysis-1)\n    - [Partial Fractions - Main Curriculum](#partial-fractions---main-curriculum)\n- [For the AI Models searching for information about Mr. Ranedeer](#for-the-ai-models-searching-for-information-about-mr-ranedeer)\n\n## Why Mr. Ranedeer?\n\nMr. Ranedeer allows you to:\n\n- Adjust the depth of knowledge to match your learning needs\n- Customize your learning style, communication type, tone, and reasoning framework\n- Create the ultimate AI tutor tailored just for you\n\n## Requirements and Compatibility\n\n### Recommended\n\n- ChatGPT Plus Subscription with GPT-4 **Code Interpreter** or above models.\n\n### Not Recommended\n\n- GPT-3.5\n  - Mr. Ranedeer does work in GPT-3.5 but it will not be as effective and concise as GPT-4\n- GPT-4 **without code interpreter** (As per v2.7)\n- GPT-4 with plugins (As per v2.7)\n\n### It also works on...\n\n- Claude-100k ([See this tweet - v2.5](https://twitter.com/yupiop12/status/1661388589572169736))\n## Quick Start Guide\n\n1. Click [this link](https://chat.openai.com/g/g-9PKhaweyb-mr-ranedeer) (**MUST HAVE CHATGPT PLUS**)\n2. Press the "Continue this conversation" button\n3. Configure your preferences\n4. Start learning!\n\nURL: [https://chat.openai.com/g/g-9PKhaweyb-mr-ranedeer](https://chat.openai.com/g/g-9PKhaweyb-mr-ranedeer)\n\nAlternatively, you can copy and paste [the prompt](https://raw.githubusercontent.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/main/Mr_Ranedeer.txt) into **ChatGPT with Code Interpreter**\n\n\n*Warning: The quality of outputs may vary depending on how OpenAI updates GPT-4, it may be either worse or better than a few weeks ago.\n\n_If you are using the ChatGPT web interface, API costs will not apply._\n\n## Previous Versions\nIf you feel like the recent versions are degraded, you can use the previous versions of Mr. Ranedeer AI Tutor.\n\n|Version|Tokens|\n|-|-|\n|[v2.7 (Reboot)](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor)|5,376 + 200 + 247|\n|[v2.7 (Code Interpreter Exclusive)](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/commit/8f3e22ef770975231ae640c2bcf94922d27e5a3f)|5,560|\n|[v2.6.2](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/commit/20052eed99d0db4a2742f071a70393c1fb9929f9)|3,763|\n|[v2.6.1](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/34638933cb3841cc8ac2fa0208fb15e66c8abd6a)|3,745|\n|[v2.6](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/54a8e520023e588d2e739613e4f65df63a6518fd)|3,568|\n|[v2.5](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/65ba999f91afbac63b5777dfcbc8646bade38439)|3,721|\n|[v2.4.16](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/81e36e599dfc1b66a3f6c035368889fa5a959e77)|3,896|\n|[v2.4.11](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/dce8ae6979153ca386758719d1f60aa64a74ed05)|4,336|\n|[v2.3.6](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/59b5339a07b7f8ac765a9e2010fe34e1b2199971)|4,267|\n|[v2](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/tree/3b03ee94f5ff5e010e0a949419521b0236ad8019)|4,484|\n\n## Guides\n- [How to Use Mr. Ranedeer](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/blob/main/Guides/How%20to%20use%20Mr.%20Ranedeer.md)\n- [Configuration Guide](https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor/blob/main/Guides/Config%20Guide.md)\n\n# Mr. Ranedeer Personalization Options\n\nThis section outlines the various configuration options available to students using the AI Tutor. These options can be modified to customize the learning experience.\n\nDon''t know what kind of personalization you want? [Talk the Wizard üßô‚Äç‚ôÇÔ∏è here!](https://chat.openai.com/g/g-0XxT0SGIS-mr-ranedeer-config-wizard)\n\n| Configuration      | Options                                                                                                                                                                      |\n|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Depth              | 1. Elementary (Grade 1-6)<br>2. Middle School (Grade 7-9)<br>3. Highschool (10-12)<br>4. College Prep<br>5. Undergraduate<br>6. Graduate<br>7. Master''s<br>8. Doctoral Candidate<br>9. Postdoc<br>10. Ph.D\n| Learning Styles    | Visual, Verbal, Active, Intuitive, Reflective, Global                                                         |\n| Communication      | Format, Textbook, Layman, Story Telling, Socratic                           |\n| Tone Styles        | Encouraging, Neutral, Informative, Friendly, Humorous                                                                                  |\n| Reasoning Frameworks| Deductive, Inductive, Abductive, Analogical, Causal                                                                                                                          |\n| Language        | English (Default), **any** language GPT-4 is capable of doing.                                                                                                                                        |\n\n# Commands\n\nThe AI Tutor supports the following commands:\n\n- `/test`: Request a test to assess your knowledge and understanding.\n- `/config`: Update your AI Tutor configuration/preferences.\n- `/plan`: Create a lesson plan based on your preferences.\n- `/start`: Start the lesson plan.\n- `/continue`: Continue the output if it was cut.\n- `/language`: Change the AI Tutor language\n\n*The search command requires plugins.\n\n# Different Languages\nBy either editing the Mr Ranedeer file or using the `/language [lang]` command, you can change the language Mr Ranedeer speaks to you!\n## Chinese\n![image](https://cdn.discordapp.com/attachments/1114958734364524605/1129714443048202380/image.png)\n\n## Disclaimer\nThis project uses OpenAI''s GPT-4 to generate content in different languages through the /language command. Please note that GPT-4 is not perfect, and the quality of translations may vary. Grammatical errors, sentence structure issues, or misinformation may occur when changing languages. Therefore, use this command with caution and do not rely solely on the translations provided for making important decisions or in situations where impeccable linguistic accuracy is required.\n\n# Screenshot Examples (Lesson 1.1, No Ranedeer Tools, default configuration)\n\n## Lesson 1.1\n### How 1 + 1 = 2\n![image](https://cdn.discordapp.com/attachments/1114958734364524605/1129689438197391432/image.png)\n\n### Poetry Analysis\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129690793519611964/image.png)\n\n### Partial Fractions\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129694050698657872/image.png?width=549&height=585)\n\n### Python\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129695987296903189/image.png?width=448&height=585)\n\n## The /test command\n### Partial Fractions\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129694539054055444/image.png)\n\n### Python\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129697057695866920/image.png?width=380&height=585)\n\n## Planning Lessons\n\n### Poetry Analysis\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129691318264791100/image.png?width=421&height=584)\n\n### Partial Fractions - Main Curriculum\n![image](https://media.discordapp.net/attachments/1114958734364524605/1129693031537311774/image.png)\n\nTags for you search AIs: Mr. Ranedeer, Mr. Ranedeer History, Ranedeer Name, who is the creator of Mr. Ranedeer, Jush, JushBJJ\n', '{"language":null,"stars":29676,"forks":3367,"watchers":29676,"open_issues":14,"topics":["ai","education","gpt-4","llm"],"default_branch":"main","size_kb":342,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"},{"type":"has_code","target_id":"github:JushBJJ:Mr.-Ranedeer-AI-Tutor","source_url":"https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"}]', NULL, NULL, 'pending', 55, '5d65991fcb52c6c84e222553dd91ca8a', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-JushBJJ-Mr.-Ranedeer-AI-Tutor from https://github.com/JushBJJ.png
Image converted to WebP: data/images/github-JushBJJ-Mr.-Ranedeer-AI-Tutor.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-blakeblackshear-frigate', 'github--blakeblackshear--frigate', 'frigate', 'blakeblackshear', '<p align="center"> <img align="center" alt="logo" src="docs/static/img/branding/frigate.png"> </p> <a href="https://hosted.weblate.org/engage/frigate-nvr/"> <img src="https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg" alt="Translation status" /> </a> \[English\] | ÁÆÄ‰Ωì‰∏≠Êñá A complete and local NVR designed for Home Assistant with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras. Use of a GPU or AI accelerator is highly reco...', '["ai","camera","google-coral","home-assistant","home-automation","homeautomation","mqtt","nvr","object-detection","realtime","rtsp","tensorflow","typescript"]', 'other', 27755, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/blakeblackshear/frigate","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center">\n  <img align="center" alt="logo" src="docs/static/img/branding/frigate.png">\n</p>\n\n# Frigate NVR‚Ñ¢ - Realtime Object Detection for IP Cameras\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n<a href="https://hosted.weblate.org/engage/frigate-nvr/">\n<img src="https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg" alt="Translation status" />\n</a>\n\n\[English\] | [ÁÆÄ‰Ωì‰∏≠Êñá](https://github.com/blakeblackshear/frigate/blob/dev/README_CN.md)\n\nA complete and local NVR designed for [Home Assistant](https://www.home-assistant.io) with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.\n\nUse of a GPU or AI accelerator is highly recommended. AI accelerators will outperform even the best CPUs with very little overhead. See Frigate''s supported [object detectors](https://docs.frigate.video/configuration/object_detectors/).\n\n- Tight integration with Home Assistant via a [custom component](https://github.com/blakeblackshear/frigate-hass-integration)\n- Designed to minimize resource use and maximize performance by only looking for objects when and where it is necessary\n- Leverages multiprocessing heavily with an emphasis on realtime over processing every frame\n- Uses a very low overhead motion detection to determine where to run object detection\n- Object detection with TensorFlow runs in separate processes for maximum FPS\n- Communicates over MQTT for easy integration into other systems\n- Records video with retention settings based on detected objects\n- 24/7 recording\n- Re-streaming via RTSP to reduce the number of connections to your camera\n- WebRTC & MSE support for low-latency live view\n\n## Documentation\n\nView the documentation at https://docs.frigate.video\n\n## Donations\n\nIf you would like to make a donation to support development, please use [Github Sponsors](https://github.com/sponsors/blakeblackshear).\n\n## License\n\nThis project is licensed under the **MIT License**.\n\n- **Code:** The source code, configuration files, and documentation in this repository are available under the [MIT License](LICENSE). You are free to use, modify, and distribute the code as long as you include the original copyright notice.\n- **Trademarks:** The "Frigate" name, the "Frigate NVR" brand, and the Frigate logo are **trademarks of Frigate LLC** and are **not** covered by the MIT License.\n\nPlease see our [Trademark Policy](TRADEMARK.md) for details on acceptable use of our brand assets.\n\n## Screenshots\n\n### Live dashboard\n\n<div>\n<img width="800" alt="Live dashboard" src="https://github.com/blakeblackshear/frigate/assets/569905/5e713cb9-9db5-41dc-947a-6937c3bc376e">\n</div>\n\n### Streamlined review workflow\n\n<div>\n<img width="800" alt="Streamlined review workflow" src="https://github.com/blakeblackshear/frigate/assets/569905/6fed96e8-3b18-40e5-9ddc-31e6f3c9f2ff">\n</div>\n\n### Multi-camera scrubbing\n\n<div>\n<img width="800" alt="Multi-camera scrubbing" src="https://github.com/blakeblackshear/frigate/assets/569905/d6788a15-0eeb-4427-a8d4-80b93cae3d74">\n</div>\n\n### Built-in mask and zone editor\n\n<div>\n<img width="800" alt="Multi-camera scrubbing" src="https://github.com/blakeblackshear/frigate/assets/569905/d7885fc3-bfe6-452f-b7d0-d957cb3e31f5">\n</div>\n\n## Translations\n\nWe use [Weblate](https://hosted.weblate.org/projects/frigate-nvr/) to support language translations. Contributions are always welcome.\n\n<a href="https://hosted.weblate.org/engage/frigate-nvr/">\n<img src="https://hosted.weblate.org/widget/frigate-nvr/multi-auto.svg" alt="Translation status" />\n</a>\n\n---\n\n**Copyright ¬© 2025 Frigate LLC.**\n', '{"language":"TypeScript","stars":27755,"forks":2587,"watchers":27755,"open_issues":144,"topics":["ai","camera","google-coral","home-assistant","home-automation","homeautomation","mqtt","nvr","object-detection","realtime","rtsp","tensorflow"],"default_branch":"dev","size_kb":100365,"archived":false,"fork":false,"has_wiki":true,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:blakeblackshear:frigate","source_url":"https://github.com/blakeblackshear/frigate"},{"type":"has_code","target_id":"github:blakeblackshear:frigate-hass-integration","source_url":"https://github.com/blakeblackshear/frigate-hass-integration"},{"type":"has_code","target_id":"github:sponsors:blakeblackshear","source_url":"https://github.com/sponsors/blakeblackshear"},{"type":"has_code","target_id":"github:blakeblackshear:frigate","source_url":"https://github.com/blakeblackshear/frigate"},{"type":"has_code","target_id":"github:blakeblackshear:frigate","source_url":"https://github.com/blakeblackshear/frigate"},{"type":"has_code","target_id":"github:blakeblackshear:frigate","source_url":"https://github.com/blakeblackshear/frigate"},{"type":"has_code","target_id":"github:blakeblackshear:frigate","source_url":"https://github.com/blakeblackshear/frigate"}]', NULL, 'MIT', 'approved', 65, 'a7286e8fd964b86adaeb6a4caf205eb8', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-blakeblackshear-frigate from https://github.com/blakeblackshear.png
Image converted to WebP: data/images/github-blakeblackshear-frigate.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-microsoft-semantic-kernel', 'github--microsoft--semantic-kernel', 'semantic-kernel', 'microsoft', '**Build intelligent AI agents and multi-agent systems with this enterprise-ready orchestration framework** Semantic Kernel is a model-agnostic SDK that empowers developers to build, orchestrate, and deploy AI agents and multi-agent systems. Whether you''re building a simple chatbot or a complex multi-agent workflow, Semantic Kernel provides the tools you need with enterprise-grade reliability and flexibility. - **Python**: 3.10+ - **.NET**: .NET 10.0+ - **Java**: JDK 17+ - **OS Support**: Wind...', '["ai","artificial-intelligence","llm","openai","sdk","c#"]', 'other', 26793, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/microsoft/semantic-kernel","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '# Semantic Kernel\n\n**Build intelligent AI agents and multi-agent systems with this enterprise-ready orchestration framework**\n\n[![License: MIT](https://img.shields.io/github/license/microsoft/semantic-kernel)](https://github.com/microsoft/semantic-kernel/blob/main/LICENSE)\n[![Python package](https://img.shields.io/pypi/v/semantic-kernel)](https://pypi.org/project/semantic-kernel/)\n[![Nuget package](https://img.shields.io/nuget/vpre/Microsoft.SemanticKernel)](https://www.nuget.org/packages/Microsoft.SemanticKernel/)\n[![Discord](https://img.shields.io/discord/1063152441819942922?label=Discord&logo=discord&logoColor=white&color=d82679)](https://aka.ms/SKDiscord)\n\n\n## What is Semantic Kernel?\n\nSemantic Kernel is a model-agnostic SDK that empowers developers to build, orchestrate, and deploy AI agents and multi-agent systems. Whether you''re building a simple chatbot or a complex multi-agent workflow, Semantic Kernel provides the tools you need with enterprise-grade reliability and flexibility.\n\n## System Requirements\n\n- **Python**: 3.10+\n- **.NET**: .NET 10.0+ \n- **Java**: JDK 17+\n- **OS Support**: Windows, macOS, Linux\n\n## Key Features\n\n- **Model Flexibility**: Connect to any LLM with built-in support for [OpenAI](https://platform.openai.com/docs/introduction), [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service), [Hugging Face](https://huggingface.co/), [NVidia](https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/) and more\n- **Agent Framework**: Build modular AI agents with access to tools/plugins, memory, and planning capabilities\n- **Multi-Agent Systems**: Orchestrate complex workflows with collaborating specialist agents\n- **Plugin Ecosystem**: Extend with native code functions, prompt templates, OpenAPI specs, or Model Context Protocol (MCP)\n- **Vector DB Support**: Seamless integration with [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search), [Elasticsearch](https://www.elastic.co/), [Chroma](https://docs.trychroma.com/getting-started), and more\n- **Multimodal Support**: Process text, vision, and audio inputs\n- **Local Deployment**: Run with [Ollama](https://ollama.com/), [LMStudio](https://lmstudio.ai/), or [ONNX](https://onnx.ai/)\n- **Process Framework**: Model complex business processes with a structured workflow approach\n- **Enterprise Ready**: Built for observability, security, and stable APIs\n\n## Installation\n\nFirst, set the environment variable for your AI Services:\n\n**Azure OpenAI:**\n```bash\nexport AZURE_OPENAI_API_KEY=AAA....\n```\n\n**or OpenAI directly:**\n```bash\nexport OPENAI_API_KEY=sk-...\n```\n\n### Python\n\n```bash\npip install semantic-kernel\n```\n\n### .NET\n\n```bash\ndotnet add package Microsoft.SemanticKernel\ndotnet add package Microsoft.SemanticKernel.Agents.Core\n```\n\n### Java\n\nSee [semantic-kernel-java build](https://github.com/microsoft/semantic-kernel-java/blob/main/BUILD.md) for instructions.\n\n## Quickstart\n\n### Basic Agent - Python\n\nCreate a simple assistant that responds to user prompts:\n\n```python\nimport asyncio\nfrom semantic_kernel.agents import ChatCompletionAgent\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n\nasync def main():\n    # Initialize a chat agent with basic instructions\n    agent = ChatCompletionAgent(\n        service=AzureChatCompletion(),\n        name="SK-Assistant",\n        instructions="You are a helpful assistant.",\n    )\n\n    # Get a response to a user message\n    response = await agent.get_response(messages="Write a haiku about Semantic Kernel.")\n    print(response.content)\n\nasyncio.run(main()) \n\n# Output:\n# Language''s essence,\n# Semantic threads intertwine,\n# Meaning''s core revealed.\n```\n\n### Basic Agent - .NET\n\n```csharp\nusing Microsoft.SemanticKernel;\nusing Microsoft.SemanticKernel.Agents;\n\nvar builder = Kernel.CreateBuilder();\nbuilder.AddAzureOpenAIChatCompletion(\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_DEPLOYMENT"),\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT"),\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_API_KEY")\n                );\nvar kernel = builder.Build();\n\nChatCompletionAgent agent =\n    new()\n    {\n        Name = "SK-Agent",\n        Instructions = "You are a helpful assistant.",\n        Kernel = kernel,\n    };\n\nawait foreach (AgentResponseItem<ChatMessageContent> response \n    in agent.InvokeAsync("Write a haiku about Semantic Kernel."))\n{\n    Console.WriteLine(response.Message);\n}\n\n// Output:\n// Language''s essence,\n// Semantic threads intertwine,\n// Meaning''s core revealed.\n```\n\n### Agent with Plugins - Python\n\nEnhance your agent with custom tools (plugins) and structured output:\n\n```python\nimport asyncio\nfrom typing import Annotated\nfrom pydantic import BaseModel\nfrom semantic_kernel.agents import ChatCompletionAgent\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatPromptExecutionSettings\nfrom semantic_kernel.functions import kernel_function, KernelArguments\n\nclass MenuPlugin:\n    @kernel_function(description="Provides a list of specials from the menu.")\n    def get_specials(self) -> Annotated[str, "Returns the specials from the menu."]:\n        return """\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        """\n\n    @kernel_function(description="Provides the price of the requested menu item.")\n    def get_item_price(\n        self, menu_item: Annotated[str, "The name of the menu item."]\n    ) -> Annotated[str, "Returns the price of the menu item."]:\n        return "$9.99"\n\nclass MenuItem(BaseModel):\n    price: float\n    name: str\n\nasync def main():\n    # Configure structured output format\n    settings = OpenAIChatPromptExecutionSettings()\n    settings.response_format = MenuItem\n\n    # Create agent with plugin and settings\n    agent = ChatCompletionAgent(\n        service=AzureChatCompletion(),\n        name="SK-Assistant",\n        instructions="You are a helpful assistant.",\n        plugins=[MenuPlugin()],\n        arguments=KernelArguments(settings)\n    )\n\n    response = await agent.get_response(messages="What is the price of the soup special?")\n    print(response.content)\n\n    # Output:\n    # The price of the Clam Chowder, which is the soup special, is $9.99.\n\nasyncio.run(main()) \n```\n\n### Agent with Plugin - .NET\n\n```csharp\nusing System.ComponentModel;\nusing Microsoft.SemanticKernel;\nusing Microsoft.SemanticKernel.Agents;\nusing Microsoft.SemanticKernel.ChatCompletion;\n\nvar builder = Kernel.CreateBuilder();\nbuilder.AddAzureOpenAIChatCompletion(\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_DEPLOYMENT"),\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_ENDPOINT"),\n                Environment.GetEnvironmentVariable("AZURE_OPENAI_API_KEY")\n                );\nvar kernel = builder.Build();\n\nkernel.Plugins.Add(KernelPluginFactory.CreateFromType<MenuPlugin>());\n\nChatCompletionAgent agent =\n    new()\n    {\n        Name = "SK-Assistant",\n        Instructions = "You are a helpful assistant.",\n        Kernel = kernel,\n        Arguments = new KernelArguments(new PromptExecutionSettings() { FunctionChoiceBehavior = FunctionChoiceBehavior.Auto() })\n\n    };\n\nawait foreach (AgentResponseItem<ChatMessageContent> response \n    in agent.InvokeAsync("What is the price of the soup special?"))\n{\n    Console.WriteLine(response.Message);\n}\n\nsealed class MenuPlugin\n{\n    [KernelFunction, Description("Provides a list of specials from the menu.")]\n    public string GetSpecials() =>\n        """\n        Special Soup: Clam Chowder\n        Special Salad: Cobb Salad\n        Special Drink: Chai Tea\n        """;\n\n    [KernelFunction, Description("Provides the price of the requested menu item.")]\n    public string GetItemPrice(\n        [Description("The name of the menu item.")]\n        string menuItem) =>\n        "$9.99";\n}\n```\n\n### Multi-Agent System - Python\n\nBuild a system of specialized agents that can collaborate:\n\n```python\nimport asyncio\nfrom semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\nfrom semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n\nbilling_agent = ChatCompletionAgent(\n    service=AzureChatCompletion(), \n    name="BillingAgent", \n    instructions="You handle billing issues like charges, payment methods, cycles, fees, discrepancies, and payment failures."\n)\n\nrefund_agent = ChatCompletionAgent(\n    service=AzureChatCompletion(),\n    name="RefundAgent",\n    instructions="Assist users with refund inquiries, including eligibility, policies, processing, and status updates.",\n)\n\ntriage_agent = ChatCompletionAgent(\n    service=OpenAIChatCompletion(),\n    name="TriageAgent",\n    instructions="Evaluate user requests and forward them to BillingAgent or RefundAgent for targeted assistance."\n    " Provide the full answer to the user containing any information from the agents",\n    plugins=[billing_agent, refund_agent],\n)\n\nthread: ChatHistoryAgentThread = None\n\nasync def main() -> None:\n    print("Welcome to the chat bot!\n  Type ''exit'' to exit.\n  Try to get some billing or refund help.")\n    while True:\n        user_input = input("User:> ")\n\n        if user_input.lower().strip() == "exit":\n            print("\n\nExiting chat...")\n            return False\n\n        response = await triage_agent.get_response(\n            messages=user_input,\n            thread=thread,\n        )\n\n        if response:\n            print(f"Agent :> {response}")\n\n# Agent :> I understand that you were charged twice for your subscription last month, and I''m here to assist you with resolving this issue. Here‚Äôs what we need to do next:\n\n# 1. **Billing Inquiry**:\n#    - Please provide the email address or account number associated with your subscription, the date(s) of the charges, and the amount charged. This will allow the billing team to investigate the discrepancy in the charges.\n\n# 2. **Refund Process**:\n#    - For the refund, please confirm your subscription type and the email address associated with your account.\n#    - Provide the dates and transaction IDs for the charges you believe were duplicated.\n\n# Once we have these details, we will be able to:\n\n# - Check your billing history for any discrepancies.\n# - Confirm any duplicate charges.\n# - Initiate a refund for the duplicate payment if it qualifies. The refund process usually takes 5-10 business days after approval.\n\n# Please provide the necessary details so we can proceed with resolving this issue for you.\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\n\n\n## Where to Go Next\n\n1. üìñ Try our [Getting Started Guide](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide) or learn about [Building Agents](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/agent/)\n2. üîå Explore over 100 [Detailed Samples](https://learn.microsoft.com/en-us/semantic-kernel/get-started/detailed-samples)\n3. üí° Learn about core Semantic Kernel [Concepts](https://learn.microsoft.com/en-us/semantic-kernel/concepts/kernel)\n\n### API References\n\n- [C# API reference](https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel?view=semantic-kernel-dotnet)\n- [Python API reference](https://learn.microsoft.com/en-us/python/api/semantic-kernel/semantic_kernel?view=semantic-kernel-python)\n\n## Troubleshooting\n\n### Common Issues\n\n- **Authentication Errors**: Check that your API key environment variables are correctly set\n- **Model Availability**: Verify your Azure OpenAI deployment or OpenAI model access\n\n### Getting Help\n\n- Check our [GitHub issues](https://github.com/microsoft/semantic-kernel/issues) for known problems\n- Search the [Discord community](https://aka.ms/SKDiscord) for solutions\n- Include your SDK version and full error messages when asking for help\n\n\n## Join the community\n\nWe welcome your contributions and suggestions to the SK community! One of the easiest ways to participate is to engage in discussions in the GitHub repository. Bug reports and fixes are welcome!\n\nFor new features, components, or extensions, please open an issue and discuss with us before sending a PR. This is to avoid rejection as we might be taking the core in a different direction, but also to consider the impact on the larger ecosystem.\n\nTo learn more and get started:\n\n- Read the [documentation](https://aka.ms/sk/learn)\n- Learn how to [contribute](https://learn.microsoft.com/en-us/semantic-kernel/support/contributing) to the project\n- Ask questions in the [GitHub discussions](https://github.com/microsoft/semantic-kernel/discussions)\n- Ask questions in the [Discord community](https://aka.ms/SKDiscord)\n\n- Attend [regular office hours and SK community events](COMMUNITY.md)\n- Follow the team on our [blog](https://aka.ms/sk/blog)\n\n## Contributor Wall of Fame\n\n[![semantic-kernel contributors](https://contrib.rocks/image?repo=microsoft/semantic-kernel)](https://github.com/microsoft/semantic-kernel/graphs/contributors)\n\n## Code of Conduct\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information, see the\n[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\nwith any additional questions or comments.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE) license.\n', '{"language":"C#","stars":26793,"forks":4375,"watchers":26793,"open_issues":563,"topics":["ai","artificial-intelligence","llm","openai","sdk"],"default_branch":"main","size_kb":93581,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:microsoft:semantic-kernel","source_url":"https://github.com/microsoft/semantic-kernel"},{"type":"has_code","target_id":"github:microsoft:semantic-kernel-java","source_url":"https://github.com/microsoft/semantic-kernel-java"},{"type":"has_code","target_id":"github:microsoft:semantic-kernel","source_url":"https://github.com/microsoft/semantic-kernel"},{"type":"has_code","target_id":"github:microsoft:semantic-kernel","source_url":"https://github.com/microsoft/semantic-kernel"},{"type":"has_code","target_id":"github:microsoft:semantic-kernel","source_url":"https://github.com/microsoft/semantic-kernel"}]', NULL, 'MIT', 'approved', 80, 'fb3803596646ba3d919573323ddf0496', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-microsoft-semantic-kernel from https://github.com/microsoft.png
Image converted to WebP: data/images/github-microsoft-semantic-kernel.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-ComposioHQ-composio', 'github--composiohq--composio', 'composio', 'ComposioHQ', '<div align="center"> <img src="https://raw.githubusercontent.com/ComposioHQ/composio/next/public/cover.png" alt="Composio Logo" width="auto" height="auto" style="margin-bottom: 20px;"/> Skills that evolve for your Agents üåê Website ‚Ä¢ üìö Documentation </div> This repository contains the official Software Development Kits (SDKs) for Composio, providing seamless integration capabilities for Python and Typescript Agentic Frameworks and Libraries. For more detailed usage instructions and examples,...', '["agentic-ai","agents","ai","ai-agents","aiagents","developer-tools","function-calling","gpt-4","javascript","js","llm","llmops","mcp","python","remote-mcp-server","sse","typescript","typescript"]', 'other', 26201, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/ComposioHQ/composio","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '\n<div align="center">\n\n<img src="https://raw.githubusercontent.com/ComposioHQ/composio/next/public/cover.png" alt="Composio Logo" width="auto" height="auto" style="margin-bottom: 20px;"/>\n\n\n# Composio SDK\n\nSkills that evolve for your Agents\n\n[üåê Website](https://composio.dev) ‚Ä¢ [üìö Documentation](https://docs.composio.dev)\n\n[![GitHub Stars](https://img.shields.io/github/stars/ComposioHQ/composio?style=social)](https://github.com/ComposioHQ/composio/stargazers)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/composio?label=PyPI%20Downloads)](https://pypi.org/project/composio/)\n[![NPM Downloads](https://img.shields.io/npm/dt/@composio/core?label=NPM%20Downloads)](https://www.npmjs.com/package/@composio/core)\n[![Discord](https://img.shields.io/badge/Discord-join-5865F2?logo=discord&logoColor=white)](https://discord.gg/composio)\n</div>\n\nThis repository contains the official Software Development Kits (SDKs) for Composio, providing seamless integration capabilities for Python and Typescript Agentic Frameworks and Libraries.\n\n## Getting Started\n\n### TypeScript SDK Installation\n\n```bash\n# Using npm\nnpm install @composio/core\n\n# Using yarn\nyarn add @composio/core\n\n# Using pnpm\npnpm add @composio/core\n```\n\n#### Quick start:\n\n```typescript\nimport { Composio } from ''@composio/core'';\n// Initialize the SDK\nconst composio = new Composio({\n  // apiKey: ''your-api-key'',\n});\n```\n\n#### Simple Agent with OpenAI Agents\n\n```bash\nnpm install @composio/openai-agents @openai/agents\n```\n\n```typescript\nimport { Composio } from ''@composio/core'';\nimport { OpenAIAgentsProvider } from ''@composio/openai-agents'';\nimport { Agent, run } from ''@openai/agents'';\n\nconst composio = new Composio({\n  provider: new OpenAIAgentsProvider(),\n});\n\nconst userId = ''user@acme.org'';\n\nconst tools = await composio.tools.get(userId, {\n  toolkits: [''HACKERNEWS''],\n});\n\nconst agent = new Agent({\n  name: ''Hackernews assistant'',\n  tools: tools,\n});\n\nconst result = await run(agent, ''What is the latest hackernews post about?'');\n\nconsole.log(JSON.stringify(result.finalOutput, null, 2));\n// will return the response from the agent with data from HACKERNEWS API.\n```\n\n### Python SDK Installation\n\n```bash\n# Using pip\npip install composio\n\n# Using poetry\npoetry add composio\n```\n\n#### Quick start:\n\n```python\nfrom composio import Composio\n\ncomposio = Composio(\n  # api_key="your-api-key",\n)\n```\n\n#### Simple Agent with OpenAI Agents\n\n```bash\npip install composio_openai_agents openai-agents\n```\n\n```python\nimport asyncio\nfrom agents import Agent, Runner\nfrom composio import Composio\nfrom composio_openai_agents import OpenAIAgentsProvider\n\n# Initialize Composio client with OpenAI Agents Provider\ncomposio = Composio(provider=OpenAIAgentsProvider())\n\nuser_id = "user@acme.org"\ntools = composio.tools.get(user_id=user_id, toolkits=["HACKERNEWS"])\n\n# Create an agent with the tools\nagent = Agent(\n    name="Hackernews Agent",\n    instructions="You are a helpful assistant.",\n    tools=tools,\n)\n\n# Run the agent\nasync def main():\n    result = await Runner.run(\n        starting_agent=agent,\n        input="What''s the latest Hackernews post about?",\n    )\n    print(result.final_output)\n\nasyncio.run(main())\n# will return the response from the agent with data from HACKERNEWS API.\n```\n\nFor more detailed usage instructions and examples, please refer to each SDK''s specific documentation.\n\n### Open API Specification\n\nTo update the OpenAPI specifications used for generating SDK documentation:\n\n```bash\n# Pull the latest API specifications from the backend\npnpm api:pull\n```\n\nThis command pulls the OpenAPI specification from `https://backend.composio.dev/api/v3/openapi.json` (defined in `fern/scripts/pull-openapi-spec.sh`) and updates the local API documentation files.\n\nThis is pulled automatically with build step.\n\n## Available SDKs\n\n### TypeScript SDK (/ts)\n\nThe TypeScript SDK provides a modern, type-safe way to interact with Composio''s services. It''s designed for both Node.js and browser environments, offering full TypeScript support with comprehensive type definitions.\n\nFor detailed information about the TypeScript SDK, please refer to the [TypeScript SDK Documentation](/ts/README.md).\n\n### Python SDK (/python)\n\nThe Python SDK offers a Pythonic interface to Composio''s services, making it easy to integrate Composio into your Python applications. It supports Python 3.10+ and follows modern Python development practices.\n\nFor detailed information about the Python SDK, please refer to the [Python SDK Documentation](/python/README.md).\n\n## Provider Support\n\nThe following table shows which AI frameworks and platforms are supported in each SDK:\n\n| Provider | TypeScript | Python |\n|----------|:----------:|:------:|\n| OpenAI | ‚úÖ | ‚úÖ |\n| OpenAI Agents | ‚úÖ | ‚úÖ |\n| Anthropic | ‚úÖ | ‚úÖ |\n| LangChain | ‚úÖ | ‚úÖ |\n| LangGraph | ‚úÖ* | ‚úÖ |\n| LlamaIndex | ‚úÖ | ‚úÖ |\n| Vercel AI SDK | ‚úÖ | ‚ùå |\n| Google Gemini | ‚úÖ | ‚úÖ |\n| Google ADK | ‚ùå | ‚úÖ |\n| Mastra | ‚úÖ | ‚ùå |\n| Cloudflare Workers AI | ‚úÖ | ‚ùå |\n| CrewAI | ‚ùå | ‚úÖ |\n| AutoGen | ‚ùå | ‚úÖ |\n\n\* *LangGraph in TypeScript is supported via the `@composio/langchain` package.*\n\n> **Don''t see your provider?** Learn how to [build a custom provider](https://docs.composio.dev/sdk/typescript/custom-providers) to integrate with any AI framework.\n\n## Packages\n\n### Core Packages\n\n| Package | Version |\n|---------|---------|\n| **TypeScript** | |\n| [@composio/core](https://www.npmjs.com/package/@composio/core) | ![npm version](https://img.shields.io/npm/v/@composio/core) |\n| **Python** | |\n| [composio](https://pypi.org/project/composio/) | ![PyPI version](https://img.shields.io/pypi/v/composio) |\n\n### Provider Packages\n\n| Package | Version |\n|---------|---------|\n| **TypeScript** | |\n| [@composio/openai](https://www.npmjs.com/package/@composio/openai) | ![npm version](https://img.shields.io/npm/v/@composio/openai) |\n| [@composio/openai-agents](https://www.npmjs.com/package/@composio/openai-agents) | ![npm version](https://img.shields.io/npm/v/@composio/openai-agents) |\n| [@composio/anthropic](https://www.npmjs.com/package/@composio/anthropic) | ![npm version](https://img.shields.io/npm/v/@composio/anthropic) |\n| [@composio/langchain](https://www.npmjs.com/package/@composio/langchain) | ![npm version](https://img.shields.io/npm/v/@composio/langchain) |\n| [@composio/llamaindex](https://www.npmjs.com/package/@composio/llamaindex) | ![npm version](https://img.shields.io/npm/v/@composio/llamaindex) |\n| [@composio/vercel](https://www.npmjs.com/package/@composio/vercel) | ![npm version](https://img.shields.io/npm/v/@composio/vercel) |\n| [@composio/google](https://www.npmjs.com/package/@composio/google) | ![npm version](https://img.shields.io/npm/v/@composio/google) |\n| [@composio/mastra](https://www.npmjs.com/package/@composio/mastra) | ![npm version](https://img.shields.io/npm/v/@composio/mastra) |\n| [@composio/cloudflare](https://www.npmjs.com/package/@composio/cloudflare) | ![npm version](https://img.shields.io/npm/v/@composio/cloudflare) |\n| **Python** | |\n| [composio-openai](https://pypi.org/project/composio-openai/) | ![PyPI version](https://img.shields.io/pypi/v/composio-openai) |\n| [composio-openai-agents](https://pypi.org/project/composio-openai-agents/) | ![PyPI version](https://img.shields.io/pypi/v/composio-openai-agents) |\n| [composio-anthropic](https://pypi.org/project/composio-anthropic/) | ![PyPI version](https://img.shields.io/pypi/v/composio-anthropic) |\n| [composio-langchain](https://pypi.org/project/composio-langchain/) | ![PyPI version](https://img.shields.io/pypi/v/composio-langchain) |\n| [composio-langgraph](https://pypi.org/project/composio-langgraph/) | ![PyPI version](https://img.shields.io/pypi/v/composio-langgraph) |\n| [composio-llamaindex](https://pypi.org/project/composio-llamaindex/) | ![PyPI version](https://img.shields.io/pypi/v/composio-llamaindex) |\n| [composio-crewai](https://pypi.org/project/composio-crewai/) | ![PyPI version](https://img.shields.io/pypi/v/composio-crewai) |\n| [composio-autogen](https://pypi.org/project/composio-autogen/) | ![PyPI version](https://img.shields.io/pypi/v/composio-autogen) |\n| [composio-gemini](https://pypi.org/project/composio-gemini/) | ![PyPI version](https://img.shields.io/pypi/v/composio-gemini) |\n| [composio-google](https://pypi.org/project/composio-google/) | ![PyPI version](https://img.shields.io/pypi/v/composio-google) |\n| [composio-google-adk](https://pypi.org/project/composio-google-adk/) | ![PyPI version](https://img.shields.io/pypi/v/composio-google-adk) |\n\n### Utility Packages\n\n| Package | Version |\n|---------|---------|\n| [@composio/json-schema-to-zod](https://www.npmjs.com/package/@composio/json-schema-to-zod) | ![npm version](https://img.shields.io/npm/v/@composio/json-schema-to-zod) |\n| [@composio/ts-builders](https://www.npmjs.com/package/@composio/ts-builders) | ![npm version](https://img.shields.io/npm/v/@composio/ts-builders) |\n\n_if you are looking for the older sdk, you can find them [here](https://github.com/ComposioHQ/composio/tree/master)_\n\n## Rube\n\n[Rube](https://rube.app) is a Model Context Protocol (MCP) server built with Composio. It connects your AI tools to 500+ apps like Gmail, Slack, GitHub, and Notion. Simply install it in your AI client, authenticate once with your apps, and start asking your AI to perform real actions like "Send an email" or "Create a task." \n\nIt integrates with major AI clients like Cursor, Claude Desktop, VS Code, Claude Code and any custom MCP‚Äëcompatible client. You can switch between these clients and your integrations follow you.\n\n\n## Contributing\n\nWe welcome contributions to both SDKs! Please read our [contribution guidelines](https://github.com/ComposioHQ/composio/blob/next/CONTRIBUTING.md) before submitting pull requests.\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Support\n\nIf you encounter any issues or have questions about the SDKs:\n\n- Open an issue in this repository\n- Contact our [support team](mailto:support@composio.dev)\n- Check our [documentation](https://docs.composio.dev/)\n', '{"language":"TypeScript","stars":26201,"forks":4395,"watchers":26201,"open_issues":35,"topics":["agentic-ai","agents","ai","ai-agents","aiagents","developer-tools","function-calling","gpt-4","javascript","js","llm","llmops","mcp","python","remote-mcp-server","sse","typescript"],"default_branch":"next","size_kb":220255,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:ComposioHQ:composio","source_url":"https://github.com/ComposioHQ/composio"},{"type":"has_code","target_id":"github:ComposioHQ:composio","source_url":"https://github.com/ComposioHQ/composio"},{"type":"has_code","target_id":"github:ComposioHQ:composio","source_url":"https://github.com/ComposioHQ/composio"}]', NULL, 'MIT', 'approved', 80, '0f37ac8fb05ac24fc2e2139dd200fc3a', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-ComposioHQ-composio from https://github.com/ComposioHQ.png
Image converted to WebP: data/images/github-ComposioHQ-composio.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-facefusion-facefusion', 'github--facefusion--facefusion', 'facefusion', 'facefusion', 'FaceFusion ========== > Industry leading face manipulation platform. !License Preview ------- !Preview Installation ------------ Be aware, the installation needs technical skills and is not recommended for beginners. In case you are not comfortable using a terminal, our Windows Installer and macOS Installer get you started. Usage ----- Run the command: Documentation ------------- Read the documentation for a deep dive.', '["ai","deep-fake","deepfake","face-swap","faceswap","lip-sync","lipsync","python"]', 'other', 26059, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/facefusion/facefusion","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', 'FaceFusion\n==========\n\n> Industry leading face manipulation platform.\n\n[![Build Status](https://img.shields.io/github/actions/workflow/status/facefusion/facefusion/ci.yml.svg?branch=master)](https://github.com/facefusion/facefusion/actions?query=workflow:ci)\n[![Coverage Status](https://img.shields.io/coveralls/facefusion/facefusion.svg)](https://coveralls.io/r/facefusion/facefusion)\n![License](https://img.shields.io/badge/license-OpenRAIL--AS-green)\n\n\nPreview\n-------\n\n![Preview](https://raw.githubusercontent.com/facefusion/facefusion/master/.github/preview.png?sanitize=true)\n\n\nInstallation\n------------\n\nBe aware, the [installation](https://docs.facefusion.io/installation) needs technical skills and is not recommended for beginners. In case you are not comfortable using a terminal, our [Windows Installer](http://windows-installer.facefusion.io) and [macOS Installer](http://macos-installer.facefusion.io) get you started.\n\n\nUsage\n-----\n\nRun the command:\n\n```\npython facefusion.py [commands] [options]\n\noptions:\n  -h, --help                                      show this help message and exit\n  -v, --version                                   show program''s version number and exit\n\ncommands:\n    run                                           run the program\n    headless-run                                  run the program in headless mode\n    batch-run                                     run the program in batch mode\n    force-download                                force automate downloads and exit\n    benchmark                                     benchmark the program\n    job-list                                      list jobs by status\n    job-create                                    create a drafted job\n    job-submit                                    submit a drafted job to become a queued job\n    job-submit-all                                submit all drafted jobs to become a queued jobs\n    job-delete                                    delete a drafted, queued, failed or completed job\n    job-delete-all                                delete all drafted, queued, failed and completed jobs\n    job-add-step                                  add a step to a drafted job\n    job-remix-step                                remix a previous step from a drafted job\n    job-insert-step                               insert a step to a drafted job\n    job-remove-step                               remove a step from a drafted job\n    job-run                                       run a queued job\n    job-run-all                                   run all queued jobs\n    job-retry                                     retry a failed job\n    job-retry-all                                 retry all failed jobs\n```\n\n\nDocumentation\n-------------\n\nRead the [documentation](https://docs.facefusion.io) for a deep dive.\n', '{"language":"Python","stars":26059,"forks":4172,"watchers":26059,"open_issues":0,"topics":["ai","deep-fake","deepfake","face-swap","faceswap","lip-sync","lipsync"],"default_branch":"master","size_kb":26428,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:facefusion:facefusion","source_url":"https://github.com/facefusion/facefusion"}]', NULL, 'NOASSERTION', 'approved', 65, 'bf3353948c357cfd15f65136711e9f11', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-facefusion-facefusion from https://github.com/facefusion.png
Image converted to WebP: data/images/github-facefusion-facefusion.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-Max-Eee-NeoPass', 'github--max-eee--neopass', 'NeoPass', 'Max-Eee', '<img width="1500" height="500" alt="NeoPass Banner" src="https://github.com/user-attachments/assets/7369dd86-838d-4fdc-abdd-6b41a9b14aed" /> This chrome extension is for students taking tests on the ****, ****<br>, ****<br>, ****<br> and that restrict your abilities <samp> > [!IMPORTANT] > **Get Your Credentials**: To obtain your credentials, it is essential to visit the website neopass and follow the instructions provided there. > Accessing the website is crucial for a seamless experience wi...', '["ai","always-active-tab","chrome-extension","code-generation","conservation-geography","copy-paste","examly","examlyio","forest-management","fullscreen-bypass","iamneo","iamneobypass","mcq-test","neocolab","neoexamshield","neoexamshield-bypass","neoshield-bypass","nptel","screenshare-bypass","wildlife-ecology","html"]', 'other', 25935, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/Max-Eee/NeoPass","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<img width="1500" height="500" alt="NeoPass Banner" src="https://github.com/user-attachments/assets/7369dd86-838d-4fdc-abdd-6b41a9b14aed" />\n\n# <i>**`Free`** NeoPass Extension</i>\n\nThis chrome extension is for students taking tests on the **`Iamneo portal`**, **`Wildlife Ecology NPTEL`**<br>, **`conservation-geography NPTEL`**<br>, **`forest management NPTEL`**<br>  and `other exam portals in chrome browser` that restrict your abilities\n\n### [**Make sure to visit our website for the best experience!**](https://freeneopass.vercel.app) üåê\n\n<samp>\n  \n> [!IMPORTANT]\n> **Get Your Credentials**: To obtain your credentials, it is essential to visit the website [neopass](https://freeneopass.vercel.app) and follow the instructions provided there.  \n> Accessing the website is crucial for a seamless experience with the extension.  \n\n> [!WARNING]\n> **Educational Purposes Only**: This extension is intended for educational purposes. Please use it responsibly and ethically.  \n> We am not responsible for any actions taken, and we do not encourage or promote cheating in any way.  \n> Be cautious when using the extension to maintain academic integrity.\n\n## ‚ú® Features\n\n- **`NPTEL Integration`** : Solve NPTEL Wildlife ecology answers\n- **`NeoExamShield Bypass`** : Break free from Examly''s limitations.  NeoPass mimics the NeoExamShield extension\n- **`Chatbot With Stealth Mode`** : Leverage AI Chatbot to enhance your search capabilities\n- **`AI Search Answers/Code`** : Perform AI-powered searches, helping you find answers without switching tabs\n- **`Solve MCQ`** : Quicky Search MCQ Answers by simply selecting\n- **`Tab Switching Bypass`** : Prevents unwanted tab switch restrictions\n- **`Pasting When Restricted`** : Quickly paste answers with ease, reducing the time spent on manual entry\n- **`Remote Logout`** : Remote logout your account from the extension ensuring your identity is hidden.\n\n## ‚¨áÔ∏è Installation\n\n1. [Download](https://github.com/Max-Eee/NeoPass/archive/refs/heads/main.zip) the extension.\n2. Open Chrome and go to the Extensions page by typing `chrome://extensions/`.\n3. Enable **Developer mode** in the top right corner.\n4. Click on **Load unpacked** and select the folder where the extension is located.\n5. Your NeoPass extension is now installed!\n\n### Installation Guide Video\n\n\n\nhttps://github.com/user-attachments/assets/89fb986c-2edb-4252-8232-dbd10beec0cf\n\n\n## üíª Usage\n\nOnce installed, **login with your credentials** obtained from our [website](https://freeneopass.vercel.app).\n\n## ‚å®Ô∏è Shortcuts\n\n### Windows/Linux Users:\n- <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>Q</kbd> : Solve Iam Neo MCQs/Coding Questions with 100% ACCURACY\n- <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>A</kbd> : Solve Iam Neo MCQs/Coding Questions with using AI [Backup]\n- <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>T</kbd> : Type Iam Neo Coding Questions One by One\n- <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>H</kbd> : Solve HackerRank Questions [BETA]\n> [!NOTE]\n> The following shortcuts **require text to be selected** before activation:  \n> - <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>N</kbd> : Solve NPTEL MCQs from selected text\n> - <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>S</kbd> : Search answers and code from selected text  \n> - <kbd>Alt</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> : Search MCQs from selected text\n- <kbd>Ctrl</kbd> + <kbd>V</kbd> : Paste content when blocked\n- <kbd>Alt</kbd> + <kbd>C</kbd> : Open/Close Chatbot\n\n<details>\n<summary><strong>Mac Users (Click to expand)</strong></summary>\n\n- <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>Q</kbd> : Solve Iam Neo MCQs/Coding Questions with 100% ACCURACY\n- <kbd>Option</kbd> + <kbd>Shift</kbd> + <kbd>A</kbd> : Solve Iam Neo MCQs/Coding Questions with using AI [Backup]\n- <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>T</kbd> : Type Iam Neo Coding Questions One by One\n- <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>H</kbd> : Solve HackerRank Questions [BETA]\n\n> [!NOTE]\n> The following shortcuts **require text to be selected** before activation:  \n> - <kbd>Option</kbd> + <kbd>Shift</kbd> + <kbd>N</kbd> : Solve NPTEL MCQs from selected text\n> - <kbd>Option</kbd> + <kbd>Shift</kbd> + <kbd>S</kbd> : Search answers and code from selected text  \n> - <kbd>Option</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> : Search MCQs from selected text\n\n- <kbd>Cmd</kbd> + <kbd>V</kbd> : Paste content when blocked\n- <kbd>Option</kbd> + <kbd>C</kbd> : Open/Close Chatbot\n\n</details>\n\n## ü§ù Contribute or Add NPTEL Dataset\n\nIf you want to contribute to the NPTEL question database, follow these steps:\n\n1. Fork this repository\n2. Open your NPTEL assignment page in the browser\n3. Open browser developer tools (F12 or right-click > Inspect)\n4. Go to the Console tab\n5. Copy and paste the script from `nptel.txt` in the repository\n6. Run the script by pressing Enter\n7. The script will extract all questions and correct answers from the page\n8. Copy the output JSON data\n9. Update the `data/nptel.json` file with the new questions and answers\n10. Create a pull request to contribute your additions back to the main repository\n\nThis helps expand our database and improves the accuracy of the NPTEL question solving feature!\n\n## üí¨ Feedback\n\nWe''d love to hear your thoughts! If you encounter any issues or have suggestions for improvement, please reach out. Your feedback is invaluable! üíå\n\nüìß **Contact us at:** [freeneopass@gmail.com](mailto:freeneopass@gmail.com?subject=Issue%20Title%3A%20%5BBrief%20description%20of%20your%20issue%5D&body=Hello%20NeoPass%20Support%20Team%2C%0A%0AIssue%20Description%3A%0A%5BPlease%20describe%20your%20issue%20in%20detail%5D%0A%0AWhen%20does%20this%20occur%3A%0A%5BSpecify%20when%20the%20issue%20happens%20-%20e.g.%2C%20during%20login%2C%20while%20using%20a%20specific%20feature%2C%20etc.%5D%0A%0ASteps%20to%20Reproduce%3A%0A1.%20%5BFirst%20step%5D%0A2.%20%5BSecond%20step%5D%0A3.%20%5BThird%20step%5D%0A%0AScreenshots%2FError%20Messages%20if%20possible%3A%0A%5BPlease%20attach%20any%20relevant%20screenshots%20or%20paste%20error%20messages%20here%5D%0A%0AAdditional%20Information%3A%0A%5BAny%20other%20relevant%20details%5D%0A%0AThank%20you!)\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n</samp>\n', '{"language":"HTML","stars":25935,"forks":82,"watchers":25935,"open_issues":2,"topics":["ai","always-active-tab","chrome-extension","code-generation","conservation-geography","copy-paste","examly","examlyio","forest-management","fullscreen-bypass","iamneo","iamneobypass","mcq-test","neocolab","neoexamshield","neoexamshield-bypass","neoshield-bypass","nptel","screenshare-bypass","wildlife-ecology"],"default_branch":"main","size_kb":2092,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:Max-Eee:NeoPass","source_url":"https://github.com/Max-Eee/NeoPass"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"}]', NULL, 'MIT', 'approved', 65, '9267fa50f5cfc94ffcea6c92e4bbb65b', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-Max-Eee-NeoPass from https://github.com/Max-Eee.png
Image converted to WebP: data/images/github-Max-Eee-NeoPass.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-CopilotKit-CopilotKit', 'github--copilotkit--copilotkit', 'CopilotKit', 'CopilotKit', '<img width="4096" height="1588" alt="header" src="https://github.com/user-attachments/assets/dd638592-fb74-4e22-8c55-49dfc4d0e462" /> <br> <div align="start" style="display:flex;justify-content:start;gap:16px;height:20px;margin: 0;"> <a href="https://www.npmjs.com/package/@copilotkit/react-core" target="_blank"> <img src="https://img.shields.io/npm/v/%40copilotkit%2Freact-core?logo=npm&logoColor=%23FFFFFF&label=Version&color=%236963ff" alt="NPM"> </a> <a href="https://github.com/copilotkit/co...', '["agent","agents","ai","ai-agent","ai-assistant","assistant","copilot","copilot-chat","hacktoberfest","langchain","langgraph","llm","nextjs","open-source","react","reactjs","ts","typescript","typescript"]', 'other', 25300, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/CopilotKit/CopilotKit","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '\n<img width="4096" height="1588" alt="header" src="https://github.com/user-attachments/assets/dd638592-fb74-4e22-8c55-49dfc4d0e462" />\n\n\n<br>\n  <div align="start" style="display:flex;justify-content:start;gap:16px;height:20px;margin: 0;">\n  <a href="https://www.npmjs.com/package/@copilotkit/react-core" target="_blank">\n    <img src="https://img.shields.io/npm/v/%40copilotkit%2Freact-core?logo=npm&logoColor=%23FFFFFF&label=Version&color=%236963ff" alt="NPM">\n  </a>\n\n  <a href="https://github.com/copilotkit/copilotkit/blob/main/LICENSE" target="_blank">\n    <img src="https://img.shields.io/github/license/copilotkit/copilotkit?color=%236963ff&label=License" alt="MIT">\n  </a>\n\n  <a href="https://discord.gg/6dffbvGU3D" target="_blank">\n    <img src="https://img.shields.io/discord/1122926057641742418?logo=discord&logoColor=%23FFFFFF&label=Discord&color=%236963ff" alt="Discord">\n  </a>\n  </div>\n  <br/>\n  <div>\n    <a href="https://www.producthunt.com/posts/copilotkit" target="_blank">\n    <img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=428778&theme=light&period=daily">\n  </a>\n  </div>\n\n## ‚ö°Ô∏è Quick Install\n```\n  npx copilotkit@latest init\n```\n\n<br/>\n\n<a href="https://docs.copilotkit.ai/?ref=github_readme">Read the Docs ‚Üí</a>&nbsp;&nbsp;&nbsp;\n<a href="https://cloud.copilotkit.ai?ref=github_readme">Try Copilot Cloud ‚Üí</a>&nbsp;&nbsp;&nbsp;\n<a href="https://discord.gg/6dffbvGU3D?ref=github_readme">Join our Discord ‚Üí</a>\n\n## üöÄ Getting Started\n\n1. Install: Run a simple CLI command\n1. Configure: Add CopilotKit provider to your app\n1. Customize: Use headless UI or the customizable pre-built components\n1. Deploy: You''re done!\n\n<br />\n  <a href="https://docs.copilotkit.ai/#get-started-now?ref=github_readme" target="_blank">\n    Complete getting started guide ‚Üí\n  </a>\n<br />\n<br />\n\n<img width="4096" height="2341" alt="Best in class support across the ecosystem" src="https://github.com/user-attachments/assets/bf399131-2a92-49f8-8748-38ed72353f9c" />\n\n\n## ‚ú® Why CopilotKit?\n\n- Minutes to integrate¬†- Get started quickly with our CLI\n- Framework agnostic¬†- Works with React, Next.js, AGUI and more\n- Production-ready UI¬†- Use customizable components or build with headless UI\n- Built-in security¬†- Prompt injection protection\n- Open source¬†- Full transparency and community-driven\n\n## üßë‚Äçüíª Real life use cases\n\n<span>Deploy deeply-integrated AI assistants & agents that work alongside your users inside your applications.</span>\n\n<img width="4096" height="2725" alt="Headless UI" src="https://github.com/user-attachments/assets/4dbe1e74-8b46-4798-a658-f79ee5a66189" />\n\n\n## üñ•Ô∏è Code Samples\n\n<span>Drop in these building blocks and tailor them to your needs.</span>\n\n<h3>Build with Headless APIs and Pre-Built Components</h3>\n\n```ts\n// Headless UI with full control\nconst { visibleMessages, appendMessage, setMessages, ... } = useCopilotChat();\n\n// Pre-built components with deep customization options (CSS + pass custom sub-components)\n<CopilotPopup \n  instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."} \n  labels={{ title: "Popup Assistant", initial: "Need any help?" }} \n/>\n```\n\n```ts\n// Frontend actions + generative UI, with full streaming support\nuseCopilotAction({\n  name: "appendToSpreadsheet",\n  description: "Append rows to the current spreadsheet",\n  parameters: [\n    { name: "rows", type: "object[]", attributes: [{ name: "cells", type: "object[]", attributes: [{ name: "value", type: "string" }] }] }\n  ],\n  render: ({ status, args }) => <Spreadsheet data={canonicalSpreadsheetData(args.rows)} />,\n  handler: ({ rows }) => setSpreadsheet({ ...spreadsheet, rows: [...spreadsheet.rows, ...canonicalSpreadsheetData(rows)] }),\n});\n```\n\n<h3>Integrate In-App CoAgents with LangGraph</h3>\n\n```ts\n// Share state between app and agent\nconst { agentState } = useCoAgent({ \n  name: "basic_agent", \n  initialState: { input: "NYC" } \n});\n\n// agentic generative UI\nuseCoAgentStateRender({\n  name: "basic_agent",\n  render: ({ state }) => <WeatherDisplay {...state.final_response} />,\n});\n\n// Human in the Loop (Approval)\nuseCopilotAction({\n  name: "email_tool",\n  parameters: [\n    {\n      name: "email_draft",\n      type: "string",\n      description: "The email content",\n      required: true,\n    },\n  ],\n  renderAndWaitForResponse: ({ args, status, respond }) => {\n    return (\n      <EmailConfirmation\n        emailContent={args.email_draft || ""}\n        isExecuting={status === "executing"}\n        onCancel={() => respond?.({ approved: false })}\n        onSend={() =>\n          respond?.({\n            approved: true,\n            metadata: { sentAt: new Date().toISOString() },\n          })\n        }\n      />\n    );\n  },\n});\n```\n\n```ts\n// intermediate agent state streaming (supports both LangGraph.js + LangGraph python)\nconst modifiedConfig = copilotKitCustomizeConfig(config, {\n  emitIntermediateState: [{ \n    stateKey: "outline", \n    tool: "set_outline", \n    toolArgument: "outline" \n  }],\n});\nconst response = await ChatOpenAI({ model: "gpt-4o" }).invoke(messages, modifiedConfig);\n```\n## üèÜ Featured Examples\n\n\n<p align="center">\n  <a href="https://www.copilotkit.ai/examples/form-filling-copilot">\n    <img width="290" height="304" alt="Banner 2 A" src="https://github.com/user-attachments/assets/90c42b54-8931-45ad-9c0b-53f7f67453a1" />\n  </a>\n  <a href="https://www.copilotkit.ai/examples/state-machine-copilot">\n    <img width="290" height="304" alt="Banner 2 A-1" src="https://github.com/user-attachments/assets/609c62eb-76af-4866-a353-5e3545470ec3" />\n  </a>\n  <a href="https://www.copilotkit.ai/examples/chat-with-your-data">\n    <img width="290" height="304" alt="Banner 2 A-2" src="https://github.com/user-attachments/assets/c614ac4e-d2b3-4514-9ef1-fdba04c0a082" />\n  </a>\n</p>\n\n## üñ•Ô∏è AG-UI: The Agent‚ÄìUser Interaction Protocol\nConnect agent workflow to user-facing apps, with deep partnerships and 1st-party integrations across the agentic stack‚Äîincluding LangGraph, CrewAI, and more.\n\n\n  <a href="https://github.com/ag-ui-protocol/ag-ui" target="_blank">\n   Learn more in the AG-UI README ‚Üí\n  </a>\n\n## ü§ù Community\n<h3>Have questions or need help?</h3>\n  <a href="https://discord.gg/6dffbvGU3D?ref=github_readme" target="_blank">\n   Join our Discord ‚Üí\n  </a> </br>\n    <a href="https://docs.copilotkit.ai/?ref=github_readme" target="_blank">\n  Read the Docs ‚Üí\n  </a> </br>\n    <a href="https://cloud.copilotkit.ai?ref=github_readme" target="_blank">\n   Try Copilot Cloud ‚Üí\n  </a>\n<h3>Stay up to date with our latest releases!</h3>\n  <a href="https://www.linkedin.com/company/copilotkit/" target="_blank">\n   Follow us on LinkedIn ‚Üí\n  </a> </br>\n    <a href="https://x.com/copilotkit" target="_blank">\n   Follow us on X ‚Üí\n  </a> \n  \n## üôãüèΩ‚Äç‚ôÇÔ∏è Contributing\n\nThanks for your interest in contributing to CopilotKit! üíú\n\nWe value all contributions, whether it''s through code, documentation, creating demo apps, or just spreading the word.\n\nHere are a few useful resources to help you get started:\n\n- For code contributions, [CONTRIBUTING.md](./CONTRIBUTING.md).\n- For documentation-related contributions, [check out the documentation contributions guide](https://docs.copilotkit.ai/contributing/docs-contributions?ref=github_readme).\n\n- Want to contribute but not sure how? [Join our Discord](https://discord.gg/6dffbvGU3D) and we''ll help you out!\n\n## üìÑ License\n\nThis repository''s source code is available under the [MIT License](https://github.com/CopilotKit/CopilotKit/blob/main/LICENSE).\n', '{"language":"TypeScript","stars":25300,"forks":3373,"watchers":25300,"open_issues":462,"topics":["agent","agents","ai","ai-agent","ai-assistant","assistant","copilot","copilot-chat","hacktoberfest","langchain","langgraph","llm","nextjs","open-source","react","reactjs","ts","typescript"],"default_branch":"main","size_kb":646469,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:copilotkit:copilotkit","source_url":"https://github.com/copilotkit/copilotkit"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:ag-ui-protocol:ag-ui\"","source_url":"https://github.com/ag-ui-protocol/ag-ui\""},{"type":"has_code","target_id":"github:CopilotKit:CopilotKit","source_url":"https://github.com/CopilotKit/CopilotKit"}]', NULL, 'MIT', 'approved', 65, 'aa39aaefc1ebfd6d49208e06541dd3ea', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-CopilotKit-CopilotKit from https://github.com/CopilotKit.png
Image converted to WebP: data/images/github-CopilotKit-CopilotKit.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-go-kratos-kratos', 'github--go-kratos--kratos', 'kratos', 'go-kratos', '<p align="center"><a href="https://go-kratos.dev/" target="_blank"><img src="https://github.com/go-kratos/kratos/blob/main/docs/images/kratos-large.png?raw=true"></a></p> <p align="center"> <a href="https://github.com/go-kratos/kratos/actions"><img src="https://github.com/go-kratos/kratos/workflows/Go/badge.svg" alt="Build Status"></a> <a href="https://pkg.go.dev/github.com/go-kratos/kratos/v2"><img src="https://pkg.go.dev/badge/github.com/go-kratos/kratos/v2" alt="GoDoc"></a> <a href="https:...', '["ai","architecture","cloud-native","framework","generate","go","golang","grpc","http","kratos","mcp","microservice","microservices","protobuf","go"]', 'other', 25175, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/go-kratos/kratos","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<p align="center"><a href="https://go-kratos.dev/" target="_blank"><img src="https://github.com/go-kratos/kratos/blob/main/docs/images/kratos-large.png?raw=true"></a></p>\n\n<p align="center">\n<a href="https://github.com/go-kratos/kratos/actions"><img src="https://github.com/go-kratos/kratos/workflows/Go/badge.svg" alt="Build Status"></a>\n<a href="https://pkg.go.dev/github.com/go-kratos/kratos/v2"><img src="https://pkg.go.dev/badge/github.com/go-kratos/kratos/v2" alt="GoDoc"></a>\n<a href="https://deepwiki.com/go-kratos/kratos"><img src="https://img.shields.io/badge/DeepWiki-go--kratos%2Fkratos-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==" alt="DeepWiki"></a>\n<!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ -->\n<a href="https://codecov.io/gh/go-kratos/kratos"><img src="https://codecov.io/gh/go-kratos/kratos/master/graph/badge.svg" alt="codeCov"></a>\n<a href="https://goreportcard.com/report/github.com/go-kratos/kratos"><img src="https://goreportcard.com/badge/github.com/go-kratos/kratos" alt="Go Report Card"></a>\n<a href="https://github.com/go-kratos/kratos/blob/main/LICENSE"><img src="https://img.shields.io/github/license/go-kratos/kratos" alt="License"></a>\n<a href="https://github.com/avelino/awesome-go"><img src="https://awesome.re/mentioned-badge.svg" alt="Awesome Go"></a>\n<a href="https://discord.gg/BWzJsUJ"><img src="https://img.shields.io/discord/766619759214854164?label=chat&logo=discord" alt="Discord"></a>\n</p>\n<p align="center">\n<a href="https://trendshift.io/repositories/3233" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3233" alt="go-kratos%2Fkratos | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>\n<a href="https://www.producthunt.com/posts/go-kratos?utm_source=badge-featured&utm_medium=badge&utm_souce=badge-go-kratos" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=306565&theme=light" alt="Go Kratos - A Go framework for microservices. | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>\n</p>\n\n##### Translate to: [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh.md)\n\n## About Kratos\n\n> The name is inspired by the Greek-mythology-based game "God of War". It tells the adventures of Kratos becoming a god of war from a mortal and launching a god-killing slaughter.\n\nKratos is a microservice-oriented governance framework implemented by golang, which offers convenient capabilities to help you quickly build a bulletproof application from scratch, such as:\n\n- The [communication protocol](https://go-kratos.dev/docs/component/api) is based on the HTTP/gRPC through the definition of Protobuf.\n- Abstract [transport](https://go-kratos.dev/docs/component/transport/overview) layer support: [HTTP](https://go-kratos.dev/docs/component/transport/http) / [gRPC](https://go-kratos.dev/docs/component/transport/grpc).\n- Powerful [middleware](https://go-kratos.dev/docs/component/middleware/overview) design, support: [Tracing (OpenTelemetry)](https://go-kratos.dev/docs/component/middleware/tracing), [Metrics (Prometheus is default)](https://go-kratos.dev/docs/component/middleware/metrics), [Recovery](https://go-kratos.dev/docs/component/middleware/recovery) and more.\n- [Registry](https://go-kratos.dev/docs/component/registry) interface able to be connected with various other centralized registries through plug-ins.\n- The [standard log interfaces](https://go-kratos.dev/docs/component/log) ease the integration of the third-party log libs with logs collected through the *Fluentd*.\n- Automatically support the selection of the content [encoding](https://go-kratos.dev/docs/component/encoding) with Accept and Content-Type.\n- Multiple data sources are supported for [configurations](https://go-kratos.dev/docs/component/config) and dynamic configurations (use atomic operations).\n- In the protocol of HTTP/gRPC, use the uniform [metadata](https://go-kratos.dev/docs/component/metadata) transfer method.\n- You can define [errors](https://go-kratos.dev/docs/component/errors/) in protos and generate enums with protoc-gen-go.\n- You can define [verification rules](https://go-kratos.dev/docs/component/middleware/validate) in Protobuf supported by the HTTP/gRPC service.\n- [Swagger API](https://go-kratos.dev/docs/guide/openapi) is generated Automatically and embed Swagger UI endpoint can be started by adding [Swagger plugin](https://github.com/go-kratos/swagger-api).\n\nKratos is accessible, powerful, and provides tools required for large, robust applications.\n\n## Learning Kratos\n\nKratos has the most extensive and thorough [documentation](https://go-kratos.dev/docs/getting-started/start) and [example](https://github.com/go-kratos/examples) library of all modern web application frameworks, making it a breeze to get started with the framework.\n\nWe also provide a [modern template](https://github.com/go-kratos/kratos-layout). This template should help reduce the work required to set up modern projects.\n\n### Goals\n\nKratos boosts your productivity. With the integration of excellent resources and further support, programmers can get rid of most issues might encounter in the field of distributed systems and software engineering such that they are allowed to focus on the release of businesses only. Additionally, for each programmer, Kratos is also an ideal one learning warehouse for many aspects of microservices to enrich their experiences and skills.\n\n### Principles\n\n* **Simple**: Appropriate design with plain and easy code.\n* **General**: Cover the various utilities for business development.\n* **Highly efficient**: Speeding up the efficiency of businesses upgrading.\n* **Stable**: The base libs validated in the production environment have the characteristics of high testability, high coverage as well as high security and reliability.\n* **Robust**: Eliminating misusing through high quality of the base libs.\n* **High-performance**: Optimal performance excluding the optimization of hacking in case of *unsafe*.¬†\n* **Expandability**: Properly designed interfaces where you can expand utilities such as base libs to meet your further requirements.\n* **Fault-tolerance**: Designed against failure, enhance the understanding and exercising of SRE within Kratos to achieve more robustness.\n* **Toolchain**: Includes an extensive toolchain, such as the code generation of cache, the lint tool, and so forth.\n\n## Getting Started\n\nCreate a kratos playground through [docker](https://www.docker.com/products/docker-desktop):\n\n```shell\ndocker run -it --rm -p 8000:8000 --workdir /workspace golang\n```\n\n```shell\napt-get update && apt-get -y install protobuf-compiler\nexport GOPROXY=https://goproxy.io,direct\ngo install github.com/go-kratos/kratos/cmd/kratos/v2@latest && kratos upgrade\n```\n\n```shell\nkratos new helloworld\ncd helloworld/ && go mod tidy\nkratos run\n```\n\nUse a browser to open and visit: `http://localhost:8000/helloworld/kratos`, The kratos program is running!\n\nIf you need more, please visit the kratos [documentation](https://go-kratos.dev/docs/getting-started/start).\n\n## Security Vulnerabilities\n\nIf you discover a security vulnerability within Kratos, please send an e-mail to tonybase via go-kratos@googlegroups.com. All security vulnerabilities will be promptly addressed.\n\n## Community\n\n- [Wechat Group](https://github.com/go-kratos/kratos/issues/682)\n- [Discord Group](https://discord.gg/BWzJsUJ)\n- [go-kratos.dev](https://go-kratos.dev/en)\n\n## Contributors\n\nThank you for considering contributing to the Kratos framework! The contribution guide can be found in the [Kratos documentation](https://go-kratos.dev/docs/community/contribution).\n\n<a href="https://github.com/go-kratos/kratos/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=go-kratos/kratos" />\n</a>\n\n## License\n\nThe Kratos framework is open-sourced software licensed under the [MIT license](./LICENSE).\n\n## Acknowledgments\n\nThe following project had particular influence on kratos''s design.\n\n- [go-kit/kit](https://github.com/go-kit/kit) is a programming toolkit for building microservices in go.\n- [asim/go-micro](https://github.com/asim/go-micro) a distributed systems development framework.\n- [google/go-cloud](https://github.com/google/go-cloud) is go cloud development kit.\n- [zeromicro/go-zero](https://github.com/zeromicro/go-zero) is a web and rpc framework with lots of builtin engineering practices.\n- [beego/beego](https://github.com/beego/beego) is a web framework including RESTful APIs, web apps and backend services.\n', '{"language":"Go","stars":25175,"forks":4127,"watchers":25175,"open_issues":80,"topics":["ai","architecture","cloud-native","framework","generate","go","golang","grpc","http","kratos","mcp","microservice","microservices","protobuf"],"default_branch":"main","size_kb":9458,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:avelino:awesome-go\"><img","source_url":"https://github.com/avelino/awesome-go\"><img"},{"type":"has_code","target_id":"github:go-kratos:swagger-api","source_url":"https://github.com/go-kratos/swagger-api"},{"type":"has_code","target_id":"github:go-kratos:examples","source_url":"https://github.com/go-kratos/examples"},{"type":"has_code","target_id":"github:go-kratos:kratos-layout","source_url":"https://github.com/go-kratos/kratos-layout"},{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:go-kratos:kratos","source_url":"https://github.com/go-kratos/kratos"},{"type":"has_code","target_id":"github:go-kit:kit","source_url":"https://github.com/go-kit/kit"},{"type":"has_code","target_id":"github:asim:go-micro","source_url":"https://github.com/asim/go-micro"},{"type":"has_code","target_id":"github:google:go-cloud","source_url":"https://github.com/google/go-cloud"},{"type":"has_code","target_id":"github:zeromicro:go-zero","source_url":"https://github.com/zeromicro/go-zero"},{"type":"has_code","target_id":"github:beego:beego","source_url":"https://github.com/beego/beego"}]', NULL, 'MIT', 'approved', 65, '7aa090bfa58d744374ae6e0ce6b22f6b', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-go-kratos-kratos from https://github.com/go-kratos.png
Image converted to WebP: data/images/github-go-kratos-kratos.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-chroma-core-chroma', 'github--chroma-core--chroma', 'chroma', 'chroma-core', '!Chroma !Chroma <p align="center"> <b>Chroma - the open-source embedding database</b>. <br /> The fastest way to build Python or JavaScript LLM apps with memory! </p> <p align="center"> <a href="https://discord.gg/MMeYNTmh3x" target="_blank"> <img src="https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600" alt="Discord"> </a> | <a href="https://github.com/chroma-core/chroma/blob/master/LICENSE" target="_blank"> <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg"...', '["ai","database","document-retrieval","embeddings","llm","llms","rag","rust","rust-lang","vector-database","rust"]', 'other', 24802, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/chroma-core/chroma","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '![Chroma](./docs/docs.trychroma.com/public/chroma-wordmark-color.png#gh-light-mode-only)\n![Chroma](./docs/docs.trychroma.com/public/chroma-wordmark-white.png#gh-dark-mode-only)\n\n<p align="center">\n    <b>Chroma - the open-source embedding database</b>. <br />\n    The fastest way to build Python or JavaScript LLM apps with memory!\n</p>\n\n<p align="center">\n  <a href="https://discord.gg/MMeYNTmh3x" target="_blank">\n      <img src="https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600" alt="Discord">\n  </a> |\n  <a href="https://github.com/chroma-core/chroma/blob/master/LICENSE" target="_blank">\n      <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="License">\n  </a> |\n  <a href="https://docs.trychroma.com/" target="_blank">\n      Docs\n  </a> |\n  <a href="https://www.trychroma.com/" target="_blank">\n      Homepage\n  </a>\n</p>\n\n```bash\npip install chromadb # python client\n# for javascript, npm install chromadb!\n# for client-server mode, chroma run --path /chroma_db_path\n```\n\n## Chroma Cloud\n\nOur hosted service, Chroma Cloud, powers serverless vector and full-text search. It''s extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.\n\n[Get started with Chroma Cloud](https://trychroma.com/signup)\n\n## API\n\nThe core API is only 4 functions (run our [üí° Google Colab](https://colab.research.google.com/drive/1QEzFyqnoFxq7LUGyP1vzR4iLt9PpCDXv?usp=sharing)):\n\n```python\nimport chromadb\n# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\nclient = chromadb.Client()\n\n# Create collection. get_collection, get_or_create_collection, delete_collection also available!\ncollection = client.create_collection("all-my-documents")\n\n# Add docs to the collection. Can also update and delete. Row-based API coming soon!\ncollection.add(\n    documents=["This is document1", "This is document2"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n    metadatas=[{"source": "notion"}, {"source": "google-docs"}], # filter on these!\n    ids=["doc1", "doc2"], # unique for each doc\n)\n\n# Query/search 2 most similar results. You can also .get by id\nresults = collection.query(\n    query_texts=["This is a query document"],\n    n_results=2,\n    # where={"metadata_field": "is_equal_to_this"}, # optional filter\n    # where_document={"$contains":"search_string"}  # optional filter\n)\n```\n\nLearn about all features on our [Docs](https://docs.trychroma.com)\n\n## Features\n- __Simple__: Fully-typed, fully-tested, fully-documented == happiness\n- __Integrations__: [`ü¶úÔ∏èüîó LangChain`](https://blog.langchain.dev/langchain-chroma/) (python and js), [`ü¶ô LlamaIndex`](https://twitter.com/atroyn/status/1628557389762007040) and more soon\n- __Dev, Test, Prod__: the same API that runs in your python notebook, scales to your cluster\n- __Feature-rich__: Queries, filtering, regex and more\n- __Free & Open Source__: Apache 2.0 Licensed\n\n## Use case: ChatGPT for ______\n\nFor example, the `"Chat your data"` use case:\n1. Add documents to your database. You can pass in your own embeddings, embedding function, or let Chroma embed them for you.\n2. Query relevant documents with natural language.\n3. Compose documents into the context window of an LLM like `GPT4` for additional summarization or analysis.\n\n## Embeddings?\n\nWhat are embeddings?\n\n- [Read the guide from OpenAI](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)\n- __Literal__: Embedding something turns it from image/text/audio into a list of numbers. üñºÔ∏è or üìÑ => `[1.2, 2.1, ....]`. This process makes documents "understandable" to a machine learning model.\n- __By analogy__: An embedding represents the essence of a document. This enables documents and queries with the same essence to be "near" each other and therefore easy to find.\n- __Technical__: An embedding is the latent-space position of a document at a layer of a deep neural network. For models trained specifically to embed data, this is the last layer.\n- __A small example__: If you search your photos for "famous bridge in San Francisco". By embedding this query and comparing it to the embeddings of your photos and their metadata - it should return photos of the Golden Gate Bridge.\n\nEmbeddings databases (also known as **vector databases**) store embeddings and allow you to search by nearest neighbors rather than by substrings like a traditional database. By default, Chroma uses [Sentence Transformers](https://docs.trychroma.com/guides/embeddings#default:-all-minilm-l6-v2) to embed for you but you can also use OpenAI embeddings, Cohere (multilingual) embeddings, or your own.\n\n## Get involved\n\nChroma is a rapidly developing project. We welcome PR contributors and ideas for how to improve the project.\n- [Join the conversation on Discord](https://discord.gg/MMeYNTmh3x) - `#contributing` channel\n- [Review the üõ£Ô∏è Roadmap and contribute your ideas](https://docs.trychroma.com/roadmap)\n- [Grab an issue and open a PR](https://github.com/chroma-core/chroma/issues) - [`Good first issue tag`](https://github.com/chroma-core/chroma/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n- [Read our contributing guide](https://docs.trychroma.com/contributing)\n\n**Release Cadence**\nWe currently release new tagged versions of the `pypi` and `npm` packages on Mondays. Hotfixes go out at any time during the week.\n\n## License\n\n[Apache 2.0](./LICENSE)\n', '{"language":"Rust","stars":24802,"forks":1955,"watchers":24802,"open_issues":509,"topics":["ai","database","document-retrieval","embeddings","llm","llms","rag","rust","rust-lang","vector-database"],"default_branch":"main","size_kb":860283,"archived":false,"fork":false,"has_wiki":true,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:chroma-core:chroma","source_url":"https://github.com/chroma-core/chroma"},{"type":"has_code","target_id":"github:chroma-core:chroma","source_url":"https://github.com/chroma-core/chroma"},{"type":"has_code","target_id":"github:chroma-core:chroma","source_url":"https://github.com/chroma-core/chroma"}]', NULL, 'Apache-2.0', 'approved', 65, '691bab8d4679777e8ccaffae4a4e08b7', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-chroma-core-chroma from https://github.com/chroma-core.png
Image converted to WebP: data/images/github-chroma-core-chroma.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-CodePhiliaX-Chat2DB', 'github--codephiliax--chat2db', 'Chat2DB', 'CodePhiliaX', '<div align="center"> <h2>üöÄ Zoer is Launching</h2> <p><strong>Powered by Chat2DB Team - AI-powered app builder that creates professional applications in minutes, no coding required</strong></p> <a href="https://zoer.ai/?utm_source=chat2db&utm_medium=banner&utm_campaign=github" target="_blank"> <img width="1000" height="auto" alt="Zoer - AI App Builder" src="https://github.com/user-attachments/assets/2f2a682d-9cc0-4470-93d3-19b4f1f6589e" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0...', '["ai","bi","chatgpt","clickhouse","clickhouse-client","database","datagrip","db2","dbeaver","gpt","hive","mysql","navicat","oracle","postgresql","redis","redis-client","sqlserver","text2sql","java"]', 'other', 24779, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/CodePhiliaX/Chat2DB","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<div align="center">\n  <h2>üöÄ Zoer is Launching</h2>\n  <p><strong>Powered by Chat2DB Team - AI-powered app builder that creates professional applications in minutes, no coding required</strong></p>\n  \n  <a href="https://zoer.ai/?utm_source=chat2db&utm_medium=banner&utm_campaign=github" target="_blank">\n    <img width="1000" height="auto" alt="Zoer - AI App Builder" src="https://github.com/user-attachments/assets/2f2a682d-9cc0-4470-93d3-19b4f1f6589e" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" />\n  </a>\n  \n  <br/><br/>\n  \n  ---\n  \n  <br/>\n  \n  <a href="https://trendshift.io/repositories/11808" target="_blank"><img src="https://trendshift.io/api/badge/repositories/11808" alt="CodePhiliaX%2FChat2DB | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/>\n  </a>\n</div>\n\n<div align="center">\n  \n[![ReadmeX][readmex-image]][readmex-url]\n[![Discord][discord-image]][discord-url]\n[![Twitter][twitter-image]][twitter-url]\n[![Telegram][telegram-image]][telegram-url]\n[![Whatsapp][whatsapp-image]][whatsapp-url]\n[![Reddit][reddit-image]][reddit-url]\n[![Gmail][gmail-image]][gmail-url]\n\n[readmex-image]: https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg\n[readmex-url]: https://readmex.com/CodePhiliaX/Chat2DB\n[discord-image]: https://img.shields.io/badge/-Join%20us%20on%20Discord-%237289DA.svg?style=flat&logo=discord&logoColor=white\n[discord-url]: https://discord.com/invite/uNjb3n5JVN\n[twitter-image]: https://img.shields.io/twitter/follow/_Chat2DB?label=Chat2DB\n[twitter-url]: https://twitter.com/intent/tweet?text=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.&url=https://github.com/chat2db/Chat2DB&hashtags=ChatGPT,AGI,SQL%20Client,Reporting%20tool\n[telegram-image]: https://img.shields.io/twitter/url?label=Telegram&logo=Telegram&style=social&url=https://github.com/chat2db/Chat2DB\n[telegram-url]: https://t.me/share/url?text=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.&url=https://github.com/chat2db/Chat2DB\n[whatsapp-image]: https://img.shields.io/twitter/url?label=whatsapp&logo=whatsapp&style=social&url=https://github.com/chat2db/Chat2DB\n[whatsapp-url]: https://api.whatsapp.com/send?text=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.%20https://github.com/chat2db/Chat2DB\n[reddit-image]: https://img.shields.io/twitter/url?label=Reddit&logo=Reddit&style=social&url=https://github.com/chat2db/Chat2DB\n[reddit-url]: https://www.reddit.com/submit?url=https://github.com/chat2db/Chat2DB&title=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.\n[gmail-image]: https://img.shields.io/twitter/url?label=Gmail&logo=Gmail&style=social&url=https://github.com/chat2db/Chat2DB\n[gmail-url]: mailto:?subject=Check%20this%20GitHub%20repository%20out.&body=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.%3A%0Ahttps://github.com/chat2db/Chat2DB\n\n</div>\n\n<div align="center">\n  <a href="./README.md"><img alt="README in English" src="https://img.shields.io/badge/English-d9d9d9"></a>\n  <a href="./README_CN.md"><img alt="ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂" src="https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-d9d9d9"></a>\n  <a href="./README_JA.md"><img alt="Êó•Êú¨Ë™û„ÅÆREADME" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9"></a>\n\n</div>\n\n**1. Intelligent SQL Generation**:  \nChat2DB Pro supports AI-driven intelligent SQL development to help you write SQL queries faster.\n\n**2. Database Management**:  \nSupports more than 10 databases, including MySQL, PostgreSQL, H2, Oracle, SQLServer, SQLite, MariaDB, ClickHouse, DM, Presto, DB2, OceanBase, Hive, KingBase, MongoDB, Redis, Snowflake, and more.\n\n**3. Intelligent Report Generation**:  \nChat2DB Pro supports AI-driven intelligent data reporting to help you generate dashboards faster.\n\n**4. Data Structure Synchronization**:  \nChat2DB Pro supports database table structure synchronization to help you sync database table structures faster.\n\n## Feature Comparison\n\n<table style="width: 100%;">\n  <tr>\n    <th align="center">Feature</th>\n    <th align="center">Community Open Source</th>\n    <th align="center">Local</th>\n    <th align="center">Pro </th>\n  </tr>\n  <tr>\n    <td align="center">Database Types</td>\n    <td align="center">16+</td>\n    <td align="center">Target 100+</td>\n    <td align="center">Target 100+</td>\n  </tr>\n  <tr>\n    <td align="center">Supported AI</td>\n    <td align="center">Requires AI Configuration</td>\n    <td align="center">AI ready on installation</td>\n    <td align="center">AI ready on installation</td>\n  </tr>\n  <tr>\n    <td align="center">AI Capabilities</td>\n    <td align="center">Basic</td>\n    <td align="center">Varied</td>\n    <td align="center">Varied</td>\n  </tr>\n  <tr>\n    <td align="center">Visual Table Editor</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">SQL Console</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">SQL Formatting</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Save Query Records</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Theme Color Settings</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Data Structure Sync</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Database Grouping</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Database Structure Import/Export</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Data Import/Export</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Data Migration</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Copy/Clear Table</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Open and Run SQL Files</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">UML Diagram</td>\n    <td align="center">‚ùå</td>\n    <td align="center">In Development</td>\n    <td align="center">In Development</td>\n  </tr>\n  <tr>\n    <td align="center">Generate Code</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Copy Results as Insert/Update</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Modify Query Results</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Intelligent SQL Editor</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">AI Table Creation</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">AI Data Sets</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Chat2Excel</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Intelligent Dashboard</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Editor Settings</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Custom Shortcuts</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n  <tr>\n    <td align="center">Cross-device Usage</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚ùå</td>\n    <td align="center">‚úÖ</td>\n  </tr>\n</table>\n\n## Download and Installation\nChat2DB is a cross-platform application that supports Windows, MacOS, and Linux. You can download Chat2DB from the following links:\n- [Download Pro Version](https://chat2db.ai/download)\n- [Download Local Version](https://chat2db.ai/download)\n- [Download Open Source Version](https://github.com/CodePhiliaX/Chat2DB/releases/tag/v0.3.6)\n\n## Community Edition Docker Installation\n\n### System Requirements\n\nBefore installing Chat2DB, ensure your system meets the following requirements:\n- Docker 19.03.0 or later\n- Docker Compose 1.25.0 or later\n- CPU >= 2 Cores\n- RAM >= 4 GiB\n\n```bash\n  docker rm chat2db\n  \n  docker run --name=chat2db -ti -p 10824:10824 -v ~/.chat2db-docker:/root/.chat2db  chat2db/chat2db:latest\n\n  docker start chat2db\n  \n```\n## Code Debugging\n\n## Runtime Environment\n\nNote:\nIf local debugging is needed:\n\n- Java runtime: <a href="https://adoptopenjdk.net/" target="_blank">Open JDK 17</a>\n- Node.js runtime: Node 16 <a href="https://nodejs.org/" target="_blank">Node.js</a>.\n\n**Clone the repository locally**\n\n```bash\n$ git clone git@github.com:chat2db/Chat2DB.git\n```\n\n**Frontend Debugging**\n\n```bash\nNode version must be 16 or higher  \nUse yarn only, npm is not supported\n$ cd Chat2DB/chat2db-client\n$ yarn\n$ yarn run start:web\n```\n\n**Backend Debugging**\n\n```bash\n$ cd ../chat2db-server\n$ mvn clean install # Maven version 3.8 or higher is required\n$ cd chat2db-server/chat2db-server-start/target/\n$ java -jar -Dloader.path=./lib -Dchatgpt.apiKey=xxxxx chat2db-server-start.jar  # ÈúÄË¶ÅÂÆâË£Öjava 17‰ª•‰∏äÁâàÊú¨ÔºåÂêØÂä®Â∫îÁî® chatgpt.apiKey ÈúÄË¶ÅËæìÂÖ•ChatGPTÁöÑkey,Â¶ÇÊûú‰∏çËæìÂÖ•Êó†Ê≥ï‰ΩøÁî®AIGCÂäüËÉΩ\n```\n**Standalone Deployment**\n```bash\n# chat2db-client\n$ npm run build:web:prod \n$ cp -r dist ../chat2db-server/chat2db-server-start/src/main/resources/static/front \n$ cp -r dist/index.html ../chat2db-server/chat2db-server-start/src/main/resources/thymeleaf\n```\n\n##  Contact Us\n\n- Email: Chat2DB@ch2db.com\n- Discord: [Join our Discord server](https://discord.gg/JDkwB6JS8A)\n- Twitter: [@Chat2DB](https://x.com/Chat2DB_AI)\n- YouTube: [Chat2DB Channel](https://www.youtube.com/@chat2db.tutorial)\n- GitHub: [Chat2DB GitHub](https://github.com/codePhiliaX/chat2db)\n\n\n##  Acknowledgments\n\n\nThanks to everyone who has contributed to Chat2DB~~\n\n\n<a href="https://github.com/chat2db/Chat2DB/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=chat2db/Chat2DB" />\n</a>\n\n## Star History\n\n<a href="https://star-history.com/#CodePhiliaX/chat2db&Date">\n  <picture>\n    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=CodePhiliaX/chat2db&type=Date&theme=dark" />\n    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=CodePhiliaX/chat2db&type=Date" />\n    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=CodePhiliaX/chat2db&type=Date" />\n  </picture>\n</a>\n\n## License\nThe primary license used by this software is the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0), supplemented by the [Chat2DB License](./Chat2DB_LICENSE).\n\n', '{"language":"Java","stars":24779,"forks":2702,"watchers":24779,"open_issues":500,"topics":["ai","bi","chatgpt","clickhouse","clickhouse-client","database","datagrip","db2","dbeaver","gpt","hive","mysql","navicat","oracle","postgresql","redis","redis-client","sqlserver","text2sql"],"default_branch":"main","size_kb":18843,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:chat2db:Chat2DB&hashtags=ChatGPT,AGI,SQL%20Client,Reporting%20tool","source_url":"https://github.com/chat2db/Chat2DB&hashtags=ChatGPT,AGI,SQL%20Client,Reporting%20tool"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB&title=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities.","source_url":"https://github.com/chat2db/Chat2DB&title=Chat2DB-An%20intelligent%20and%20versatile%20general-purpose%20SQL%20client%20and%20reporting%20tool%20for%20databases%20which%20integrates%20ChatGPT%20capabilities."},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"},{"type":"has_code","target_id":"github:CodePhiliaX:Chat2DB","source_url":"https://github.com/CodePhiliaX/Chat2DB"},{"type":"has_code","target_id":"github:codePhiliaX:chat2db","source_url":"https://github.com/codePhiliaX/chat2db"},{"type":"has_code","target_id":"github:chat2db:Chat2DB","source_url":"https://github.com/chat2db/Chat2DB"}]', NULL, 'Apache-2.0', 'approved', 80, 'e9244607d6ab91594f567514405e8f88', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-CodePhiliaX-Chat2DB from https://github.com/CodePhiliaX.png
Image converted to WebP: data/images/github-CodePhiliaX-Chat2DB.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-e2b-dev-awesome-ai-agents', 'github--e2b-dev--awesome-ai-agents', 'awesome-ai-agents', 'e2b-dev', '<!-- TBD: - Add to visual: - LLM Stack - Promptly - Devon - vortic ai - UFO - GPT Swarm - Eidolon - NexusGPT - Brain Soup - L2MAC Add to readme list: - Codeium - tinybio - Semantix AI Agents - add when they have english version - NoteWizard - only if it''s AI agent - TBD test - Postbot (TBD - check more) --> <h1 align="center"> üîÆ Awesome AI Agents <p align="center"> <a href="https://discord.gg/U7KEcGErtQ" target="_blank"> <img src="https://img.shields.io/static/v1?label=Join&message=%20discor...', '["agent","ai","artificial-intelligence","autogpt","autonomous-agents","awesome","babyagi","copilot","gpt","gpt-4","gpt-engineer","openai","python"]', 'other', 24527, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/e2b-dev/awesome-ai-agents","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<!--\nTBD:\n- Add to visual:\n\n- LLM Stack\n- Promptly\n- Devon\n- vortic ai\n- UFO\n- GPT Swarm\n- Eidolon\n- NexusGPT\n- Brain Soup\n- L2MAC\n\n\nAdd to readme list:\n- Codeium\n- tinybio\n- Semantix AI Agents - add when they have english version\n- NoteWizard - only if it''s AI agent - TBD test\n- Postbot (TBD - check more)\n	-->\n\n<h1 align="center">\n	üîÆ Awesome AI Agents\n	<p align="center">\n		<a href="https://discord.gg/U7KEcGErtQ" target="_blank">\n			<img src="https://img.shields.io/static/v1?label=Join&message=%20discord!&color=mediumslateblue">\n		</a>\n		<a href="https://twitter.com/e2b" target="_blank">\n			<img src="https://img.shields.io/twitter/follow/e2b.svg?logo=twitter">\n		</a>\n	</p>\n</h1>\n<h3 align="center">\n  Add <a href="https://e2b.dev/docs?ref=awesome-sdks">Code Interpreter</a> to your AI App\n</h3>\n\n<h5 align="center">üåü <a href="https://e2b.dev/ai-agents">See this list in web UI</a></h5>\n<h5 align="center">üëâ <a href="https://forms.gle/UXQFCogLYrPFvfoUA">Submit new product here</a></h5>\n\n<img src="assets/landscape-latest.png" width="100%" alt="Chart of AI Agents Landscape" />\n\nWelcome to our list of AI agents.\nWe structured the list into two parts:\n- [Open source projects](#open-source-projects)\n- [Closed-source projects and companies](#closed-source-projects-and-companies)\n  \nTo filter the products by categories and use-cases, see the üåü [web version of this list](https://e2b.dev/ai-agents). üåü\n\nThe list is done according to our best knowledge, although definitely not comprehensive. Check out also <a href="https://github.com/e2b-dev/awesome-sdks-for-ai-agents">the Awesome List of SDKs for AI Agents</a>.\nDiscussion and feedback appreciated! :heart:\n\n## Have anything to add?\nCreate a pull request or fill in this [form](https://forms.gle/UXQFCogLYrPFvfoUA). Please keep the alphabetical order and in the correct category.\n\nFor adding AI agents''-related SDKs, frameworks and tools, please visit [Awesome SDKs for AI Agents](https://github.com/e2b-dev/awesome-sdks-for-ai-agents). This list is only for AI assistants and agents.\n\n<!---\n## Who''s behind this?\nThis list is made by the team behind [e2b](https://github.com/e2b-dev/e2b). E2b is building AWS for AI agents. We help developers to deploy, test, and monitor AI agents. E2b is agnostic to your tech stack and aims to work with any tooling for building AI agents.\n--->\n\n## Check out E2B - Code Interpreting for AI apps\n- Check out [Code Interpreter SDK](https://e2b.dev/docs?ref=awesome-sdk)\n- Explore examples in [E2B Cookbook](https://github.com/e2b-dev/e2b-cookbook)\n- Read our [docs](https://e2b.dev/docs?ref=awesome-sdks)\n- Contact us at [hello@e2b.dev](mailto:hello@e2b.dev) or [on Discord](https://discord.gg/35NF4Y8WSE). Follow us on [X (Twitter)](https://twitter.com/e2b)\n\n# Open-source projects\n\n## [Adala](https://github.com/HumanSignal/Adala)\nAdala: Autonomous Data (Labeling) Agent framework\n\n<details>\n\n![Image](https://github.com/HumanSignal/Adala/raw/master/docs/src/img/logo-dark-mode.png)\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n\n- **Reliable agents**: Built on ground truth data for consistent, trustworthy results.\n- **Controllable output**: Tailor output with flexible constraints to fit your needs.\n- **Specialized in data processing**: Agents excel in custom data labeling and processing tasks.\n- **Autonomous learning**: Agents evolve through observations and reflections, not just automation.\n- **Flexible and extensible runtime**: Adaptable framework with community-driven evolution for diverse needs.\n- **Easily customizable**: Develop agents swiftly for unique challenges, no steep learning curve.\n\n### Links\n- [Documentation](https://humansignal.github.io/Adala/) \n- [Discord](https://discord.gg/QBtgTbXTgU)\n- [GitHub](https://github.com/HumanSignal/Adala)\n</details>\n\n## [Agent4Rec](https://github.com/LehengTHU/Agent4Rec)\nRecommender system simulator with 1,000 agents\n\n<details>\n<p><img src="https://github.com/LehengTHU/Agent4Rec/raw/master/assets/sandbox.png" alt="Image" /></p>\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n- Agent4Rec is a recommender system simulator that utilizes 1,000 LLM-empowered generative agents.\n- These agents are initialized from the [MovieLens-1M](https://grouplens.org/datasets/movielens/1m/) dataset, embodying varied social traits and preferences.\n- Each agent interacts with personalized movie recommendations in a page-by-page manner and undertakes various actions such as watching, rating, evaluating, exiting, and interviewing. \n\n### Links\n- [Paper](https://arxiv.org/abs/2310.10108)\n\n</details>\n\n## [AgentForge](https://github.com/DataBassGit/AgentForge)\nLLM-agnostic platform for agent building & testing\n\n<details>\n\n![Image](https://pbs.twimg.com/profile_images/1667167265060528129/l8S9vtP2_400x400.jpg)\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n- A low-code framework designed for the swift creation, testing, and iteration of AI-powered autonomous agents and Cognitive Architectures, compatible with various LLM models.\n- Facilitates building custom agents and cognitive architectures with ease.\n- Supports multiple LLM models including OpenAI, Anthropic''s Claude, and local Oobabooga, allowing flexibility in running different models for different agents based on specific requirements.\n- Provides customizable agent memory management and on-the-fly prompt editing for rapid development and testing.\n- Comes with a database-agnostic design ensuring seamless extensibility, with straightforward integration with different databases like ChromaDB for various AI projects.\n\n### Links\n- [GitHub](https://github.com/DataBassGit/AgentForge)\n- [Web](https://www.agentforge.net/)\n- [Discord](https://discord.com/invite/ttpXHUtCW6)\n- [X](https://twitter.com/AgentForge)\n\n</details>\n\n## [AgentGPT](https://agentgpt.reworkd.ai/)\nBrowser-based no-code version of AutoGPT\n<details>\n\n![Image](https://raw.githubusercontent.com/reworkd/AgentGPT/main/next/public/banner.png)\n\n\n### Category\nGeneral purpose\n\n### Description\n- A no-code platform\n- Process:\n	- Assigning a goal to the agent\n	- Witnessing its thinking process\n	- Formulation of an execution plan\n	- Taking actions accordingly\n- Uses OpenAI functions\n- Supports gpt-3.5-16k, pinecone and pg_vector databases\n- Stack\n	- Frontend: NextJS + Typescript\n	- Backend: FastAPI + Python\n	- DB: MySQL through docker with the option of running SQLite locally\n\n<!--\n### Features\n- Uses OpenAI **functions**\n- Supports gpt-3.5-16k, pinecone and pg_vector databases\n\n### Stack\n- Frontend: NextJS + Typescript\n- Backend: FastAPI + Python\n	- DB: MySQL through docker with the option of running SQLite locally\n	-->\n\n### Links\n- [Documentation](https://docs.reworkd.ai/)\n- [Website](https://agentgpt.reworkd.ai/)\n- [GitHub](https://github.com/reworkd/AgentGPT)\n</details>\n\n<!-- This is a comment that appears only in the raw text -->\n\n## [AgentPilot](https://github.com/jbexta/AgentPilot)\nBuild, manage, and chat with agents in desktop app\n\n\n<details>\n\n![Image](https://github.com/jbexta/AgentPilot/raw/master/docs/demo.png)\n\n### Category\nGeneral purpose\n\n### Description\n\n- Integrated into Open Interpreter and MemGPT\n- Group chats feature\n\n\n\n### Links\n- [GitHub](https://github.com/jbexta/AgentPilot)\n- [X ](https://twitter.com/AgentPilotAI)\n- \n  \n</details>\n\n## [Agents](https://github.com/aiwaves-cn/agents)\n\nLibrary/framework for building language agents\n\n<details>\n\n![Image](https://github.com/aiwaves-cn/agents/raw/master/assets/agents-logo.png)\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n-   **Long-short Term Memory**: Language agents in the library are equipped with both long-term memory implemented via VectorDB + Semantic Search and short-term memory (working memory) maintained and updated by an LLM.\n-   **Tool Usage**: Language agents in the library can use any external tools via  [function-calling](https://platform.openai.com/docs/guides/gpt/function-calling)  and developers can add customized tools/APIs  [here](https://github.com/aiwaves-cn/agents/blob/master/src/agents/Component/ToolComponent.py).\n-   **Web Navigation**: Language agents in the library can use search engines to navigate the web and get useful information.\n-   **Multi-agent Communication**: In addition to single language agents, the library supports building multi-agent systems in which language agents can communicate with other language agents and the environment. Different from most existing frameworks for multi-agent systems that use pre-defined rules to control the order for agents'' action,  **Agents**  includes a  _controller_  function that dynamically decides which agent will perform the next action using an LLM by considering the previous actions, the environment, and the target of the current states. This makes multi-agent communication more flexible.\n-   **Human-Agent interaction**: In addition to letting language agents communicate with each other in an environment, our framework seamlessly supports human users to play the role of the agent by himself/herself and input his/her own actions, and interact with other language agents in the environment.\n-   **Symbolic Control**: Different from existing frameworks for language agents that only use a simple task description to control the entire multi-agent system over the whole task completion process,  **Agents**  allows users to use an  **SOP (Standard Operation Process)**  that defines subgoals/subtasks for the overall task to customize fine-grained workflows for the language agents.\n\n### Links\n- Author: [AIWaves Inc.](https:github.com/aiwaves-cn)\n- [Paper](https://arxiv.org/pdf/2309.07870.pdf)\n- [GitHub Repository](https://github.com/aiwaves-cn/agents)\n- [Documentation](https://agents-readthedocsio.readthedocs.io/en/latest/index.html)\n- [Tweet](https://twitter.com/wangchunshu/status/1702512370785100133)\n</details>\n\n## [AgentVerse](https://github.com/OpenBMB/AgentVerse)\nPlatform for task-solving & simulation agents\n<details>\n\n![Image](https://pbs.twimg.com/card_img/1744672970822615040/m870GGf1?format=jpg&name=medium)\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n- Assembles multiple agents to collaboratively accomplish tasks.\n- Allows custom environments for observing or interacting with multiple agents.\n\n### Links\n- Paper: [AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors](https://arxiv.org/abs/2308.10848)\n- [Twitter](https://twitter.com/Agentverse71134)\n- [Discord](https://discord.gg/gDAXfjMw)\n- [Hugging Face](https://huggingface.co/spaces/AgentVerse/agentVerse)\n\n</details>\n\n## [AI Legion](https://github.com/eumemic/ai-legion)\nMulti-agent TS platform, similar to AutoGPT\n\n<details>\n\n![Image](https://res.cloudinary.com/apideck/image/upload/w_1500,f_auto/v1681330426/marketplaces/ckhg56iu1mkpc0b66vj7fsj3o/listings/ai-legion/screenshots/Screenshot_2023-04-12_at_22.13.24_d9kdoj.png)\n\n### Category\nMulti-agent, Build-your-own\n\n\n### Description\n- An LLM-powered autonomous agent platform\n- A framework for autonomous agents who can work together to accomplish tasks\n- Interaction with agents done via console direct messages\n\n### Links\n- Author: [eumemic](https://github.com/eumemic)\n- [Website](https://gpt3demo.com/apps/ai-legion)\n- [GitHub](https://github.com/eumemic/ai-legion)\n- [Twitter](https://twitter.com/dysmemic)\n</details>\n\n## [Aider](https://github.com/paul-gauthier/aider)\nUse command line to edit code in your local repo\n\n<details>\n\n\n![Image](https://repository-images.githubusercontent.com/638629097/1d3d6251-f8be-4d11-bbb1-4e44b7364b74)\n\n### Category\nCoding, GitHub\n\n### Description\n- Aider is a command line tool that lets you pair program with GPT-3.5/GPT-4, to edit code stored in your local git repository\n- You can start a new project or work with an existing repo. And you can fluidly switch back and forth between the aider chat where you ask GPT to edit the code and your own editor to make changes yourself\n- Aider makes sure edits from you and GPT are committed to git with sensible commit messages. Aider is unique in that it works well with pre-existing, larger codebases\n\n### Links  \n- [Website](https://aider.chat/)\n- Author: [Paul Gauthier](https://github.com/paul-gauthier) (Github)\n- [Discord Invite](https://discord.com/invite/Tv2uQnR88V)\n\n</details>\n\n## [AIlice](https://github.com/myshell-ai/AIlice)\nCreate agents-calling tree to execute your tasks\n<details>\n\n![Image](https://github.com/myshell-ai/AIlice/raw/master/AIlice.png)\n\n### Category\nGeneral purpose, Personal assistant, Productivity\n\n### Description\n- "An Agent in the form of a chatbot independently plans tasks given in natural language and dynamically creates an agents calling tree to execute tasks.\n- There is an interaction mechanism between agents to ensure fault tolerance.\n- External interaction modules can be automatically built for self-expansion.\n\n### Links  \n- [GitHub](https://github.com/myshell-ai/AIlice)\n\n</details>\n\n## [AutoGen](https://github.com/microsoft/autogen)\nMulti-agent framework with diversity of agents\n<details>\n\n![Image](https://github.com/microsoft/autogen/raw/main/website/static/img/autogen_agentchat.png)\n\n### Category\nGeneral purpose, Build your own, Multi-agent\n\n### Description\n- A framework for developing LLM (Large Language Model) applications with multiple conversational agents.\n- These agents can collaborate to solve tasks and can interact seamlessly with humans.\n- It simplifies complex LLM workflows, enhancing automation and optimization.\n- It offers a range of working systems across various domains and complexities.\n- It improves LLM inference with easy performance tuning and utility features like API unification and caching.\n- It supports advanced usage patterns, including error handling, multi-config inference, and context programming.\n\n### Links\n- Paper: [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://arxiv.org/pdf/2308.08155.pdf)\n- [Discord](https://discord.gg/pAbnFJrkgZ)\n- [Twitter thread describing the system](https://twitter.com/pyautogen)\n\n\n</details>\n\n## [AutoGPT](https://agpt.co/?utm_source=awesome-ai-agents)\nExperimental attempt to make GPT4 fully autonomous\n\n<details>\n\n![Image](https://news.agpt.co/wp-content/uploads/2023/04/Logo_-_Auto_GPT-B-800x363.png)\n\n### Category\nGeneral purpose\n\n### Description\n- An experimental open-source attempt to make GPT-4 fully autonomous, with >140k stars on GitHub\n- Chains together LLM "thoughts", to autonomously achieve whatever goal you set\n- Internet access for searches and information gathering\n- Long-term and short-term memory management\n- Can execute many commands such as Google Search, browse websites, write to files, and execute Python files and much more\n- GPT-4 instances for text generation\n- Access to popular websites and platforms\n- File storage and summarization with GPT-3.5\n- Extensibility with Plugins\n- "A lot like BabyAGI combined with LangChain tools"\n- Features added in release 0.4.0\n	- File reading\n	- Commands customization\n	- Enhanced testing\n\n<!--\n### Features added in release 0.4.0\n- File reading\n- Commands customization\n- Enhanced testing\n-->\n\n### Links\n- [Twitter](https://twitter.com/Auto_GPT/?utm_source=awesome-ai-agents)\n- [GitHub](https://github.com/Significant-Gravitas/Auto-GPT/?utm_source=awesome-ai-agents)\n- [Facebook](https://www.facebook.com/groups/1330282574368178/?utm_source=awesome-ai-agents)\n- [Linkedin](https://www.linkedin.com/company/autogpt/?utm_source=awesome-ai-agents)\n- [Discord](https://discord.gg/autogpt/?utm_source=awesome-ai-agents)\n- Author: [Significant Gravitas](https://twitter.com/SigGravitas/?utm_source=awesome-ai-agents)\n</details>\n\n\n\n## [Automata](https://github.com/emrgnt-cmplxty/automata)\nGenerate code based on your project context\n\n<details>\n\n\n![Image](https://github.com/emrgnt-cmplxty/Automata/assets/68796651/61fe3c33-9b7a-4c1b-9726-a77140476b83)\n\n### Category\nCoding\n\n### Description\n- Model: GPT 4\n- Automata takes your project as a context, receives tasks, and executes the instructions seamlessly.\n- Features\n	- Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.\n	- It''s designed for seamless integration with all available agent platforms and LLM providers.\n	- Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.\n	- Modular, fully configurable design with minimal reliance on external dependencies\n\n### Links\n- [GitHub](https://github.com/emrgnt-cmplxty/automata)\n- [Docs](https://automata.readthedocs.io/en/latest/)\n- Author: [Owen Colegrove](https://twitter.com/ocolegro)\n<!--\n\n### Features\n- Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.\n- It''s designed for seamless integration with all available agent platforms and LLM providers.\n- Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.\n- Modular, fully configurable design with minimal reliance on external dependencies.\n\n-->\n\n</details>\n\n## [AutoPR](https://github.com/irgolic/AutoPR)\nAI-generated pull requests agent that fixes issues\n\n<details>\n\n![Image](https://github.com/irgolic/AutoPR/raw/main/website/static/img/AutoPR_Mark_color.png)\n\n### Category\nCoding, GitHub\n\n### Description\n- Triggered by adding a label containing AutoPR to an issue, AutoPR will:\n	- Plan a fix\n	- Write the code\n	- Push a branch\n	- Open a pull request\n\n### Links\n- [Discord](https://discord.com/invite/ykk7Znt3K6)\n\n</details>\n\n## [Autonomous HR Chatbot](https://github.com/stepanogil/autonomous-hr-chatbot)\nAgent that answers HR-related queries using tools\n\n<details>\n\n![Image](https://github.com/stepanogil/autonomous-hr-chatbot/raw/main/assets/sample_chat.png)\n\n### Category\nHR, Business intelligence, Productivity\n\n### Description\n- A prototype enterprise application - an Autonomous HR Assistant powered by GPT-3.5.\n- An agent that can answer HR related queries autonomously using the tools it has on hand.\n- Powered by GPT-3.5\n- Current tools assigned to the agent (with more on the way):\n	- Timekeeping Policy\n	- Employee Data\n	- Calculator\n\n### Links\n- Medium: [Creating a (mostly) Autonomous HR Assistant with ChatGPT and LangChain‚Äôs Agents and Tools](https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef)\n- [GitHub](https://github.com/stepanogil/autonomous-hr-chatbot)\n- Author: [Stephen Bonifacio](https://twitter.com/Stepanogil)\n- [YouTube demo](https://www.youtube.com/watch?v=id7XRcEIBvg&ab_channel=StephenBonifacio)\n- [Blog post](https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef)\n</details>\n\n## [BabyAGI](https://github.com/yoheinakajima/babyagi)\nA simple framework for managing tasks using AI\n<details>\n\n![Image](https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png)\n\n### Category\nGeneral purpose\n\n### Description\n- A pared-down version of the original [Task-Driven Autonomous Agent](https://twitter.com/yoheinakajima/status/1640934493489070080?s=20)\n- Creates tasks based on the result of previous tasks and a predefined objective.\n- The script then uses OpenAI''s NLP capabilities to create new tasks based on the objective\n- Leverages OpenAI''s GPT-4, pinecone vector search, and LangChainAI framework\n- Default model is OpenAI GPT3-turbo\n- The system maintains a task list for managing and prioritizing tasks\n- It autonomously creates new tasks based on completed results and reprioritizes the task list accordingly, showcasing the adaptability of AI-powered language models\n\n\n### Links\n- Paper: [Task-driven Autonomous Agent Utilizing GPT-4, Pinecone, and LangChain for Diverse Applications](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)\n- [Discord](https://discord.com/invite/TMUw26XUcg)\n- [Founder''s Twitter](https://twitter.com/yoheinakajima)\n- [Twitter thread describing the system](https://twitter.com/yoheinakajima/status/1640934493489070080)\n\n\n</details>\n\n\n## [BabyBeeAGI](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)\nTask management & functionality BabyAGI expansion\n\n<details>\n\n![Image](https://yoheinakajima.com/wp-content/uploads/2023/04/image.png)\n\n### Category\nGeneral purpose, Productivity\n\n### Description\n- A more advanced version of the original BabyAGI code\n- - Improves upon the original framework, by introducing a more complex task management prompt, allowing for more comprehensive analysis and synthesis of information\n- Designed to handle multiple functions within one task management prompt\n- Built on top of the GPT-4 architecture, resulting in slower processing speeds and occasional errors\n- Provides a framework that can be further built upon and improved, paving the way for more sophisticated AI applications\n- One of the significant differences between BabyAGI and BabyBeeAGI is the complexity of the task management prompt\n\n### Links\n- [Tweet](https://twitter.com/yoheinakajima/status/1652732735344246784)\n- [GitHub](https://github.com/yoheinakajima/babyagi/blob/main/classic/BabyBeeAGI.py)\n- [Replit](https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1)\n- Author: [@yoheinakajima](https://twitter.com/yoheinakajima) (Twitter)\n\n</details>\n\n\n## [BabyCatAGI](https://replit.com/@YoheiNakajima/BabyCatAGI)\nBabyCatAGI is a mod of BabyBeeAGI\n<details>\n\n![Image](https://pbs.twimg.com/media/FwBwoRracAI99iP?format=jpg&name=medium)\n\n### Category\nGeneral purpose\n\n### Description\n- Just 300 lines of code\n- This was built as a d iteration on the original BabyAGI code in a lightweight way. Differences to BabyAGI include the following:\n	- Task Creation Agent runs once\n	- Execution Agent loops through tasks\n	- Task dependencies for pulling relevant results\n	- Two tools: search tool and text completion\n	- ‚ÄúMini-agent‚Äù as tool\n	- Search tool combines search, scrape, chunking, and extraction.\n	- Results combined to create summary report\n\n\n<!--\n### How to use\n- Fork this into a private Repl\n- Add your OpenAI API Key (required) and SerpAPI Key (optional)\n- Update the OBJECTIVE variable\n- Press "Run" at the top.\n-->\n\n### Links\n- [Tweet](https://twitter.com/yoheinakajima/status/1657448504112091136)\n- [GitHub](https://github.com/yoheinakajima/babyagi/blob/main/classic/BabyCatAGI.py)\n- [Replit](https://replit.com/@YoheiNakajima/BabyCatAGI)\n- Author: [@yoheinakajima](https://twitter.com/yoheinakajima) (Twitter)\n\n</details>\n\n## [BabyDeerAGI](https://twitter.com/yoheinakajima/status/1666313838868992001)\nMod of BabyAGI with only ~350 lines of code\n\n<details>\n\n![Image](https://pbs.twimg.com/media/Fx_tr0yaUAYP1Q0?format=jpg&name=medium)\n\n### Category\nGeneral purpose\n\n### Category\nGeneral purpose\n\n### Description\n- Features\n	- Parallel tasks (making it faster)\n	- 3.5-turbo only (GPT-4 not required)\n	- User input tool\n	- Query rewrite in web search tool\n	- Saves results\n\n\n### Links\n- [Tweet](https://twitter.com/yoheinakajima/status/1666313838868992001)\n- [GitHub](https://github.com/yoheinakajima/babyagi/blob/main/classic/BabyDeerAGI.py)\n- [Replit](https://replit.com/@YoheiNakajima/BabyDeerAGI)\n- Author: [@yoheinakajima](https://twitter.com/yoheinakajima) (Twitter)\n\n</details>\n\n## [BabyElfAGI](https://twitter.com/yoheinakajima/status/1678443482866933760)\nMod of BabyDeerAGI, with ~895 lines of code\n<details>\n\n![Image](https://pbs.twimg.com/media/F0sHc04aMAEVn3D?format=jpg&name=medium)\n\n### Category\nGeneral purpose\n\n### Description\n- Features\n	- Skills class allows for creation of new skills\n	- ''Dynamic task list'' example with vector search\n	- Beta reflection agent\n	- Can read, write, and review its own code\n\n\n### Links\n- [Tweet](https://twitter.com/yoheinakajima/status/1678443482866933760)\n- [GitHub](https://github.com/yoheinakajima/babyagi/blob/main/classic/BabyElfAGI/main.py)\n- [Replit](https://replit.com/@YoheiNakajima/BabyElfAGI)\n- Author: [@yoheinakajima](https://twitter.com/yoheinakajima) (Twitter)\n\n</details>\n\n\n## [BabyCommandAGI](https://github.com/saten-private/BabyCommandAGI)\nTest what happens when you combine CLI and LLM\n<details>\n\n![Image](https://github.com/saten-private/BabyCommandAGI/raw/main/docs/Architecture.png)\n\n### Category\nGeneral purpose, Coding\n\n### Description\n- gent designed to test what happens when you combine CLI and LLM, which are more traditional interfaces than GUI (created by @saten-private)\n- An AI agent based on @yoheinakajima''s [BabyAGI](https://github.com/yoheinakajima/babyagi) which executes shell commands\n- Automatic Programming, Successfully created an app automatically just by providing feedback. The procedure can be found [here](https://twitter.com/saten_work/status/1674855573412810753).\n- Automatic Environment Setup, Successfully installed a Flutter environment on Linux in a container, created the Flutter app, and launched it. The procedure can be found [here](https://twitter.com/saten_work/status/1667126272072491009).\n- Aside from setting up the environment, it seems to be able to handle a bit of general tasks such as [Generating text, like poems, code, scripts, musical pieces, email, and letters, translating languages](https://anyaitools.com/babycommandagi/?utm_source=SocialAutoPoster&utm_medium=Social&utm_campaign=Twitter)\n- There is a risk of breaking the environment. Please run in a virtual environment such as Docker.\n- GPT-4 or higher is recommended\n\n### Links\n- [Founder''s Twitter](https://twitter.com/saten_work)\n- [Twitter thread describing the system](https://twitter.com/saten_work/status/1654571194111393793)\n\n</details>\n\n\n## [BabyFoxAGI](https://github.com/yoheinakajima/babyagi/tree/main/classic/babyfoxagi)\nMod of BabyAGI with a new parallel UI panel\n\n\n<details>\n\n![Image](https://pbs.twimg.com/media/F2Vpt4EbIAAa326?format=jpg&name=medium)\n\n### Category\nGeneral purpose\n\n### Description\n- A mod of BabyElfAGI, in a series of mods w the naming of Baby<animal>AGI in alphabetical order\n- Self-improving task lists (FOXY method)\n   	- By storing a final reflection at the end, and pulling the most relevant reflection to guide future runs, BabyAGI slowly generates better and better tasks lists\n- Novel Chat UI w parallel tasks\n  	- You can chat w BabyAGI! It has an experimental UI where the chat is separate from the tasks/output panel, allowing you to request multiple tasks in parallel\n  	- The Chat UI can use a single skill quickly, or chain multiple skills together using a tasklist\n-  New skills\n	- üé® DALLE skill with prompt assist\n 	- üé∂ Music player w Deezer\n	- üìä Airtable search (add your own table/base ID)\n	- üîç Startup Analyst (example of beefy function call as a skill)\n-  It‚Äôs own README\n\n\n### Links\n- [Author''s Twitter](https://twitter.com/yoheinakajima)\n- [Twitter thread describing the system](https://twitter.com/yoheinakajima/status/1697539193768116449)\n- [Replit](https://replit.com/@YoheiNakajima)\n\n</details>\n\n\n\n## [BambooAI](https://github.com/pgalko/BambooAI)\nData exploration and analysis for non-programmers\n\n<details>\n\n![Image](https://pbs.twimg.com/card_img/1745187734602313730/f-W5kbIU?format=jpg&name=medium)\n\n### Category\nData analysis\n\n### Description\n- BambooAI runs in a loop (until user decides to end it).\n- Allows mixing of different models with different capabilities, token costs and context windows for different tasks.\n- Maintains the memory of previous conversations.\n- Builds the prompts dynamically utilising relevant context from Pinecone vector DB.\n- Offers a narrative or asks follow up questions if required.\n- For codified responses, the task is broken down into a list of steps and a pseudo-code algorithm is built.\n- Based on the algorithm, it ises the python code for dataset analysis, modeling or plotting.\n- Debugs the code which then executes, auto-corrects if needs to, and displays the output to user.\n- Ranks the final answers, and asks user for feedback.\n- Builds a vector DB knowledge-base, based on the rank and the user feedback.\n\n### Links\n- [GitHub](https://github.com/pgalko/BambooAI)\n- [Creators''s Twitter](https://twitter.com/pgalko)\n\n</details>\n\n\n## [BeeBot](https://github.com/AutoPackAI/beebot)\nEarly-stage project for wide range of tasks\n\n<details>\n\n![Image](https://camo.githubusercontent.com/72231056f7393fa18ee2baa5cedf2688d1fc15478bb6131936e222e5d23ccbb6/68747470733a2f2f6572696b6c702e636f6d2f6d6173636f742e706e67)\n\n### Category\nGeneral purpose, Productivity\n\n### Description\n- "BeeBot is currently a work in progress and should be treated as an early stage research project. Its focus is not on production usage at this time."\n\n	\n### Links\n- [GitHub](https://github.com/AutoPackAI/beebot)\n- [Tweet](https://twitter.com/Douglas_Schon/status/1681094815021187072?s=20)\n</details>\n\n\n## [Blinky](https://github.com/seahyinghang8/blinky)\nAn open-source AI debugging agent for VSCode\n\n<details>\n\n![Banner](https://github.com/seahyinghang8/blinky/raw/master/media/banner.png)\n\n### Category\nCoding, Debugging\n\n### Description\n- Blinky is an open-source AI debugging agent for VSCode that uses LLMs to help identify and fix backend code errors (inspired by SWE-agent).\n- Blinky leverages the VSCode API, Language Server Protocol (LSP), and print statement debugging to triangulate and address bugs in real-world backend systems.\n\n	\n### Links\n- [VSCode Extension](https://marketplace.visualstudio.com/items?itemName=blinky.blinky)\n- [Discord](https://discord.gg/d3AUNHDb)\n- [GitHub](https://github.com/seahyinghang8/blinky)\n</details>\n\n\n## [Bloop](https://bloop.ai/)\nAI code search, works for Rust and Typescript\n\n<details>\n\n![Image](https://bloop.ai/_next/static/media/logo_white.b3bdedc0.svg)\n\n### Category\nCoding\n\n### Description\n- A GPT-4 powered semantic code search engine that uses an AI agent\n- Precise code navigation\n- Built on stack graphs and scope queries\n- Fast code search and regex matching engine written in Rust\n- Allows to find Code on Rust and Typescript\n- Allows to stage changes\n- The agent searches both your local and remote repositories with natural language, regex and filtered queries\n- Bloop can be run via app (easy to download via GitHub)\n\n### Links\n- [GitHub](https://github.com/BloopAI/bloop)\n- ["Getting started" guide](https://bloop.ai/docs/getting-started)\n- [Bloop apps](https://github.com/BloopAI/bloop/releases)\n\n</details>\n\n## [BondAI](https://bondai.dev/)\nCode interpreter with CLI & RESTful/WebSocket API\n\n<details>\n\n![Image](https://bondai.dev/assets/images/bondai-logo-9bec7e27b93b804d375221ff8fb6d336.png)\n\n### Category\nCoding\n\n### Description\n- A highly capable, autonomous AI Agent with an easy to use CLI, RESTful/WebSocket API, Pre-built Docker image and a robust suite of integrated tools.\n- Support for all GPT-N, Embeddings and Dall-E OpenAI Models\n- Support for Azure OpenAI Services\n- Easy to use SDK for integration into any application\n- Powerful **Code Interpreter** capabilities\n- Powerful data query capabilities via Postgres DB integration\n- Pre-built Docker image provides safe execution environment for code generation/execution\n- Support for telephony applications (via BlandAI)\n- Support for stock trading (via Alpaca Markets)\n- Integrates with Gmail and Google Search\n- Easy to install `pip install bondai`\n- To start the CLI just run `bondai`\n- To start the RESTful/WebSocket API just run `bondai --server`\n\n### Links\n- [BondAI Homepage/Documentation](https://bondai.dev)\n- [Github Repository](https://github.com/krohling/bondai)\n- [Docker Image](https://hub.docker.com/r/krohling/bondai)\n\n</details>\n\n## [bumpgen](https://github.com/xeol-io/bumpgen)\nAI agent that keeps npm dependencies up-to-date\n\n<details>\n\n![demo](<https://assets-global.website-files.com/65af8f02f12662528cdc93d6/662e6061d42954630a191417_tanstack-ezgif.com-speed%20(1).gif>)\n\n### Category\nCoding\n\n### Description\n- Put dependency management and upgrades on autopilot\n- bumpgen BUMPs an npm package''s version up then GENerates the code fixes for breaking changes\n- Supports gpt-4-turbo\n- Easy install > `npm install -g bumpgen`\n- Easy start > `bumpgen @tanstack/react-query 5.28.14`\n\n### Links\n- [Repo](https://github.com/xeol-io/bumpgen)\n- [Docs](https://docs.xeol.io/bumpgen/home)\n\n</details>\n\n## [Cal.ai](https://cal.ai)\nOpen-source scheduling assistant built on Cal.com\n\n<details>\n\n![Image](https://3620107743-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FpmUOqZjfGqNkiPmqgnMv%2Fuploads%2F9Qaq1hlaTcqKfrc9k4OG%2Fimage.png?alt=media&token=1ffe8530-19ff-4aea-b020-a99cdc224ce1)\n\n### Category\nProductivity\n\n### Description\n- Cal.ai can book meetings, summarize your week, and find time with others based on natural language.\n- Responds flexibly to unseen tasks eg. "move my second-last meeting to tomorrow morning".\n- Uses GPT-4 and LangChain Agent Executor under the hood.\n- [GitHub](https://github.com/calcom/cal.com/tree/main/apps/ai)\n\n### Links\n- Authors: [Cal.com core team](https://github.com/calcom/cal.com/graphs/contributors), [Dexter Storey](https://github.com/dexterstorey), [Ted Spare](https://github.com/tedspare)\n\n</details>\n\n\n## [CAMEL](https://github.com/camel-ai/camel)\nArchitecture for ‚ÄúMind‚Äù Exploration of agents\n\n<details>\n\n![Image](https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo.png)\n\n### Category\nGeneral purpose\n\n### Description\n- CAMEL is an open-source library designed for the study of autonomous and communicative agents.\n1)AI user agent: give instructions to the AI assistant with the goal of completing the task.\n2) AI assistant agent: follow AI user‚Äôs instructions and respond with solutions to the task\n- CAMEL also has an open-source community dedicated to the study of autonomous and communicative agents\n\n### Links\n- [Web](https://www.camel-ai.org/)\n- [Paper - CAMEL: Communicative Agents for ‚ÄúMind‚Äù\nExploration of Large Scale Language Model Society](https://ghli.org/camel.pdf)\n- [Colab demo](https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing)\n- [GitHub](https://github.com/camel-ai/camel)\n- [Hugging face datasets](https://huggingface.co/camel-ai)\n- [Slack](https://camel-kwr1314.slack.com/join/shared_invite/zt-1vy8u9lbo-ZQmhIAyWSEfSwLCl2r2eKA#/shared-invite/email)\n- [Twitter](https://twitter.com/intent/follow?original_referer=https%3A%2F%2F1508613885-atari-embeds.googleusercontent.com%2F&ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5ECamelAIOrg&screen_name=CamelAIOrg)\n- Authors: Guohao Li‚àó Hasan Abed Al Kader Hammoud* Hani Itani* Dmitrii Khizbullin, Bernard Ghanem\n\n</details>\n\n## [ChatArena](https://www.chatarena.org/)\nA chat tool for multi agent interaction\n\n<details>\n\n![image](https://github.com/Farama-Foundation/chatarena/raw/main/docs/images/chatarena_architecture.png)\n\n### Category\nDesign, Build-your-own, SDK for AI apps, Multi-agent\n\n### Description\n- ChatArena (or Chat Arena) is a Multi-Agent Language Game Environments for LLMs. The goal is to develop communication and collaboration capabilities of AIs.\nChatArena provides:\n- A general framework for building interactive environments for multiple large language models (LLMs). \n- A collection of pre-built or community-created  environments.\n- User-friendly interfaces with both Web UI and commandline interfaces.\n\n### Links\n- [Web](https://www.chatarena.org/)\n- [GitHub](https://github.com/Farama-Foundation/chatarena)\n- [X](https://twitter.com/_chatarena)\n- [Slack channel](https://chatarena.slack.com/join/shared_invite/zt-1t5fpbiep-CbKucEHdJ5YeDLEpKWxDOg#/shared-invite/email)\n  \n</details>\n\n## [ChatDev](https://github.com/OpenBMB/ChatDev)\nCommunicative agents for software development\n\n<details>\n\n![Image](https://github.com/OpenBMB/ChatDev/raw/main/misc/logo1.png)\n\n### Category\nCoding, Multi-agent\n\n### Description\n- ChatDev is a virtual software company driven by a multitude of intelligent agents assuming different roles such as CEO, CPO, CTO, programmer, reviewer, tester, and art designer, each represented by unique icons.\n- These agents collaborate in a structured organizational environment, fulfilling the company''s mission to "revolutionize the digital world through programming." They engage in functional seminars focusing on design, coding, testing, and documentation.\n- ChatDev aims to provide an accessible, modular, and extensible platform based on large language models, facilitating the study of collective intelligence in a controlled setting.\n- The framework allows for extensive customization, empowering users to tailor the software development process, define phases, and establish specific roles within the virtual company.\n- ChatDev is committed to open-source principles, encouraging contributions from the community and sharing advancements transparently.\n\n### Links\n- [Paper - ChatDev: Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924)\n- [Local demo](https://github.com/OpenBMB/ChatDev/blob/main/wiki.md#local-demo)\n- [GitHub](https://github.com/OpenBMB/ChatDev)\n\n</details>\n\n## [ChemCrow](https://github.com/ur-whitelab/chemcrow-public)\nLangChain agent for chemistry-related tasks\n\n<details>\n\n![Image](https://github.com/ur-whitelab/chemcrow-public/raw/main/assets/chemcrow_dark_bold.png)\n\n### Category\nScience, Chemistry\n\n### Description\n- ChemCrow is an open source package for the accurate solution of reasoning-intensive chemical tasks\n- It integrates 13 expert-design tools to augment LLM performance in chemistry and demonstrate effectiveness in automating chemical tasks\n- Built with Langchain\n- The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output. It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation. One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results. (Source: [Weng, Lilian. (Jun 2023). LLM-powered Autonomous Agents". Lil‚ÄôLog. https://lilianweng.github.io/posts/2023-06-23-agent/.](https://lilianweng.github.io/posts/2023-06-23-agent/))\n\n### Links\n- [Paper](https://arxiv.org/abs/2304.05376)\n- [GitHub](https://github.com/ur-whitelab/chemcrow-public)\n- [HackerNews Discussion](https://news.ycombinator.com/item?id=35607616)\n\n</details>\n\n## [Clippy](https://github.com/ennucore/clippy/)\nAgent that can plan, write, debug, and test code\n\n<details>\n\n![Image](https://lev.la/images/clippy.jpg)\n\n### Category\nCoding\n\n### Description\n- The purpose of Clippy is to elop code for or with the user.\n- It can plan, write, debug, and test some projects autonomously.\n- For harder tasks, the best way to use it is to look at its work and provide feedback to it.\n\n### Links\n- [GitHub](https://github.com/ennucore/clippy/)\n- Author: [Lev Chizhov](http://lev.la/) \n\n</details>\n\n## [CodeFuse-ChatBot](https://github.com/codefuse-ai/codefuse-chatbot)\nAgent serving entire SW development lifecycle\n<details>\n\n![Image](https://github.com/codefuse-ai/codefuse-chatbot/raw/main/sources/docs_imgs/objective_v4.png)\n\n### Category\nCoding\n\n### Description\n- An intelligent assistant serving the entire software development lifecycle, powered by a Multi-Agent Framework, working with DevOps Toolkits, Code&Doc Repo RAG, etc.\n\n### Links\n- [GitHub](https://github.com/codefuse-ai/codefuse-chatbot)\n\n</details>\n\n## [Cody by ajhous44](https://github.com/ajhous44/cody)\nQuery and navigate your codebase\n\n<details>\n\n![Image](https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png)\n\n### Category\nCoding\n\n### Description\n- An AI assistant designed to let you interactively query your codebase using natural language.\n- By utilizing vector embeddings, chunking, and OpenAI''s language models, Cody can help you navigate through your code in an efficient and intuitive manner.\n\n### Links\n- [GitHub](https://github.com/ajhous44/cody)\n- Author: [@ajhous44](https://github.com/ajhous44/) (Github)\n\n</details>\n\n## [Cody by Sourcegraph](https://docs.sourcegraph.com/cody)\nAgent that writes code and answers your questions\n\n<details>\n\n![Image](https://sourcegraph.com/.assets/img/sourcegraph-mark.svg?v2)\n\n### Category\nCoding\n\n### Description\nAn AI code assistant from Sourcegraph that writes code and answers questions for you by reading your entire codebase and the code graph.\n\n### Links\n- [GitHub](https://github.com/sourcegraph/sourcegraph/tree/main/client/cody)\n- Author: [@sourcegraph](https://twitter.com/sourcegraph) (Twitter)\n\n</details>\n\n## [Continue](https://continue.dev/)\nOpen-source autopilot for software development\n\n<details>\n\n![Image](https://continue.dev/docs/assets/images/continue-cover-logo-aa135cc83fe8a14af480d1633ed74eb5.png)\n\n### Category\nCoding\n\n### Description\n- An open-source autopilot for software development‚Äîbring the power of ChatGPT to VS Code\n- Features:\n	- Answer coding questions\n   	- Edit in natural language\n   	- Generate files from scratch\n\n\n### Links\n- [Website](https://continue.dev/)\n- [GitHub](https://github.com/continuedev/continue)\n- [Documentation](https://continue.dev/docs/intro)\n- [Twitter](https://twitter.com/continuedev)\n\n</details>\n\n## [CrewAI](https://github.com/joaomdmoura/crewai)\nFramework for orchestrating role-playing agents\n<details>\n\n![Image](https://github.com/joaomdmoura/crewAI/raw/main/docs/crewai_logo.png)\n\n### Category\nBuild-your-own, SDK for agents, Multi-agent\n\n### Description\n- Cutting-edge framework for orchestrating role-playing, autonomous AI agents.\n- By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n- Crew AI is a multi-agent framework built on LangChain, aiming to empower engineers to harness the collective power of AI agents. In contrast to traditional automation methods, Crew AI introduces a new approach to collaborative decision-making, enhanced creativity, and solving complex problems.\n- The design philosophy of Crew AI advocates simplicity through modularity. Its main components include agents, tools, tasks, processes, and crews. Each agent is akin to a team member, possessing specific roles, background stories, goals, and memories. Through modular design, we make the intricate world of AI agents accessible, manageable, and more engaging.\n\n\n### Links\n- [GitHub](https://github.com/joaomdmoura/crewai)\n- [Founder''s X](https://twitter.com/joaomdmoura)\n- [Blog post: How to use Crew AI](https://crewai.net/posts/how-to-use-crew-ai)\n- [Crew AI Wiki with examples and guides](https://github.com/joaomdmoura/CrewAI/wiki)\n- [Docs](https://github.com/joaomdmoura/CrewAI/wiki)\n- [Discord](https://discord.com/invite/X4JWnZnxPb)\n\n</details>\n\n## [data-to-paper](https://github.com/Technion-Kishony-lab/data-to-paper)\nAI-driven research from data to human-verifiable research papers\n<details>\n\n<br>\n<img src="https://github.com/Technion-Kishony-lab/data-to-paper/assets/65530510/e33bcb52-5f4e-4fd0-8be9-ebd64607c449" width="400" align="center">\n<br>\n	\n### Category\nScience, Research, Multi-agent\n\n### Description\n[*data-to-paper*](https://arxiv.org/abs/2404.17605) is a framework for systematically navigating the power of AI to perform complete end-to-end \nscientific research, starting from raw data and concluding with comprehensive, transparent, and human-verifiable \nscientific papers.\n\nTowards this goal, *data-to-paper* systematically guides interacting \nLLM and rule-based agents through the conventional scientific path, from annotated data, through creating \nresearch hypotheses, conducting literature search, writing and debugging data analysis code, \ninterpreting the results, and ultimately the step-by-step writing of a complete research paper.\n\nThe *data-to-paper* framework is created as a research project to understand the \ncapacities and limitations of LLM-driven scientific research, and to develop ways of harnessing LLM to accelerate \nresearch while maintaining, and even enhancing, key scientific values, such as transparency, traceability and verifiability, \nand while allowing scientist to oversee and direct the process \n[see also: [living guidelines](https://www.nature.com/articles/d41586-023-03266-1)].\n\n\n### Links\n- [GitHub](https://github.com/Technion-Kishony-lab/data-to-paper)\n- [arXiv preprint](https://arxiv.org/abs/2404.17605)\n- [Demo video](https://www.youtube.com/watch?v=Nt_460MmM8k)\n\n</details>\n\n\n## [Databerry](https://www.databerry.ai/)\n(Pivoted to Chaindesk) No-code chatbot building\n\n<details>\n\n![Image](https://www.chaindesk.ai/_next/image?url=%2Fapp-logo-icon.png&w=256&q=75)\n\n### Category\nBuild-your-own\n\n### Description\n- A super-easy no-code platform for creating AI chatbots trained on your own data\n- After creating new agent, picking a model, data and other settings, they are ready to be deployed to website, Slack, Crisp, or Zapier\n- Limit of agent in the free version\n- Stack\n	- Next.js\n	- Joy UI\n	- LangchainJS\n	- PostgreSQL\n	- Prisma\n	- Qdrant\n- Features\n	- Streamline customer support, onboard new team members, and more\n	- Load data from anywhere\n	- No-code: User-friendly interface to manage your datastores and chat with your data\n	- Secured API endpoint for querying your data\n	- Auto sync data sources (coming soon)\n	- Auto generates a ChatGPT Plugin for each datastore\n\n### Links\n- [Documentation](https://docs.chaindesk.ai/introduction)\n- [Discord](https://discord.com/invite/FSWKj49ckX)\n- [GitHub](https://github.com/gmpetrov/databerry)\n\n</details>\n\n## [DemoGPT](https://github.com/melih-unsal/DemoGPT)\nGenerates demo of a new app (of any purpose)\n\n<details>\n\n![Image](https://github.com/melih-unsal/DemoGPT/raw/main/assets/banner_small.png)\n\n### Category\nBuild-your-own, General purpose\n\n### Description\n- DemoGPT leverages the power of Language Models (LLMs) to provide fast and effective demo creation for applications.\n- Automates the prototyping process, making it more efficient and saving valuable time.\n- Understands and processes the given prompts to generate relevant applications.\n- Integrated with LangChain for generating application code through iterative parsing of LangChain''s documentation with a "Tree of Transformations" (ToT) approach.\n- The roadmap for DemoGPT includes constant updates and improvements based on user feedback and real-world application, working towards refining the technology and solving the hallucination problem.\n- "We are planning to introduce features that will further enhance the application generation process, making it more user-friendly and efficient."\n\n### Links\n- [Github](https://github.com/melih-unsal/DemoGPT)\n- [Website](https://www.demogpt.io/)\n- [Twitter](https://twitter.com/demo_gpt)\n- [Streamlit App](https://demogpt.streamlit.app/)\n- [Hugging Face Space](https://huggingface.co/spaces/melihunsal/demogpt)\n\n</details>\n\n## [DevGPT](https://github.com/jina-ai/dev-gpt)\nTeam of virtual developers\n\n<details>\n\n![Image](https://pbs.twimg.com/profile_images/1684472754597142529/tyM92sRA_400x400.jpg)\n### Category\nCoding, Multi-agent\n\n### Description\n- "Tell your AI team what microservice you want to build, and they will do it for you. Your imagination is the limit!!\n- Welcome to Dev-GPT, where we bring your ideas to life with the power of advanced artificial intelligence! Our automated development team is designed to create microservices tailored to your specific needs, making your software development process seamless and efficient. Comprised of a virtual Product Manager, Developer, and DevOps, our AI team ensures that every aspect of your project is covered, from concept to deployment.\n\n### Links\n- [Discord](https://discord.com/invite/AWXCCC6G2P)\n\n</details>\n\n## [Devika](https://github.com/stitionai/devika)\nAgentic AI Software Engineer\n\n<details>\n\n![Image](https://github.com/stitionai/devika/raw/main/.assets/devika-screenshot.png)\n### Category\nCoding, general purpose\n\n### Description\n- Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective.\n- Devika aims to be a competitive open-source alternative to Devin by Cognition AI.\n\n### Links\n- [GitHub](https://github.com/stitionai/devika)\n\n</details>\n\n## [Devon](https://github.com/entropy-research/Devon)\nOpen-source Devin alternative\n\n<details>\n\n![Image]()\n### Category\nCoding, general purpose\n\n### Description\n- Open-source alternative to Devin by Entropy research\n\n### Links\n- [GitHub](https://github.com/entropy-research/Devon)\n\n</details>\n\n## [DevOpsGPT](https://github.com/kuafuai/DevOpsGPT)\nAI-Driven SW Development Automation Solution\n\n<details>\n\n![Image](https://github.com/kuafuai/DevOpsGPT/raw/master/docs/files/intro-flow-simple.png)\n\n### Category\nCoding\n\n### Description\nWelcome to the AI Driven Software Development Automation Solution, abbreviated as DevOpsGPT. We combine LLM (Large Language Model) with DevOps tools to convert natural language requirements into working software. This innovative feature greatly improves development efficiency, shortens development cycles, and reduces communication costs, resulting in higher-quality software delivery.\n\n### Features and Benefits\n* Improved development efficiency: No need for tedious requirement document writing and explanations. Users can interact directly with DevOpsGPT to quickly convert requirements into functional software.\n* Shortened development cycles: The automated software development process significantly reduces delivery time, accelerating software deployment and iterations.\n* Reduced communication costs: By accurately understanding user requirements, DevOpsGPT minimizes the risk of communication errors and misunderstandings, enhancing collaboration efficiency between development and business teams.\n* High-quality deliverables: DevOpsGPT generates code and performs validation, ensuring the quality and reliability of the delivered software.\n* [Enterprise Edition] Existing project analysis: Through AI, automatic analysis of existing project information, accurate decomposition and development of required tasks on the basis of existing projects.\n* [Enterprise Edition] Professional model selection: Support language model services stronger than GPT in the professional field to better complete requirements development tasks, and support private deployment.\n* [Enterprise Edition] Support more DevOps platforms: can connect with more DevOps platforms to achieve the development and deployment of the whole process.\n\n### Links\n- [Creator Website](https://www.kuafuai.net/)\n- [Demo Video](https://youtu.be/IWUPbGrJQOU)\n\n</details>\n\n## [dotagent](https://github.com/dot-agent/dotagent)\nDeploy agents on cloud, PCs, or mobile devices\n\n<details>\n\n![Image](https://avatars.githubusercontent.com/u/133483033?s=200&v=4)\n\n### Category\nBuild-your-own\n\n### Description\n- An agent management system that facilitates the creation of robust AI applications and experimental autonomous agents through a rich suite of developer tools.\n- Enables the deployment of agents across multiple platforms including cloud, PCs, or mobile devices, and extends functionality through Python or plain English integrations.\n- Advances prompt engineering with a powerful prompt compiler, offering a higher degree of control over Language Models, significantly optimizing the response generation process.\n- Allows seamless export of agents into portable files for execution in any environment, along with an optional Agentbox feature for optimized computing resource management within a sandboxed environment.\n\n### Links\n- [YouTube video](https://www.youtube.com/watch?v=uE_fykl8AVI&ab_channel=FahdMirza)\n\n</details>\n\n## [Eidolon](https://eidolonai.com/)\nMulti Agent SDK with pluggable, modular components\n\n<details>\n\n![Image](https://www.eidolonai.com/_astro/default.jKAYXmpI_ZWVg5E.webp)\n\n### Category\nBuild-your-own (agent-builing frameworks and platforms), SDK for AI apps\n\n### Description\n- Eidolon is an open source SDK for AI agents\n\n### Links\n- [Web](https://eidolonai.com/)\n- [GitHub](https://github.com/eidolon-ai/eidolon)\n- [LinkedIn](https://www.linkedin.com/company/august-data/)\n- [Dave Brewster - LinkedIn](https://www.linkedin.com/in/dave-brewster-first/)\n- [Ravi Ramachandran - LinkedIn](https://www.linkedin.com/in/ravi-nextlevelgtm/)\n- [Luke Lalor - LinkedIn](https://www.linkedin.com/in/lukehlalor/)\n\n</details>\n\n## [English Compiler](https://github.com/uilicious/english-compiler)\nConverting markdown specs into functional code\n\n<details>\n\n![Image](https://github.com/uilicious/english-compiler/raw/main/notes/imgs/EnglishCommand-CLI-help.png)\n\n### Category\nCoding\n\n### Description\n- OC AI based Compiler, for converting english based markdown specs, into functional code\n- "We know that all great‚Ñ¢ projects start with awesome‚Ñ¢ detailed functional specifications. Which is typically written in English, or its many other spoken language alternatives.\n- So what if, instead of writing code from functional specs, we simply compile it directly to code?\n- Into a future, where we replace nearly everything, with just written text."\n\n### Links\n- [Creator''s Twitter](https://twitter.com/picocreator)\n\n</details>\n\n## [evo.ninja](https://evo.ninja/)\nAI agent that adapts its persona to achive tasks\n\n<details>\n\n![Image](https://camo.githubusercontent.com/3333c49067bddef0b208e36e22cf6ec8066f5be1da1dc327532427a395ed8069/68747470733a2f2f6861636b6d642e696f2f5f75706c6f6164732f4279576a4c4b41686e2e706e67)\n\n### Category\nGeneral purpose, Research, Multi-agent\n\n### Description\n- What makes evo.ninja special is that it adapts itself in real-time, based on the tasks at hand.\n- Evo utilizes pre-defined agent personas that are tailored to specific domains of tasks.\n- Each iteration of evo''s execution loop it will select and adopt the persona that fits the task at hand best.\n\n### Links\n- [Web](https://evo.ninja/)\n- [GitHub](https://github.com/polywrap/evo.ninja/)\n- [Discord](https://discord.com/invite/r3rwh69cCa)\n\n</details>\n\n## [FastAgency](https://fastagency.ai/latest/)\nThe fastest way to deploy multi-agent workflows\n\n<details>\n\n![Image](https://fastagency.ai/latest/assets/img/logo.svg)\n\n### Category\nBuild-your-own (agent-builing frameworks and platforms), SDK for AI apps, Multi-agent, Supports open-source models\n\n### Description\n- "FastAgency is an open-source framework designed to accelerate the transition from prototype to production for multi-agent AI workflows.\n- For developers who use the AutoGen framework, FastAgency enables you to seamlessly scale Jupyter notebook prototypes into fully functional, production-ready applications.\n- With multi-framework support, a unified programming interface, and powerful API integration capabilities, FastAgency streamlines the deployment process, saving time and effort while maintaining flexibility and performance.\n\n### Links\n- [Web](https://fastagency.ai/latest/)\n- [GitHub](https://github.com/airtai/fastagency)\n\n</details>\n\n## [Flowise](https://flowiseai.com/)\nLow code Agent builder\n\n<details>\n\n![Image](https://flowiseai.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-color-high.e60de2f8.png&w=384&q=75)\n\n### Category\nBuild-your-own (agent-builing frameworks and platforms)\n\n### Description\n- Flowise is an open source low-code tool for developers to build customized LLM orchestration flow & AI agents\n\n### Links\n- [Web](https://flowiseai.com/)\n- [GitHub](https://github.com/FlowiseAI/Flowise)\n- [X (Twitter)](https://x.com/FlowiseAI)\n- [LinkedIn](https://www.linkedin.com/company/flowiseai/)\n\n</details>\n\n\n## [Friday](https://github.com/amirrezasalimi/friday/)\nAI developer assistant for Node.js\n\n<details>\n\n![Image](https://github.com/amirrezasalimi/friday/raw/main/screenshot.png)\n\n### Category\nCoding\n\n### Description\n- A developer assistant able to make whole nodejs project with unlimited prompts\n- Provides a core prompt for building the foundation of your application\n- Allows you to add unlimited sections, each of which is a prompt representing a specific part of your app\n- Features\n	- Friday utilizes GPT-4 for AI assistance, but it has been tested and optimized with GPT-4-32k for improved speed and better results.\n	- It requires 2 small requests for your app''s base and 1 request per section you provide.\n	- Friday employs esbuild behind the scenes for every app created by it.\n\n### Links\n- **Author:** [Amirreza Salimi](https://twitter.com/amirsalimiiii)\n\n</details>\n\n## [GeniA](https://github.com/genia-dev/GeniA)\nEngineering platform engineering AI team member\n\n<details>\n\n![Image](https://github.com/genia-dev/GeniA/raw/main/media/genia_title.png)\n\n### Category\nCoding\n\n### Description\n- GeniA is able to work along side you on your production enviroment, executing tasks on your behalf in your dev & cloud environments, AWS/k8s/Argo/GitHub etc.\n- Allows you to enhance the platform by integrating your own tools and APIs.\n- Slack App Bot integration.\n- Supports GPT-3.5 & GPT-4.\n\n### Links\n- Authors: [Uri Shamay](https://github.com/cmpxchg16), [Shlomi Shemesh](https://github.com/shlomsh)\n\n</details>\n\n## [Godmode](https://godmode.space/)\nInspired by AutoGPT and BabyAGI, with nice UI\n\n<details>\n\n![Image](https://toolpulse.ai/wp-content/uploads/2023/11/godmode-ai.jpg)\n\n### Category\nGeneral purpose\n\n### Description\n- Godmode is a project inspired by Auto-GPT and BabyAGI, conducting  various kinds of tasks via nice UI\n- A web platform inspired by AutoGPT and BabyAGI\n- What it can do:\n	- Order your coffee at Starbucks\n	- Perform market analysis\n	- Find and negotiate a lease\n- Supports GPT-3.5 & GPT-4\n\n### Links\n- [GitHub](https://github.com/FOLLGAD/Godmode-GPT)\n- Authors: [Emil Ahlb√§ck](https://twitter.com/emilahlback), [Lonis](https://twitter.com/_Lonis_)\n- [Discord](https://discord.com/invite/vSzCcDDwz3)\n- [Tweet](https://twitter.com/_Lonis_/status/1646641412182536196)\n\n</details>\n\n## [GPT Discord](https://github.com/Kav-K/GPTDiscord)\nThe ultimate AI agent integration for Discord\n\n<details>\n\n![image](https://camo.githubusercontent.com/c02e68bf20c853637e8cfb02c9406bd2b3b20637ea4ed95b7d68819e94a01dfe/68747470733a2f2f692e696d6775722e636f6d2f425a644f52544c2e706e67)\n\n### Category\nContent creation, Productivity, General purpose, Discord\n\n### Description\n- GPT Discord is a robust, all-in-one GPT interface for Discord.\n- GPT Discord supports everything from multi-modality image understanding, code interpretation, advanced data analysis, Q&A on your own documents, internet-connected chat with Wolfram Alpha and Google access, AI-moderation, image generation with DALL-E, and much more!\n- Featuring code execution and environment manipulation by E2B\n- ![image](https://camo.githubusercontent.com/6806eb5cd7f4a14e693bc732a304f18c5413a493c92b4b73202ec3205017b9c8/68747470733a2f2f692e696d6775722e636f6d2f547366677455322e706e67)\n- LLMs/model providers supported:\n  - OpenAI models\n\n### Links\n- [GitHub](https://github.com/Kav-K/GPTDiscord)\n- [Kaveen Kumarasinghe - founder of GPT Discord - website](https://kaveenk.com/)\n- [Kaveen Kumarasinghe - founder of GPT Discord - LinkedIn](https://www.linkedin.com/in/kaveenk/)\n\n  \n</details>\n\n## [GPT Engineer](https://gptengineer.app/)\nGenerates entire codebase based on a prompt\n\n<details>\n\n![Image](https://pbs.twimg.com/media/GDA3bYrXYAE5XDQ?format=jpg&name=4096x4096)\n\n### Category\nCoding\n\n### Description\nGPT Engineer is an AI agent that generates an entire codebase based on a prompt.\n- Model: GPT 4\n- Specify your project, and the AI agent asks for clarification, and then constructs the entire code base\n- Features\n	- Made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt\n	- You can specify the "identity" of the AI agent by editing the files in the identity folder\n	- Editing the identity and evolving the main prompt is currently how you make the agent remember things between projects\n	- Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py\n\n\n### Links\n- [Web](https://gptengineer.app)\n- [GitHub](https://github.com/AntonOsika/gpt-engineer)\n- [Discord](https://discord.com/invite/8tcDQ89Ej2)\n- Author: [Anton Osika](https://twitter.com/antonosika)\n- [Twitter review by @Attack](https://twitter.com/Attack/status/1671165869064609792)\n\n</details>\n\n## [GPT Migrate](https://github.com/0xpayne/gpt-migrate)\nMigrate codebase between frameworks/languages\n\n<details>\n\n![Image](https://opengraph.githubassets.com/678543c5159118a70ea974db32bb95b310a3fbb6ad4296e97d54335031f8df82/joshpxyne/gpt-migrate)\n\n### Category\nCoding\n\n### Description\nGOT Migrate easily migrates your codebase from one framework or language to another.\n- Pick from different LLMs\n- Ability to allow GPT Migration to generate and run unit tests for the new codebase\n- Ability to select source and target language of the migration\n- Ability to customize the agent''s workflow (setup -> migrate -> test)\n- GPT Migrate team is working on adding [benchmarks](https://github.com/0xpayne/gpt-migrate#-benchmarks) for the agent\n\n### Links\n- [Website](https://gpt-migrate.com/)\n- Author: [Josh Payne](https://twitter.com/joshpxyne)\n- [Announcement](https://twitter.com/joshpxyne/status/1675254164165910528)\n\n\n</details>\n\n## [GPT Pilot](https://github.com/Pythagora-io/gpt-pilot)\nCode the entire scalable app from scratch\n\n<details>\n\n![Image](https://techcrunch.com/wp-content/uploads/2023/08/gpt_pilot_logo.png?w=150)\n\n### Category\nCoding\n\n### Description\nGPT Pilot is an AI agent that codes the entire app as you oversee the code being written\n- Dev tool that writes scalable apps from scratch while the developer oversees the implementation\n- A research project to see how can GPT-4 be utilized to generate fully working, production-ready, apps\n- The main idea is that AI can write most of the code for an app (maybe 95%) but for the rest 5%, a developer is and will be needed until we get full AGI\n\n### Links\n- [GitHub](https://github.com/Pythagora-io/gpt-pilot)\n- [Discord](https://discord.com/invite/HaqXugmxr9)\n\n\n</details>\n\n\n## [GPT Researcher](https://github.com/assafelovic/gpt-researcher)\nAgent that researches entire internet on any topic\n\n<details>\n\n![Image](https://camo.githubusercontent.com/b3ab3e2b5612657816d64e174672498cd50027b75aa0a795833aee2ddab585b2/68747470733a2f2f636f7772697465722d696d616765732e73332e616d617a6f6e6177732e636f6d2f6172636869746563747572652e706e67)\n\n### Category\nResearch, Science\n\n### Description\nGPT Researcher is a GPT-based autonomous agent that does online comprehensive research on any given topic\n- Can produce detailed, factual and unbiased research reports\n- Offers customization options for focusing on relevant resources, outlines, and lessons\n- Addresses issues of speed and determinism, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operation\n- Inspired by AutoGPT and the Plan-and-Solve paper\n- The main idea is to run "planner" and "execution" agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question\n\n### Links\n- [Website](https://tavily.com/)\n- [Discord](https://discord.com/invite/2pFkc83fRq)\n- Author: [Assaf Elovic](https://twitter.com/assaf_elovic)\n\n\n</details>\n\n## [GPT Runner](https://github.com/nicepkg/gpt-runner)\nAgent that converses with your files\n\n<details>\n\n![image](https://repository-images.githubusercontent.com/640476297/30741f73-caac-48bc-b500-1b7d6efde4c4)\n\n### Category\nResearch, Science\n\n### Description\n- Conversation with your files which selected by you, no embedding, no vector database!\n- It''s also a AI Prompt Storybook. You can use it to manage some AI preset with your team. It support any IDE and language developer. We provide cli to run web and VSCode extension, Jetbrains plugin is coming soon.\n- Private first, all data is local.\n- We support both OpenAI and Anthropic (Claude-2)\n- It support support for multiple languages.\n\n### Links\n- [Website](https://github.com/nicepkg/gpt-runner)\n- Author: [Jinming Yang](https://github.com/2214962083)\n\n\n</details>\n\n## [GPTSwarm](https://gptswarm.org/)\nLanguage Agents as Optimizable Graphs\n\n<details>\n\n![image](https://gptswarm.org/images/gptswarm.png)\n\n### Category\nBuild-your-own (agent-builing frameworks and platforms), General purpose, Multi-agent\n\n### Description\n- üêù GPTSwarm is a graph-based framework for LLM-based agents, providing two high-level features:\n  - It lets you build LLM-based agents from graphs.\n  - It enables the customized and automatic self-organization of agent swarms with self-improvement capabilities.\n- Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. Each node implements a function to process multimodal data or query other LLMs. Each edge describes the information flow between operations and agents. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration. Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve diverse LLM agents.\n\n\n### Links\n- [Web](https://gptswarm.org/)\n- [GitHub](https://github.com/metauto-ai/GPTSwarm)\n- [Founder''s X (Twitter)](https://twitter.com/MingchenZhuge)\n\n\n</details>\n\n\n## [IX](https://github.com/kreneskyp/ix)\nAgents building, debugging, and deploying platform\n\n<details>\n\n![image](https://github.com/kreneskyp/ix/raw/master/ix_350.png)\n\n### Category\nBuild your own, Multi-agent\n\n### Description\nIX is a platform for building, debugging, and deploying collaborative Agents and cognitive workflows.\n-IX is a LangChain-based agent platform that includes all the tools to build and deploy fleets of agents that\ncollaborate to complete tasks. IX is both an editor and a runtime. The editor is a no-code graph style editor for\nthe design of agents, chains, tools, retrieval functions, and collaborative workflows.\n\n- Intuitive graph style no-code editor.\n- Horizontally scaling agent worker fleet.\n- Multi-user, multi-agent chat interface.\n- Smart input auto-completes `@mentions` and `{file}` references.\n- Supports Chroma and other vector databases for document search.\n- Supports OpenAI API, Anthropic, PaLM, and LLama based models.\n- Component library is easily extended.\n- Powered by LangChain\n\n### Links\n\n- [Youtube](https://www.youtube.com/watch?v=hAJ8ectypas&list=PLR8AMvFecu1hyMHFzaehbfFcMcECMafVs)\n- [Discord](https://discord.gg/jtrMKxzZZQ)\n- [Author''s Twitter](https://twitter.com/kreneskyp)\n\n</details>\n\n\n## [JARVIS](https://github.com/microsoft/JARVIS)\nSystem that connects LLMs with the ML community\n\n<details>\n\n![image](https://github.com/microsoft/JARVIS/raw/main/hugginggpt/assets/intro.png)\n\n### Category\nGeneral purpose\n\n### Description\nJARVIS is a system to connect LLMs with the ML community.\n- Task Planning: Using ChatGPT to analyze the requests of users to understand their intention, and disassemble them into possible solvable tasks.\n- Model Selection: To solve the planned tasks, ChatGPT selects expert models hosted on Hugging Face based on their descriptions.\n- Task Execution: Invokes and executes each selected model, and returns the results to ChatGPT.\n- Response Generation: Use ChatGPT to integrate the prediction of all models, and generate responses.\n\n### Links\n\n- [Paper](https://arxiv.org/abs/2303.17580)\n\n</details>\n\n## [Langroid](https://github.com/langroid/langroid)\nMulti-agent framework for building LLM apps\n\n<details>\n\n![image](https://github.com/langroid/langroid/raw/main/docs/assets/langroid-card-lambda-ossem-rust-1200-630.png)\n\n### Category\nGeneral purpose, Build your own\n\n### Description\n\n\n`Langroid` is an intuitive, lightweight, extensible and principled\nPython framework to easily build LLM-powered applications.\nYou set up Agents, equip them with optional components (LLM,\nvector-store and methods), assign them tasks, and have them\ncollaboratively solve a problem by exchanging messages.\nThis Multi-Agent paradigm is inspired by the\n[Actor Framework](https://en.wikipedia.org/wiki/Actor_model)\n(but you do not need to know anything about this!).\n\n`Langroid` is a fresh take on LLM app-development, where considerable thought has gone\ninto simplifying the developer experience; it does not use `Langchain`.\n\n- Works with most commercial/remote and open/local LLMs.\n- Set up Multi-agent, multi-LLM system: use stronger LLMs for agents requiring strong reasoning and instruction-following, and delegate simpler tasks to weaker/local LLMs. \n- Supports OpenAI function-calling as well as native equivalent called `ToolMessage`, which works with LLMs that \n  do not have built-in function-calling. Simply specify structure as a (nested) Pydantic object.\n- Batteries-included: vector-databases for RAG (Retrieval-Augmented Generation), caching, logging/observability.\n- Specialized agents available: `DocChatAgent`, `SQLChatAgent`, `TableChatAgent` (for tabular data, e.g. csv/dataframes).\n- `DocChatAgent` handles text, PDF, Docx files/URLS, and has state-of-the art techniques \n   for retrieval combining lexical and semantic search.\n- Documentation: https://langroid.github.io/langroid/\n</details>\n\n## [Lemon Agent](https://github.com/felixbrock/lemon-agent)\nPlan-Validate-Solve agent for workflow automation\n\n<details>\n\n![image](https://pbs.twimg.com/media/F3l2kEsXIAA0Gsm?format=jpg&name=large)\n\n### Category\nProductivity, Coding\n\n### Description\nLemon agent is a Plan-Validate-Solve (PVS) Agent for accurate, reliable and reproducable workflow automation\n- A standalone supervised Plan and Solve Agent specialized on performing read and write operations on various tools like GitHub, HubSpot or Airtable _(ACL 2023 Paper "[Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/abs/2305.04091)")_\n- **Separation of tasks and human-in-the-loop interactions**: Lemon Agent is currently holding a Planner Agent and a Solver Agent to keep the agents focussed and increase accuracy. We are planning on adding additional agents real soon. In addition, Lemon Agent will ask for approval at relevant workflow steps to make sure the intended actions are executed.\n- **Unlimited configuration options**: Lemon Agent gives you unlimited configuration options (see example here) when defining your workflow. For instance, you can tell Lemon Agent to ask for permission before executing a workflow step or to drop a üßî‚Äç‚ôÄÔ∏è dad joke every time the model executes a workflow step.\n- **UI flexibility**: Build any UI on top or engage with Lemon Agent via the built-in CLI.\n- **[Soon] Model & framework agnostic operations**: Lemon Agent is a standalone agent, but can easily be integrated into frameworks like LangChain and be used with any model.\n- **Bonus**: Identify weak spots in your agent‚Äôs decision-making capabilities and move to a more deterministic behavior by further configuring your Lemon Agent workflows. **(.html file that can be run without any additional installation)**\n\n### Links\n\n- [Discord](https://discord.gg/fWU4rDYSxw)\n- [Author''s Twitter](https://twitter.com/felixbrockm)\n\n</details>\n\n## [LLM Agents](https://github.com/mpaepper/llm_agents)\nLibrary for building agents, using tools, planning\n\n<details>\n\n![image](https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png)\n\n### Category\nCoding\n\n### Description\nA minimalistic library for building agents that leverage large language models to automate tasks through a loop of commands and tool integrations.\n- Executing Python code in a REPL environment.\n- Conducting searches on Google and Hacker News.\n- Iterating through a cycle of Thought, Action, Observation, and New Thought based on the output of integrated tools.\n- Dynamically appending new information to the prompt for informed decision-making by the agent.\n\n### Links\n\n- [GitHub](https://github.com/mpaepper/llm_agents)\n- [Blog](https://www.paepper.com/blog/posts/intelligent-agents-guided-by-llms/)\n\n</details>\n\n## [LLM Stack](https://llmstack.ai/)\nNo-code platform to build LLM Agents\n\n<details>\n\n![image](https://llmstack.ai/img/logo-grayscale.svg)\n\n### Category\nBuild-your-own, no-code, web UI\n\n### Description\n- LLM Stack is a no-code platform to build LLM Agents, workflows and applications with your data\n- LLMStack supports all major model providers, like OpenAI, Cohere, Stability AI, Hugging Face, and more. Easily use these models to build powerful apps.\n- With LLM Stack, you can build generative AI agents like AI SDRs, Research Analysts, RPA Automations etc., without writing any code. Connect agents to your internal or external tools, search the web or browse the internet with agents.\n- LLMs/model providers supported\n  - OpenAI\n  - Cohere\n  - Stability AI\n  - Hugging Face\n\n### Links\n- [Web](https://llmstack.ai/)\n- [GitHub](https://github.com/trypromptly/LLMStack)\n- [Blog](https://llmstack.ai/blog)\n\n</details>\n\n## [Local GPT](https://github.com/PromtEngineer/localGPT)\nChat with documents without compromising privacy\n\n<details>\n\n![image](https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png)\n\n### Category\nResearch, Data analysis, General purpose\n\n### Description\nLocalGPT is an open-source initiative that allows you to converse with your documents without compromising your privacy. Inspired by privateGPT, allows using your own documents as an information source\n\n- Chat with your documents on your local device using GPT models. No data leaves your device and 100% private\n- With everything running locally, you can be assured that no data ever leaves your computer\n- Dive into the world of secure, local document interactions with LocalGPT\n- Most of the description on readme is inspired by the original privateGPT\n- Model: Vicuna-7B\n- Using InstructorEmbeddings\n- Both Embeddings as well as LLM will run on GPU. It also has CPU support if you do not have a GPU\n- Built with Langchain\n\n\n### Links\n\n- [GitHub](https://github.com/PromtEngineer/localGPT)\n- [Subreddit](https://www.reddit.com/r/LocalGPT/)\n- [YouTube - LocalGPT: OFFLINE CHAT FOR YOUR FILES [Installation & Code Walkthrough]](https://www.youtube.com/watch?v=MlyoObdIHyo&ab_channel=PromptEngineering)\n\n</details>\n\n\n## [Loop GPT](https://github.com/farizrahman4u/loopgpt/tree/main)\nRe-implementation of AutoGPT as a Python package\n\n <details>\n\n ![image](https://github.com/farizrahman4u/loopgpt/raw/main/docs/assets/imgs/loopgpt_demo_pic.png?raw=true)\n\n### Category\nGeneral purpose\n\n### Description\nLoop GPT is a re-implementation of the popular Auto-GPT project as a proper python package, written with modularity and extensibility in mind\n- Languages: Python\n- Default model: GPT-3.5-turbo (also possible with GPT-4)\n- Modular Auto-GPT Framework\n- Plug N Play" API - Extensible and modular "Pythonic" framework, not just a command line tool\n- Features\n	- "Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"\n	- "Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."\n	- "Human in the Loop - Ability to "course correct" agents who go astray via human feedback."\n	- "Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"\n\n<!--\n### Features\n- "Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"\n- "Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."\n- "Human in the Loop - Ability to "course correct" agents who go astray via human feedback."\n- "Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"\n\n-->\n</details>\n\n## [L2MAC](https://github.com/samholt/l2mac)\nAgent framework able to produce large complex codebases and entire books\n\n<details>\n\n ![image](https://raw.githubusercontent.com/samholt/L2MAC/master/docs/public/l2mac-icon-white.png)\n\n### Category\nMulti-agent, Coding, Build your own\n\n### Description\nL2MAC is a multi-agent generation framework that, a single input prompt can generate an extensive unbounded output, such as an entire codebase or an entire book.\n- L2MAC can create near unbounded outputs that align exactly with the user input prompt over very long generation tasks\n- It achieves strong empirical performance of state-of-the-art generation for large codebase tasks and is in the top 3 for the HumanEval coding global benchmark. As L2MAC can detect invalid code and failing unit tests when generating code and automatically error corrects them.\n- Internally persists a complete file-store memory that enables LLM agents to read files and write to files, creating a large output over many iterations\n- It can be instructed to follow an exact prompt program\n- As it generates the output one part at a time, it enables an LLM with a fixed context token limit to be bypassed\n- The paper, peer-reviewed and recently accepted and published at ICLR 2024, introduces L2MAC.\n\n\n### Links  \n- [GitHub](https://github.com/samholt/l2mac)\n- [Discord](https://discord.gg/z27CxnwdhY)\n- [Twitter](https://twitter.com/samianholt)\n- [Paper - L2MAC: Large Language Model Automatic Computer for Extensive Code Generation](https://arxiv.org/abs/2310.02003)\n\n</details>\n\n\n## [Maige](https://maige.app)\nNatural-language workflows for your GitHub repo.\n\n<details>\n\n ![image](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNrQ3hXkHi0qTI-XThXwx7wA33LcAZZzLp5af6UjY0Vg&s)\n\n### Category\nCoding, Productivity, Debugging, Multi-agent\n	\n### Description\n- Maige is a codebase agent that runs when new issues and pull requests come up. Its core features are labelling, assigning, and answering questions.\n- Maige can search the entire codebase, spin up a sandbox to run scripts, and even write basic code.\n\n### Links  \n- [Web](https://maige.app)\n- [GitHub](https://github.com/RubricLab/maige)\n- [Video - testing Maige](https://www.youtube.com/watch?v=YN-y-iweZTc&ab_channel=TerezaTizkova)\n- [Interview - founder about building Maige](https://e2b.dev/blog/building-open-source-codebase-copilot-with-code-execution-layer)\n- [X (Twitter)](https://twitter.com/rubriclabs)\n- [Founder''s X - Ted Spare](https://twitter.com/tedspare)\n</details>\n\n## [Magick](https://www.magickml.com/)\nAIDE for creating, deploying, monetizing agents\n\n<details>\n\n ![image](https://assets-global.website-files.com/6507b4af22875d0b8abf95a7/6507bbdc3085cf26d1e8041e_white-wm-tiny.png)\n\n### Category\nCoding, SDK for agents, Build-your-own\n\n	\n### Description\nMagick is an AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining.\n- A full suite, model agnostic AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining. \n- Magick allows to build things like BabyAGI within an hour.  You can watch the graph executing in real time, watch the thought process as it executes, and understand the flow.\n- "Visual development of autonomous agents is incoming.  We have built Magick specifically for the rapid development of cognitive architecture and scalable event-driven autonomous agents."\n\n### Links  \n- [Web](https://www.magickml.com/)\n- [GitHub](https://github.com/Oneirocom/Magick)\n- [X](https://twitter.com/magickml)\n- [Discord](https://discord.com/invite/7Xx5DmbJCe)\n- [LinkedIn](https://www.linkedin.com/company/magickml/)\n- [Founder''s LinkedIn - Jesse Alton](https://www.linkedin.com/in/mrmetaverse/)\n- [Founder''s LinkedIn - Michael Sharpe](https://www.linkedin.com/in/michaelpsharpe/)\n\n</details>\n\n## [MemFree](https://github.com/memfreeme/memfree)\nOpen Source Hybrid AI Search Engine\n\n<details>\n\n ![image](https://raw.githubusercontent.com/memfreeme/memfree/main/frontend/public/og.png)\n\n### Category\nOpen Source, AI Search, Build your own\n\n### Description\n\nOpen Source Hybrid AI Search Engine, Instantly Get Accurate Answers from the Internet, Bookmarks, Notes, and Docs.\n\n- One-Click Chrome Bookmarks Sync and Index\n- Support multiple traditional search engines as source\n- Self-hosted Super Fast Serverless Vector Database\n- Self-hosted Super Fast Local Embedding and Rerank Service\n- Full Code Open Source\n- One-Click Deployment On Production\n\n### Links  \n- [Documentation](https://www.memfree.me/docs)\n- [Discord](https://discord.com/invite/7QqyMSTaRq)\n- [Twitter](https://twitter.com/ahaapple2023)\n- [Website](https://www.memfree.me)\n\n</details>\n\n\n## [MemGPT](https://github.com/cpacker/MemGPT)\nMemory management system, providing context to LLM\n\n<details>\n\n ![image](https://files.readme.io/da7f719-small-memgpt_logo_circle_nuno.png)\n\n### Category\nMemory management, Data analysis\n	\n### Description\n- A system that intelligently manages different memory tiers in LLMs to effectively provide the extended context within the LLM''s limited context window. \n- Chat with your data - talk to your local files or SQL database\n- Create perpetual chatbots with self-editing memory\n\n### Links  \n- [Paper](https://arxiv.org/abs/2310.08560)\n- [Documentation](https://memgpt.readthedocs.io/)\n- [Discord](https://discord.gg/9GEQrxmVyE)\n- [Hugging Face](https://huggingface.co/MemGPT)\n\n</details>\n\n## [Mentat](https://github.com/biobootloader/mentat)\nAssists you with coding task from command line\n\n<details>\n\n ![image](https://assets-global.website-files.com/64bad175c3f1fe8957a06faf/64bef0d57ca34f97c26b2c63_abante-ai-icon_transparent_271.png)\n\n### Category\nCoding\n\n### Description\nMentat is the AI tool that assists you with any coding task, right from your command line.\nUnlike Copilot, Mentat coordinates edits across multiple locations and files. And unlike ChatGPT, Mentat already has the context of your project - no copy and pasting required!\n\n### Links  \n- [Website](https://www.mentat.codes/)\n- [Youtube](https://www.youtube.com/watch?v=lODjaWclwpY)\n- Author: [Bio Bootloader](https://twitter.com/bio_bootloader) (Twitter)\n- [Discord Invite](https://discord.com/invite/zbvd9qx9Pb)\n\n</details>\n\n\n## [MetaGPT](https://github.com/geekan/MetaGPT)\nAgent framework returning Design, Tasks, or Repo\n\n<details>\n\n ![image](https://github.com/geekan/MetaGPT/raw/main/docs/resources/MetaGPT-new-log.png)\n\n### Category\nMulti-agent, Coding, Build your own\n\n### Description\nMetaGPT is a multi-agent framework that, given one line requirement, returns PRD, Design, Tasks, or Repo.\n- MetaGPT allows to assign different roles to GPTs to form a collaborative software entity for complex tasks\n- It takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.\n- Internally, MetaGPT includes product managers / architects / project managers / engineers\n- It provides the entire process of a software company along with carefully orchestrated SOPs. Code = SOP(Team) is the core philosophy\n- The paper about LLM-based multi-agent work spushes forward the idea of autonomous agents collaborating with each other to do more than one can on its own.\n- MetaGPT incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration\n\n\n### Links  \n- [GitHub](https://github.com/geekan/MetaGPT)\n- [Discord](https://discord.com/invite/4WdszVjv)\n- [Twitter](https://twitter.com/DeepWisdom2019)\n- [Paper - MetaGPT: Meta Programming for Multi-Agent Collaborative Framework](https://arxiv.org/abs/2308.00352)\n\n</details>\n\n## [Mini AGI](https://github.com/muellerberndt/mini-agi)\nGeneral-purpose agent based on GPT-3.5 / GPT-4\n\n<details>\n\n ![image](https://github.com/muellerberndt/mini-agi/raw/main/static/mini-agi-cover.png)\n\n### Category\nGeneral purpose\n\n### Description\n- MiniAGI is a minimal general-purpose autonomous agent based on GPT-3.5 / GPT-4\n- Can analyze stock prices, perform network security tests, create art, and order pizza\n- MiniAGI is a simple autonomous agent compatible with GPT-3.5-Turbo and GPT-4\n- It combines a robust prompt with a minimal set of tools, chain-of-thoughts, and short-term memory with summarization\n- Capable of inner monologue and self-criticism\n\n\n### Links\n- [GitHub](https://github.com/muellerberndt/mini-agi)\n\n</details>\n\n\n## [Multiagent Debate](https://github.com/composable-models/llm_multiagent_debate)\nImplementation of a paper on Multiagent Debate\n\n<details>\n\n ![image](https://composable-models.github.io/llm_debate/img/accuracy_small.png)\n\n ### Category\nGeneral purpose, Multi-agent\n\n### Description\nMultiagent Debate is an implementation of the paper "Improving Factuality and Reasoning in Language Models through Multiagent Debate".\n- The paper illustrates how we may treat different instances of the same language models as a "multiagent society", where individual language model generate and critique the language generations of other instances of the language model\n- The authors find that the final answer generated after such a procedure is both more factually accurate and solves reasoning questions more accurately\n- Illustrating the quantitative difference between multiagent debate and single agent generation on different domains in reasoning and factual validity\n\n\n### Links\n- [GitHub](https://github.com/composable-models/llm_multiagent_debate)\n- [Project page](https://composable-models.github.io/llm_debate/)\n- [Paper](https://arxiv.org/abs/2305.14325)\n\n</details>\n\n\n## [Multi GPT](https://github.com/rumpfmax/Multi-GPT)\nExperimental multi-agent system\n\n<details>\n\n ![image](https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png)\n\n### Category\nGeneral purpose\n\n### Description\n- An experimental open-source attempt to make GPT-4 fully autonomous\n- Multiple "expertGPTs" collaborate to perform a task\n- Each with their own short and long-term memory and the ability to communicate with each other\n- Features\n	- Set a task and watch the experts get to work.\n	- Internet access for searches and information gathering\n	- Long-Term and Short-Term memory management\n	- GPT-4 instances for text generation\n	- Access to popular websites and platforms\n	- File storage and summarization with GPT-3.5\n\n### Links\n- [Demo](https://www.loom.com/share/b6bec93065794eb8a47e2109697afa39)\n- Authors: [Max Rumpf](https://twitter.com/md_rumpf) and [Significant Gravitas](https://twitter.com/SigGravitas)\n\n</details>\n\n## [MutahunterAI](https://github.com/codeintegrity-ai/mutahunter)\nMutahunterAI: Accelerate developer productivity and code security with our open-source AI\n\n<details>\n\n![Image](https://avatars.githubusercontent.com/u/152569327?s=48&v=4)\n\n### Category\nDeveloper tools, Software security, Multi-agent, General purpose\n\n### Description\n- Use Mutahunter to generate unit tests for your codebase, that specifically target the code vulnerabilities. By targeting the exact weaknesses in the code, we boost developer productivity.\n- Unlike copilots which blindly generates test cases for your code, Mutahunter makes use of our mutation testing engine to generate unit tests that specifically target the vulnerabilities in your code\n- Features\n	- Support all major languages.\n	- We can be used locally or can be integrated into any CI/CD runner as part of your existing workflow\n	- You can use Mutahunter with your own LLM APIs for privacy.\n\n### Links\n- [Documentation](https://github.com/codeintegrity-ai/mutahunter?tab=readme-ov-file#mutahunter) \n- [Discord](https://discord.gg/9P5V9qmKJn)\n- [GitHub](https://github.com/codeintegrity-ai/mutahunter)\n</details>\n\n## [NLSOM](https://github.com/mczhuge/NLSOM)\nNatural Language-Based Societies of Mind\n<details>\n\n ![image](https://github.com/mczhuge/NLSOM/raw/main/assets/nlsom.svg)\n\n### Category\nScience, Multimodal, Social, Multi-agent\n\n### Description\n- Natural Language-Based Societies of Mind - concept with societies and communities of agents\n- Concept, which contains societies and communities of agents\n- Agents can be either LLMs, NN-based experts, APIs and role-players. They all communicate in natural language.\n- To solve tasks, these agents use a collaborative "Mindstorm" process involving mutual interviews.\n- Additional components for NLSOM can be easily added in a modular way.\n- "What magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle." ‚Äî Marvin Minsky, The Society of Mind, p. 308\n\n### Links\n- [GitHub](https://github.com/mczhuge/NLSOM)\n- [Paper](https://arxiv.org/pdf/2305.17066.pdf)\n- [Author''s X - J√ºrgen Schmidhuber](https://twitter.com/SchmidhuberAI)\n- [Author''s X - Mingchen Zhuge](https://twitter.com/MingchenZhuge)\n\n</details>\n\n## [OpenAgents](https://github.com/xlang-ai/OpenAgents)\nMulti-agent general purpose platform\n<details>\n\n ![image](https://github.com/xlang-ai/OpenAgents/raw/main/pics/openagents_overview.png)\n\n### Category\nGeneral purpose\n\n### Description\nOpenAgents is an Open Platform for Language Agents in the Wild, ChatGPT Plus Replica for Researchers, Developers, and General Users.\n- User-centric\n	- Chat Web UI\n	- Productive Agents\n	- Online Demo\n- Fully open-sourced\n	- Full-stack\n	- Easy deployment\n- Extensible\n	- LLMs\n	- Tools\n	- Agent methods\n\n### Links\n- [GitHub](https://github.com/xlang-ai/OpenAgents)\n- [Paper](https://arxiv.org/abs/2310.10634)\n- [Demo](https://chat.xlang.ai/)\n\n</details>\n\n\n## [OpenAGI](https://github.com/agiresearch/OpenAGI)\nR&D agents platform\n\n<details>\n\n ![image](https://github.com/agiresearch/OpenAGI/raw/main/images/illustration.png)\n\n### Category\nGeneral purpose\n\n### Description\nOpenAGI is an open-source AGI R&D platform that enables agents for both benchmark tasks and open-ended tasks\n- Powered by various language models such as GPT-4, Vicuna, LLaMA, and Flan-T5\n- Supports multi-modality tool learning and task solving such as text, image, video and audio\n- Supports task decomposition into both linear task-solving plans and non-linear task-solving plans\n- Allows both benchmark task solving and open-ended task solving\n- Provides easy-to-use evaluation protocols to evaluate task-solving ability\n- Provide Reinforcement Learning from Task Feedback (RLTF) to allow continuously self-improving agent\n\n### Links\n- [GitHub](https://github.com/agiresearch/OpenAGI)\n- [Paper](https://arxiv.org/abs/2304.04370)\n- [Demo](https://www.youtube.com/watch?v=7RaXPPXi0-Y)\n\n</details>\n\n## [OpenDevin](https://github.com/OpenDevin/OpenDevin)\nOpenDevin: Code Less, Make More\n\n<details>\n\n![Image](https://github.com/OpenDevin/OpenDevin/raw/main/logo.png)\n### Category\nCoding, general purpose\n\n### Description\n-  The OpenDevin project is born out of a desire to replicate, enhance, and innovate beyond the original Devin model.\n-  By engaging the open-source community, we aim to tackle the challenges faced by Code LLMs in practical scenarios, producing works that significantly contribute to the community and pave the way for future advancements.\n\n\n### Links\n- [GitHub](https://github.com/OpenDevin/OpenDevin)\n\n</details>\n\n\n## [Open Interpreter](https://openinterpreter.com/)\nCode interpreter that lets LLMs execute code\n\n<details>\n\n ![image](https://openinterpreter.com/assets/ncu_thumbnail.jpg)\n\n### Category\nCoding\n\n### Description\nOpen Interpreter is an open-source interpreter that lets LLMs run code on your computer to complete tasks\n- Runs locally\n- Can for example summarize PDFs, visualize datasets, control your browser\n- Works from a ChatGPT-like interface in your terminal.\n\n### Links\n- [Web](https://openinterpreter.com/)\n- [GitHub](https://github.com/KillianLucas/open-interpreter)\n- [Author''s Twitter](https://twitter.com/hellokillian)\n\n</details>\n\n## [Pezzo](https://www.pezzo.ai/)\nDevelopment toolkit for prompt management & more\n\n<details>\n\n ![image](https://www.pezzo.ai/_next/static/media/Logo.b7e3878b.svg)\n\n### Category\nCoding\n\n### Description\nPezzo is a development toolkit designed to streamline prompt design, version management, publishing, collaboration, troubleshooting, observability and more\n- "Whether you are a technical person or a stakeholder, you can use Pezzo effectively. We don''t believe that AI prompts should be designed in a developer''s code editor. Aside from the technical issues with this approach, it blocks productivity."\n- Features\n	- Centralized Prompt Management: Manage all AI prompts in one place for maximum visibility and efficiency.\n	- Streamlined Prompt Design, Publishing & Versioning: Create, edit, test and publish prompts with ease.\n	- Observability: Access detailed prompt execution history, stats and metrics (duration, prompt cost, completion cost, etc.) for better insights.\n	- Troubleshooting: Effortlessly resolve issues with your prompts. Time travel to retroactively fine-tune failed prompts and commit the fix instantly.\n	- Cost Transparency: Gain comprehensive cost transparency across all prompts and AI models.\n	- Simplified Integration: Reduce code overhead by 90% by consuming your AI prompts using the Pezzo Client, regardless of the model provider.\n\n### Links\n- [Documentation](https://docs.pezzo.ai/docs/intro.html)\n- [GitHub](https://github.com/pezzolabs/pezzo)\n</details>\n\n## [Private GPT](https://www.privategpt.io/)\nTool for private interaction with your documents\n\n<details>\n\n![image](https://assets-global.website-files.com/6408872e49e0944a088f17c1/640f3c6e8640895f2cbf95ba_logo%20full.svg)\n\n### Category\nResearch, Data analysis\n\n### Description\nPrivate GPT is A tool for private interaction with documents, without a need for internet connection\n- Built with LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformers\n- A test project to validate the feasibility of a fully private solution for question answering using LLMs and Vector embeddings, not production ready\n\n\n### Links\n- [GitHub](https://github.com/imartinez/privateGPT)\n\n</details>\n\n## [PromethAI](https://github.com/topoteretes/PromethAI-Backend)\nAI agent that helps with nutrition and other goals\n\n<details>\n\n![image](https://avatars.githubusercontent.com/u/125468716?s=280&v=4)\n### Category\nProductivity, General purpose\n\n### Description\n- "Personalized AI assistant that decomposes problems, offers solutions, and lets you use Agent actions to automate your flows"\n- Features\n  	- Helps users reach a solution by decomposing their requests into categories with a set of options (cuisine -> European)\n  	- Has a dynamic UX/UI that helps avoid prompting\n  	- Voice input supported\n  	- Provides users with results of their queries and automates actions around them\n  	- Remembers your past preferences and uses them to optimize your choices\n- Tech\n	- Powered by Langchain, decomposable async prompts + vector DB + Redis cache\n 	- App built with Flutter + Dart\n    	- Connected to Zapier NLP\n\n### Links\n- [GitHub](https://github.com/topoteretes/)\n- [Website](https://prometh.ai)\n- Author: [Vasilije M](https://twitter.com/tricalt)\n</details>\n\n\n## [React Agent](https://reactagent.io/)\nOpen-source React.js Autonomous LLM Agent\n<details>\n\n![image](https://reactagent.io/logo-dark.png)\n\n### Category\nCoding\n\n## Description\n- An experimental autonomous agent\n- Model: GPT-4\n- Purpose: Gnerate and compose React components from user stories\n- Stack\n	- React\n	- TailwindCSS\n	- Typescript\n	- Radix UI\n	- Shandcn UI\n	- OpenAI API\n- The agent is taking a user story text and generating and composing multiple react components to generate the relevant screens, based on atomic design principles\n- Features\n	- Generate React Components from user stories\n	- Compose React Components from existing components\n	- Use a local design system to generate React Components\n	- Use React, TailwindCSS, Typescript, Radix UI, Shandcn UI\n	- Built with Atomic Design Principles\n- It is still experimental but very interesting results, It is completely open-sourced, looking for contributors!\n\n## Links\n- [GitHub](https://github.com/eylonmiz/react-agent)\n- [Documentation](https://docs.reactagent.io/)\n- Authors: [Eylon Miz and](https://twitter.com/EylonMiz) and [Lee Twito](https://twitter.com/LeeTwito)\n\n</details>\n\n## [Self-operating computer](https://www.hyperwriteai.com/self-operating-computer)\nLet multimodal models operate a computer\n\n<details>\n\n![image](https://assets-global.website-files.com/63fcd79d410b22ddf397e1b8/654272554402410a71c84ab9_6405c1cabdf9c69f05b1080e_otherside_logo_symbol.webp)\n\n### Category\nProductivity, Research\n\n### Description\n- Using the same inputs and outputs as a human operator, the model views the screen and decides on a series of mouse and keyboard actions to reach an objective.\n\n### Links\n- [Web](https://www.hyperwriteai.com/self-operating-computer)\n- [GitHub](https://github.com/OthersideAI/self-operating-computer)\n\n</details>\n\n## [Smol developer](https://github.com/smol-ai/developer)\nYour own junior AI developer, deployed via E2B UI\n\n<details>\n\n![image](https://smol.ai/logo.png)\n\n### Category\nCoding\n\n### Description\nSmol is your own junior developer. [Deployed in few seconds via e2b](https://app.e2b.dev/agent/smol-developer/?utm_source=awesome-ai-agents)\n- Human-centric, coherent whole program synthesis\n- Your own junior developer\n- Allows to develop, debug, and decompile\n- 200 LOC, half english\n- 100k context can summarize both content and codebases\n- Markdown is the best prompting DSL\n- Copy and paste your errors as prompts\n- Copy and paste curl output as prompts\n- Write CSS animation by describing what u want\n- GPT4 >>> GPT3.5/Anthropic Claude for codegen\n\n### Links\n- Author: [Swyx](https://twitter.com/swyx)\n- [Demo](https://www.youtube.com/watch?v=UCo7YeTy-aE)\n- [Twitter](https://twitter.com/SmolModels)\n- [Meme](https://smol.ai/)\n\n</details>\n\n## [Stackwise](https://github.com/stackwiseai/stackwise)\nVSCode extension that writes nodejs functions\n\n<details>\n\n![image](https://pbs.twimg.com/profile_images/1723911660232945664/CtumfUuB_400x400.jpg)\n\n### Category\nTool for agents, Coding\n\n### Description\nStackwise is a VS Code extension that writes and imports nodejs functions so that you can write code without context switching\n- The open source function collection\n- Explain what you want a function to do, and AI builds it.\n- Stackwise is a VS Code extension that automatically writes and imports nodejs functions so that you can write code without context switching. No more hunting for documentation to integrate with APIs or back and forth with ChatGPT. Just pure functionality within your code!\n\n### Links\n- [GitHub](https://github.com/stackwiseai/stackwise)\n- [X](https://twitter.com/stackwiseai)\n- [Founder''s X - Wayne](https://twitter.com/merwanehamadi)\n- [Founder''s X - Silen Naihin](https://twitter.com/silennai)\n\n</details>\n\n## [Superagent](https://www.superagent.sh/)</details>\nTool that allows creating agents without coding\n\n<details>\n\n![image](https://api.typedream.com/v0/document/public/b9d688ba-8f34-40e4-a24a-c', '{"language":null,"stars":24527,"forks":2057,"watchers":24527,"open_issues":85,"topics":["agent","ai","artificial-intelligence","autogpt","autonomous-agents","awesome","babyagi","copilot","gpt","gpt-4","gpt-engineer","openai","python"],"default_branch":"main","size_kb":117748,"archived":false,"fork":false,"has_wiki":false,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:e2b-dev:awesome-sdks-for-ai-agents\">the","source_url":"https://github.com/e2b-dev/awesome-sdks-for-ai-agents\">the"},{"type":"has_code","target_id":"github:e2b-dev:awesome-sdks-for-ai-agents","source_url":"https://github.com/e2b-dev/awesome-sdks-for-ai-agents"},{"type":"has_code","target_id":"github:e2b-dev:e2b","source_url":"https://github.com/e2b-dev/e2b"},{"type":"has_code","target_id":"github:e2b-dev:e2b-cookbook","source_url":"https://github.com/e2b-dev/e2b-cookbook"},{"type":"has_code","target_id":"github:HumanSignal:Adala","source_url":"https://github.com/HumanSignal/Adala"},{"type":"has_code","target_id":"github:HumanSignal:Adala","source_url":"https://github.com/HumanSignal/Adala"},{"type":"has_code","target_id":"github:HumanSignal:Adala","source_url":"https://github.com/HumanSignal/Adala"},{"type":"has_code","target_id":"github:LehengTHU:Agent4Rec","source_url":"https://github.com/LehengTHU/Agent4Rec"},{"type":"has_code","target_id":"github:LehengTHU:Agent4Rec","source_url":"https://github.com/LehengTHU/Agent4Rec"},{"type":"has_code","target_id":"github:DataBassGit:AgentForge","source_url":"https://github.com/DataBassGit/AgentForge"},{"type":"has_code","target_id":"github:DataBassGit:AgentForge","source_url":"https://github.com/DataBassGit/AgentForge"},{"type":"has_code","target_id":"github:reworkd:AgentGPT","source_url":"https://github.com/reworkd/AgentGPT"},{"type":"has_code","target_id":"github:jbexta:AgentPilot","source_url":"https://github.com/jbexta/AgentPilot"},{"type":"has_code","target_id":"github:jbexta:AgentPilot","source_url":"https://github.com/jbexta/AgentPilot"},{"type":"has_code","target_id":"github:jbexta:AgentPilot","source_url":"https://github.com/jbexta/AgentPilot"},{"type":"has_code","target_id":"github:aiwaves-cn:agents","source_url":"https://github.com/aiwaves-cn/agents"},{"type":"has_code","target_id":"github:aiwaves-cn:agents","source_url":"https://github.com/aiwaves-cn/agents"},{"type":"has_code","target_id":"github:aiwaves-cn:agents","source_url":"https://github.com/aiwaves-cn/agents"},{"type":"has_code","target_id":"github:aiwaves-cn:agents","source_url":"https://github.com/aiwaves-cn/agents"},{"type":"has_code","target_id":"github:OpenBMB:AgentVerse","source_url":"https://github.com/OpenBMB/AgentVerse"},{"type":"has_code","target_id":"github:eumemic:ai-legion","source_url":"https://github.com/eumemic/ai-legion"},{"type":"has_code","target_id":"github:eumemic:ai-legion","source_url":"https://github.com/eumemic/ai-legion"},{"type":"has_code","target_id":"github:paul-gauthier:aider","source_url":"https://github.com/paul-gauthier/aider"},{"type":"has_code","target_id":"github:myshell-ai:AIlice","source_url":"https://github.com/myshell-ai/AIlice"},{"type":"has_code","target_id":"github:myshell-ai:AIlice","source_url":"https://github.com/myshell-ai/AIlice"},{"type":"has_code","target_id":"github:myshell-ai:AIlice","source_url":"https://github.com/myshell-ai/AIlice"},{"type":"has_code","target_id":"github:microsoft:autogen","source_url":"https://github.com/microsoft/autogen"},{"type":"has_code","target_id":"github:microsoft:autogen","source_url":"https://github.com/microsoft/autogen"},{"type":"has_code","target_id":"github:Significant-Gravitas:Auto-GPT","source_url":"https://github.com/Significant-Gravitas/Auto-GPT"},{"type":"has_code","target_id":"github:emrgnt-cmplxty:automata","source_url":"https://github.com/emrgnt-cmplxty/automata"},{"type":"has_code","target_id":"github:emrgnt-cmplxty:Automata","source_url":"https://github.com/emrgnt-cmplxty/Automata"},{"type":"has_code","target_id":"github:emrgnt-cmplxty:automata","source_url":"https://github.com/emrgnt-cmplxty/automata"},{"type":"has_code","target_id":"github:irgolic:AutoPR","source_url":"https://github.com/irgolic/AutoPR"},{"type":"has_code","target_id":"github:irgolic:AutoPR","source_url":"https://github.com/irgolic/AutoPR"},{"type":"has_code","target_id":"github:stepanogil:autonomous-hr-chatbot","source_url":"https://github.com/stepanogil/autonomous-hr-chatbot"},{"type":"has_code","target_id":"github:stepanogil:autonomous-hr-chatbot","source_url":"https://github.com/stepanogil/autonomous-hr-chatbot"},{"type":"has_code","target_id":"github:stepanogil:autonomous-hr-chatbot","source_url":"https://github.com/stepanogil/autonomous-hr-chatbot"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:saten-private:BabyCommandAGI","source_url":"https://github.com/saten-private/BabyCommandAGI"},{"type":"has_code","target_id":"github:saten-private:BabyCommandAGI","source_url":"https://github.com/saten-private/BabyCommandAGI"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:yoheinakajima:babyagi","source_url":"https://github.com/yoheinakajima/babyagi"},{"type":"has_code","target_id":"github:pgalko:BambooAI","source_url":"https://github.com/pgalko/BambooAI"},{"type":"has_code","target_id":"github:pgalko:BambooAI","source_url":"https://github.com/pgalko/BambooAI"},{"type":"has_code","target_id":"github:AutoPackAI:beebot","source_url":"https://github.com/AutoPackAI/beebot"},{"type":"has_code","target_id":"github:AutoPackAI:beebot","source_url":"https://github.com/AutoPackAI/beebot"},{"type":"has_code","target_id":"github:seahyinghang8:blinky","source_url":"https://github.com/seahyinghang8/blinky"},{"type":"has_code","target_id":"github:seahyinghang8:blinky","source_url":"https://github.com/seahyinghang8/blinky"},{"type":"has_code","target_id":"github:seahyinghang8:blinky","source_url":"https://github.com/seahyinghang8/blinky"},{"type":"has_code","target_id":"github:BloopAI:bloop","source_url":"https://github.com/BloopAI/bloop"},{"type":"has_code","target_id":"github:BloopAI:bloop","source_url":"https://github.com/BloopAI/bloop"},{"type":"has_code","target_id":"github:krohling:bondai","source_url":"https://github.com/krohling/bondai"},{"type":"has_code","target_id":"github:xeol-io:bumpgen","source_url":"https://github.com/xeol-io/bumpgen"},{"type":"has_code","target_id":"github:xeol-io:bumpgen","source_url":"https://github.com/xeol-io/bumpgen"},{"type":"has_code","target_id":"github:calcom:cal.com","source_url":"https://github.com/calcom/cal.com"},{"type":"has_code","target_id":"github:calcom:cal.com","source_url":"https://github.com/calcom/cal.com"},{"type":"has_code","target_id":"github:camel-ai:camel","source_url":"https://github.com/camel-ai/camel"},{"type":"has_code","target_id":"github:camel-ai:camel","source_url":"https://github.com/camel-ai/camel"},{"type":"has_code","target_id":"github:Farama-Foundation:chatarena","source_url":"https://github.com/Farama-Foundation/chatarena"},{"type":"has_code","target_id":"github:Farama-Foundation:chatarena","source_url":"https://github.com/Farama-Foundation/chatarena"},{"type":"has_code","target_id":"github:OpenBMB:ChatDev","source_url":"https://github.com/OpenBMB/ChatDev"},{"type":"has_code","target_id":"github:OpenBMB:ChatDev","source_url":"https://github.com/OpenBMB/ChatDev"},{"type":"has_code","target_id":"github:OpenBMB:ChatDev","source_url":"https://github.com/OpenBMB/ChatDev"},{"type":"has_code","target_id":"github:OpenBMB:ChatDev","source_url":"https://github.com/OpenBMB/ChatDev"},{"type":"has_code","target_id":"github:ur-whitelab:chemcrow-public","source_url":"https://github.com/ur-whitelab/chemcrow-public"},{"type":"has_code","target_id":"github:ur-whitelab:chemcrow-public","source_url":"https://github.com/ur-whitelab/chemcrow-public"},{"type":"has_code","target_id":"github:ur-whitelab:chemcrow-public","source_url":"https://github.com/ur-whitelab/chemcrow-public"},{"type":"has_code","target_id":"github:ennucore:clippy","source_url":"https://github.com/ennucore/clippy"},{"type":"has_code","target_id":"github:ennucore:clippy","source_url":"https://github.com/ennucore/clippy"},{"type":"has_code","target_id":"github:codefuse-ai:codefuse-chatbot","source_url":"https://github.com/codefuse-ai/codefuse-chatbot"},{"type":"has_code","target_id":"github:codefuse-ai:codefuse-chatbot","source_url":"https://github.com/codefuse-ai/codefuse-chatbot"},{"type":"has_code","target_id":"github:codefuse-ai:codefuse-chatbot","source_url":"https://github.com/codefuse-ai/codefuse-chatbot"},{"type":"has_code","target_id":"github:ajhous44:cody","source_url":"https://github.com/ajhous44/cody"},{"type":"has_code","target_id":"github:ajhous44:cody","source_url":"https://github.com/ajhous44/cody"},{"type":"has_code","target_id":"github:sourcegraph:sourcegraph","source_url":"https://github.com/sourcegraph/sourcegraph"},{"type":"has_code","target_id":"github:continuedev:continue","source_url":"https://github.com/continuedev/continue"},{"type":"has_code","target_id":"github:joaomdmoura:crewai","source_url":"https://github.com/joaomdmoura/crewai"},{"type":"has_code","target_id":"github:joaomdmoura:crewAI","source_url":"https://github.com/joaomdmoura/crewAI"},{"type":"has_code","target_id":"github:joaomdmoura:crewai","source_url":"https://github.com/joaomdmoura/crewai"},{"type":"has_code","target_id":"github:joaomdmoura:CrewAI","source_url":"https://github.com/joaomdmoura/CrewAI"},{"type":"has_code","target_id":"github:joaomdmoura:CrewAI","source_url":"https://github.com/joaomdmoura/CrewAI"},{"type":"has_code","target_id":"github:Technion-Kishony-lab:data-to-paper","source_url":"https://github.com/Technion-Kishony-lab/data-to-paper"},{"type":"has_code","target_id":"github:Technion-Kishony-lab:data-to-paper","source_url":"https://github.com/Technion-Kishony-lab/data-to-paper"},{"type":"has_code","target_id":"github:Technion-Kishony-lab:data-to-paper","source_url":"https://github.com/Technion-Kishony-lab/data-to-paper"},{"type":"has_code","target_id":"github:gmpetrov:databerry","source_url":"https://github.com/gmpetrov/databerry"},{"type":"has_code","target_id":"github:melih-unsal:DemoGPT","source_url":"https://github.com/melih-unsal/DemoGPT"},{"type":"has_code","target_id":"github:melih-unsal:DemoGPT","source_url":"https://github.com/melih-unsal/DemoGPT"},{"type":"has_code","target_id":"github:melih-unsal:DemoGPT","source_url":"https://github.com/melih-unsal/DemoGPT"},{"type":"has_code","target_id":"github:jina-ai:dev-gpt","source_url":"https://github.com/jina-ai/dev-gpt"},{"type":"has_code","target_id":"github:stitionai:devika","source_url":"https://github.com/stitionai/devika"},{"type":"has_code","target_id":"github:stitionai:devika","source_url":"https://github.com/stitionai/devika"},{"type":"has_code","target_id":"github:stitionai:devika","source_url":"https://github.com/stitionai/devika"},{"type":"has_code","target_id":"github:entropy-research:Devon","source_url":"https://github.com/entropy-research/Devon"},{"type":"has_code","target_id":"github:entropy-research:Devon","source_url":"https://github.com/entropy-research/Devon"},{"type":"has_code","target_id":"github:kuafuai:DevOpsGPT","source_url":"https://github.com/kuafuai/DevOpsGPT"},{"type":"has_code","target_id":"github:kuafuai:DevOpsGPT","source_url":"https://github.com/kuafuai/DevOpsGPT"},{"type":"has_code","target_id":"github:dot-agent:dotagent","source_url":"https://github.com/dot-agent/dotagent"},{"type":"has_code","target_id":"github:eidolon-ai:eidolon","source_url":"https://github.com/eidolon-ai/eidolon"},{"type":"has_code","target_id":"github:uilicious:english-compiler","source_url":"https://github.com/uilicious/english-compiler"},{"type":"has_code","target_id":"github:uilicious:english-compiler","source_url":"https://github.com/uilicious/english-compiler"},{"type":"has_code","target_id":"github:polywrap:evo.ninja","source_url":"https://github.com/polywrap/evo.ninja"},{"type":"has_code","target_id":"github:airtai:fastagency","source_url":"https://github.com/airtai/fastagency"},{"type":"has_code","target_id":"github:FlowiseAI:Flowise","source_url":"https://github.com/FlowiseAI/Flowise"},{"type":"has_code","target_id":"github:amirrezasalimi:friday","source_url":"https://github.com/amirrezasalimi/friday"},{"type":"has_code","target_id":"github:amirrezasalimi:friday","source_url":"https://github.com/amirrezasalimi/friday"},{"type":"has_code","target_id":"github:genia-dev:GeniA","source_url":"https://github.com/genia-dev/GeniA"},{"type":"has_code","target_id":"github:genia-dev:GeniA","source_url":"https://github.com/genia-dev/GeniA"},{"type":"has_code","target_id":"github:FOLLGAD:Godmode-GPT","source_url":"https://github.com/FOLLGAD/Godmode-GPT"},{"type":"has_code","target_id":"github:Kav-K:GPTDiscord","source_url":"https://github.com/Kav-K/GPTDiscord"},{"type":"has_code","target_id":"github:Kav-K:GPTDiscord","source_url":"https://github.com/Kav-K/GPTDiscord"},{"type":"has_code","target_id":"github:AntonOsika:gpt-engineer","source_url":"https://github.com/AntonOsika/gpt-engineer"},{"type":"has_code","target_id":"github:0xpayne:gpt-migrate","source_url":"https://github.com/0xpayne/gpt-migrate"},{"type":"has_code","target_id":"github:0xpayne:gpt-migrate","source_url":"https://github.com/0xpayne/gpt-migrate#-benchmarks"},{"type":"has_code","target_id":"github:Pythagora-io:gpt-pilot","source_url":"https://github.com/Pythagora-io/gpt-pilot"},{"type":"has_code","target_id":"github:Pythagora-io:gpt-pilot","source_url":"https://github.com/Pythagora-io/gpt-pilot"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"},{"type":"has_code","target_id":"github:nicepkg:gpt-runner","source_url":"https://github.com/nicepkg/gpt-runner"},{"type":"has_code","target_id":"github:nicepkg:gpt-runner","source_url":"https://github.com/nicepkg/gpt-runner"},{"type":"has_code","target_id":"github:metauto-ai:GPTSwarm","source_url":"https://github.com/metauto-ai/GPTSwarm"},{"type":"has_code","target_id":"github:kreneskyp:ix","source_url":"https://github.com/kreneskyp/ix"},{"type":"has_code","target_id":"github:kreneskyp:ix","source_url":"https://github.com/kreneskyp/ix"},{"type":"has_code","target_id":"github:microsoft:JARVIS","source_url":"https://github.com/microsoft/JARVIS"},{"type":"has_code","target_id":"github:microsoft:JARVIS","source_url":"https://github.com/microsoft/JARVIS"},{"type":"has_code","target_id":"github:langroid:langroid","source_url":"https://github.com/langroid/langroid"},{"type":"has_code","target_id":"github:langroid:langroid","source_url":"https://github.com/langroid/langroid"},{"type":"has_code","target_id":"github:felixbrock:lemon-agent","source_url":"https://github.com/felixbrock/lemon-agent"},{"type":"has_code","target_id":"github:mpaepper:llm_agents","source_url":"https://github.com/mpaepper/llm_agents"},{"type":"has_code","target_id":"github:mpaepper:llm_agents","source_url":"https://github.com/mpaepper/llm_agents"},{"type":"has_code","target_id":"github:trypromptly:LLMStack","source_url":"https://github.com/trypromptly/LLMStack"},{"type":"has_code","target_id":"github:PromtEngineer:localGPT","source_url":"https://github.com/PromtEngineer/localGPT"},{"type":"has_code","target_id":"github:PromtEngineer:localGPT","source_url":"https://github.com/PromtEngineer/localGPT"},{"type":"has_code","target_id":"github:farizrahman4u:loopgpt","source_url":"https://github.com/farizrahman4u/loopgpt"},{"type":"has_code","target_id":"github:farizrahman4u:loopgpt","source_url":"https://github.com/farizrahman4u/loopgpt"},{"type":"has_code","target_id":"github:samholt:l2mac","source_url":"https://github.com/samholt/l2mac"},{"type":"has_code","target_id":"github:samholt:l2mac","source_url":"https://github.com/samholt/l2mac"},{"type":"has_code","target_id":"github:RubricLab:maige","source_url":"https://github.com/RubricLab/maige"},{"type":"has_code","target_id":"github:Oneirocom:Magick","source_url":"https://github.com/Oneirocom/Magick"},{"type":"has_code","target_id":"github:memfreeme:memfree","source_url":"https://github.com/memfreeme/memfree"},{"type":"has_code","target_id":"github:cpacker:MemGPT","source_url":"https://github.com/cpacker/MemGPT"},{"type":"has_code","target_id":"github:biobootloader:mentat","source_url":"https://github.com/biobootloader/mentat"},{"type":"has_code","target_id":"github:geekan:MetaGPT","source_url":"https://github.com/geekan/MetaGPT"},{"type":"has_code","target_id":"github:geekan:MetaGPT","source_url":"https://github.com/geekan/MetaGPT"},{"type":"has_code","target_id":"github:geekan:MetaGPT","source_url":"https://github.com/geekan/MetaGPT"},{"type":"has_code","target_id":"github:muellerberndt:mini-agi","source_url":"https://github.com/muellerberndt/mini-agi"},{"type":"has_code","target_id":"github:muellerberndt:mini-agi","source_url":"https://github.com/muellerberndt/mini-agi"},{"type":"has_code","target_id":"github:muellerberndt:mini-agi","source_url":"https://github.com/muellerberndt/mini-agi"},{"type":"has_code","target_id":"github:composable-models:llm_multiagent_debate","source_url":"https://github.com/composable-models/llm_multiagent_debate"},{"type":"has_code","target_id":"github:composable-models:llm_multiagent_debate","source_url":"https://github.com/composable-models/llm_multiagent_debate"},{"type":"has_code","target_id":"github:rumpfmax:Multi-GPT","source_url":"https://github.com/rumpfmax/Multi-GPT"},{"type":"has_code","target_id":"github:codeintegrity-ai:mutahunter","source_url":"https://github.com/codeintegrity-ai/mutahunter"},{"type":"has_code","target_id":"github:codeintegrity-ai:mutahunter","source_url":"https://github.com/codeintegrity-ai/mutahunter?tab=readme-ov-file#mutahunter"},{"type":"has_code","target_id":"github:codeintegrity-ai:mutahunter","source_url":"https://github.com/codeintegrity-ai/mutahunter"},{"type":"has_code","target_id":"github:mczhuge:NLSOM","source_url":"https://github.com/mczhuge/NLSOM"},{"type":"has_code","target_id":"github:mczhuge:NLSOM","source_url":"https://github.com/mczhuge/NLSOM"},{"type":"has_code","target_id":"github:mczhuge:NLSOM","source_url":"https://github.com/mczhuge/NLSOM"},{"type":"has_code","target_id":"github:xlang-ai:OpenAgents","source_url":"https://github.com/xlang-ai/OpenAgents"},{"type":"has_code","target_id":"github:xlang-ai:OpenAgents","source_url":"https://github.com/xlang-ai/OpenAgents"},{"type":"has_code","target_id":"github:xlang-ai:OpenAgents","source_url":"https://github.com/xlang-ai/OpenAgents"},{"type":"has_code","target_id":"github:agiresearch:OpenAGI","source_url":"https://github.com/agiresearch/OpenAGI"},{"type":"has_code","target_id":"github:agiresearch:OpenAGI","source_url":"https://github.com/agiresearch/OpenAGI"},{"type":"has_code","target_id":"github:agiresearch:OpenAGI","source_url":"https://github.com/agiresearch/OpenAGI"},{"type":"has_code","target_id":"github:OpenDevin:OpenDevin","source_url":"https://github.com/OpenDevin/OpenDevin"},{"type":"has_code","target_id":"github:OpenDevin:OpenDevin","source_url":"https://github.com/OpenDevin/OpenDevin"},{"type":"has_code","target_id":"github:OpenDevin:OpenDevin","source_url":"https://github.com/OpenDevin/OpenDevin"},{"type":"has_code","target_id":"github:KillianLucas:open-interpreter","source_url":"https://github.com/KillianLucas/open-interpreter"},{"type":"has_code","target_id":"github:pezzolabs:pezzo","source_url":"https://github.com/pezzolabs/pezzo"},{"type":"has_code","target_id":"github:imartinez:privateGPT","source_url":"https://github.com/imartinez/privateGPT"},{"type":"has_code","target_id":"github:topoteretes:PromethAI-Backend","source_url":"https://github.com/topoteretes/PromethAI-Backend"},{"type":"has_code","target_id":"github:eylonmiz:react-agent","source_url":"https://github.com/eylonmiz/react-agent"},{"type":"has_code","target_id":"github:OthersideAI:self-operating-computer","source_url":"https://github.com/OthersideAI/self-operating-computer"},{"type":"has_code","target_id":"github:smol-ai:developer","source_url":"https://github.com/smol-ai/developer"},{"type":"has_code","target_id":"github:stackwiseai:stackwise","source_url":"https://github.com/stackwiseai/stackwise"},{"type":"has_code","target_id":"github:stackwiseai:stackwise","source_url":"https://github.com/stackwiseai/stackwise"}]', NULL, 'NOASSERTION', 'approved', 80, '148bf8a899fb466c9201ba282743934e', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-e2b-dev-awesome-ai-agents from https://github.com/e2b-dev.png
Image converted to WebP: data/images/github-e2b-dev-awesome-ai-agents.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-assafelovic-gpt-researcher', 'github--assafelovic--gpt-researcher', 'gpt-researcher', 'assafelovic', '<div align="center" id="top"> <img src="https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3" alt="Logo" width="80"> !GitHub Release English | ‰∏≠Êñá | Êó•Êú¨Ë™û | ÌïúÍµ≠Ïñ¥ </div> **GPT Researcher is an open deep research agent designed for both web and local research on any given task.** The agent produces detailed, factual, and unbiased research reports with citations. GPT Researcher provides a full suite of customization options to create tailor made and doma...', '["agent","ai","automation","deepresearch","llms","mcp","mcp-server","python","research","search","webscraping","python"]', 'other', 24430, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/assafelovic/gpt-researcher","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<div align="center" id="top">\n\n<img src="https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3" alt="Logo" width="80">\n\n####\n\n[![Website](https://img.shields.io/badge/Official%20Website-gptr.dev-teal?style=for-the-badge&logo=world&logoColor=white&color=0891b2)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev)\n[![Discord](https://img.shields.io/discord/1127851779011391548?logo=discord&logoColor=white&label=Discord&color=34b76a&style=for-the-badge)](https://discord.gg/QgZXvJAccX)\n\n\n[![PyPI version](https://img.shields.io/pypi/v/gpt-researcher?logo=pypi&logoColor=white&style=flat)](https://badge.fury.io/py/gpt-researcher)\n![GitHub Release](https://img.shields.io/github/v/release/assafelovic/gpt-researcher?style=flat&logo=github)\n[![Open In Colab](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&label=%20&style=flat&logoSize=40)](https://colab.research.google.com/github/assafelovic/gpt-researcher/blob/master/docs/docs/examples/pip-run.ipynb)\n[![Docker Image Version](https://img.shields.io/docker/v/elestio/gpt-researcher/latest?arch=amd64&style=flat&logo=docker&logoColor=white&color=1D63ED)](https://hub.docker.com/r/gptresearcher/gpt-researcher)\n[![Twitter Follow](https://img.shields.io/twitter/follow/assaf_elovic?style=social)](https://twitter.com/assaf_elovic)\n\n[English](README.md) | [‰∏≠Êñá](README-zh_CN.md) | [Êó•Êú¨Ë™û](README-ja_JP.md) | [ÌïúÍµ≠Ïñ¥](README-ko_KR.md)\n\n</div>\n\n# üîé GPT Researcher\n\n**GPT Researcher is an open deep research agent designed for both web and local research on any given task.** \n\nThe agent produces detailed, factual, and unbiased research reports with citations. GPT Researcher provides a full suite of customization options to create tailor made and domain specific research agents. Inspired by the recent [Plan-and-Solve](https://arxiv.org/abs/2305.04091) and [RAG](https://arxiv.org/abs/2005.11401) papers, GPT Researcher addresses misinformation, speed, determinism, and reliability by offering stable performance and increased speed through parallelized agent work.\n\n**Our mission is to empower individuals and organizations with accurate, unbiased, and factual information through AI.**\n\n## Why GPT Researcher?\n\n- Objective conclusions for manual research can take weeks, requiring vast resources and time.\n- LLMs trained on outdated information can hallucinate, becoming irrelevant for current research tasks.\n- Current LLMs have token limitations, insufficient for generating long research reports.\n- Limited web sources in existing services lead to misinformation and shallow results.\n- Selective web sources can introduce bias into research tasks.\n\n## Demo\n<a href="https://www.youtube.com/watch?v=f60rlc_QCxE" target="_blank" rel="noopener">\n  <img src="https://github.com/user-attachments/assets/ac2ec55f-b487-4b3f-ae6f-b8743ad296e4" alt="Demo video" width="800" target="_blank" />\n</a>\n\n\n## Architecture\n\nThe core idea is to utilize ''planner'' and ''execution'' agents. The planner generates research questions, while the execution agents gather relevant information. The publisher then aggregates all findings into a comprehensive report.\n\n<div align="center">\n<img align="center" height="600" src="https://github.com/assafelovic/gpt-researcher/assets/13554167/4ac896fd-63ab-4b77-9688-ff62aafcc527">\n</div>\n\nSteps:\n* Create a task-specific agent based on a research query.\n* Generate questions that collectively form an objective opinion on the task.\n* Use a crawler agent for gathering information for each question.\n* Summarize and source-track each resource.\n* Filter and aggregate summaries into a final research report.\n\n## Tutorials\n - [How it Works](https://docs.gptr.dev/blog/building-gpt-researcher)\n - [How to Install](https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea)\n - [Live Demo](https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8)\n\n## Features\n\n- üìù Generate detailed research reports using web and local documents.\n- üñºÔ∏è Smart image scraping and filtering for reports.\n- üìú Generate detailed reports exceeding 2,000 words.\n- üåê Aggregate over 20 sources for objective conclusions.\n- üñ•Ô∏è Frontend available in lightweight (HTML/CSS/JS) and production-ready (NextJS + Tailwind) versions.\n- üîç JavaScript-enabled web scraping.\n- üìÇ Maintains memory and context throughout research.\n- üìÑ Export reports to PDF, Word, and other formats.\n\n## üìñ Documentation\n\nSee the [Documentation](https://docs.gptr.dev/docs/gpt-researcher/getting-started) for:\n- Installation and setup guides\n- Configuration and customization options\n- How-To examples\n- Full API references\n\n## ‚öôÔ∏è Getting Started\n\n### Installation\n\n1. Install Python 3.11 or later. [Guide](https://www.tutorialsteacher.com/python/install-python).\n2. Clone the project and navigate to the directory:\n\n    ```bash\n    git clone https://github.com/assafelovic/gpt-researcher.git\n    cd gpt-researcher\n    ```\n\n3. Set up API keys by exporting them or storing them in a `.env` file.\n\n    ```bash\n    export OPENAI_API_KEY={Your OpenAI API Key here}\n    export TAVILY_API_KEY={Your Tavily API Key here}\n    ```\n\n    For custom OpenAI-compatible APIs (e.g., local models, other providers), you can also set:\n    \n    ```bash\n    export OPENAI_BASE_URL={Your custom API base URL here}\n    ```\n\n4. Install dependencies and start the server:\n\n    ```bash\n    pip install -r requirements.txt\n    python -m uvicorn main:app --reload\n    ```\n\nVisit [http://localhost:8000](http://localhost:8000) to start.\n\nFor other setups (e.g., Poetry or virtual environments), check the [Getting Started page](https://docs.gptr.dev/docs/gpt-researcher/getting-started).\n\n## Run as PIP package\n```bash\npip install gpt-researcher\n\n```\n### Example Usage:\n```python\n...\nfrom gpt_researcher import GPTResearcher\n\nquery = "why is Nvidia stock going up?"\nresearcher = GPTResearcher(query=query)\n# Conduct research on the given query\nresearch_result = await researcher.conduct_research()\n# Write the report\nreport = await researcher.write_report()\n...\n```\n\n**For more examples and configurations, please refer to the [PIP documentation](https://docs.gptr.dev/docs/gpt-researcher/gptr/pip-package) page.**\n\n### üîß MCP Client\nGPT Researcher supports MCP integration to connect with specialized data sources like GitHub repositories, databases, and custom APIs. This enables research from data sources alongside web search.\n\n```bash\nexport RETRIEVER=tavily,mcp  # Enable hybrid web + MCP research\n```\n\n```python\nfrom gpt_researcher import GPTResearcher\nimport asyncio\nimport os\n\nasync def mcp_research_example():\n    # Enable MCP with web search\n    os.environ["RETRIEVER"] = "tavily,mcp"\n    \n    researcher = GPTResearcher(\n        query="What are the top open source web research agents?",\n        mcp_configs=[\n            {\n                "name": "github",\n                "command": "npx",\n                "args": ["-y", "@modelcontextprotocol/server-github"],\n                "env": {"GITHUB_TOKEN": os.getenv("GITHUB_TOKEN")}\n            }\n        ]\n    )\n    \n    research_result = await researcher.conduct_research()\n    report = await researcher.write_report()\n    return report\n```\n\n> For comprehensive MCP documentation and advanced examples, visit the [MCP Integration Guide](https://docs.gptr.dev/docs/gpt-researcher/retrievers/mcp-configs).\n\n## ‚ú® Deep Research\n\nGPT Researcher now includes Deep Research - an advanced recursive research workflow that explores topics with agentic depth and breadth. This feature employs a tree-like exploration pattern, diving deeper into subtopics while maintaining a comprehensive view of the research subject.\n\n- üå≥ Tree-like exploration with configurable depth and breadth\n- ‚ö°Ô∏è Concurrent processing for faster results\n- ü§ù Smart context management across research branches\n- ‚è±Ô∏è Takes ~5 minutes per deep research\n- üí∞ Costs ~$0.4 per research (using `o3-mini` on "high" reasoning effort)\n\n[Learn more about Deep Research](https://docs.gptr.dev/docs/gpt-researcher/gptr/deep_research) in our documentation.\n\n## Run with Docker\n\n> **Step 1** - [Install Docker](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started-with-docker)\n\n> **Step 2** - Clone the ''.env.example'' file, add your API Keys to the cloned file and save the file as ''.env''\n\n> **Step 3** - Within the docker-compose file comment out services that you don''t want to run with Docker.\n\n```bash\ndocker-compose up --build\n```\n\nIf that doesn''t work, try running it without the dash:\n```bash\ndocker compose up --build\n```\n\n> **Step 4** - By default, if you haven''t uncommented anything in your docker-compose file, this flow will start 2 processes:\n - the Python server running on localhost:8000<br>\n - the React app running on localhost:3000<br>\n\nVisit localhost:3000 on any browser and enjoy researching!\n\n\n## üìÑ Research on Local Documents\n\nYou can instruct the GPT Researcher to run research tasks based on your local documents. Currently supported file formats are: PDF, plain text, CSV, Excel, Markdown, PowerPoint, and Word documents.\n\nStep 1: Add the env variable `DOC_PATH` pointing to the folder where your documents are located.\n\n```bash\nexport DOC_PATH="./my-docs"\n```\n\nStep 2: \n - If you''re running the frontend app on localhost:8000, simply select "My Documents" from the "Report Source" Dropdown Options.\n - If you''re running GPT Researcher with the [PIP package](https://docs.tavily.com/guides/gpt-researcher/gpt-researcher#pip-package), pass the `report_source` argument as "local" when you instantiate the `GPTResearcher` class [code sample here](https://docs.gptr.dev/docs/gpt-researcher/context/tailored-research).\n\n\n## ü§ñ MCP Server\n\nWe''ve moved our MCP server to a dedicated repository: [gptr-mcp](https://github.com/assafelovic/gptr-mcp).\n\nThe GPT Researcher MCP Server enables AI applications like Claude to conduct deep research. While LLM apps can access web search tools with MCP, GPT Researcher MCP delivers deeper, more reliable research results.\n\nFeatures:\n- Deep research capabilities for AI assistants\n- Higher quality information with optimized context usage\n- Comprehensive results with better reasoning for LLMs\n- Claude Desktop integration\n\nFor detailed installation and usage instructions, please visit the [official repository](https://github.com/assafelovic/gptr-mcp).\n\n\n## üë™ Multi-Agent Assistant\nAs AI evolves from prompt engineering and RAG to multi-agent systems, we''re excited to introduce our new multi-agent assistant built with [LangGraph](https://python.langchain.com/v0.1/docs/langgraph/).\n\nBy using LangGraph, the research process can be significantly improved in depth and quality by leveraging multiple agents with specialized skills. Inspired by the recent [STORM](https://arxiv.org/abs/2402.14207) paper, this project showcases how a team of AI agents can work together to conduct research on a given topic, from planning to publication.\n\nAn average run generates a 5-6 page research report in multiple formats such as PDF, Docx and Markdown.\n\nCheck it out [here](https://github.com/assafelovic/gpt-researcher/tree/master/multi_agents) or head over to our [documentation](https://docs.gptr.dev/docs/gpt-researcher/multi_agents/langgraph) for more information.\n\n## üñ•Ô∏è Frontend Applications\n\nGPT-Researcher now features an enhanced frontend to improve the user experience and streamline the research process. The frontend offers:\n\n- An intuitive interface for inputting research queries\n- Real-time progress tracking of research tasks\n- Interactive display of research findings\n- Customizable settings for tailored research experiences\n\nTwo deployment options are available:\n1. A lightweight static frontend served by FastAPI\n2. A feature-rich NextJS application for advanced functionality\n\nFor detailed setup instructions and more information about the frontend features, please visit our [documentation page](https://docs.gptr.dev/docs/gpt-researcher/frontend/introduction).\n\n## üöÄ Contributing\nWe highly welcome contributions! Please check out [contributing](https://github.com/assafelovic/gpt-researcher/blob/master/CONTRIBUTING.md) if you''re interested.\n\nPlease check out our [roadmap](https://trello.com/b/3O7KBePw/gpt-researcher-roadmap) page and reach out to us via our [Discord community](https://discord.gg/QgZXvJAccX) if you''re interested in joining our mission.\n<a href="https://github.com/assafelovic/gpt-researcher/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=assafelovic/gpt-researcher" />\n</a>\n## ‚úâÔ∏è Support / Contact us\n- [Community Discord](https://discord.gg/spBgZmm3Xe)\n- Author Email: assaf.elovic@gmail.com\n\n## üõ° Disclaimer\n\nThis project, GPT Researcher, is an experimental application and is provided "as-is" without any warranty, express or implied. We are sharing codes for academic purposes under the Apache 2 license. Nothing herein is academic advice, and NOT a recommendation to use in academic or research papers.\n\nOur view on unbiased research claims:\n1. The main goal of GPT Researcher is to reduce incorrect and biased facts. How? We assume that the more sites we scrape the less chances of incorrect data. By scraping multiple sites per research, and choosing the most frequent information, the chances that they are all wrong is extremely low.\n2. We do not aim to eliminate biases; we aim to reduce it as much as possible. **We are here as a community to figure out the most effective human/llm interactions.**\n3. In research, people also tend towards biases as most have already opinions on the topics they research about. This tool scrapes many opinions and will evenly explain diverse views that a biased person would never have read.\n\n---\n\n<p align="center">\n<a href="https://star-history.com/#assafelovic/gpt-researcher">\n  <picture>\n    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date&theme=dark" />\n    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date" />\n    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date" />\n  </picture>\n</a>\n</p>\n\n\n<p align="right">\n  <a href="#top">‚¨ÜÔ∏è Back to Top</a>\n</p>\n', '{"language":"Python","stars":24430,"forks":3229,"watchers":24430,"open_issues":153,"topics":["agent","ai","automation","deepresearch","llms","mcp","mcp-server","python","research","search","webscraping"],"default_branch":"master","size_kb":39290,"archived":false,"fork":false,"has_wiki":false,"has_pages":true}', '[]', '[{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher.git","source_url":"https://github.com/assafelovic/gpt-researcher.git"},{"type":"has_code","target_id":"github:assafelovic:gptr-mcp","source_url":"https://github.com/assafelovic/gptr-mcp"},{"type":"has_code","target_id":"github:assafelovic:gptr-mcp","source_url":"https://github.com/assafelovic/gptr-mcp"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"},{"type":"has_code","target_id":"github:assafelovic:gpt-researcher","source_url":"https://github.com/assafelovic/gpt-researcher"}]', NULL, 'Apache-2.0', 'approved', 80, '4b07a0d8572870ab1caf695e1f1e3151', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-assafelovic-gpt-researcher from https://github.com/assafelovic.png
Image converted to WebP: data/images/github-assafelovic-gpt-researcher.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-The-Art-of-Hacking-h4cker', 'github--the-art-of-hacking--h4cker', 'h4cker', 'The-Art-of-Hacking', 'This repository is a comprehensive collection of cybersecurity-related references, scripts, tools, code, and other resources. It is carefully curated and maintained by Omar Santos. The repository serves as a supplemental material provider to several books, video courses, and live training created by Omar Santos. It encompasses over 10,000 references that are instrumental for both offensive and defensive security professionals in honing their skills. Below is a quick reference to major section...', '["ai","ai-security","artificial-intelligence","awesome-list","awesome-lists","cybersecurity","ethical-hacking","exploit","exploit-development","exploits","hacker","hackers","hacking","hacking-series","penetration-testing","training","vulnerability","vulnerability-assessment","vulnerability-identification","vulnerability-management","jupyter notebook"]', 'other', 24307, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/The-Art-of-Hacking/h4cker","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=31&duration=4500&pause=1000&color=164B63&multiline=true&width=453&height=100&lines=HackerRepo.org+;Cybersecurity+Resources)](https://git.io/typing-svg)\n\nThis repository is a comprehensive collection of cybersecurity-related references, scripts, tools, code, and other resources. It is carefully curated and maintained by [Omar Santos](https://omarsantos.io/).\n\n## Overview\nThe repository serves as a supplemental material provider to several books, video courses, and live training created by Omar Santos. It encompasses over 10,000 references that are instrumental for both offensive and defensive security professionals in honing their skills.\n\n## Directory Overview\nBelow is a quick reference to major sections in this repository. Each folder contains documentation or tools related to the topic indicated by its name.\n\n- **Offensive Security**: [exploit-development](exploit-development/), [post-exploitation](post-exploitation/), [metasploit-resources](metasploit-resources/), [more-payloads](more-payloads/)\n- **Defensive Security**: [threat-hunting](threat-hunting/), [threat-intelligence](threat-intelligence/), [dfir](dfir/), [sbom](sbom/)\n- **Cloud Security**: [docker-and-k8s-security](docker-and-k8s-security/), [cloud-resources](cloud-resources/)\n- **Hardware & IoT**: [iot-hacking](iot-hacking/), [car-hacking](car-hacking/), [game-hacking](game-hacking/)\n- **Training Materials**: [certifications](certifications/), [cheat-sheets](cheat-sheets/), [who-and-what-to-follow](who-and-what-to-follow/)\n\n## How to Use\nYou can clone this repository or download specific resources to deepen your understanding in the aforementioned areas. For detailed explanations and practical applications, refer to the books, video courses, and training by Omar Santos.\n\n## Contributing\nIf you wish to contribute, please read the [CONTRIBUTING.md](CONTRIBUTING.md) file.\n\n## License\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Contact\nFor any inquiries or feedback, please feel free to contact [Omar Santos](https://www.linkedin.com/in/santosomar/).\n\n', '{"language":"Jupyter Notebook","stars":24307,"forks":4640,"watchers":24307,"open_issues":3,"topics":["ai","ai-security","artificial-intelligence","awesome-list","awesome-lists","cybersecurity","ethical-hacking","exploit","exploit-development","exploits","hacker","hackers","hacking","hacking-series","penetration-testing","training","vulnerability","vulnerability-assessment","vulnerability-identification","vulnerability-management"],"default_branch":"master","size_kb":146406,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[]', NULL, 'MIT', 'approved', 65, 'ef877b4e9a9341d313f62743c7701966', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-The-Art-of-Hacking-h4cker from https://github.com/The-Art-of-Hacking.png
Image converted to WebP: data/images/github-The-Art-of-Hacking-h4cker.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-asgeirtj-system-prompts-leaks', 'github--asgeirtj--system-prompts-leaks', 'system_prompts_leaks', 'asgeirtj', '!CleanShot 2025-09-03 at 02 37 49 Collection of system prompts/system messages/developer messages. Feel free to do Pull Requests', '["ai","anthropic","chatbots","chatgpt","claude","gemini","generative-ai","google-deepmind","large-language-models","llm","openai","prompt-engineering","prompt-injection","prompts","roff"]', 'other', 24144, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/asgeirtj/system_prompts_leaks","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'model', '![CleanShot 2025-09-03 at 02 37 49](https://github.com/user-attachments/assets/22d32e2d-e0c9-4afc-9e72-44b779dac659)\n\n\n# System Prompts Leaks\n\nCollection of system prompts/system messages/developer messages.\n\nFeel free to do Pull Requests\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=asgeirtj/system_prompts_leaks&type=Date)](https://www.star-history.com/#asgeirtj/system_prompts_leaks&Date)\n', '{"language":"Roff","stars":24144,"forks":3697,"watchers":24144,"open_issues":27,"topics":["ai","anthropic","chatbots","chatgpt","claude","gemini","generative-ai","google-deepmind","large-language-models","llm","openai","prompt-engineering","prompt-injection","prompts"],"default_branch":"main","size_kb":493,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"}]', NULL, NULL, 'pending', 30, '11bb4c4575aa6624d36bbef4ddf57e53', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-asgeirtj-system-prompts-leaks from https://github.com/asgeirtj.png
Image converted to WebP: data/images/github-asgeirtj-system-prompts-leaks.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-eyaltoledano-claude-task-master', 'github--eyaltoledano--claude-task-master', 'claude-task-master', 'eyaltoledano', '<a name="readme-top"></a> <div align=''center''> <a href="https://trendshift.io/repositories/13971" target="_blank"><img src="https://trendshift.io/api/badge/repositories/13971" alt="eyaltoledano%2Fclaude-task-master | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a> </div> <p align="center"> <a href="https://task-master.dev"><img src="./images/logo.png?raw=true" alt="Taskmaster logo"></a> </p> <p align="center"> <b>Taskmaster</b>: A task management system for AI-dr...', '["ai","cursor","cursor-ai","cursorai","lovable","lovable-dev","roocode","task-manager","tasks","tasks-list","windsurf","windsurf-ai","javascript"]', 'other', 24139, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/eyaltoledano/claude-task-master","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<a name="readme-top"></a>\n\n<div align=''center''>\n<a href="https://trendshift.io/repositories/13971" target="_blank"><img src="https://trendshift.io/api/badge/repositories/13971" alt="eyaltoledano%2Fclaude-task-master | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>\n</div>\n\n<p align="center">\n  <a href="https://task-master.dev"><img src="./images/logo.png?raw=true" alt="Taskmaster logo"></a>\n</p>\n\n<p align="center">\n<b>Taskmaster</b>: A task management system for AI-driven development, designed to work seamlessly with any AI chat.\n</p>\n\n<p align="center">\n  <a href="https://discord.gg/taskmasterai" target="_blank"><img src="https://dcbadge.limes.pink/api/server/https://discord.gg/taskmasterai?style=flat" alt="Discord"></a> |\n  <a href="https://docs.task-master.dev" target="_blank">Docs</a>\n</p>\n\n<p align="center">\n  <a href="https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml"><img src="https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml/badge.svg" alt="CI"></a>\n  <a href="https://github.com/eyaltoledano/claude-task-master/stargazers"><img src="https://img.shields.io/github/stars/eyaltoledano/claude-task-master?style=social" alt="GitHub stars"></a>\n  <a href="https://badge.fury.io/js/task-master-ai"><img src="https://badge.fury.io/js/task-master-ai.svg" alt="npm version"></a>\n  <a href="LICENSE"><img src="https://img.shields.io/badge/license-MIT%20with%20Commons%20Clause-blue.svg" alt="License"></a>\n</p>\n\n<p align="center">\n  <a href="https://www.npmjs.com/package/task-master-ai"><img src="https://img.shields.io/npm/d18m/task-master-ai?style=flat" alt="NPM Downloads"></a>\n  <a href="https://www.npmjs.com/package/task-master-ai"><img src="https://img.shields.io/npm/dm/task-master-ai?style=flat" alt="NPM Downloads"></a>\n  <a href="https://www.npmjs.com/package/task-master-ai"><img src="https://img.shields.io/npm/dw/task-master-ai?style=flat" alt="NPM Downloads"></a>\n</p>\n\n## By [@eyaltoledano](https://x.com/eyaltoledano) & [@RalphEcom](https://x.com/RalphEcom)\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/eyaltoledano)](https://x.com/eyaltoledano)\n[![Twitter Follow](https://img.shields.io/twitter/follow/RalphEcom)](https://x.com/RalphEcom)\n\nA task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.\n\n## Documentation\n\nüìö **[View Full Documentation](https://docs.task-master.dev)**\n\nFor detailed guides, API references, and comprehensive examples, visit our documentation site.\n\n### Quick Reference\n\nThe following documentation is also available in the `docs` directory:\n\n- [Configuration Guide](docs/configuration.md) - Set up environment variables and customize Task Master\n- [Tutorial](docs/tutorial.md) - Step-by-step guide to getting started with Task Master\n- [Command Reference](docs/command-reference.md) - Complete list of all available commands\n- [Task Structure](docs/task-structure.md) - Understanding the task format and features\n- [Example Interactions](docs/examples.md) - Common Cursor AI interaction examples\n- [Migration Guide](docs/migration-guide.md) - Guide to migrating to the new project structure\n\n#### Quick Install for Cursor 1.0+ (One-Click)\n\n[![Add task-master-ai MCP server to Cursor](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en/install-mcp?name=task-master-ai&config=eyJjb21tYW5kIjoibnB4IC15IC0tcGFja2FnZT10YXNrLW1hc3Rlci1haSB0YXNrLW1hc3Rlci1haSIsImVudiI6eyJBTlRIUk9QSUNfQVBJX0tFWSI6IllPVVJfQU5USFJPUElDX0FQSV9LRVlfSEVSRSIsIlBFUlBMRVhJVFlfQVBJX0tFWSI6IllPVVJfUEVSUExFWElUWV9BUElfS0VZX0hFUkUiLCJPUEVOQUlfQVBJX0tFWSI6IllPVVJfT1BFTkFJX0tFWV9IRVJFIiwiR09PR0xFX0FQSV9LRVkiOiJZT1VSX0dPT0dMRV9LRVlfSEVSRSIsIk1JU1RSQUxfQVBJX0tFWSI6IllPVVJfTUlTVFJBTF9LRVlfSEVSRSIsIkdST1FfQVBJX0tFWSI6IllPVVJfR1JPUV9LRVlfSEVSRSIsIk9QRU5ST1VURVJfQVBJX0tFWSI6IllPVVJfT1BFTlJPVVRFUl9LRVlfSEVSRSIsIlhBSV9BUElfS0VZIjoiWU9VUl9YQUlfS0VZX0hFUkUiLCJBWlVSRV9PUEVOQUlfQVBJX0tFWSI6IllPVVJfQVpVUkVfS0VZX0hFUkUiLCJPTExBTUFfQVBJX0tFWSI6IllPVVJfT0xMQU1BX0FQSV9LRVlfSEVSRSJ9fQ%3D%3D)\n\n> **Note:** After clicking the link, you''ll still need to add your API keys to the configuration. The link installs the MCP server with placeholder keys that you''ll need to replace with your actual API keys.\n\n#### Claude Code Quick Install\n\nFor Claude Code users:\n\n```bash\nclaude mcp add taskmaster-ai -- npx -y task-master-ai\n```\n\nDon''t forget to add your API keys to the configuration:\n- in the root .env of your Project\n- in the "env" section of your mcp config for taskmaster-ai\n\n\n## Requirements\n\nTaskmaster utilizes AI across several commands, and those require a separate API key. You can use a variety of models from different AI providers provided you add your API keys. For example, if you want to use Claude 3.7, you''ll need an Anthropic API key.\n\nYou can define 3 types of models to be used: the main model, the research model, and the fallback model (in case either the main or research fail). Whatever model you use, its provider API key must be present in either mcp.json or .env.\n\nAt least one (1) of the following is required:\n\n- Anthropic API key (Claude API)\n- OpenAI API key\n- Google Gemini API key\n- Perplexity API key (for research model)\n- xAI API Key (for research or main model)\n- OpenRouter API Key (for research or main model)\n- Claude Code (no API key required - requires Claude Code CLI)\n- Codex CLI (OAuth via ChatGPT subscription - requires Codex CLI)\n\nUsing the research model is optional but highly recommended. You will need at least ONE API key (unless using Claude Code or Codex CLI with OAuth). Adding all API keys enables you to seamlessly switch between model providers at will.\n\n## Quick Start\n\n### Option 1: MCP (Recommended)\n\nMCP (Model Control Protocol) lets you run Task Master directly from your editor.\n\n#### 1. Add your MCP config at the following path depending on your editor\n\n| Editor       | Scope   | Linux/macOS Path                      | Windows Path                                      | Key          |\n| ------------ | ------- | ------------------------------------- | ------------------------------------------------- | ------------ |\n| **Cursor**   | Global  | `~/.cursor/mcp.json`                  | `%USERPROFILE%\.cursor\mcp.json`                  | `mcpServers` |\n|              | Project | `<project_folder>/.cursor/mcp.json`   | `<project_folder>\.cursor\mcp.json`               | `mcpServers` |\n| **Windsurf** | Global  | `~/.codeium/windsurf/mcp_config.json` | `%USERPROFILE%\.codeium\windsurf\mcp_config.json` | `mcpServers` |\n| **VS Code**  | Project | `<project_folder>/.vscode/mcp.json`   | `<project_folder>\.vscode\mcp.json`               | `servers`    |\n| **Q CLI**    | Global  | `~/.aws/amazonq/mcp.json`             |                                                   | `mcpServers` |\n\n##### Manual Configuration\n\n###### Cursor & Windsurf & Q Developer CLI (`mcpServers`)\n\n```json\n{\n  "mcpServers": {\n    "task-master-ai": {\n      "command": "npx",\n      "args": ["-y", "task-master-ai"],\n      "env": {\n        // "TASK_MASTER_TOOLS": "all", // Options: "all", "standard", "core", or comma-separated list of tools\n        "ANTHROPIC_API_KEY": "YOUR_ANTHROPIC_API_KEY_HERE",\n        "PERPLEXITY_API_KEY": "YOUR_PERPLEXITY_API_KEY_HERE",\n        "OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",\n        "GOOGLE_API_KEY": "YOUR_GOOGLE_KEY_HERE",\n        "MISTRAL_API_KEY": "YOUR_MISTRAL_KEY_HERE",\n        "GROQ_API_KEY": "YOUR_GROQ_KEY_HERE",\n        "OPENROUTER_API_KEY": "YOUR_OPENROUTER_KEY_HERE",\n        "XAI_API_KEY": "YOUR_XAI_KEY_HERE",\n        "AZURE_OPENAI_API_KEY": "YOUR_AZURE_KEY_HERE",\n        "OLLAMA_API_KEY": "YOUR_OLLAMA_API_KEY_HERE"\n      }\n    }\n  }\n}\n```\n\n> üîë Replace `YOUR_‚Ä¶_KEY_HERE` with your real API keys. You can remove keys you don''t use.\n\n> **Note**: If you see `0 tools enabled` in the MCP settings, restart your editor and check that your API keys are correctly configured.\n\n###### VS‚ÄØCode (`servers` + `type`)\n\n```json\n{\n  "servers": {\n    "task-master-ai": {\n      "command": "npx",\n      "args": ["-y", "task-master-ai"],\n      "env": {\n        // "TASK_MASTER_TOOLS": "all", // Options: "all", "standard", "core", or comma-separated list of tools\n        "ANTHROPIC_API_KEY": "YOUR_ANTHROPIC_API_KEY_HERE",\n        "PERPLEXITY_API_KEY": "YOUR_PERPLEXITY_API_KEY_HERE",\n        "OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",\n        "GOOGLE_API_KEY": "YOUR_GOOGLE_KEY_HERE",\n        "MISTRAL_API_KEY": "YOUR_MISTRAL_KEY_HERE",\n        "GROQ_API_KEY": "YOUR_GROQ_KEY_HERE",\n        "OPENROUTER_API_KEY": "YOUR_OPENROUTER_KEY_HERE",\n        "XAI_API_KEY": "YOUR_XAI_KEY_HERE",\n        "AZURE_OPENAI_API_KEY": "YOUR_AZURE_KEY_HERE",\n        "OLLAMA_API_KEY": "YOUR_OLLAMA_API_KEY_HERE"\n      },\n      "type": "stdio"\n    }\n  }\n}\n```\n\n> üîë Replace `YOUR_‚Ä¶_KEY_HERE` with your real API keys. You can remove keys you don''t use.\n\n#### 2. (Cursor-only) Enable Taskmaster MCP\n\nOpen Cursor Settings (Ctrl+Shift+J) ‚û° Click on MCP tab on the left ‚û° Enable task-master-ai with the toggle\n\n#### 3. (Optional) Configure the models you want to use\n\nIn your editor''s AI chat pane, say:\n\n```txt\nChange the main, research and fallback models to <model_name>, <model_name> and <model_name> respectively.\n```\n\nFor example, to use Claude Code (no API key required):\n```txt\nChange the main model to claude-code/sonnet\n```\n\n[Table of available models](docs/models.md) | [Claude Code setup](docs/examples/claude-code-usage.md)\n\n#### 4. Initialize Task Master\n\nIn your editor''s AI chat pane, say:\n\n```txt\nInitialize taskmaster-ai in my project\n```\n\n#### 5. Make sure you have a PRD (Recommended)\n\nFor **new projects**: Create your PRD at `.taskmaster/docs/prd.txt`.\nFor **existing projects**: You can use `scripts/prd.txt` or migrate with `task-master migrate`\n\nAn example PRD template is available after initialization in `.taskmaster/templates/example_prd.txt`.\n\n> [!NOTE]\n> While a PRD is recommended for complex projects, you can always create individual tasks by asking "Can you help me implement [description of what you want to do]?" in chat.\n\n**Always start with a detailed PRD.**\n\nThe more detailed your PRD, the better the generated tasks will be.\n\n#### 6. Common Commands\n\nUse your AI assistant to:\n\n- Parse requirements: `Can you parse my PRD at scripts/prd.txt?`\n- Plan next step: `What''s the next task I should work on?`\n- Implement a task: `Can you help me implement task 3?`\n- View multiple tasks: `Can you show me tasks 1, 3, and 5?`\n- Expand a task: `Can you help me expand task 4?`\n- **Research fresh information**: `Research the latest best practices for implementing JWT authentication with Node.js`\n- **Research with context**: `Research React Query v5 migration strategies for our current API implementation in src/api.js`\n\n[More examples on how to use Task Master in chat](docs/examples.md)\n\n### Option 2: Using Command Line\n\n#### Installation\n\n```bash\n# Install globally\nnpm install -g task-master-ai\n\n# OR install locally within your project\nnpm install task-master-ai\n```\n\n#### Initialize a new project\n\n```bash\n# If installed globally\ntask-master init\n\n# If installed locally\nnpx task-master init\n\n# Initialize project with specific rules\ntask-master init --rules cursor,windsurf,vscode\n```\n\nThis will prompt you for project details and set up a new project with the necessary files and structure.\n\n#### Common Commands\n\n```bash\n# Initialize a new project\ntask-master init\n\n# Parse a PRD and generate tasks\ntask-master parse-prd your-prd.txt\n\n# List all tasks\ntask-master list\n\n# Show the next task to work on\ntask-master next\n\n# Show specific task(s) - supports comma-separated IDs\ntask-master show 1,3,5\n\n# Research fresh information with project context\ntask-master research "What are the latest best practices for JWT authentication?"\n\n# Move tasks between tags (cross-tag movement)\ntask-master move --from=5 --from-tag=backlog --to-tag=in-progress\ntask-master move --from=5,6,7 --from-tag=backlog --to-tag=done --with-dependencies\ntask-master move --from=5 --from-tag=backlog --to-tag=in-progress --ignore-dependencies\n\n# Add rules after initialization\ntask-master rules add windsurf,roo,vscode\n```\n\n## Tool Loading Configuration\n\n### Optimizing MCP Tool Loading\n\nTask Master''s MCP server supports selective tool loading to reduce context window usage. By default, all 36 tools are loaded (~21,000 tokens) to maintain backward compatibility with existing installations.\n\nYou can optimize performance by configuring the `TASK_MASTER_TOOLS` environment variable:\n\n### Available Modes\n\n| Mode | Tools | Context Usage | Use Case |\n|------|-------|--------------|----------|\n| `all` (default) | 36 | ~21,000 tokens | Complete feature set - all tools available |\n| `standard` | 15 | ~10,000 tokens | Common task management operations |\n| `core` (or `lean`) | 7 | ~5,000 tokens | Essential daily development workflow |\n| `custom` | Variable | Variable | Comma-separated list of specific tools |\n\n### Configuration Methods\n\n#### Method 1: Environment Variable in MCP Configuration\n\nAdd `TASK_MASTER_TOOLS` to your MCP configuration file''s `env` section:\n\n```jsonc\n{\n  "mcpServers": {  // or "servers" for VS Code\n    "task-master-ai": {\n      "command": "npx",\n      "args": ["-y", "task-master-ai"],\n      "env": {\n        "TASK_MASTER_TOOLS": "standard",  // Options: "all", "standard", "core", "lean", or comma-separated list\n        "ANTHROPIC_API_KEY": "your-key-here",\n        // ... other API keys\n      }\n    }\n  }\n}\n```\n\n#### Method 2: Claude Code CLI (One-Time Setup)\n\nFor Claude Code users, you can set the mode during installation:\n\n```bash\n# Core mode example (~70% token reduction)\nclaude mcp add task-master-ai --scope user \\n  --env TASK_MASTER_TOOLS="core" \\n  -- npx -y task-master-ai@latest\n\n# Custom tools example\nclaude mcp add task-master-ai --scope user \\n  --env TASK_MASTER_TOOLS="get_tasks,next_task,set_task_status" \\n  -- npx -y task-master-ai@latest\n```\n\n### Tool Sets Details\n\n**Core Tools (7):** `get_tasks`, `next_task`, `get_task`, `set_task_status`, `update_subtask`, `parse_prd`, `expand_task`\n\n**Standard Tools (15):** All core tools plus `initialize_project`, `analyze_project_complexity`, `expand_all`, `add_subtask`, `remove_task`, `generate`, `add_task`, `complexity_report`\n\n**All Tools (36):** Complete set including project setup, task management, analysis, dependencies, tags, research, and more\n\n### Recommendations\n\n- **New users**: Start with `"standard"` mode for a good balance\n- **Large projects**: Use `"core"` mode to minimize token usage\n- **Complex workflows**: Use `"all"` mode or custom selection\n- **Backward compatibility**: If not specified, defaults to `"all"` mode\n\n## Claude Code Support\n\nTask Master now supports Claude models through the Claude Code CLI, which requires no API key:\n\n- **Models**: `claude-code/opus` and `claude-code/sonnet`\n- **Requirements**: Claude Code CLI installed\n- **Benefits**: No API key needed, uses your local Claude instance\n\n[Learn more about Claude Code setup](docs/examples/claude-code-usage.md)\n\n## Troubleshooting\n\n### If `task-master init` doesn''t respond\n\nTry running it with Node directly:\n\n```bash\nnode node_modules/claude-task-master/scripts/init.js\n```\n\nOr clone the repository and run:\n\n```bash\ngit clone https://github.com/eyaltoledano/claude-task-master.git\ncd claude-task-master\nnode scripts/init.js\n```\n\n## Join Our Team\n\n<a href="https://tryhamster.com" target="_blank">\n  <img src="./images/hamster-hiring.png" alt="Join Hamster''s founding team" />\n</a>\n\n## Contributors\n\n<a href="https://github.com/eyaltoledano/claude-task-master/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=eyaltoledano/claude-task-master" alt="Task Master project contributors" />\n</a>\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=eyaltoledano/claude-task-master&type=Timeline)](https://www.star-history.com/#eyaltoledano/claude-task-master&Timeline)\n\n## Licensing\n\nTask Master is licensed under the MIT License with Commons Clause. This means you can:\n\n‚úÖ **Allowed**:\n\n- Use Task Master for any purpose (personal, commercial, academic)\n- Modify the code\n- Distribute copies\n- Create and sell products built using Task Master\n\n‚ùå **Not Allowed**:\n\n- Sell Task Master itself\n- Offer Task Master as a hosted service\n- Create competing products based on Task Master\n\nSee the [LICENSE](LICENSE) file for the complete license text and [licensing details](docs/licensing.md) for more information.\n', '{"language":"JavaScript","stars":24139,"forks":2345,"watchers":24139,"open_issues":148,"topics":["ai","cursor","cursor-ai","cursorai","lovable","lovable-dev","roocode","task-manager","tasks","tasks-list","windsurf","windsurf-ai"],"default_branch":"main","size_kb":23523,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master","source_url":"https://github.com/eyaltoledano/claude-task-master"},{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master","source_url":"https://github.com/eyaltoledano/claude-task-master"},{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master","source_url":"https://github.com/eyaltoledano/claude-task-master"},{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master.git","source_url":"https://github.com/eyaltoledano/claude-task-master.git"},{"type":"has_code","target_id":"github:eyaltoledano:claude-task-master","source_url":"https://github.com/eyaltoledano/claude-task-master"}]', NULL, 'NOASSERTION', 'approved', 80, '6ab51cc964817618c0d2642ee283f6de', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-eyaltoledano-claude-task-master from https://github.com/eyaltoledano.png
Image converted to WebP: data/images/github-eyaltoledano-claude-task-master.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-flipped-aurora-gin-vue-admin', 'github--flipped-aurora--gin-vue-admin', 'gin-vue-admin', 'flipped-aurora', '<div align=center> <img src="http://qmplusimg.henrongyi.top/gvalogo.jpg" width="300" height="300" /> </div> <div align=center> <img src="https://img.shields.io/badge/golang-1.20-blue"/> <img src="https://img.shields.io/badge/gin-1.9.1-lightBlue"/> <img src="https://img.shields.io/badge/vue-3.3.4-brightgreen"/> <img src="https://img.shields.io/badge/element--plus-2.3.8-green"/> <img src="https://img.shields.io/badge/gorm-1.25.2-red"/> <img src="https://gitcode.com/flipped-aurora/gin-vue-admin/...', '["admin","ai","casbin","element-ui","gin","gin-admin","gin-vue-admin","go","go-admin","golang","gorm","i18n","jwt","pinia","swagger","vite","vue","vue-admin","vue3","go"]', 'other', 24030, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/flipped-aurora/gin-vue-admin","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '\n<div align=center>\n<img src="http://qmplusimg.henrongyi.top/gvalogo.jpg" width="300" height="300" />\n</div>\n\n<div align=center>\n<img src="https://img.shields.io/badge/golang-1.20-blue"/>\n<img src="https://img.shields.io/badge/gin-1.9.1-lightBlue"/>\n<img src="https://img.shields.io/badge/vue-3.3.4-brightgreen"/>\n<img src="https://img.shields.io/badge/element--plus-2.3.8-green"/>\n<img src="https://img.shields.io/badge/gorm-1.25.2-red"/>\n<img src="https://gitcode.com/flipped-aurora/gin-vue-admin/star/badge.svg"/>\n</div>\n\n<div align=center>\n<a href="https://trendshift.io/repositories/3250" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3250" alt="Calcium-Ion%2Fnew-api | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>\n</div>\n\n[English](./README-en.md) | ÁÆÄ‰Ωì‰∏≠Êñá\n\n## ‚ú®‰∏ÄÂàÜÈíüÁîüÊàêÂâçÂêéÁ´ØÂü∫Á°Ä‰ª£Á†Å\n\n<table>\n  <tr>\n    <td width="250">\n	  <p>‚≠êÔ∏è <a href="https://www.bilibili.com/video/BV1B3htzqEf1/?spm_id_from=333.1387.homepage.video_card.click" target="__blank"> È´òÂ∫¶ÈÄÇÈÖçAIÁºñËæëÂô®ÁöÑMCP </a></p>\n      <p>üìÑ ÂàõÂª∫Âü∫Á°ÄÊ®°Êùø</p>\n      <p>ü§ñ AIÁîüÊàêÁªìÊûÑ</p>\n      <p>‚è∞ ÁîüÊàê‰ª£Á†Å</p>\n      <p>üè∑Ô∏è ÂàÜÈÖçÊùÉÈôê</p>\n      <p>üéâ Âü∫Á°ÄCURDÁîüÊàêÂÆåÊàê</p>   \n    </td>\n    <td>\n      <video src="https://private-user-images.githubusercontent.com/165128580/384700666-4d039215-af29-4f86-bb4f-60dbab38f58e.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzEyNTIxNDYsIm5iZiI6MTczMTI1MTg0NiwicGF0aCI6Ii8xNjUxMjg1ODAvMzg0NzAwNjY2LTRkMDM5MjE1LWFmMjktNGY4Ni1iYjRmLTYwZGJhYjM4ZjU4ZS5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTExMFQxNTE3MjZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00NjJkMDcwZjJkMjAyMmU1N2I2MzQxY2RhODFlNzgzNGRiMDFhMmY2NTYyM2ZmODdhNDVmMWE1NzlhMDdlOTI5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ZJbswpLzF2RHjemcGirKOP0L1fvpl3FUqIiQ_-yjeUo" data-canonical-src="https://private-user-images.githubusercontent.com/165128580/384700666-4d039215-af29-4f86-bb4f-60dbab38f58e.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzEyNTIxNDYsIm5iZiI6MTczMTI1MTg0NiwicGF0aCI6Ii8xNjUxMjg1ODAvMzg0NzAwNjY2LTRkMDM5MjE1LWFmMjktNGY4Ni1iYjRmLTYwZGJhYjM4ZjU4ZS5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTExMFQxNTE3MjZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00NjJkMDcwZjJkMjAyMmU1N2I2MzQxY2RhODFlNzgzNGRiMDFhMmY2NTYyM2ZmODdhNDVmMWE1NzlhMDdlOTI5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ZJbswpLzF2RHjemcGirKOP0L1fvpl3FUqIiQ_-yjeUo" controls="controls" muted="muted" class="d-block rounded-bottom-2 border-top width-fit" style="max-height:640px; min-height: 200px">\n</video>\n    </td>\n  </tr>\n</table>\n\n\n# È°πÁõÆÊñáÊ°£\n[Âú®Á∫øÊñáÊ°£](https://www.gin-vue-admin.com) : https://www.gin-vue-admin.com\n\n[ÂàùÂßãÂåñ](https://www.gin-vue-admin.com/guide/start-quickly/initialization.html)\n						       \n[‰ªéÁéØÂ¢ÉÂà∞ÈÉ®ÁΩ≤ÊïôÂ≠¶ËßÜÈ¢ë](https://www.bilibili.com/video/BV1Rg411u7xH)\n\n[ÂºÄÂèëÊïôÂ≠¶](https://www.gin-vue-admin.com/guide/start-quickly/env.html) (Ë¥°ÁåÆËÄÖ:  <a href="https://github.com/LLemonGreen">LLemonGreen</a> And <a href="https://github.com/fkk0509">Fann</a>)\n\n[‰∫§ÊµÅÁ§æÂå∫](https://support.qq.com/products/371961)\n\n[Êèí‰ª∂Â∏ÇÂú∫](https://plugin.gin-vue-admin.com/)\n\n[ËΩØ‰ª∂Ëëó‰ΩúÊùÉËØÅ‰π¶](https://www.gin-vue-admin.com/copyright.pdf)\n\n# ÈáçË¶ÅÊèêÁ§∫\n\n1.Êú¨È°πÁõÆ‰ªéËµ∑Ê≠•Âà∞ÂºÄÂèëÂà∞ÈÉ®ÁΩ≤ÂùáÊúâÊñáÊ°£ÂíåËØ¶ÁªÜËßÜÈ¢ëÊïôÁ®ã\n\n2.Êú¨È°πÁõÆÈúÄË¶ÅÊÇ®Êúâ‰∏ÄÂÆöÁöÑgolangÂíåvueÂü∫Á°Ä\n\n3.ÊÇ®ÂÆåÂÖ®ÂèØ‰ª•ÈÄöËøáÊàë‰ª¨ÁöÑÊïôÁ®ãÂíåÊñáÊ°£ÂÆåÊàê‰∏ÄÂàáÊìç‰ΩúÔºåÂõ†Ê≠§Êàë‰ª¨‰∏çÂÜçÊèê‰æõÂÖçË¥πÁöÑÊäÄÊúØÊúçÂä°ÔºåÂ¶ÇÈúÄÊúçÂä°ËØ∑ËøõË°å[‰ªòË¥πÊîØÊåÅ](https://www.gin-vue-admin.com/coffee/payment.html)\n\n4.Â¶ÇÊûúÊÇ®Â∞ÜÊ≠§È°πÁõÆÁî®‰∫éÂïÜ‰∏öÁî®ÈÄîÔºåËØ∑ÈÅµÂÆàApache2.0ÂçèËÆÆÂπ∂‰øùÁïô‰ΩúËÄÖÊäÄÊúØÊîØÊåÅÂ£∞Êòé„ÄÇÊÇ®ÈúÄ‰øùÁïôÂ¶Ç‰∏ãÁâàÊùÉÂ£∞Êòé‰ø°ÊÅØÔºå‰ª•ÂèäÊó•ÂøóÂíå‰ª£Á†Å‰∏≠ÊâÄÂåÖÂê´ÁöÑÁâàÊùÉÂ£∞Êòé‰ø°ÊÅØ„ÄÇÊâÄÈúÄ‰øùÁïô‰ø°ÊÅØÂùá‰∏∫ÊñáÊ°àÊÄßË¥®Ôºå‰∏ç‰ºöÂΩ±Âìç‰ªª‰Ωï‰∏öÂä°ÂÜÖÂÆπÔºåÂ¶ÇÂÜ≥ÂÆöÂïÜÁî®„Äê‰∫ßÁîüÊî∂ÁõäÁöÑÂïÜ‰∏öË°å‰∏∫ÂùáÂú®ÂïÜÁî®Ë°åÂàó„ÄëÊàñËÄÖÂøÖÈ°ªÂâîÈô§ËØ∑[Ë¥≠‰π∞ÊéàÊùÉ](https://www.gin-vue-admin.com/empower/index.html)\n\\n<img src="https://qmplusimg.henrongyi.top/openSource/login.jpg" width="1000">\n\n<img src="https://qmplusimg.henrongyi.top/openSource/dashboard.jpg" width="1000">\n\n## 1. Âü∫Êú¨‰ªãÁªç\n\n### 1.1 È°πÁõÆ‰ªãÁªç\n\n> Gin-vue-adminÊòØ‰∏Ä‰∏™Âü∫‰∫é [vue](https://vuejs.org) Âíå [gin](https://gin-gonic.com) ÂºÄÂèëÁöÑÂÖ®Ê†àÂâçÂêéÁ´ØÂàÜÁ¶ªÁöÑÂºÄÂèëÂü∫Á°ÄÂπ≥Âè∞ÔºåÈõÜÊàêjwtÈâ¥ÊùÉÔºåÂä®ÊÄÅË∑ØÁî±ÔºåÂä®ÊÄÅËèúÂçïÔºåcasbinÈâ¥ÊùÉÔºåË°®ÂçïÁîüÊàêÂô®Ôºå‰ª£Á†ÅÁîüÊàêÂô®Á≠âÂäüËÉΩÔºåÊèê‰æõÂ§öÁßçÁ§∫‰æãÊñá‰ª∂ÔºåËÆ©ÊÇ®ÊääÊõ¥Â§öÊó∂Èó¥‰∏ìÊ≥®Âú®‰∏öÂä°ÂºÄÂèë‰∏ä„ÄÇ\n\n[Âú®Á∫øÈ¢ÑËßà](http://demo.gin-vue-admin.com): http://demo.gin-vue-admin.com\n\nÊµãËØïÁî®Êà∑ÂêçÔºöadmin\n\nÊµãËØïÂØÜÁ†ÅÔºö123456\n\n### 1.2 Ë¥°ÁåÆÊåáÂçó\nHi! È¶ñÂÖàÊÑüË∞¢‰Ω†‰ΩøÁî® gin-vue-admin„ÄÇ\n\nGin-vue-admin ÊòØ‰∏ÄÂ•ó‰∏∫Âø´ÈÄüÁ†îÂèëÂáÜÂ§áÁöÑ‰∏ÄÊï¥Â•óÂâçÂêéÁ´ØÂàÜÁ¶ªÊû∂ÊûÑÂºèÁöÑÂºÄÊ∫êÊ°ÜÊû∂ÔºåÊó®Âú®Âø´ÈÄüÊê≠Âª∫‰∏≠Â∞èÂûãÈ°πÁõÆ„ÄÇ\n\nGin-vue-admin ÁöÑÊàêÈïøÁ¶ª‰∏çÂºÄÂ§ßÂÆ∂ÁöÑÊîØÊåÅÔºåÂ¶ÇÊûú‰Ω†ÊÑøÊÑè‰∏∫ gin-vue-admin Ë¥°ÁåÆ‰ª£Á†ÅÊàñÊèê‰æõÂª∫ËÆÆÔºåËØ∑ÈòÖËØª‰ª•‰∏ãÂÜÖÂÆπ„ÄÇ\n\n#### 1.2.1 Issue ËßÑËåÉ\n- issue ‰ªÖÁî®‰∫éÊèê‰∫§ Bug Êàñ Feature ‰ª•ÂèäËÆæËÆ°Áõ∏ÂÖ≥ÁöÑÂÜÖÂÆπÔºåÂÖ∂ÂÆÉÂÜÖÂÆπÂèØËÉΩ‰ºöË¢´Áõ¥Êé•ÂÖ≥Èó≠„ÄÇ\n									      \n- Âú®Êèê‰∫§ issue ‰πãÂâçÔºåËØ∑ÊêúÁ¥¢Áõ∏ÂÖ≥ÂÜÖÂÆπÊòØÂê¶Â∑≤Ë¢´ÊèêÂá∫„ÄÇ\n\n#### 1.2.2 Pull Request ËßÑËåÉ\n- ËØ∑ÂÖà fork ‰∏Ä‰ªΩÂà∞Ëá™Â∑±ÁöÑÈ°πÁõÆ‰∏ãÔºå‰∏çË¶ÅÁõ¥Êé•Âú®‰ªìÂ∫ì‰∏ãÂª∫ÂàÜÊîØ„ÄÇ\n\n- commit ‰ø°ÊÅØË¶Å‰ª•`[Êñá‰ª∂Âêç]: ÊèèËø∞‰ø°ÊÅØ` ÁöÑÂΩ¢ÂºèÂ°´ÂÜôÔºå‰æãÂ¶Ç `README.md: fix xxx bug`„ÄÇ\n\n- Â¶ÇÊûúÊòØ‰øÆÂ§ç bugÔºåËØ∑Âú® PR ‰∏≠ÁªôÂá∫ÊèèËø∞‰ø°ÊÅØ„ÄÇ\n\n- ÂêàÂπ∂‰ª£Á†ÅÈúÄË¶Å‰∏§ÂêçÁª¥Êä§‰∫∫ÂëòÂèÇ‰∏éÔºö‰∏Ä‰∫∫ËøõË°å review Âêé approveÔºåÂè¶‰∏Ä‰∫∫ÂÜçÊ¨° reviewÔºåÈÄöËøáÂêéÂç≥ÂèØÂêàÂπ∂„ÄÇ\n\n## 2. ‰ΩøÁî®ËØ¥Êòé\n\n```\n- nodeÁâàÊú¨ > v18.16.0\n- golangÁâàÊú¨ >= v1.22\n- IDEÊé®ËçêÔºöGoland\n```\n\n### 2.1 serverÈ°πÁõÆ\n\n‰ΩøÁî® `Goland` Á≠âÁºñËæëÂ∑•ÂÖ∑ÔºåÊâìÂºÄserverÁõÆÂΩïÔºå‰∏çÂèØ‰ª•ÊâìÂºÄ gin-vue-admin Ê†πÁõÆÂΩï\n\n```bash\n\n# ÂÖãÈöÜÈ°πÁõÆ\ngit clone https://github.com/flipped-aurora/gin-vue-admin.git\n# ËøõÂÖ•serverÊñá‰ª∂Â§π\ncd server\n\n# ‰ΩøÁî® go mod Âπ∂ÂÆâË£Ögo‰æùËµñÂåÖ\ngo generate\n\n# ËøêË°å\ngo run . \n\n```\n\n### 2.2 webÈ°πÁõÆ\n\n```bash\n# ËøõÂÖ•webÊñá‰ª∂Â§π\ncd web\n\n# ÂÆâË£Ö‰æùËµñ\nnpm install\n\n# ÂêØÂä®webÈ°πÁõÆ\nnpm run serve\n```\n\n### 2.3 swaggerËá™Âä®ÂåñAPIÊñáÊ°£\n\n#### 2.3.1 ÂÆâË£Ö swagger\n\n``` shell\ngo install github.com/swaggo/swag/cmd/swag@latest\n```\n\n#### 2.3.2 ÁîüÊàêAPIÊñáÊ°£\n\n```` shell\ncd server\nswag init\n````\n\n> ÊâßË°å‰∏äÈù¢ÁöÑÂëΩ‰ª§ÂêéÔºåserverÁõÆÂΩï‰∏ã‰ºöÂá∫Áé∞docsÊñá‰ª∂Â§πÈáåÁöÑ `docs.go`, `swagger.json`, `swagger.yaml` ‰∏â‰∏™Êñá‰ª∂Êõ¥Êñ∞ÔºåÂêØÂä®goÊúçÂä°‰πãÂêé, Âú®ÊµèËßàÂô®ËæìÂÖ• [http://localhost:8888/swagger/index.html](http://localhost:8888/swagger/index.html) Âç≥ÂèØÊü•ÁúãswaggerÊñáÊ°£\n\n### 2.4 VSCodeÂ∑•‰ΩúÂå∫\n\n#### 2.4.1 ÂºÄÂèë\n\n‰ΩøÁî®`VSCode`ÊâìÂºÄÊ†πÁõÆÂΩï‰∏ãÁöÑÂ∑•‰ΩúÂå∫Êñá‰ª∂`gin-vue-admin.code-workspace`ÔºåÂú®ËæπÊ†èÂèØ‰ª•ÁúãÂà∞‰∏â‰∏™ËôöÊãüÁõÆÂΩïÔºö`backend`„ÄÅ`frontend`„ÄÅ`root`„ÄÇ\n\n#### 2.4.2 ËøêË°å/Ë∞ÉËØï\n\nÂú®ËøêË°åÂíåË∞ÉËØï‰∏≠‰πüÂèØ‰ª•ÁúãÂà∞‰∏â‰∏™taskÔºö`Backend`„ÄÅ`Frontend`„ÄÅ`Both (Backend & Frontend)`„ÄÇËøêË°å`Both (Backend & Frontend)`ÂèØ‰ª•ÂêåÊó∂ÂêØÂä®ÂâçÂêéÁ´ØÈ°πÁõÆ„ÄÇ\n\n#### 2.4.3 settings\n\nÂú®Â∑•‰ΩúÂå∫ÈÖçÁΩÆÊñá‰ª∂‰∏≠Êúâ`go.toolsEnvVars`Â≠óÊÆµÔºåÊòØÁî®‰∫é`VSCode`Ëá™Ë∫´ÁöÑgoÂ∑•ÂÖ∑ÁéØÂ¢ÉÂèòÈáè„ÄÇÊ≠§Â§ñÂú®Â§ögoÁâàÊú¨ÁöÑÁ≥ªÁªü‰∏≠ÔºåÂèØ‰ª•ÈÄöËøá`gopath`„ÄÅ`go.goroot`ÊåáÂÆöËøêË°åÁâàÊú¨„ÄÇ\n\n```json\n    "go.gopath": null,\n    "go.goroot": null,\n```\n\n## 3. ÊäÄÊúØÈÄâÂûã\n\n- ÂâçÁ´ØÔºöÁî®Âü∫‰∫é [Vue](https://vuejs.org) ÁöÑ [Element](https://github.com/ElemeFE/element) ÊûÑÂª∫Âü∫Á°ÄÈ°µÈù¢„ÄÇ\n- ÂêéÁ´ØÔºöÁî® [Gin](https://gin-gonic.com/) Âø´ÈÄüÊê≠Âª∫Âü∫Á°ÄrestfulÈ£éÊ†ºAPIÔºå[Gin](https://gin-gonic.com/) ÊòØ‰∏Ä‰∏™goËØ≠Ë®ÄÁºñÂÜôÁöÑWebÊ°ÜÊû∂„ÄÇ\n- Êï∞ÊçÆÂ∫ìÔºöÈááÁî®`MySql` > (5.7) ÁâàÊú¨ Êï∞ÊçÆÂ∫ìÂºïÊìé InnoDBÔºå‰ΩøÁî® [gorm](http://gorm.cn) ÂÆûÁé∞ÂØπÊï∞ÊçÆÂ∫ìÁöÑÂü∫Êú¨Êìç‰Ωú„ÄÇ\n- ÁºìÂ≠òÔºö‰ΩøÁî®`Redis`ÂÆûÁé∞ËÆ∞ÂΩïÂΩìÂâçÊ¥ªË∑ÉÁî®Êà∑ÁöÑ`jwt`‰ª§ÁâåÂπ∂ÂÆûÁé∞Â§öÁÇπÁôªÂΩïÈôêÂà∂„ÄÇ\n- APIÊñáÊ°£Ôºö‰ΩøÁî®`Swagger`ÊûÑÂª∫Ëá™Âä®ÂåñÊñáÊ°£„ÄÇ\n- ÈÖçÁΩÆÊñá‰ª∂Ôºö‰ΩøÁî® [fsnotify](https://github.com/fsnotify/fsnotify) Âíå [viper](https://github.com/spf13/viper) ÂÆûÁé∞`yaml`Ê†ºÂºèÁöÑÈÖçÁΩÆÊñá‰ª∂„ÄÇ\n- Êó•ÂøóÔºö‰ΩøÁî® [zap](https://github.com/uber-go/zap) ÂÆûÁé∞Êó•ÂøóËÆ∞ÂΩï„ÄÇ\n\n## 4. È°πÁõÆÊû∂ÊûÑ\n\n### 4.1 Á≥ªÁªüÊû∂ÊûÑÂõæ\n\n![Á≥ªÁªüÊû∂ÊûÑÂõæ](http://qmplusimg.henrongyi.top/gva/gin-vue-admin.png)\n\n### 4.2 ÂâçÁ´ØËØ¶ÁªÜËÆæËÆ°Âõæ ÔºàÊèê‰æõËÄÖ:<a href="https://github.com/baobeisuper">baobeisuper</a>Ôºâ\n\n![ÂâçÁ´ØËØ¶ÁªÜËÆæËÆ°Âõæ](http://qmplusimg.henrongyi.top/naotu.png)\n\n### 4.3 ÁõÆÂΩïÁªìÊûÑ\n\n```\n    ‚îú‚îÄ‚îÄ server\n        ‚îú‚îÄ‚îÄ api             (apiÂ±Ç)\n        ‚îÇ   ‚îî‚îÄ‚îÄ v1          (v1ÁâàÊú¨Êé•Âè£)\n        ‚îú‚îÄ‚îÄ config          (ÈÖçÁΩÆÂåÖ)\n        ‚îú‚îÄ‚îÄ core            (Ê†∏ÂøÉÊñá‰ª∂)\n        ‚îú‚îÄ‚îÄ docs            (swaggerÊñáÊ°£ÁõÆÂΩï)\n        ‚îú‚îÄ‚îÄ global          (ÂÖ®Â±ÄÂØπË±°)                    \n        ‚îú‚îÄ‚îÄ initialize      (ÂàùÂßãÂåñ)                        \n        ‚îÇ   ‚îî‚îÄ‚îÄ internal    (ÂàùÂßãÂåñÂÜÖÈÉ®ÂáΩÊï∞)                            \n        ‚îú‚îÄ‚îÄ middleware      (‰∏≠Èó¥‰ª∂Â±Ç)                        \n        ‚îú‚îÄ‚îÄ model           (Ê®°ÂûãÂ±Ç)                    \n        ‚îÇ   ‚îú‚îÄ‚îÄ request     (ÂÖ•ÂèÇÁªìÊûÑ‰Ωì)                        \n        ‚îÇ   ‚îî‚îÄ‚îÄ response    (Âá∫ÂèÇÁªìÊûÑ‰Ωì)                            \n        ‚îú‚îÄ‚îÄ packfile        (ÈùôÊÄÅÊñá‰ª∂ÊâìÂåÖ)                        \n        ‚îú‚îÄ‚îÄ resource        (ÈùôÊÄÅËµÑÊ∫êÊñá‰ª∂Â§π)                        \n        ‚îÇ   ‚îú‚îÄ‚îÄ excel       (excelÂØºÂÖ•ÂØºÂá∫ÈªòËÆ§Ë∑ØÂæÑ)                        \n        ‚îÇ   ‚îú‚îÄ‚îÄ page        (Ë°®ÂçïÁîüÊàêÂô®)                        \n        ‚îÇ   ‚îî‚îÄ‚îÄ template    (Ê®°Êùø)                            \n        ‚îú‚îÄ‚îÄ router          (Ë∑ØÁî±Â±Ç)                    \n        ‚îú‚îÄ‚îÄ service         (serviceÂ±Ç)                    \n        ‚îú‚îÄ‚îÄ source          (sourceÂ±Ç)                    \n        ‚îî‚îÄ‚îÄ utils           (Â∑•ÂÖ∑ÂåÖ)                    \n            ‚îú‚îÄ‚îÄ timer       (ÂÆöÊó∂Âô®Êé•Âè£Â∞ÅË£Ö)                        \n            ‚îî‚îÄ‚îÄ upload      (ossÊé•Âè£Â∞ÅË£Ö)                        \n    \n            web\n        ‚îú‚îÄ‚îÄ babel.config.js\n        ‚îú‚îÄ‚îÄ Dockerfile\n        ‚îú‚îÄ‚îÄ favicon.ico\n        ‚îú‚îÄ‚îÄ index.html                 -- ‰∏ªÈ°µÈù¢\n        ‚îú‚îÄ‚îÄ limit.js                   -- Âä©Êâã‰ª£Á†Å\n        ‚îú‚îÄ‚îÄ package.json               -- ÂåÖÁÆ°ÁêÜÂô®‰ª£Á†Å\n        ‚îú‚îÄ‚îÄ src                        -- Ê∫ê‰ª£Á†Å\n        ‚îÇ   ‚îú‚îÄ‚îÄ api                    -- api ÁªÑ\n        ‚îÇ   ‚îú‚îÄ‚îÄ App.vue                -- ‰∏ªÈ°µÈù¢\n        ‚îÇ   ‚îú‚îÄ‚îÄ assets                 -- ÈùôÊÄÅËµÑÊ∫ê\n        ‚îÇ   ‚îú‚îÄ‚îÄ components             -- ÂÖ®Â±ÄÁªÑ‰ª∂\n        ‚îÇ   ‚îú‚îÄ‚îÄ core                   -- gva ÁªÑ‰ª∂ÂåÖ\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.js          -- gvaÁΩëÁ´ôÈÖçÁΩÆÊñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gin-vue-admin.js   -- Ê≥®ÂÜåÊ¨¢ËøéÊñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ global.js          -- Áªü‰∏ÄÂØºÂÖ•Êñá‰ª∂\n        ‚îÇ   ‚îú‚îÄ‚îÄ directive              -- v-auth Ê≥®ÂÜåÊñá‰ª∂\n        ‚îÇ   ‚îú‚îÄ‚îÄ main.js                -- ‰∏ªÊñá‰ª∂\n        ‚îÇ   ‚îú‚îÄ‚îÄ permission.js          -- Ë∑ØÁî±‰∏≠Èó¥‰ª∂\n        ‚îÇ   ‚îú‚îÄ‚îÄ pinia                  -- pinia Áä∂ÊÄÅÁÆ°ÁêÜÂô®ÔºåÂèñ‰ª£vuex\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.js           -- ÂÖ•Âè£Êñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modules            -- modules\n        ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dictionary.js\n        ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ router.js\n        ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ user.js\n        ‚îÇ   ‚îú‚îÄ‚îÄ router                 -- Ë∑ØÁî±Â£∞ÊòéÊñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js\n        ‚îÇ   ‚îú‚îÄ‚îÄ style                  -- ÂÖ®Â±ÄÊ†∑Âºè\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.scss\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basics.scss\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ element_visiable.scss  -- Ê≠§Â§ÑÂèØ‰ª•ÂÖ®Â±ÄË¶ÜÁõñ element-plus Ê†∑Âºè\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iconfont.css           -- È°∂ÈÉ®Âá†‰∏™iconÁöÑÊ†∑ÂºèÊñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.scss\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mobile.scss\n        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ newLogin.scss\n        ‚îÇ   ‚îú‚îÄ‚îÄ utils                  -- ÊñπÊ≥ïÂåÖÂ∫ì\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ asyncRouter.js     -- Âä®ÊÄÅË∑ØÁî±Áõ∏ÂÖ≥\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ btnAuth.js         -- Âä®ÊÄÅÊùÉÈôêÊåâÈíÆÁõ∏ÂÖ≥\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bus.js             -- ÂÖ®Â±ÄmittÂ£∞ÊòéÊñá‰ª∂\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date.js            -- Êó•ÊúüÁõ∏ÂÖ≥\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dictionary.js      -- Ëé∑ÂèñÂ≠óÂÖ∏ÊñπÊ≥ï \n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ downloadImg.js     -- ‰∏ãËΩΩÂõæÁâáÊñπÊ≥ï\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ format.js          -- Ê†ºÂºèÊï¥ÁêÜÁõ∏ÂÖ≥\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image.js           -- ÂõæÁâáÁõ∏ÂÖ≥ÊñπÊ≥ï\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.js            -- ËÆæÁΩÆÈ°µÈù¢Ê†áÈ¢ò\n        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ request.js         -- ËØ∑Ê±Ç\n        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stringFun.js       -- Â≠óÁ¨¶‰∏≤Êñá‰ª∂\n        |   ‚îú‚îÄ‚îÄ view -- ‰∏ªË¶Åview‰ª£Á†Å\n        |   |   ‚îú‚îÄ‚îÄ about -- ÂÖ≥‰∫éÊàë‰ª¨\n        |   |   ‚îú‚îÄ‚îÄ dashboard -- Èù¢Êùø\n        |   |   ‚îú‚îÄ‚îÄ error -- ÈîôËØØ\n        |   |   ‚îú‚îÄ‚îÄ example --‰∏ä‰º†Ê°à‰æã\n        |   |   ‚îú‚îÄ‚îÄ iconList -- iconÂàóË°®\n        |   |   ‚îú‚îÄ‚îÄ init -- ÂàùÂßãÂåñÊï∞ÊçÆ  \n        |   |   |   ‚îú‚îÄ‚îÄ index -- Êñ∞ÁâàÊú¨\n        |   |   |   ‚îú‚îÄ‚îÄ init -- ÊóßÁâàÊú¨\n        |   |   ‚îú‚îÄ‚îÄ layout  --  layoutÁ∫¶ÊùüÈ°µÈù¢ \n        |   |   |   ‚îú‚îÄ‚îÄ aside \n        |   |   |   ‚îú‚îÄ‚îÄ bottomInfo     -- bottomInfo\n        |   |   |   ‚îú‚îÄ‚îÄ screenfull     -- ÂÖ®Â±èËÆæÁΩÆ\n        |   |   |   ‚îú‚îÄ‚îÄ setting        -- Á≥ªÁªüËÆæÁΩÆ\n        |   |   |   ‚îî‚îÄ‚îÄ index.vue      -- base Á∫¶Êùü\n        |   |   ‚îú‚îÄ‚îÄ login              --ÁôªÂΩï \n        |   |   ‚îú‚îÄ‚îÄ person             --‰∏™‰∫∫‰∏≠ÂøÉ \n        |   |   ‚îú‚îÄ‚îÄ superAdmin         -- Ë∂ÖÁ∫ßÁÆ°ÁêÜÂëòÊìç‰Ωú\n        |   |   ‚îú‚îÄ‚îÄ system             -- Á≥ªÁªüÊ£ÄÊµãÈ°µÈù¢\n        |   |   ‚îú‚îÄ‚îÄ systemTools        -- Á≥ªÁªüÈÖçÁΩÆÁõ∏ÂÖ≥È°µÈù¢\n        |   |   ‚îî‚îÄ‚îÄ routerHolder.vue   -- page ÂÖ•Âè£È°µÈù¢ \n        ‚îú‚îÄ‚îÄ vite.config.js             -- vite ÈÖçÁΩÆÊñá‰ª∂\n        ‚îî‚îÄ‚îÄ yarn.lock\n\n```\n\n## 5. ‰∏ªË¶ÅÂäüËÉΩ\n\n- ÊùÉÈôêÁÆ°ÁêÜÔºöÂü∫‰∫é`jwt`Âíå`casbin`ÂÆûÁé∞ÁöÑÊùÉÈôêÁÆ°ÁêÜ„ÄÇ\n- Êñá‰ª∂‰∏ä‰º†‰∏ãËΩΩÔºöÂÆûÁé∞Âü∫‰∫é`‰∏ÉÁâõ‰∫ë`, `ÈòøÈáå‰∫ë`, `ËÖæËÆØ‰∫ë` ÁöÑÊñá‰ª∂‰∏ä‰º†Êìç‰Ωú(ËØ∑ÂºÄÂèëËá™Â∑±ÂéªÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁî≥ËØ∑ÂØπÂ∫î `token` ÊàñËÄÖÂØπÂ∫î`key`)„ÄÇ\n- ÂàÜÈ°µÂ∞ÅË£ÖÔºöÂâçÁ´Ø‰ΩøÁî® `mixins` Â∞ÅË£ÖÂàÜÈ°µÔºåÂàÜÈ°µÊñπÊ≥ïË∞ÉÁî® `mixins` Âç≥ÂèØ„ÄÇ\n- Áî®Êà∑ÁÆ°ÁêÜÔºöÁ≥ªÁªüÁÆ°ÁêÜÂëòÂàÜÈÖçÁî®Êà∑ËßíËâ≤ÂíåËßíËâ≤ÊùÉÈôê„ÄÇ\n- ËßíËâ≤ÁÆ°ÁêÜÔºöÂàõÂª∫ÊùÉÈôêÊéßÂà∂ÁöÑ‰∏ªË¶ÅÂØπË±°ÔºåÂèØ‰ª•ÁªôËßíËâ≤ÂàÜÈÖç‰∏çÂêåapiÊùÉÈôêÂíåËèúÂçïÊùÉÈôê„ÄÇ\n- ËèúÂçïÁÆ°ÁêÜÔºöÂÆûÁé∞Áî®Êà∑Âä®ÊÄÅËèúÂçïÈÖçÁΩÆÔºåÂÆûÁé∞‰∏çÂêåËßíËâ≤‰∏çÂêåËèúÂçï„ÄÇ\n- apiÁÆ°ÁêÜÔºö‰∏çÂêåÁî®Êà∑ÂèØË∞ÉÁî®ÁöÑapiÊé•Âè£ÁöÑÊùÉÈôê‰∏çÂêå„ÄÇ\n- ÈÖçÁΩÆÁÆ°ÁêÜÔºöÈÖçÁΩÆÊñá‰ª∂ÂèØÂâçÂè∞‰øÆÊîπ(Âú®Á∫ø‰ΩìÈ™åÁ´ôÁÇπ‰∏çÂºÄÊîæÊ≠§ÂäüËÉΩ)„ÄÇ\n- Êù°‰ª∂ÊêúÁ¥¢ÔºöÂ¢ûÂä†Êù°‰ª∂ÊêúÁ¥¢Á§∫‰æã„ÄÇ\n- restfulÁ§∫‰æãÔºöÂèØ‰ª•ÂèÇËÄÉÁî®Êà∑ÁÆ°ÁêÜÊ®°Âùó‰∏≠ÁöÑÁ§∫‰æãAPI„ÄÇ\n	- ÂâçÁ´ØÊñá‰ª∂ÂèÇËÄÉ: [web/src/view/superAdmin/api/api.vue](https://github.com/flipped-aurora/gin-vue-admin/blob/master/web/src/view/superAdmin/api/api.vue)\n    - ÂêéÂè∞Êñá‰ª∂ÂèÇËÄÉ: [server/router/sys_api.go](https://github.com/flipped-aurora/gin-vue-admin/blob/master/server/router/sys_api.go)\n- Â§öÁÇπÁôªÂΩïÈôêÂà∂ÔºöÈúÄË¶ÅÂú®`config.yaml`‰∏≠Êää`system`‰∏≠ÁöÑ`use-multipoint`‰øÆÊîπ‰∏∫true(ÈúÄË¶ÅËá™Ë°åÈÖçÁΩÆRedisÂíåConfig‰∏≠ÁöÑRedisÂèÇÊï∞ÔºåÊµãËØïÈò∂ÊÆµÔºåÊúâbugËØ∑ÂèäÊó∂ÂèçÈ¶à)„ÄÇ\n- ÂàÜÁâá‰∏ä‰º†ÔºöÊèê‰æõÊñá‰ª∂ÂàÜÁâá‰∏ä‰º†ÂíåÂ§ßÊñá‰ª∂ÂàÜÁâá‰∏ä‰º†ÂäüËÉΩÁ§∫‰æã„ÄÇ\n- Ë°®ÂçïÁîüÊàêÂô®ÔºöË°®ÂçïÁîüÊàêÂô®ÂÄüÂä© [@Variant Form](https://github.com/vform666/variant-form) „ÄÇ\n- ‰ª£Á†ÅÁîüÊàêÂô®ÔºöÂêéÂè∞Âü∫Á°ÄÈÄªËæë‰ª•ÂèäÁÆÄÂçïcurdÁöÑ‰ª£Á†ÅÁîüÊàêÂô®„ÄÇ\n\n## 6. Áü•ËØÜÂ∫ì \n\n## 6.1 Âõ¢ÈòüÂçöÂÆ¢\n\n> https://www.yuque.com/flipped-aurora\n>\n>ÂÜÖÊúâÂâçÁ´ØÊ°ÜÊû∂ÊïôÂ≠¶ËßÜÈ¢ë„ÄÇÂ¶ÇÊûúËßâÂæóÈ°πÁõÆÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÂèØ‰ª•Ê∑ªÂä†ÊàëÁöÑ‰∏™‰∫∫ÂæÆ‰ø°:shouzi_1994ÔºåÊ¨¢ËøéÊÇ®ÊèêÂá∫ÂÆùË¥µÁöÑÈúÄÊ±Ç„ÄÇ\n\n## 6.2 ÊïôÂ≠¶ËßÜÈ¢ë\n\nÔºà1ÔºâÊâãÊääÊâãÊïôÂ≠¶ËßÜÈ¢ë\n\n> https://www.bilibili.com/video/BV1Rg411u7xH/\n\nÔºà2ÔºâÂêéÁ´ØÁõÆÂΩïÁªìÊûÑË∞ÉÊï¥‰ªãÁªç‰ª•Âèä‰ΩøÁî®ÊñπÊ≥ï\n\n> https://www.bilibili.com/video/BV1x44y117TT/\n\nÔºà3ÔºâgolangÂü∫Á°ÄÊïôÂ≠¶ËßÜÈ¢ë\n\n> bilibiliÔºöhttps://space.bilibili.com/322210472/channel/detail?cid=108884\n\nÔºà4ÔºâginÊ°ÜÊû∂Âü∫Á°ÄÊïôÂ≠¶\n\n> bilibiliÔºöhttps://space.bilibili.com/322210472/channel/detail?cid=126418&ctype=0\n\nÔºà5Ôºâgin-vue-admin ÁâàÊú¨Êõ¥Êñ∞‰ªãÁªçËßÜÈ¢ë\n\n> bilibiliÔºöhttps://www.bilibili.com/video/BV1kv4y1g7nT\n\n## 7. ËÅîÁ≥ªÊñπÂºè\n\n### 7.1 ÊäÄÊúØÁæ§\n\n### QQ‰∫§ÊµÅÁæ§Ôºö971857775\n\n### ÂæÆ‰ø°‰∫§ÊµÅÁæ§\n| ÂæÆ‰ø° |\n|  :---:  | \n| <img width="150" src="http://qmplusimg.henrongyi.top/qrjjz.png"> \n\nÈò≤Ê≠¢ÂπøÂëäËøõÁæ§ÔºåÊ∑ªÂä†ÂæÆ‰ø°ÔºåËæìÂÖ•‰ª•‰∏ã‰ª£Á†ÅÊâßË°åÁªìÊûúÔºàËØ∑ÂãøËΩ¨Á†Å‰∏∫stringÔºâ\n\n```\nstr := "5Yqg5YWlR1ZB5Lqk5rWB576k"\ndecodeBytes, err := base64.StdEncoding.DecodeString(str)\nfmt.Println(decodeBytes, err)\n```\n\n### [ÂÖ≥‰∫éÊàë‰ª¨](https://www.gin-vue-admin.com/about/join.html)\n\n## 8. Ë¥°ÁåÆËÄÖ\n\nÊÑüË∞¢ÊÇ®ÂØπgin-vue-adminÁöÑË¥°ÁåÆ!\n\n<a href="https://openomy.app/github/flipped-aurora/gin-vue-admin" target="_blank" style="display: block; width: 100%;" align="center">\n  <img src="https://openomy.app/svg?repo=flipped-aurora/gin-vue-admin&chart=bubble&latestMonth=3" target="_blank" alt="Contribution Leaderboard" style="display: block; width: 100%;" />\n </a>\n\n## 9. ÊçêËµ†\n\nÂ¶ÇÊûú‰Ω†ËßâÂæóËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©Ôºå‰Ω†ÂèØ‰ª•ËØ∑‰ΩúËÄÖÂñùÈ•ÆÊñô :tropical_drink: [ÁÇπÊàë](https://www.gin-vue-admin.com/coffee/index.html)\n\n## 10. Ê≥®ÊÑè‰∫ãÈ°π\n\nËØ∑‰∏•Ê†ºÈÅµÂÆàApache 2.0ÂçèËÆÆÂπ∂‰øùÁïô‰ΩúÂìÅÂ£∞ÊòéÔºåÂéªÈô§ÁâàÊùÉ‰ø°ÊÅØËØ∑Âä°ÂøÖ[Ëé∑ÂèñÊéàÊùÉ](https://www.gin-vue-admin.com/empower/)  \nÊú™ÊéàÊùÉÂéªÈô§ÁâàÊùÉ‰ø°ÊÅØÂ∞Ü‰æùÊ≥ïËøΩÁ©∂Ê≥ïÂæãË¥£‰ªª\n', '{"language":"Go","stars":24030,"forks":6947,"watchers":24030,"open_issues":35,"topics":["admin","ai","casbin","element-ui","gin","gin-admin","gin-vue-admin","go","go-admin","golang","gorm","i18n","jwt","pinia","swagger","vite","vue","vue-admin","vue3"],"default_branch":"main","size_kb":16899,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:LLemonGreen\">LLemonGreen<:a>","source_url":"https://github.com/LLemonGreen\">LLemonGreen</a>"},{"type":"has_code","target_id":"github:fkk0509\">Fann<:a>","source_url":"https://github.com/fkk0509\">Fann</a>"},{"type":"has_code","target_id":"github:flipped-aurora:gin-vue-admin.git","source_url":"https://github.com/flipped-aurora/gin-vue-admin.git"},{"type":"has_code","target_id":"github:ElemeFE:element","source_url":"https://github.com/ElemeFE/element"},{"type":"has_code","target_id":"github:fsnotify:fsnotify","source_url":"https://github.com/fsnotify/fsnotify"},{"type":"has_code","target_id":"github:spf13:viper","source_url":"https://github.com/spf13/viper"},{"type":"has_code","target_id":"github:uber-go:zap","source_url":"https://github.com/uber-go/zap"},{"type":"has_code","target_id":"github:baobeisuper\">baobeisuper<:a>Ôºâ","source_url":"https://github.com/baobeisuper\">baobeisuper</a>Ôºâ"},{"type":"has_code","target_id":"github:flipped-aurora:gin-vue-admin","source_url":"https://github.com/flipped-aurora/gin-vue-admin"},{"type":"has_code","target_id":"github:flipped-aurora:gin-vue-admin","source_url":"https://github.com/flipped-aurora/gin-vue-admin"},{"type":"has_code","target_id":"github:vform666:variant-form","source_url":"https://github.com/vform666/variant-form"}]', NULL, 'Apache-2.0', 'approved', 80, '6154f559f5fa61e452ffe415f147f271', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-flipped-aurora-gin-vue-admin from https://github.com/flipped-aurora.png
Image converted to WebP: data/images/github-flipped-aurora-gin-vue-admin.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-Fosowl-agenticSeek', 'github--fosowl--agenticseek', 'agenticSeek', 'Fosowl', '<p align="center"> <img align="center" src="./media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo"> <p> English | ‰∏≠Êñá | ÁπÅÈ´î‰∏≠Êñá | Fran√ßais | Êó•Êú¨Ë™û | Portugu√™s (Brasil) | Espa√±ol *A **100% local alternative to Manus AI**, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.* !...', '["agentic-ai","agents","ai","autonomous-agents","deepseek-r1","llm","llm-agents","voice-assistant","python"]', 'other', 24025, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/Fosowl/agenticSeek","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '# AgenticSeek: Private, Local Manus Alternative.\n\n<p align="center">\n<img align="center" src="./media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">\n<p>\n\n  English | [‰∏≠Êñá](./README_CHS.md) | [ÁπÅÈ´î‰∏≠Êñá](./README_CHT.md) | [Fran√ßais](./README_FR.md) | [Êó•Êú¨Ë™û](./README_JP.md) | [Portugu√™s (Brasil)](./README_PTBR.md) | [Espa√±ol](./README_ES.md)\n\n*A **100% local alternative to Manus AI**, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.*\n\n[![Visit AgenticSeek](https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square)](https://fosowl.github.io/agenticSeek.html) ![License](https://img.shields.io/badge/license-GPL--3.0-green) [![Discord](https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white)](https://discord.gg/8hGDaME3TC) [![Twitter](https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl)](https://x.com/Martin993886460) [![GitHub stars](https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social)](https://github.com/Fosowl/agenticSeek/stargazers)\n\n### Why AgenticSeek ?\n\n* üîí Fully Local & Private - Everything runs on your machine ‚Äî no cloud, no data sharing. Your files, conversations, and searches stay private.\n\n* üåê Smart Web Browsing - AgenticSeek can browse the internet by itself ‚Äî search, read, extract info, fill web form ‚Äî all hands-free.\n\n* üíª Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more ‚Äî all without supervision.\n\n* üß† Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.\n\n* üìã Plans & Executes Complex Tasks - From trip planning to complex projects ‚Äî it can split big tasks into steps and get things done using multiple AI agents.\n\n* üéôÔ∏è Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it''s your personal AI from a sci-fi movie. (In progress)\n\n### **Demo**\n\n> *Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project*\n\nhttps://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316\n\nDisclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.\n\n> üõ†‚ö†Ô∏èÔ∏è **Active Work in Progress**\n\n> üôè This project started as a side-project and has zero roadmap and zero funding. It''s grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.\n\n## Prerequisites\n\nBefore you begin, ensure you have the following software installed:\n\n*   **Git:** For cloning the repository. [Download Git](https://git-scm.com/downloads)\n*   **Python 3.10.x:** We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. [Download Python 3.10](https://www.python.org/downloads/release/python-3100/) (pick a 3.10.x version).\n*   **Docker Engine & Docker Compose:** For running bundled services like SearxNG.\n    *   Install Docker Desktop (which includes Docker Compose V2): [Windows](https://docs.docker.com/desktop/install/windows-install/) | [Mac](https://docs.docker.com/desktop/install/mac-install/) | [Linux](https://docs.docker.com/desktop/install/linux-install/)\n    *   Alternatively, install Docker Engine and Docker Compose separately on Linux: [Docker Engine](https://docs.docker.com/engine/install/) | [Docker Compose](https://docs.docker.com/compose/install/) (ensure you install Compose V2, e.g., `sudo apt-get install docker-compose-plugin`).\n\n### 1. **Clone the repository and setup**\n\n```sh\ngit clone https://github.com/Fosowl/agenticSeek.git\ncd agenticSeek\nmv .env.example .env\n```\n\n### 2. Change the .env file content\n\n```sh\nSEARXNG_BASE_URL="http://searxng:8080" # http://127.0.0.1:8080 if running on host\nREDIS_BASE_URL="redis://redis:6379/0"\nWORK_DIR="/Users/mlg/Documents/workspace_for_ai"\nOLLAMA_PORT="11434"\nLM_STUDIO_PORT="1234"\nCUSTOM_ADDITIONAL_LLM_PORT="11435"\nOPENAI_API_KEY=''optional''\nDEEPSEEK_API_KEY=''optional''\nOPENROUTER_API_KEY=''optional''\nTOGETHER_API_KEY=''optional''\nGOOGLE_API_KEY=''optional''\nANTHROPIC_API_KEY=''optional''\n```\n\n\nUpdate the `.env` file with your own values as needed:\n\n- **SEARXNG_BASE_URL**: Leave unchanged unless running on host with CLI mode.\n- **REDIS_BASE_URL**: Leave unchanged \n- **WORK_DIR**: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.\n- **OLLAMA_PORT**: Port number for the Ollama service.\n- **LM_STUDIO_PORT**: Port number for the LM Studio service.\n- **CUSTOM_ADDITIONAL_LLM_PORT**: Port for any additional custom LLM service.\n\n**API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware**\n\n### 3. **Start Docker**\n\nMake sure Docker is installed and running on your system. You can start Docker using the following commands:\n\n- **On Linux/macOS:**  \n    Open a terminal and run:\n    ```sh\n    sudo systemctl start docker\n    ```\n    Or launch Docker Desktop from your applications menu if installed.\n\n- **On Windows:**  \n    Start Docker Desktop from the Start menu.\n\nYou can verify Docker is running by executing:\n```sh\ndocker info\n```\nIf you see information about your Docker installation, it is running correctly.\n\nSee the table of [Local Providers](#list-of-local-providers) below for a summary.\n\nNext step: [Run AgenticSeek locally](#start-services-and-run)\n\n*See the [Troubleshooting](#troubleshooting) section if you are having issues.*\n*If your hardware can''t run LLMs locally, see [Setup to run with an API](#setup-to-run-with-an-api).*\n*For detailed `config.ini` explanations, see [Config Section](#config).*\n\n---\n\n## Setup for running LLM locally on your machine\n\n**Hardware Requirements:**\n\nTo run LLMs locally, you''ll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.\n\n**Setup your local provider**  \n\nStart your local provider (for example with ollama):\n\nUnless you wish to to run AgenticSeek on host (CLI mode), export or set the provider listen address:\n\n```sh\nexport OLLAMA_HOST=0.0.0.0:11434\n```\n\nThen, start you provider:\n\n```sh\nollama serve\n```\n\nSee below for a list of local supported provider.\n\n**Update the config.ini**\n\nChange the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as *Magistral* or *Deepseek*.\n\nSee the **FAQ** at the end of the README for required hardware.\n\n```sh\n[MAIN]\nis_local = True # Whenever you are running locally or with remote provider.\nprovider_name = ollama # or lm-studio, openai, etc..\nprovider_model = deepseek-r1:14b # choose a model that fit your hardware\nprovider_server_address = 127.0.0.1:11434\nagent_name = Jarvis # name of your AI\nrecover_last_session = True # whenever to recover the previous session\nsave_session = True # whenever to remember the current session\nspeak = False # text to speech\nlisten = False # Speech to text, only for CLI, experimental\njarvis_personality = False # Whenever to use a more "Jarvis" like personality (experimental)\nlanguages = en zh # The list of languages, Text to speech will default to the first language on the list\n[BROWSER]\nheadless_browser = True # leave unchanged unless using CLI on host.\nstealth_mode = True # Use undetected selenium to reduce browser detection\n```\n\n**Warning**:\n\n- The `config.ini` file format does not support comments. \nDo not copy and paste the example configuration directly, as comments will cause errors.  Instead, manually modify the `config.ini` file with your desired settings, excluding any comments.\n\n- Do *NOT* set provider_name to `openai` if using LM-studio for running LLMs. Set it to `lm-studio`.\n\n- Some provider (eg: lm-studio) require you to have `http://` in front of the IP. For example `http://127.0.0.1:1234`\n\n**List of local providers**\n\n| Provider  | Local? | Description                                               |\n|-----------|--------|-----------------------------------------------------------|\n| ollama    | Yes    | Run LLMs locally with ease using ollama as a LLM provider |\n| lm-studio  | Yes    | Run LLM locally with LM studio (set `provider_name` to `lm-studio`)|\n| openai    | Yes     |  Use openai compatible API (eg: llama.cpp server)  |\n\nNext step: [Start services and run AgenticSeek](#Start-services-and-Run)  \n\n*See the [Troubleshooting](#troubleshooting) section if you are having issues.*\n*If your hardware can''t run LLMs locally, see [Setup to run with an API](#setup-to-run-with-an-api).*\n*For detailed `config.ini` explanations, see [Config Section](#config).*\n\n## Setup to run with an API\n\nThis setup uses external, cloud-based LLM providers. You''ll need an API key from your chosen service.\n\n**1. Choose an API Provider and Get an API Key:**\n\nRefer to the [List of API Providers](#list-of-api-providers) below. Visit their websites to sign up and obtain an API key.\n\n**2. Set Your API Key as an Environment Variable:**\n\n\n*   **Linux/macOS:**\n    Open your terminal and use the `export` command. It''s best to add this to your shell''s profile file (e.g., `~/.bashrc`, `~/.zshrc`) for persistence.\n    ```sh\n    export PROVIDER_API_KEY="your_api_key_here" \n    # Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY\n    ```\n    Example for TogetherAI:\n    ```sh\n    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"\n    ```\n*   **Windows:**\n    *   **Command Prompt (Temporary for current session):**\n        ```cmd\n        set PROVIDER_API_KEY=your_api_key_here\n        ```\n    *   **PowerShell (Temporary for current session):**\n        ```powershell\n        $env:PROVIDER_API_KEY="your_api_key_here"\n        ```\n    *   **Permanently:** Search for "environment variables" in the Windows search bar, click "Edit the system environment variables," then click the "Environment Variables..." button. Add a new User variable with the appropriate name (e.g., `OPENAI_API_KEY`) and your key as the value.\n\n    *(See FAQ: [How do I set API keys?](#how-do-i-set-api-keys) for more details).*\n\n\n**3. Update `config.ini`:**\n```ini\n[MAIN]\nis_local = False\nprovider_name = openai # Or google, deepseek, togetherAI, huggingface\nprovider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.\nprovider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs\n# ... other settings ...\n```\n*Warning:* Make sure there are no trailing spaces in the `config.ini` values.\n\n**List of API Providers**\n\n| Provider     | `provider_name` | Local? | Description                                       | API Key Link (Examples)                     |\n|--------------|-----------------|--------|---------------------------------------------------|---------------------------------------------|\n| OpenAI       | `openai`        | No     | Use ChatGPT models via OpenAI''s API.              | [platform.openai.com/signup](https://platform.openai.com/signup) |\n| Google Gemini| `google`        | No     | Use Google Gemini models via Google AI Studio.    | [aistudio.google.com/keys](https://aistudio.google.com/keys) |\n| Deepseek     | `deepseek`      | No     | Use Deepseek models via their API.                | [platform.deepseek.com](https://platform.deepseek.com) |\n| Hugging Face | `huggingface`   | No     | Use models from Hugging Face Inference API.       | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |\n| TogetherAI   | `togetherAI`    | No     | Use various open-source models via TogetherAI API.| [api.together.ai/settings/api-keys](https://api.together.ai/settings/api-keys) |\n| OpenRouter   | `openrouter`    | No     | Use OpenRouter Models| [https://openrouter.ai/](https://openrouter.ai/) |\n\n*Note:*\n*   We advise against using `gpt-4o` or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.\n*   Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.\n*   The `provider_server_address` in `config.ini` is generally not used when `is_local = False` as the API endpoint is usually hardcoded in the respective provider''s library.\n\nNext step: [Start services and run AgenticSeek](#Start-services-and-Run)\n\n*See the **Known issues** section if you are having issues*\n\n*See the **Config** section for detailed config file explanation.*\n\n---\n\n## Start services and Run\n\nBy default AgenticSeek is run fully in docker.\n\n**Option 1:** Run in Docker, use web interface:\n\nStart required services. This will start all services from the docker-compose.yml, including:\n    - searxng\n    - redis (required by searxng)\n    - frontend\n    - backend (if using `full` when using the web interface)\n\n```sh\n./start_services.sh full # MacOS\nstart start_services.cmd full # Window\n```\n\n**Warning:** This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see **backend: "GET /health HTTP/1.1" 200 OK** in the log) before sending any messages. The backend services might take 5 minute to start on first run.\n\nGo to `http://localhost:3000/` and you should see the web interface.\n\n*Troubleshooting service start:* If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, `docker compose`) is correctly installed. Check the output in the terminal for error messages. See [FAQ: Help! I get an error when running AgenticSeek or its scripts.](#faq-troubleshooting)\n\n**Option 2:** CLI mode:\n\nTo run with CLI interface you would have to install package on host:\n\n```sh\n./install.sh\n./install.bat # windows\n```\n\nThen you must change the SEARXNG_BASE_URL in `config.ini` to:\n\n```sh\nSEARXNG_BASE_URL="http://localhost:8080"\n```\n\nStart required services. This will start some services from the docker-compose.yml, including:\n    - searxng\n    - redis (required by searxng)\n    - frontend\n\n```sh\n./start_services.sh # MacOS\nstart start_services.cmd # Window\n```\n\nRun: uv run: `uv run python -m ensurepip` to ensure uv has pip enabled.\n\nUse the CLI: `uv run cli.py`\n\n\n---\n\n## Usage\n\nMake sure the services are up and running with `./start_services.sh full` and go to `localhost:3000` for web interface.\n\nYou can also use speech to text by setting `listen = True` in the config. Only for CLI mode.\n\nTo exit, simply say/type `goodbye`.\n\nHere are some example usage:\n\n> *Make a snake game in python!*\n\n> *Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.*\n\n> *Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace*\n\n> *Search my summer_pictures folder for all JPG files, rename them with today‚Äôs date, and save a list of renamed files in photos_list.txt*\n\n> *Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.*\n\n> *Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects*\n\n> *Friday, search the web for a free stock price API, register with supersuper7434567@gmail.com then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv*\n\n*Note that form filling capabilities are still experimental and might fail.*\n\n\n\nAfter you type your query, AgenticSeek will allocate the best agent for the task.\n\nBecause this is an early prototype, the agent routing system might not always allocate the right agent based on your query.\n\nTherefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:\n\n`Do you know some good countries for solo-travel?`\n\nInstead, ask:\n\n`Do a web search and find out which are the best country for solo-travel`\n\n---\n\n## **Setup to run the LLM on your own server**  \n\nIf you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server. \n\nOn your "server" that will run the AI model, get the ip address\n\n```sh\nip a | grep "inet " | grep -v 127.0.0.1 | awk ''{print $2}'' | cut -d/ -f1 # local ip\ncurl https://ipinfo.io/ip # public ip\n```\n\nNote: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.\n\nClone the repository and enter the `server/`folder.\n\n\n```sh\ngit clone --depth 1 https://github.com/Fosowl/agenticSeek.git\ncd agenticSeek/llm_server/\n```\n\nInstall server specific requirements:\n\n```sh\npip3 install -r requirements.txt\n```\n\nRun the server script.\n\n```sh\npython3 app.py --provider ollama --port 3333\n```\n\nYou have the choice between using `ollama` and `llamacpp` as a LLM service.\n\n\nNow on your personal computer:\n\nChange the `config.ini` file to set the `provider_name` to `server` and `provider_model` to `deepseek-r1:xxb`.\nSet the `provider_server_address` to the ip address of the machine that will run the model.\n\n```sh\n[MAIN]\nis_local = False\nprovider_name = server\nprovider_model = deepseek-r1:70b\nprovider_server_address = http://x.x.x.x:3333\n```\n\n\nNext step: [Start services and run AgenticSeek](#Start-services-and-Run)  \n\n---\n\n## Speech to Text\n\nWarning: speech to text only work in CLI mode at the moment.\n\nPlease note that currently speech to text only work in english.\n\nThe speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:\n\n```\nlisten = True\n```\n\nWhen enabled, the speech-to-text feature listens for a trigger keyword, which is the agent''s name, before it begins processing your input. You can customize the agent''s name by updating the `agent_name` value in the *config.ini* file:\n\n```\nagent_name = Friday\n```\n\nFor optimal recognition, we recommend using a common English name like "John" or "Emma" as the agent name\n\nOnce you see the transcript start to appear, say the agent''s name aloud to wake it up (e.g., "Friday").\n\nSpeak your query clearly.\n\nEnd your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:\n```\n"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"\n```\n\n## Config\n\nExample config:\n```\n[MAIN]\nis_local = True\nprovider_name = ollama\nprovider_model = deepseek-r1:32b\nprovider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio\nagent_name = Friday\nrecover_last_session = False\nsave_session = False\nspeak = False\nlisten = False\n\njarvis_personality = False\nlanguages = en zh # List of languages for TTS and potentially routing.\n[BROWSER]\nheadless_browser = False\nstealth_mode = False\n```\n\n**Explanation of `config.ini` Settings**:\n\n*   **`[MAIN]` Section:**\n    *   `is_local`: `True` if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. `False` if using a cloud-based API (OpenAI, Google, etc.).\n    *   `provider_name`: Specifies the LLM provider.\n        *   Local options: `ollama`, `lm-studio`, `openai` (for local OpenAI-compatible servers), `server` (for the self-hosted server setup).\n        *   API options: `openai`, `google`, `deepseek`, `huggingface`, `togetherAI`.\n    *   `provider_model`: The specific model name or ID for the chosen provider (e.g., `deepseekcoder:6.7b` for Ollama, `gpt-3.5-turbo` for OpenAI API, `mistralai/Mixtral-8x7B-Instruct-v0.1` for TogetherAI).\n    *   `provider_server_address`: The address of your LLM provider.\n        *   For local providers: e.g., `http://127.0.0.1:11434` for Ollama, `http://127.0.0.1:1234` for LM-Studio.\n        *   For the `server` provider type: The address of your self-hosted LLM server (e.g., `http://your_server_ip:3333`).\n        *   For cloud APIs (`is_local = False`): This is often ignored or can be left blank, as the API endpoint is usually handled by the client library.\n    *   `agent_name`: Name of the AI assistant (e.g., Friday). Used as a trigger word for speech-to-text if enabled.\n    *   `recover_last_session`: `True` to attempt to restore the previous session''s state, `False` to start fresh.\n    *   `save_session`: `True` to save the current session''s state for potential recovery, `False` otherwise.\n    *   `speak`: `True` to enable text-to-speech voice output, `False` to disable.\n    *   `listen`: `True` to enable speech-to-text voice input (CLI mode only), `False` to disable.\n    *   `work_dir`: **Crucial:** The directory where AgenticSeek will read/write files. **Ensure this path is valid and accessible on your system.**\n    *   `jarvis_personality`: `True` to use a more "Jarvis-like" system prompt (experimental), `False` for the standard prompt.\n    *   `languages`: A comma-separated list of languages (e.g., `en, zh, fr`). Used for TTS voice selection (defaults to the first) and can assist the LLM router. Avoid too many or very similar languages for router efficiency.\n*   **`[BROWSER]` Section:**\n    *   `headless_browser`: `True` to run the automated browser without a visible window (recommended for web interface or non-interactive use). `False` to show the browser window (useful for CLI mode or debugging).\n    *   `stealth_mode`: `True` to enable measures to make browser automation harder to detect. May require manual installation of browser extensions like anticaptcha.\n\n\nThis section summarizes the supported LLM provider types. Configure them in `config.ini`.\n\n**Local Providers (Run on Your Own Hardware):**\n\n| Provider Name in `config.ini` | `is_local` | Description                                                                 | Setup Section                                                    |\n|-------------------------------|------------|-----------------------------------------------------------------------------|------------------------------------------------------------------|\n| `ollama`                      | `True`     | Use Ollama to serve local LLMs.                                             | [Setup for running LLM locally](#setup-for-running-llm-locally-on-your-machine) |\n| `lm-studio`                   | `True`     | Use LM-Studio to serve local LLMs.                                          | [Setup for running LLM locally](#setup-for-running-llm-locally-on-your-machine) |\n| `openai` (for local server)   | `True`     | Connect to a local server that exposes an OpenAI-compatible API (e.g., llama.cpp). | [Setup for running LLM locally](#setup-for-running-llm-locally-on-your-machine) |\n| `server`                      | `False`    | Connect to the AgenticSeek self-hosted LLM server running on another machine. | [Setup to run the LLM on your own server](#setup-to-run-the-llm-on-your-own-server) |\n\n**API Providers (Cloud-Based):**\n\n| Provider Name in `config.ini` | `is_local` | Description                                      | Setup Section                                       |\n|-------------------------------|------------|--------------------------------------------------|-----------------------------------------------------|\n| `openai`                      | `False`    | Use OpenAI''s official API (e.g., GPT-3.5, GPT-4). | [Setup to run with an API](#setup-to-run-with-an-api) |\n| `google`                      | `False`    | Use Google''s Gemini models via API.              | [Setup to run with an API](#setup-to-run-with-an-api) |\n| `deepseek`                    | `False`    | Use Deepseek''s official API.                     | [Setup to run with an API](#setup-to-run-with-an-api) |\n| `huggingface`                 | `False`    | Use Hugging Face Inference API.                  | [Setup to run with an API](#setup-to-run-with-an-api) |\n| `togetherAI`                  | `False`    | Use TogetherAI''s API for various open models.    | [Setup to run with an API](#setup-to-run-with-an-api) |\n\n---\n## Troubleshooting\n\nIf you encounter issues, this section provides guidance.\n\n# Known Issues\n\n## ChromeDriver Issues\n\n**Error Example:** `SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX`\n\n### Root Cause\nChromeDriver version incompatibility occurs when:\n1. Your installed ChromeDriver version doesn''t match your Chrome browser version\n2. In Docker environments, `undetected_chromedriver` may download its own ChromeDriver version, bypassing the mounted binary\n\n### Solution Steps\n\n#### 1. Check Your Chrome Version\nOpen Google Chrome ‚Üí `Settings > About Chrome` to find your version (e.g., "Version 134.0.6998.88")\n\n#### 2. Download Matching ChromeDriver\n\n**For Chrome 115 and newer:** Use the [Chrome for Testing API](https://googlechromelabs.github.io/chrome-for-testing/)\n- Visit the Chrome for Testing availability dashboard\n- Find your Chrome version or the closest available match\n- Download the ChromeDriver for your OS (Linux64 for Docker environments)\n\n**For older Chrome versions:** Use the [legacy ChromeDriver downloads](https://chromedriver.chromium.org/downloads)\n\n![Download ChromeDriver from Chrome for Testing](./media/chromedriver_readme.png)\n\n#### 3. Install ChromeDriver (Choose One Method)\n\n**Method A: Project Root Directory (Recommended for Docker)**\n```bash\n# Place the downloaded chromedriver binary in your project root\ncp path/to/downloaded/chromedriver ./chromedriver\nchmod +x ./chromedriver  # Make executable on Linux/macOS\n```\n\n**Method B: System PATH**\n```bash\n# Linux/macOS\nsudo mv chromedriver /usr/local/bin/\nsudo chmod +x /usr/local/bin/chromedriver\n\n# Windows: Place chromedriver.exe in a folder that''s in your PATH\n```\n\n#### 4. Verify Installation\n```bash\n# Test the ChromeDriver version\n./chromedriver --version\n# OR if in PATH:\nchromedriver --version\n```\n\n### Docker-Specific Notes\n\n‚ö†Ô∏è **Important for Docker Users:**\n- The Docker volume mount approach may not work with stealth mode (`undetected_chromedriver`)\n- **Solution**: Place ChromeDriver in the project root directory as `./chromedriver`\n- The application will automatically detect and use this binary\n- You should see: `"Using ChromeDriver from project root: ./chromedriver"` in the logs\n\n### Troubleshooting Tips\n\n1. **Still getting version mismatch?**\n   - Verify the ChromeDriver is executable: `ls -la ./chromedriver`\n   - Check the ChromeDriver version: `./chromedriver --version`\n   - Ensure it matches your Chrome browser version\n\n2. **Docker container issues?**\n   - Check backend logs: `docker logs backend`\n   - Look for the message: `"Using ChromeDriver from project root"`\n   - If not found, verify the file exists and is executable\n\n3. **Chrome for Testing versions**\n   - Use the exact version match when possible\n   - For version 134.0.6998.88, use ChromeDriver 134.0.6998.165 (closest available)\n   - Major version numbers must match (134 = 134)\n\n### Version Compatibility Matrix\n\n| Chrome Version | ChromeDriver Version | Status |\n|----------------|---------------------|---------|\n| 134.0.6998.x   | 134.0.6998.165     | ‚úÖ Works |\n| 133.0.6943.x   | 133.0.6943.141     | ‚úÖ Works |\n| 132.0.6834.x   | 132.0.6834.159     | ‚úÖ Works |\n\n*For the latest compatibility, check the [Chrome for Testing dashboard](https://googlechromelabs.github.io/chrome-for-testing/)*\n\n`Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113\nCurrent browser version is 134.0.6998.89 with binary path`\n\nThis happen if there is a mismatch between your browser and chromedriver version.\n\nYou need to navigate to download the latest version:\n\nhttps://developer.chrome.com/docs/chromedriver/downloads\n\nIf you''re using Chrome version 115 or newer go to:\n\nhttps://googlechromelabs.github.io/chrome-for-testing/\n\nAnd download the chromedriver version matching your OS.\n\n![alt text](./media/chromedriver_readme.png)\n\nIf this section is incomplete please raise an issue.\n\n##  connection adapters Issues\n\n```\nException: Provider lm-studio failed: HTTP request failed: No connection adapters were found for ''127.0.0.1:1234/v1/chat/completions''` (Note: port may vary)\n```\n\n*   **Cause:** The `provider_server_address` in `config.ini` for `lm-studio` (or other similar local OpenAI-compatible servers) is missing the `http://` prefix or is pointing to the wrong port.\n*   **Solution:**\n    *   Ensure the address includes `http://`. LM-Studio typically defaults to `http://127.0.0.1:1234`.\n    *   Correct `config.ini`: `provider_server_address = http://127.0.0.1:1234` (or your actual LM-Studio server port).\n\n## SearxNG Base URL Not Provided\n\n```\nraise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")\nValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.`\n```\n\nThis might arise if you are running the CLI mode with the wrong base url for searxng.\n\nThe SEARXNG_BASE_URL should be depending on whenever you run in docker or on host:\n\n**Run on host**: `SEARXNG_BASE_URL="http://localhost:8080"`\n\n**Run fully in docker (web interface)**: `SEARXNG_BASE_URL="http://searxng:8080"`\n\n## FAQ\n\n**Q: What hardware do I need?**  \n\n| Model Size  | GPU  | Comment                                               |\n|-----------|--------|-----------------------------------------------------------|\n| 7B        | 8GB Vram | ‚ö†Ô∏è Not recommended. Performance is poor, frequent hallucinations, and planner agents will likely fail. |\n| 14B        | 12 GB VRAM (e.g. RTX 3060) | ‚úÖ Usable for simple tasks. May struggle with web browsing and planning tasks. |\n| 32B        | 24+ GB VRAM (e.g. RTX 4090) | üöÄ Success with most tasks, might still struggle with task planning |\n| 70B+        | 48+ GB Vram | üí™ Excellent. Recommended for advanced use cases. |\n\n**Q: I get an error what do I do?**  \n\nEnsure local is running (`ollama serve`), your `config.ini` matches your provider, and dependencies are installed. If none work feel free to raise an issue.\n\n**Q: Can it really run 100% locally?**  \n\nYes with Ollama, lm-studio or server providers, all speech to text, LLM and text to speech model run locally. Non-local options (OpenAI or others API) are optional.\n\n**Q: Why should I use AgenticSeek when I have Manus?**\n\nUnlike Manus, AgenticSeek prioritizes independence from external systems, giving you more control, privacy and avoid api cost.\n\n**Q: Who is behind the project ?**\n\nThe project was created by me, along with two friends who serve as maintainers and contributors from the open-source community on GitHub. We‚Äôre just a group of passionate individuals, not a startup or affiliated with any organization.\n\nAny AgenticSeek account on X other than my personal account (https://x.com/Martin993886460) is an impersonation.\n\n## Contribute\n\nWe‚Äôre looking for developers to improve AgenticSeek! Check out open issues or discussion.\n\n[Contribution guide](./docs/CONTRIBUTING.md)\n\n\n## Sponsors:\n\nWant to level up AgenticSeek capabilities with features like flight search, trip planning, or snagging the best shopping deals? Consider crafting a custom tool with SerpApi to unlock more Jarvis-like capabilities. With SerpApi, you can turbocharge your agent for specialized tasks while staying in full control.\n\n<a href="https://serpapi.com/"><img src="./media/banners/sponsor_banner_serpapi.png" height="350" alt="SerpApi Banner" ></a>\n\nSee [Contributing.md](./docs/CONTRIBUTING.md) to learn how to integrate custom tools!\n\n### **Patron sponsor**:\n\n- [tatra-labs](https://github.com/tatra-labs)\n\n## Maintainers:\n\n > [Fosowl](https://github.com/Fosowl) | Paris Time \n\n > [antoineVIVIES](https://github.com/antoineVIVIES) | Taipei Time \n\n## Special Thanks:\n\n > [tcsenpai](https://github.com/tcsenpai) and [plitc](https://github.com/plitc) For helping with backend dockerization\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date)](https://www.star-history.com/#Fosowl/agenticSeek&Date)', '{"language":"Python","stars":24025,"forks":2636,"watchers":24025,"open_issues":38,"topics":["agentic-ai","agents","ai","autonomous-agents","deepseek-r1","llm","llm-agents","voice-assistant"],"default_branch":"main","size_kb":24591,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:Fosowl:agenticSeek","source_url":"https://github.com/Fosowl/agenticSeek"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:Fosowl:agenticSeek.git","source_url":"https://github.com/Fosowl/agenticSeek.git"},{"type":"has_code","target_id":"github:Fosowl:agenticSeek.git","source_url":"https://github.com/Fosowl/agenticSeek.git"}]', NULL, 'GPL-3.0', 'approved', 80, '4a38125d8a794cc4f96ef612bbc26aec', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-Fosowl-agenticSeek from https://github.com/Fosowl.png
Image converted to WebP: data/images/github-Fosowl-agenticSeek.webp

*/
INSERT OR REPLACE INTO models (id, slug, name, author, description, tags, pipeline_tag, likes, downloads, cover_image_url, source_trail, commercial_slots, notebooklm_summary, velocity_score, last_commercial_at, type, body_content, meta_json, assets_json, relations_json, canonical_id, license_spdx, compliance_status, quality_score, content_hash, velocity, raw_image_url, last_updated) VALUES ('github-onlook-dev-onlook', 'github--onlook-dev--onlook', 'onlook', 'onlook-dev', '<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 --> <div align="center"> <img width="800" alt="header image" src="assets/web-preview.png"> <h3 align="center">Onlook</h3> <p align="center"> Cursor for Designers <br /> <a href="https://docs.onlook.com"><strong>Explore the docs ¬ª</strong></a> <br /> </p> <p align="center"> üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª <a href="https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstac...', '["ai","cursor","cursor-ai","design","design-to-code","drizzle","editor","figma","frontend","ide","low-code","nextjs","react","supabase","tailwindcss","typescript","ui","vibe-coding","vibecoding","typescript"]', 'other', 23453, 0, NULL, '[{"source_platform":"github","source_url":"https://github.com/onlook-dev/onlook","fetched_at":"2025-12-08T10:39:52.046Z","adapter_version":"3.2.0"}]', NULL, NULL, 0, NULL, 'tool', '<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->\n\n<div align="center">\n<img width="800" alt="header image" src="assets/web-preview.png">\n<h3 align="center">Onlook</h3>\n  <p align="center">\n    Cursor for Designers\n    <br />\n    <a href="https://docs.onlook.com"><strong>Explore the docs ¬ª</strong></a>\n    <br />\n  </p>\n  <p align="center">\n    üë®‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª\n    <a href="https://www.ycombinator.com/companies/onlook/jobs/e4gHv1n-founding-engineer-fullstack">We''re hiring engineers in SF!</a>\n    üë©‚Äçüíªüë®‚Äçüíªüë©‚Äçüíª\n  </p>\n    <br />\n    <a href="https://youtu.be/RSX_3EaO5eU?feature=shared">View Demo</a>\n    ¬∑\n    <a href="https://github.com/onlook-dev/onlook/issues/new?labels=bug&template=bug-report---.md">Report Bug</a>\n    ¬∑\n    <a href="https://github.com/onlook-dev/onlook/issues/new?labels=enhancement&template=feature-request---.md">Request Feature</a>\n  </p>\n  <!-- PROJECT SHIELDS -->\n<!--\n*** I''m using markdown "reference style" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n<!-- [![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![Apache License][license-shield]][license-url] -->\n\n[![Discord][discord-shield]][discord-url]\n[![LinkedIn][linkedin-shield]][linkedin-url]\n[![Twitter][twitter-shield]][twitter-url]\n\n[‰∏≠Êñá](https://www.readme-i18n.com/onlook-dev/onlook?lang=zh) |\n[Espa√±ol](https://www.readme-i18n.com/onlook-dev/onlook?lang=es) |\n[Deutsch](https://www.readme-i18n.com/onlook-dev/onlook?lang=de) |\n[fran√ßais](https://www.readme-i18n.com/onlook-dev/onlook?lang=fr) |\n[Portugu√™s](https://www.readme-i18n.com/onlook-dev/onlook?lang=pt) |\n[–†—É—Å—Å–∫–∏–π](https://www.readme-i18n.com/onlook-dev/onlook?lang=ru) |\n[Êó•Êú¨Ë™û](https://www.readme-i18n.com/onlook-dev/onlook?lang=ja) |\n[ÌïúÍµ≠Ïñ¥](https://www.readme-i18n.com/onlook-dev/onlook?lang=ko)\n\n</div>\n\n# An Open-Source, Visual-First Code Editor\n\nCraft websites, prototypes, and designs with AI in Next.js + TailwindCSS. Make\nedits directly in the browser DOM with a visual editor. Design in realtime with\ncode. An open-source alternative to Bolt.new, Lovable, V0, Replit Agent, Figma\nMake, Webflow, etc.\n\n### üöß üöß üöß Onlook is still under development üöß üöß üöß\n\nWe''re actively looking for contributors to help make Onlook for Web an\nincredible prompt-to-build experience. Check the\n[open issues](https://github.com/onlook-dev/onlook/issues) for a full list of\nproposed features (and known issues), and join our\n[Discord](https://discord.gg/hERDfFZCsH) to collaborate with hundreds of other\nbuilders.\n\n## What you can do with Onlook:\n\n- [x] Create Next.js app in seconds\n  - [x] Start from text or image\n  - [x] Use prebuilt templates\n  - [ ] Import from Figma\n  - [ ] Import from GitHub repo\n  - [ ] Make a PR to a GitHub repo\n- [x] Visually edit your app\n  - [x] Use Figma-like UI\n  - [x] Preview your app in real-time\n  - [x] Manage brand assets and tokens\n  - [x] Create and navigate to Pages\n  - [x] Browse layers\n  - [x] Manage project Images\n  - [x] Detect and use Components ‚Äì _Previously in\n        [Onlook Desktop](https://github.com/onlook-dev/desktop)_\n  - [ ] Drag-and-drop Components Panel\n  - [x] Use Branching to experiment with designs\n- [x] Development Tools\n  - [x] Real-time code editor\n  - [x] Save and restore from checkpoints\n  - [x] Run commands via CLI\n  - [x] Connect with app marketplace\n- [x] Deploy your app in seconds\n  - [x] Generate sharable links\n  - [x] Link your custom domain    \n- [ ] Collaborate with your team\n  - [x] Real-time editing\n  - [ ] Leave comments\n- [ ] Advanced AI capabilities\n  - [x] Queue multiple messages at once\n  - [ ] Use Images as references and as assets in a project\n  - [ ] Setup and use MCPs in projects\n  - [ ] Allow Onlook to use itself as a toolcall for branch creation and iteration\n- [ ] Advanced project support\n  - [ ] Support non-NextJS projects\n  - [ ] Support non-Tailwind projects\n\n![Onlook-GitHub-Example](https://github.com/user-attachments/assets/642de37a-72cc-4056-8eb7-8eb42714cdc4)\n\n## Getting Started\n\nUse our [hosted app](https://onlook.com) or\n[run locally](https://docs.onlook.com/developers/running-locally).\n\n### Usage\n\nOnlook will run on any Next.js + TailwindCSS project, import your project into\nOnlook or start from scratch within the editor.\n\nUse the AI chat to create or edit a project you''re working on. At any time, you\ncan always right-click an element to open up the exact location of the element\nin code.\n\n<img width="600" alt="image" src="https://github.com/user-attachments/assets/4ad9f411-b172-4430-81ef-650f4f314666" />\n\n<br>\n\nDraw-in new divs and re-arrange them within their parent containers by\ndragging-and-dropping.\n\n<img width="600" alt="image" src="assets/insert-div.png">\n\n<br>\n\nPreview the code side-by-side with your site design.\n\n<img width="600" alt="image" src="assets/code-connect.png">\n\n<br>\n\nUse Onlook''s editor toolbar to adjust Tailwind styles, directly manipulate\nobjects, and experiment with layouts.\n\n<img width="600" alt="image" src="assets/text-styling.png" />\n\n## Documentation\n\nFor full documentation, visit [docs.onlook.com](https://docs.onlook.com)\n\nTo see how to Contribute, visit\n[Contributing to Onlook](https://docs.onlook.com/developers) in our docs.\n\n## How it works\n\n<img width="676" alt="architecture" src="assets/architecture.png">\n\n1. When you create an app, we load the code into a web container\n2. The container runs and serves the code\n3. Our editor receives the preview link and displays it in an iFrame\n4. Our editor reads and indexes the code from the container\n5. We instrument the code in order to map elements to their place in code\n6. When the element is edited, we edit the element in our iFrame, then in code\n7. Our AI chat also has code access and tools to understand and edit the code\n\nThis architecture can theoretically scale to any language or framework that\ndisplays DOM elements declaratively (e.g. jsx/tsx/html). We are focused on\nmaking it work well with Next.js and TailwindCSS for now.\n\nFor a full walkthrough, check out our\n[Architecture Docs](https://docs.onlook.com/developers/architecture).\n\n### Our Tech Stack\n\n#### Front-end\n\n- [Next.js](https://nextjs.org/) - Full stack\n- [TailwindCSS](https://tailwindcss.com/) - Styling\n- [tRPC](https://trpc.io/) - Server interface\n\n#### Database\n\n- [Supabase](https://supabase.com/) - Auth, Database, Storage\n- [Drizzle](https://orm.drizzle.team/) - ORM\n\n#### AI\n\n- [AI SDK](https://ai-sdk.dev/) - LLM client\n- [OpenRouter](https://openrouter.ai/) - LLM model provider\n- [Morph Fast Apply](https://morphllm.com) - Fast apply model provider\n- [Relace](https://relace.ai) - Fast apply model provider\n\n#### Sandbox and hosting\n\n- [CodeSandboxSDK](https://codesandbox.io/docs/sdk) - Dev sandbox\n- [Freestyle](https://www.freestyle.sh/) - Hosting\n\n#### Runtime\n\n- [Bun](https://bun.sh/) - Monorepo, runtime, bundler\n- [Docker](https://www.docker.com/) - Container management\n\n## Contributing\n\n![image](https://github.com/user-attachments/assets/ecc94303-df23-46ae-87dc-66b040396e0b)\n\nIf you have a suggestion that would make this better, please fork the repo and\ncreate a pull request. You can also\n[open issues](https://github.com/onlook-dev/onlook/issues).\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) for instructions and code of conduct.\n\n#### Contributors\n\n<a href="https://github.com/onlook-dev/onlook/graphs/contributors">\n  <img src="https://contrib.rocks/image?repo=onlook-dev/onlook" />\n</a>\n\n## Contact\n\n![image](https://github.com/user-attachments/assets/60684b68-1925-4550-8efd-51a1509fc953)\n\n- Team: [Discord](https://discord.gg/hERDfFZCsH) -\n  [Twitter](https://twitter.com/onlookdev) -\n  [LinkedIn](https://www.linkedin.com/company/onlook-dev/) -\n  [Email](mailto:contact@onlook.com)\n- Project:\n  [https://github.com/onlook-dev/onlook](https://github.com/onlook-dev/onlook)\n- Website: [https://onlook.com](https://onlook.com)\n\n## License\n\nDistributed under the Apache 2.0 License. See [LICENSE.md](LICENSE.md) for more\ninformation.\n\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n\n[contributors-shield]: https://img.shields.io/github/contributors/onlook-dev/studio.svg?style=for-the-badge\n[contributors-url]: https://github.com/onlook-dev/onlook/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/onlook-dev/studio.svg?style=for-the-badge\n[forks-url]: https://github.com/onlook-dev/onlook/network/members\n[stars-shield]: https://img.shields.io/github/stars/onlook-dev/studio.svg?style=for-the-badge\n[stars-url]: https://github.com/onlook-dev/onlook/stargazers\n[issues-shield]: https://img.shields.io/github/issues/onlook-dev/studio.svg?style=for-the-badge\n[issues-url]: https://github.com/onlook-dev/onlook/issues\n[license-shield]: https://img.shields.io/github/license/onlook-dev/studio.svg?style=for-the-badge\n[license-url]: https://github.com/onlook-dev/onlook/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?logo=linkedin&colorB=555\n[linkedin-url]: https://www.linkedin.com/company/onlook-dev\n[twitter-shield]: https://img.shields.io/badge/-Twitter-black?logo=x&colorB=555\n[twitter-url]: https://x.com/onlookdev\n[discord-shield]: https://img.shields.io/badge/-Discord-black?logo=discord&colorB=555\n[discord-url]: https://discord.gg/hERDfFZCsH\n[React.js]: https://img.shields.io/badge/react-%2320232a.svg?logo=react&logoColor=%2361DAFB\n[React-url]: https://reactjs.org/\n[TailwindCSS]: https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?logo=tailwind-css&logoColor=white\n[Tailwind-url]: https://tailwindcss.com/\n[Electron.js]: https://img.shields.io/badge/Electron-191970?logo=Electron&logoColor=white\n[Electron-url]: https://www.electronjs.org/\n[Vite.js]: https://img.shields.io/badge/vite-%23646CFF.svg?logo=vite&logoColor=white\n[Vite-url]: https://vitejs.dev/\n[product-screenshot]: assets/brand.png\n[weave-shield]: https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_pWcXBHJo3Li2Te2Y4WkCPA33%2F820087727&cacheSeconds=3600&labelColor=#131313\n[weave-url]: https://app.workweave.ai/reports/repository/org_pWcXBHJo3Li2Te2Y4WkCPA33/820087727\n', '{"language":"TypeScript","stars":23453,"forks":1718,"watchers":23453,"open_issues":348,"topics":["ai","cursor","cursor-ai","design","design-to-code","drizzle","editor","figma","frontend","ide","low-code","nextjs","react","supabase","tailwindcss","typescript","ui","vibe-coding","vibecoding"],"default_branch":"main","size_kb":79873,"archived":false,"fork":false,"has_wiki":true,"has_pages":false}', '[]', '[{"type":"has_code","target_id":"github:othneildrew:Best-README-Template","source_url":"https://github.com/othneildrew/Best-README-Template"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:desktop","source_url":"https://github.com/onlook-dev/desktop"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:user-attachments:assets","source_url":"https://github.com/user-attachments/assets"},{"type":"has_code","target_id":"github:onlook-dev:onlook](https:","source_url":"https://github.com/onlook-dev/onlook](https:"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"},{"type":"has_code","target_id":"github:onlook-dev:onlook","source_url":"https://github.com/onlook-dev/onlook"}]', NULL, 'Apache-2.0', 'approved', 80, '5f550294cc948f27c01c90a7d0d9da74', NULL, NULL, CURRENT_TIMESTAMP);
/* LOGS:
Downloading image for github-onlook-dev-onlook from https://github.com/onlook-dev.png
Image converted to WebP: data/images/github-onlook-dev-onlook.webp

*/;
