[
  {
    "id": "arxiv:2512.07112v1",
    "name": "FOAM: Blocked State Folding for Memory-Efficient LLM Training",
    "author": "Ziqing Wen",
    "description": "Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory fo...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI",
      "llm"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07112v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Large language models (LLMs) have demonstrated remarkable performance due to their large parameter counts and extensive training data. However, their scale leads to significant memory bottlenecks during training, especially when using memory-intensive optimizers like Adam. Existing memory-efficient approaches often rely on techniques such as singular value decomposition (SVD), projections, or weight freezing, which can introduce substantial computational overhead, require additional memory for projections, or degrade model performance. In this paper, we propose Folded Optimizer with Approximate Moment (FOAM), a method that compresses optimizer states by computing block-wise gradient means and incorporates a residual correction to recover lost information. Theoretically, FOAM achieves convergence rates equivalent to vanilla Adam under standard non-convex optimization settings. Empirically, FOAM reduces total training memory by approximately 50\\%, eliminates up to 90\\% of optimizer state memory overhead, and accelerates convergence. Furthermore, FOAM is compatible with other memory-efficient optimizers, delivering performance and throughput that match or surpass both full-rank and existing memory-efficient baselines.",
    "meta_json": "{\"arxiv_id\":\"2512.07112v1\",\"authors\":[\"Ziqing Wen\",\"Jiahuan Wang\",\"Ping Luo\",\"Dongsheng Li\",\"Tao Sun\"],\"categories\":[\"cs.LG\",\"cs.AI\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:48:27Z\",\"updated_date\":\"2025-12-08T02:48:27Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "a367708d7397baadb8159c03f78659a9",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07112v1\",\"fetched_at\":\"2025-12-10T01:31:39.562Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07110v1",
    "name": "MSN: Multi-directional Similarity Network for Hand-crafted and Deep-synthesized Copy-Move Forgery Detection",
    "author": "Liangwei Jiang",
    "description": "Copy-move image forgery aims to duplicate certain objects or to hide specific contents with copy-move operations, which can be achieved by a sequence of manual manipulations as well as up-to-date deep generative network-based swapping. Its detection is becoming increasingly challenging for the complex transformations and fine-tuned operations on the tampered regions. In this paper, we propose a novel two-stream model, namely Multi-directional Similarity Network (MSN), to accurate and efficien...",
    "tags": [
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07110v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Copy-move image forgery aims to duplicate certain objects or to hide specific contents with copy-move operations, which can be achieved by a sequence of manual manipulations as well as up-to-date deep generative network-based swapping. Its detection is becoming increasingly challenging for the complex transformations and fine-tuned operations on the tampered regions. In this paper, we propose a novel two-stream model, namely Multi-directional Similarity Network (MSN), to accurate and efficient copy-move forgery detection. It addresses the two major limitations of existing deep detection models in \\textbf{representation} and \\textbf{localization}, respectively. In representation, an image is hierarchically encoded by a multi-directional CNN network, and due to the diverse augmentation in scales and rotations, the feature achieved better measures the similarity between sampled patches in two streams. In localization, we design a 2-D similarity matrix based decoder, and compared with the current 1-D similarity vector based one, it makes full use of spatial information in the entire image, leading to the improvement in detecting tampered regions. Beyond the method, a new forgery database generated by various deep neural networks is presented, as a new benchmark for detecting the growing deep-synthesized copy-move. Extensive experiments are conducted on two classic image forensics benchmarks, \\emph{i.e.} CASIA CMFD and CoMoFoD, and the newly presented one. The state-of-the-art results are reported, which demonstrate the effectiveness of the proposed approach.",
    "meta_json": "{\"arxiv_id\":\"2512.07110v1\",\"authors\":[\"Liangwei Jiang\",\"Jinluo Xie\",\"Yecheng Huang\",\"Hua Zhang\",\"Hongyu Yang\",\"Di Huang\"],\"categories\":[\"cs.CV\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:47:05Z\",\"updated_date\":\"2025-12-08T02:47:05Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "48fa5e925b3e4a7ee721fa642188d7dc",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07110v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07109v1",
    "name": "A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy",
    "author": "Miguel Ingram",
    "description": "Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity fo...",
    "tags": [
      "arxiv:cs.AI",
      "arxiv:cs.CL",
      "arxiv:cs.LG",
      "transformer",
      "neural"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07109v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve &gt;80% cell accuracy (local patterns) but &lt;10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p&lt;0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,",
    "meta_json": "{\"arxiv_id\":\"2512.07109v1\",\"authors\":[\"Miguel Ingram\",\"Arthur Joseph Merritt\"],\"categories\":[\"cs.AI\",\"cs.CL\",\"cs.LG\"],\"primary_category\":\"cs.AI\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:46:00Z\",\"updated_date\":\"2025-12-08T02:46:00Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "143057d2c42f6569dd689d1cb029c376",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07109v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07107v1",
    "name": "COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision",
    "author": "Jaeyoon Lee",
    "description": "We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to...",
    "tags": [
      "arxiv:cs.CV",
      "vision"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07107v1",
    "image_url": null,
    "type": "paper",
    "body_content": "We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to-fine bidirectional 3D-to-3D alignment strategy that allows geometric signals to be learned directly in 3D space. Within this strategy, depth provides coarse alignment between the two representations, while depth gradients and normals refine fine-scale structure, and the resulting geometry supports stable BRDF-lighting decomposition. A density-control mechanism further stabilizes Gaussian growth, balancing geometric fidelity with memory efficiency. Experiments on standard benchmarks demonstrate that COREA achieves superior performance in novel-view synthesis, mesh reconstruction, and PBR within a unified framework.",
    "meta_json": "{\"arxiv_id\":\"2512.07107v1\",\"authors\":[\"Jaeyoon Lee\",\"Hojoon Jung\",\"Sungtae Hwang\",\"Jihyong Oh\",\"Jongwon Choi\"],\"categories\":[\"cs.CV\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:41:42Z\",\"updated_date\":\"2025-12-08T02:41:42Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "0081c4f2f66479ce7e3846ca1086d51c",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07107v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07100v1",
    "name": "Dual Refinement Cycle Learning: Unsupervised Text Classification of Mamba and Community Detection on Text Attributed Graph",
    "author": "Hong Wang",
    "description": "Pretrained language models offer strong text understanding capabilities but remain difficult to deploy in real-world text-attributed networks due to their heavy dependence on labeled data. Meanwhile, community detection methods typically ignore textual semantics, limiting their usefulness in downstream applications such as content organization, recommendation, and risk monitoring. To overcome these limitations, we present Dual Refinement Cycle Learning (DRCL), a fully unsupervised framework d...",
    "tags": [
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07100v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Pretrained language models offer strong text understanding capabilities but remain difficult to deploy in real-world text-attributed networks due to their heavy dependence on labeled data. Meanwhile, community detection methods typically ignore textual semantics, limiting their usefulness in downstream applications such as content organization, recommendation, and risk monitoring. To overcome these limitations, we present Dual Refinement Cycle Learning (DRCL), a fully unsupervised framework designed for practical scenarios where no labels or category definitions are available. DRCL integrates structural and semantic information through a warm-start initialization and a bidirectional refinement cycle between a GCN-based Community Detection Module (GCN-CDM) and a Text Semantic Modeling Module (TSMM). The two modules iteratively exchange pseudo-labels, allowing semantic cues to enhance structural clustering and structural patterns to guide text representation learning without manual supervision. Across several text-attributed graph datasets, DRCL consistently improves the structural and semantic quality of discovered communities. Moreover, a Mamba-based classifier trained solely from DRCL's community signals achieves accuracy comparable to supervised models, demonstrating its potential for deployment in large-scale systems where labeled data are scarce or costly.",
    "meta_json": "{\"arxiv_id\":\"2512.07100v1\",\"authors\":[\"Hong Wang\",\"Yinglong Zhang\",\"Hanhan Guo\",\"Xuewen Xia\",\"Xing Xu\"],\"categories\":[\"cs.LG\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:31:42Z\",\"updated_date\":\"2025-12-08T02:31:42Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "8fb185db651b002e575fab67a720ef1b",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07100v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07094v1",
    "name": "VIGIL: A Reflective Runtime for Self-Healing Agents",
    "author": "Christopher Cruz",
    "description": "Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime ...",
    "tags": [
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07094v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.",
    "meta_json": "{\"arxiv_id\":\"2512.07094v1\",\"authors\":[\"Christopher Cruz\"],\"categories\":[\"cs.AI\"],\"primary_category\":\"cs.AI\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:18:41Z\",\"updated_date\":\"2025-12-08T02:18:41Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "fd885579413f60818d9a48f252b66073",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07094v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07092v1",
    "name": "The Geometry of Persona: Disentangling Personality from Reasoning in Large Language Models",
    "author": "Zhixiang Wang",
    "description": "Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an \"alignment tax\" -- degrading general reasoning capabilities. Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introd...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI",
      "language"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07092v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Background: The deployment of personalized Large Language Models (LLMs) is currently constrained by the stability-plasticity dilemma. Prevailing alignment methods, such as Supervised Fine-Tuning (SFT), rely on stochastic weight updates that often incur an \"alignment tax\" -- degrading general reasoning capabilities. Methods: We propose the Soul Engine, a framework based on the Linear Representation Hypothesis, which posits that personality traits exist as orthogonal linear subspaces. We introduce SoulBench, a dataset constructed via dynamic contextual sampling. Using a dual-head architecture on a frozen Qwen-2.5 base, we extract disentangled personality vectors without modifying the backbone weights. Results: Our experiments demonstrate three breakthroughs. First, High-Precision Profiling: The model achieves a Mean Squared Error (MSE) of 0.011 against psychological ground truth. Second, Geometric Orthogonality: T-SNE visualization confirms that personality manifolds are distinct and continuous, allowing for \"Zero-Shot Personality Injection\" that maintains original model intelligence. Third, Deterministic Steering: We achieve robust control over behavior via vector arithmetic, validated through extensive ablation studies. Conclusion: This work challenges the necessity of fine-tuning for personalization. By transitioning from probabilistic prompting to deterministic latent intervention, we provide a mathematically rigorous foundation for safe, controllable AI personalization.",
    "meta_json": "{\"arxiv_id\":\"2512.07092v1\",\"authors\":[\"Zhixiang Wang\"],\"categories\":[\"cs.LG\",\"cs.AI\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T02:00:57Z\",\"updated_date\":\"2025-12-08T02:00:57Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "ad3d1b1f5af82c3cc4d800203f396b53",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07092v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07090v1",
    "name": "Leveraging KV Similarity for Online Structured Pruning in LLMs",
    "author": "Jungmin Lee",
    "description": "Pruning has emerged as a promising direction for accelerating large language model (LLM) inference, yet existing approaches often suffer from instability because they rely on offline calibration data that may not generalize across inputs. In this work, we introduce Token Filtering, a lightweight online structured pruning technique that makes pruning decisions directly during inference without any calibration data. The key idea is to measure token redundancy via joint key-value similarity and ...",
    "tags": [
      "arxiv:cs.CL",
      "arxiv:cs.AI",
      "llm"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07090v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Pruning has emerged as a promising direction for accelerating large language model (LLM) inference, yet existing approaches often suffer from instability because they rely on offline calibration data that may not generalize across inputs. In this work, we introduce Token Filtering, a lightweight online structured pruning technique that makes pruning decisions directly during inference without any calibration data. The key idea is to measure token redundancy via joint key-value similarity and skip redundant attention computations, thereby reducing inference cost while preserving critical information. To further enhance stability, we design a variance-aware fusion strategy that adaptively weights key and value similarity across heads, ensuring that informative tokens are retained even under high pruning ratios. This design introduces no additional memory overhead and provides a more reliable criterion for token importance. Extensive experiments on LLaMA-2 (7B/13B), LLaMA-3 (8B), and Mistral (7B) demonstrate that Token Filtering consistently outperforms prior structured pruning methods, preserving accuracy on commonsense reasoning benchmarks and maintaining strong performance on challenging tasks such as MMLU, even with 50% pruning.",
    "meta_json": "{\"arxiv_id\":\"2512.07090v1\",\"authors\":[\"Jungmin Lee\",\"Gwangeun Byeon\",\"Yulhwa Kim\",\"Seokin Hong\"],\"categories\":[\"cs.CL\",\"cs.AI\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:56:27Z\",\"updated_date\":\"2025-12-08T01:56:27Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "820db79bf77717f619be423acf0e07c2",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07090v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07086v1",
    "name": "ThinkTrap: Denial-of-Service Attacks against Black-box LLM Services via Infinite Thinking",
    "author": "Yunzhe Li",
    "description": "Large Language Models (LLMs) have become foundational components in a wide range of applications, including natural language understanding and generation, embodied intelligence, and scientific discovery. As their computational requirements continue to grow, these models are increasingly deployed as cloud-based services, allowing users to access powerful LLMs via the Internet. However, this deployment model introduces a new class of threat: denial-of-service (DoS) attacks via unbounded reasoni...",
    "tags": [
      "arxiv:cs.CR",
      "arxiv:cs.AI",
      "arxiv:cs.LG",
      "llm"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07086v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Large Language Models (LLMs) have become foundational components in a wide range of applications, including natural language understanding and generation, embodied intelligence, and scientific discovery. As their computational requirements continue to grow, these models are increasingly deployed as cloud-based services, allowing users to access powerful LLMs via the Internet. However, this deployment model introduces a new class of threat: denial-of-service (DoS) attacks via unbounded reasoning, where adversaries craft specially designed inputs that cause the model to enter excessively long or infinite generation loops. These attacks can exhaust backend compute resources, degrading or denying service to legitimate users. To mitigate such risks, many LLM providers adopt a closed-source, black-box setting to obscure model internals. In this paper, we propose ThinkTrap, a novel input-space optimization framework for DoS attacks against LLM services even in black-box environments. The core idea of ThinkTrap is to first map discrete tokens into a continuous embedding space, then undertake efficient black-box optimization in a low-dimensional subspace exploiting input sparsity. The goal of this optimization is to identify adversarial prompts that induce extended or non-terminating generation across several state-of-the-art LLMs, achieving DoS with minimal token overhead. We evaluate the proposed attack across multiple commercial, closed-source LLM services. Our results demonstrate that, even far under the restrictive request frequency limits commonly enforced by these platforms, typically capped at ten requests per minute (10 RPM), the attack can degrade service throughput to as low as 1% of its original capacity, and in some cases, induce complete service failure.",
    "meta_json": "{\"arxiv_id\":\"2512.07086v1\",\"authors\":[\"Yunzhe Li\",\"Jianan Wang\",\"Hongzi Zhu\",\"James Lin\",\"Shan Chang\",\"Minyi Guo\"],\"categories\":[\"cs.CR\",\"cs.AI\",\"cs.LG\"],\"primary_category\":\"cs.CR\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:41:57Z\",\"updated_date\":\"2025-12-08T01:41:57Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CR\",\"source_url\":\"https://arxiv.org/abs/cs.CR\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "5f5e3f93d954f0f0bbecf5e93fe315dd",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07086v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07082v1",
    "name": "TRACE: A Generalizable Drift Detector for Streaming Data-Driven Optimization",
    "author": "Yuan-Ting Zhong",
    "description": "Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively...",
    "tags": [
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07082v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Many optimization tasks involve streaming data with unknown concept drifts, posing a significant challenge as Streaming Data-Driven Optimization (SDDO). Existing methods, while leveraging surrogate model approximation and historical knowledge transfer, are often under restrictive assumptions such as fixed drift intervals and fully environmental observability, limiting their adaptability to diverse dynamic environments. We propose TRACE, a TRAnsferable C}oncept-drift Estimator that effectively detects distributional changes in streaming data with varying time scales. TRACE leverages a principled tokenization strategy to extract statistical features from data streams and models drift patterns using attention-based sequence learning, enabling accurate detection on unseen datasets and highlighting the transferability of learned drift patterns. Further, we showcase TRACE's plug-and-play nature by integrating it into a streaming optimizer, facilitating adaptive optimization under unknown drifts. Comprehensive experimental results on diverse benchmarks demonstrate the superior generalization, robustness, and effectiveness of our approach in SDDO scenarios.",
    "meta_json": "{\"arxiv_id\":\"2512.07082v1\",\"authors\":[\"Yuan-Ting Zhong\",\"Ting Huang\",\"Xiaolin Xiao\",\"Yue-Jiao Gong\"],\"categories\":[\"cs.LG\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:33:16Z\",\"updated_date\":\"2025-12-08T01:33:16Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "67ab6dfc86fd1c37168d14be30e3b051",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07082v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07079v1",
    "name": "Procrustean Bed for AI-Driven Retrosynthesis: A Unified Framework for Reproducible Evaluation",
    "author": "Anton Morgunov",
    "description": "Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped conf...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07079v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Progress in computer-aided synthesis planning (CASP) is obscured by the lack of standardized evaluation infrastructure and the reliance on metrics that prioritize topological completion over chemical validity. We introduce RetroCast, a unified evaluation suite that standardizes heterogeneous model outputs into a common schema to enable statistically rigorous, apples-to-apples comparison. The framework includes a reproducible benchmarking pipeline with stratified sampling and bootstrapped confidence intervals, accompanied by SynthArena, an interactive platform for qualitative route inspection. We utilize this infrastructure to evaluate leading search-based and sequence-based algorithms on a new suite of standardized benchmarks. Our analysis reveals a divergence between \"solvability\" (stock-termination rate) and route quality; high solvability scores often mask chemical invalidity or fail to correlate with the reproduction of experimental ground truths. Furthermore, we identify a \"complexity cliff\" in which search-based methods, despite high solvability rates, exhibit a sharp performance decay in reconstructing long-range synthetic plans compared to sequence-based approaches. We release the full framework, benchmark definitions, and a standardized database of model predictions to support transparent and reproducible development in the field.",
    "meta_json": "{\"arxiv_id\":\"2512.07079v1\",\"authors\":[\"Anton Morgunov\",\"Victor S. Batista\"],\"categories\":[\"cs.LG\",\"cs.AI\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:26:39Z\",\"updated_date\":\"2025-12-08T01:26:39Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "187518345e171c1ec0a43d1d8effaa07",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07079v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07078v1",
    "name": "DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection",
    "author": "Bo Gao",
    "description": "Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencie...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07078v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily. We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency. We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.",
    "meta_json": "{\"arxiv_id\":\"2512.07078v1\",\"authors\":[\"Bo Gao\",\"Jingcheng Tong\",\"Xingsheng Chen\",\"Han Yu\",\"Zichen Li\"],\"categories\":[\"cs.CV\",\"cs.LG\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:25:10Z\",\"updated_date\":\"2025-12-08T01:25:10Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "bfab3c68581fb1ba00315e136583908b",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07078v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07076v1",
    "name": "Context-measure: Contextualizing Metric for Camouflage",
    "author": "Chen-Yang Wang",
    "description": "Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, ...",
    "tags": [
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07076v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.",
    "meta_json": "{\"arxiv_id\":\"2512.07076v1\",\"authors\":[\"Chen-Yang Wang\",\"Gepeng Ji\",\"Song Shao\",\"Ming-Ming Cheng\",\"Deng-Ping Fan\"],\"categories\":[\"cs.CV\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:23:28Z\",\"updated_date\":\"2025-12-08T01:23:28Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"has_code\",\"target_id\":\"github:pursuitxi:Context-measure.\",\"source_url\":\"https://github.com/pursuitxi/Context-measure.\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "3457c31e5e4a43b41bd5c2b39252aebc",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07076v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07075v1",
    "name": "Do Large Language Models Truly Understand Cross-cultural Differences?",
    "author": "Shiwei Guo",
    "description": "In recent years, large language models (LLMs) have demonstrated strong performance on multilingual tasks. Given its wide range of applications, cross-cultural understanding capability is a crucial competency. However, existing benchmarks for evaluating whether LLMs genuinely possess this capability suffer from three key limitations: a lack of contextual scenarios, insufficient cross-cultural concept mapping, and limited deep cultural reasoning capabilities. To address these gaps, we propose S...",
    "tags": [
      "arxiv:cs.CL",
      "language"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07075v1",
    "image_url": null,
    "type": "paper",
    "body_content": "In recent years, large language models (LLMs) have demonstrated strong performance on multilingual tasks. Given its wide range of applications, cross-cultural understanding capability is a crucial competency. However, existing benchmarks for evaluating whether LLMs genuinely possess this capability suffer from three key limitations: a lack of contextual scenarios, insufficient cross-cultural concept mapping, and limited deep cultural reasoning capabilities. To address these gaps, we propose SAGE, a scenario-based benchmark built via cross-cultural core concept alignment and generative task design, to evaluate LLMs' cross-cultural understanding and reasoning. Grounded in cultural theory, we categorize cross-cultural capabilities into nine dimensions. Using this framework, we curated 210 core concepts and constructed 4530 test items across 15 specific real-world scenarios, organized under four broader categories of cross-cultural situations, following established item design principles. The SAGE dataset supports continuous expansion, and experiments confirm its transferability to other languages. It reveals model weaknesses across both dimensions and scenarios, exposing systematic limitations in cross-cultural reasoning. While progress has been made, LLMs are still some distance away from reaching a truly nuanced cross-cultural understanding. In compliance with the anonymity policy, we include data and code in the supplement materials. In future versions, we will make them publicly available online.",
    "meta_json": "{\"arxiv_id\":\"2512.07075v1\",\"authors\":[\"Shiwei Guo\",\"Sihang Jiang\",\"Qianxi He\",\"Yanghua Xiao\",\"Jiaqing Liang\",\"Bi Yude\",\"Minggui He\",\"Shimin Tao\",\"Li Zhang\"],\"categories\":[\"cs.CL\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-08T01:21:58Z\",\"updated_date\":\"2025-12-08T01:21:58Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "0d784e094a4875431b648e2d96d13a8d",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07075v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07068v1",
    "name": "SETUP: Sentence-level English-To-Uniform Meaning Representation Parser",
    "author": "Emma Markle",
    "description": "Uniform Meaning Representation (UMR) is a novel graph-based semantic representation which captures the core meaning of a text, with flexibility incorporated into the annotation schema such that the breadth of the world's languages can be annotated (including low-resource languages). While UMR shows promise in enabling language documentation, improving low-resource language technologies, and adding interpretability, the downstream applications of UMR can only be fully explored when text-to-UMR...",
    "tags": [
      "arxiv:cs.CL"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07068v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Uniform Meaning Representation (UMR) is a novel graph-based semantic representation which captures the core meaning of a text, with flexibility incorporated into the annotation schema such that the breadth of the world's languages can be annotated (including low-resource languages). While UMR shows promise in enabling language documentation, improving low-resource language technologies, and adding interpretability, the downstream applications of UMR can only be fully explored when text-to-UMR parsers enable the automatic large-scale production of accurate UMR graphs at test time. Prior work on text-to-UMR parsing is limited to date. In this paper, we introduce two methods for English text-to-UMR parsing, one of which fine-tunes existing parsers for Abstract Meaning Representation and the other, which leverages a converter from Universal Dependencies, using prior work as a baseline. Our best-performing model, which we call SETUP, achieves an AnCast score of 84 and a SMATCH++ score of 91, indicating substantial gains towards automatic UMR parsing.",
    "meta_json": "{\"arxiv_id\":\"2512.07068v1\",\"authors\":[\"Emma Markle\",\"Javier Gutierrez Bach\",\"Shira Wein\"],\"categories\":[\"cs.CL\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-08T00:56:00Z\",\"updated_date\":\"2025-12-08T00:56:00Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 75,
    "content_hash": "f6a34edefca32901a59727b83c78e757",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07068v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07065v1",
    "name": "Persistent Homology-Guided Frequency Filtering for Image Compression",
    "author": "Anil Chintapalli",
    "description": "Feature extraction in noisy image datasets presents many challenges in model reliability. In this paper, we use the discrete Fourier transform in conjunction with persistent homology analysis to extract specific frequencies that correspond with certain topological features of an image. This method allows the image to be compressed and reformed while ensuring that meaningful data can be differentiated. Our experimental results show a level of compression comparable to that of using JPEG using ...",
    "tags": [
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07065v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Feature extraction in noisy image datasets presents many challenges in model reliability. In this paper, we use the discrete Fourier transform in conjunction with persistent homology analysis to extract specific frequencies that correspond with certain topological features of an image. This method allows the image to be compressed and reformed while ensuring that meaningful data can be differentiated. Our experimental results show a level of compression comparable to that of using JPEG using six different metrics. The end goal of persistent homology-guided frequency filtration is its potential to improve performance in binary classification tasks (when augmenting a Convolutional Neural Network) compared to traditional feature extraction and compression methods. These findings highlight a useful end result: enhancing the reliability of image compression under noisy conditions.",
    "meta_json": "{\"arxiv_id\":\"2512.07065v1\",\"authors\":[\"Anil Chintapalli\",\"Peter Tenholder\",\"Henry Chen\",\"Arjun Rao\"],\"categories\":[\"cs.CV\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T00:53:09Z\",\"updated_date\":\"2025-12-08T00:53:09Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "fa03d1d6443d010e586750b2def1916d",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07065v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07064v1",
    "name": "Self-Supervised Learning on Molecular Graphs: A Systematic Investigation of Masking Design",
    "author": "Jiannan Yang",
    "description": "Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI",
      "arxiv:q-bio.QM"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07064v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Self-supervised learning (SSL) plays a central role in molecular representation learning. Yet, many recent innovations in masking-based pretraining are introduced as heuristics and lack principled evaluation, obscuring which design choices are genuinely effective. This work cast the entire pretrain-finetune workflow into a unified probabilistic framework, enabling a transparent comparison and deeper understanding of masking strategies. Building on this formalism, we conduct a controlled study of three core design dimensions: masking distribution, prediction target, and encoder architecture, under rigorously controlled settings. We further employ information-theoretic measures to assess the informativeness of pretraining signals and connect them to empirically benchmarked downstream performance. Our findings reveal a surprising insight: sophisticated masking distributions offer no consistent benefit over uniform sampling for common node-level prediction tasks. Instead, the choice of prediction target and its synergy with the encoder architecture are far more critical. Specifically, shifting to semantically richer targets yields substantial downstream improvements, particularly when paired with expressive Graph Transformer encoders. These insights offer practical guidance for developing more effective SSL methods for molecular graphs.",
    "meta_json": "{\"arxiv_id\":\"2512.07064v1\",\"authors\":[\"Jiannan Yang\",\"Veronika Thost\",\"Tengfei Ma\"],\"categories\":[\"cs.LG\",\"cs.AI\",\"q-bio.QM\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-08T00:52:46Z\",\"updated_date\":\"2025-12-08T00:52:46Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:q-bio.QM\",\"source_url\":\"https://arxiv.org/abs/q-bio.QM\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 75,
    "content_hash": "866f7ed7ae2554286e0325aecbb4b4c3",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07064v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07062v1",
    "name": "$\\mathrm{D}^{\\mathrm{3}}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction",
    "author": "Changliang Xia",
    "description": "Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric s...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.AI",
      "diffusion"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07062v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\\mathrm{D}^{\\mathrm{3}}$-Predictor, a noise-free deterministic framework built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\\mathrm{D}^{\\mathrm{3}}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\\mathrm{D}^{\\mathrm{3}}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.",
    "meta_json": "{\"arxiv_id\":\"2512.07062v1\",\"authors\":[\"Changliang Xia\",\"Chengyou Jia\",\"Minnan Luo\",\"Zhuohang Dang\",\"Xin Shen\",\"Bowen Ping\"],\"categories\":[\"cs.CV\",\"cs.AI\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-08T00:39:32Z\",\"updated_date\":\"2025-12-08T00:39:32Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "651de0385c9fe2feffa0abc230bb9279",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07062v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07059v1",
    "name": "Replicating TEMPEST at Scale: Multi-Turn Adversarial Attacks Against Trillion-Parameter Frontier Models",
    "author": "Richard Young",
    "description": "Despite substantial investment in safety alignment, the vulnerability of large language models to sophisticated multi-turn adversarial attacks remains poorly characterized, and whether model scale or inference mode affects robustness is unknown. This study employed the TEMPEST multi-turn attack framework to evaluate ten frontier models from eight vendors across 1,000 harmful behaviors, generating over 97,000 API queries across adversarial conversations with automated evaluation by independent...",
    "tags": [
      "arxiv:cs.CL"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07059v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Despite substantial investment in safety alignment, the vulnerability of large language models to sophisticated multi-turn adversarial attacks remains poorly characterized, and whether model scale or inference mode affects robustness is unknown. This study employed the TEMPEST multi-turn attack framework to evaluate ten frontier models from eight vendors across 1,000 harmful behaviors, generating over 97,000 API queries across adversarial conversations with automated evaluation by independent safety classifiers. Results demonstrated a spectrum of vulnerability: six models achieved 96% to 100% attack success rate (ASR), while four showed meaningful resistance, with ASR ranging from 42% to 78%; enabling extended reasoning on identical architecture reduced ASR from 97% to 42%. These findings indicate that safety alignment quality varies substantially across vendors, that model scale does not predict adversarial robustness, and that thinking mode provides a deployable safety enhancement. Collectively, this work establishes that current alignment techniques remain fundamentally vulnerable to adaptive multi-turn attacks regardless of model scale, while identifying deliberative inference as a promising defense direction.",
    "meta_json": "{\"arxiv_id\":\"2512.07059v1\",\"authors\":[\"Richard Young\"],\"categories\":[\"cs.CL\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-08T00:30:40Z\",\"updated_date\":\"2025-12-08T00:30:40Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "5b18edc48d250fa4f1e466ef34613fbb",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07059v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07052v1",
    "name": "RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting",
    "author": "Hoang-Nhat Tran",
    "description": "Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that su...",
    "tags": [
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07052v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code will be provided open-source upon acceptance of the work.",
    "meta_json": "{\"arxiv_id\":\"2512.07052v1\",\"authors\":[\"Hoang-Nhat Tran\",\"Francesco Di Sario\",\"Gabriele Spadaro\",\"Giuseppe Valenzise\",\"Enzo Tartaglione\"],\"categories\":[\"cs.CV\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T23:59:46Z\",\"updated_date\":\"2025-12-07T23:59:46Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "a26575aeefa63e2305077311f5a3900f",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07052v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07051v1",
    "name": "DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation",
    "author": "Adnan Munir",
    "description": "Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using Sim...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.AI",
      "arxiv:cs.LG",
      "attention"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07051v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.",
    "meta_json": "{\"arxiv_id\":\"2512.07051v1\",\"authors\":[\"Adnan Munir\",\"Shujaat Khan\"],\"categories\":[\"cs.CV\",\"cs.AI\",\"cs.LG\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T23:57:00Z\",\"updated_date\":\"2025-12-07T23:57:00Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "2d91e049e8295a9a84acf4d4efbb8dc2",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07051v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07040v1",
    "name": "Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis",
    "author": "Sakib Mostafa",
    "description": "Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependenc...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07040v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes &gt; 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.",
    "meta_json": "{\"arxiv_id\":\"2512.07040v1\",\"authors\":[\"Sakib Mostafa\",\"Lei Xing\",\"Md. Tauhidul Islam\"],\"categories\":[\"cs.LG\",\"cs.CV\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T23:17:18Z\",\"updated_date\":\"2025-12-07T23:17:18Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 75,
    "content_hash": "146e5eb4282eb53ce41b31f153e7f662",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07040v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07037v1",
    "name": "Evaluating and Preserving High-level Fidelity in Super-Resolution",
    "author": "Josep M. Rocafort",
    "description": "Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for ...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07037v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for SR models as a complementary criterion to reveal the reliability of generative SR models. We construct the first annotated dataset with fidelity scores from different SR models, and evaluate how state-of-the-art (SOTA) SR models actually perform in preserving high-level fidelity. Based on the dataset, we then analyze how existing image quality metrics correlate with fidelity measurement, and further show that this high-level task can be better addressed by foundation models. Finally, by fine-tuning SR models based on our fidelity feedback, we show that both semantic fidelity and perceptual quality can be improved, demonstrating the potential value of our proposed criteria, both in model evaluation and optimization. We will release the dataset, code, and models upon acceptance.",
    "meta_json": "{\"arxiv_id\":\"2512.07037v1\",\"authors\":[\"Josep M. Rocafort\",\"Shaolin Su\",\"Javier Vazquez-Corral\",\"Alexandra Gomez-Villa\"],\"categories\":[\"cs.CV\",\"cs.LG\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:53:34Z\",\"updated_date\":\"2025-12-07T22:53:34Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "a60c3368cc5d1d42903f698f814eedab",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07037v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07034v1",
    "name": "Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues",
    "author": "Tuan-Anh Vu",
    "description": "Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Fe...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.AI",
      "transformer",
      "vision"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07034v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Feature Enhancement and Reflection Feature Enhancement modules in a mutually beneficial way. Our proposed framework, TransCues, is a pyramidal transformer encoder-decoder architecture to segment transparent objects. We empirically show that these two modules can be used together effectively, improving overall performance across various benchmark datasets, including glass object semantic segmentation, mirror object semantic segmentation, and generic segmentation datasets. Our method outperforms the state-of-the-art by a large margin, achieving +4.2% mIoU on Trans10K-v2, +5.6% mIoU on MSD, +10.1% mIoU on RGBD-Mirror, +13.1% mIoU on TROSD, and +8.3% mIoU on Stanford2D3D, showing the effectiveness of our method against glass objects.",
    "meta_json": "{\"arxiv_id\":\"2512.07034v1\",\"authors\":[\"Tuan-Anh Vu\",\"Hai Nguyen-Truong\",\"Ziqiang Zheng\",\"Binh-Son Hua\",\"Qing Guo\",\"Ivor Tsang\",\"Sai-Kit Yeung\"],\"categories\":[\"cs.CV\",\"cs.AI\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:52:53Z\",\"updated_date\":\"2025-12-07T22:52:53Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "dac4e14ac8ba2f2f317f620c08a84cad",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07034v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07030v1",
    "name": "A Comprehensive Study of Supervised Machine Learning Models for Zero-Day Attack Detection: Analyzing Performance on Imbalanced Data",
    "author": "Zahra Lotfi",
    "description": "Among the various types of cyberattacks, identifying zero-day attacks is problematic because they are unknown to security systems as their pattern and characteristics do not match known blacklisted attacks. There are many Machine Learning (ML) models designed to analyze and detect network attacks, especially using supervised models. However, these models are designed to classify samples (normal and attacks) based on the patterns they learn during the training phase, so they perform inefficien...",
    "tags": [
      "arxiv:cs.CR",
      "arxiv:cs.AI",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07030v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Among the various types of cyberattacks, identifying zero-day attacks is problematic because they are unknown to security systems as their pattern and characteristics do not match known blacklisted attacks. There are many Machine Learning (ML) models designed to analyze and detect network attacks, especially using supervised models. However, these models are designed to classify samples (normal and attacks) based on the patterns they learn during the training phase, so they perform inefficiently on unseen attacks. This research addresses this issue by evaluating five different supervised models to assess their performance and execution time in predicting zero-day attacks and find out which model performs accurately and quickly. The goal is to improve the performance of these supervised models by not only proposing a framework that applies grid search, dimensionality reduction and oversampling methods to overcome the imbalance problem, but also comparing the effectiveness of oversampling on ml model metrics, in particular the accuracy. To emulate attack detection in real life, this research applies a highly imbalanced data set and only exposes the classifiers to zero-day attacks during the testing phase, so the models are not trained to flag the zero-day attacks. Our results show that Random Forest (RF) performs best under both oversampling and non-oversampling conditions, this increased effectiveness comes at the cost of longer processing times. Therefore, we selected XG Boost (XGB) as the top model due to its fast and highly accurate performance in detecting zero-day attacks.",
    "meta_json": "{\"arxiv_id\":\"2512.07030v1\",\"authors\":[\"Zahra Lotfi\",\"Mostafa Lotfi\"],\"categories\":[\"cs.CR\",\"cs.AI\",\"cs.LG\"],\"primary_category\":\"cs.CR\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:42:37Z\",\"updated_date\":\"2025-12-07T22:42:37Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CR\",\"source_url\":\"https://arxiv.org/abs/cs.CR\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "e7fd0fcfe3a293c1b2e219f729e898a4",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07030v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07022v1",
    "name": "Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization",
    "author": "Genevieve Caumartin",
    "description": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powere...",
    "tags": [
      "arxiv:cs.SE",
      "arxiv:cs.AI",
      "arxiv:cs.IR"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07022v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent.",
    "meta_json": "{\"arxiv_id\":\"2512.07022v1\",\"authors\":[\"Genevieve Caumartin\",\"Glaucia Melo\"],\"categories\":[\"cs.SE\",\"cs.AI\",\"cs.IR\"],\"primary_category\":\"cs.SE\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:25:11Z\",\"updated_date\":\"2025-12-07T22:25:11Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.SE\",\"source_url\":\"https://arxiv.org/abs/cs.SE\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.IR\",\"source_url\":\"https://arxiv.org/abs/cs.IR\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "28d6762ebcac410709d23664ae809563",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07022v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07021v1",
    "name": "Transferring Clinical Knowledge into ECGs Representation",
    "author": "Jose Geraldo Fernandes",
    "description": "Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enr...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07021v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Deep learning models have shown high accuracy in classifying electrocardiograms (ECGs), but their black box nature hinders clinical adoption due to a lack of trust and interpretability. To address this, we propose a novel three-stage training paradigm that transfers knowledge from multimodal clinical data (laboratory exams, vitals, biometrics) into a powerful, yet unimodal, ECG encoder. We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time. Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding. Evaluated on the MIMIC-IV-ECG dataset, our model outperforms a standard signal-only baseline in multi-label diagnosis classification and successfully bridges a substantial portion of the performance gap to a fully multimodal model that requires all data at inference. Our work demonstrates a practical and effective method for creating more accurate and trustworthy ECG classification models. By converting abstract predictions into physiologically grounded \\emph{explanations}, our approach offers a promising path toward the safer integration of AI into clinical workflows.",
    "meta_json": "{\"arxiv_id\":\"2512.07021v1\",\"authors\":[\"Jose Geraldo Fernandes\",\"Luiz Facury de Souza\",\"Pedro Robles Dutenhefner\",\"Gisele L. Pappa\",\"Wagner Meira\"],\"categories\":[\"cs.LG\",\"cs.AI\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:19:24Z\",\"updated_date\":\"2025-12-07T22:19:24Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "1e544b6eaaa5dad356b078a2ddf43018",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07021v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07019v1",
    "name": "Latency-Response Theory Model: Evaluating Large Language Models via Response Accuracy and Chain-of-Thought Length",
    "author": "Zhiyu Xu",
    "description": "The proliferation of Large Language Models (LLMs) necessitates valid evaluation methods to provide guidance for both downstream applications and actionable future improvements. The Item Response Theory (IRT) model with Computerized Adaptive Testing has recently emerged as a promising framework for evaluating LLMs via their response accuracy. Beyond simple response accuracy, LLMs' chain of thought (CoT) lengths serve as a vital indicator of their reasoning ability. To leverage the CoT length i...",
    "tags": [
      "arxiv:stat.ME",
      "arxiv:cs.AI",
      "arxiv:stat.AP",
      "arxiv:stat.ML",
      "language"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07019v1",
    "image_url": null,
    "type": "paper",
    "body_content": "The proliferation of Large Language Models (LLMs) necessitates valid evaluation methods to provide guidance for both downstream applications and actionable future improvements. The Item Response Theory (IRT) model with Computerized Adaptive Testing has recently emerged as a promising framework for evaluating LLMs via their response accuracy. Beyond simple response accuracy, LLMs' chain of thought (CoT) lengths serve as a vital indicator of their reasoning ability. To leverage the CoT length information to assist the evaluation of LLMs, we propose the Latency-Response Theory (LaRT) model, which jointly models both the response accuracy and CoT length by introducing a key correlation parameter between the latent ability and the latent speed. We derive an efficient stochastic approximation Expectation-Maximization algorithm for parameter estimation. We establish rigorous identifiability results for the latent ability and latent speed parameters to ensure the statistical validity of their estimation. Through both theoretical asymptotic analyses and simulation studies, we demonstrate LaRT's advantages over IRT in terms of superior estimation accuracy and shorter confidence intervals for latent trait estimation. To evaluate LaRT in real data, we collect responses from diverse LLMs on popular benchmark datasets. We find that LaRT yields different LLM rankings than IRT and outperforms IRT across multiple key evaluation metrics including predictive power, item efficiency, ranking validity, and LLM evaluation efficiency. Code and data are available at https://github.com/Toby-X/Latency-Response-Theory-Model.",
    "meta_json": "{\"arxiv_id\":\"2512.07019v1\",\"authors\":[\"Zhiyu Xu\",\"Jia Liu\",\"Yixin Wang\",\"Yuqi Gu\"],\"categories\":[\"stat.ME\",\"cs.AI\",\"stat.AP\",\"stat.ML\"],\"primary_category\":\"stat.ME\",\"pdf_url\":null,\"published_date\":\"2025-12-07T22:06:51Z\",\"updated_date\":\"2025-12-07T22:06:51Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"has_code\",\"target_id\":\"github:Toby-X:Latency-Response-Theory-Model.\",\"source_url\":\"https://github.com/Toby-X/Latency-Response-Theory-Model.\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.ME\",\"source_url\":\"https://arxiv.org/abs/stat.ME\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.AP\",\"source_url\":\"https://arxiv.org/abs/stat.AP\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.ML\",\"source_url\":\"https://arxiv.org/abs/stat.ML\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "5ff3abe1d588a4b246cd517f3b6778d3",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07019v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07015v1",
    "name": "FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations",
    "author": "Mayank Ravishankara",
    "description": "Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to \"hallucinate with citations....",
    "tags": [
      "arxiv:cs.CL",
      "arxiv:cs.AI",
      "arxiv:cs.IR"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07015v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to \"hallucinate with citations.\" In this work, we introduce Falsification-Verification Alignment RAG (FVA-RAG), a framework that shifts the retrieval paradigm from Inductive Verification (seeking support) to Deductive Falsification (seeking disproof). Unlike existing \"Self-Correction\" methods that rely on internal consistency, FVA-RAG deploys a distinct Adversarial Retrieval Policy that actively generates \"Kill Queries\"-targeted search terms designed to surface contradictory evidence. We introduce a dual-verification mechanism that explicitly weighs the draft answer against this \"Anti-Context.\" Preliminary experiments on a dataset of common misconceptions demonstrate that FVA-RAG significantly improves robustness against sycophantic hallucinations compared to standard RAG baselines, effectively acting as an inference-time \"Red Team\" for factual generation.",
    "meta_json": "{\"arxiv_id\":\"2512.07015v1\",\"authors\":[\"Mayank Ravishankara\"],\"categories\":[\"cs.CL\",\"cs.AI\",\"cs.IR\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:28:42Z\",\"updated_date\":\"2025-12-07T21:28:42Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.IR\",\"source_url\":\"https://arxiv.org/abs/cs.IR\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "ad78ddd31dc104dd777b39a501265a4b",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07015v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07011v1",
    "name": "Block Sparse Flash Attention",
    "author": "Daniel Ohayon",
    "description": "Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. B...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.CL",
      "arxiv:cs.PF",
      "attention"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07011v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention",
    "meta_json": "{\"arxiv_id\":\"2512.07011v1\",\"authors\":[\"Daniel Ohayon\",\"Itay Lamprecht\",\"Itay Hubara\",\"Israel Cohen\",\"Daniel Soudry\",\"Noam Elata\"],\"categories\":[\"cs.LG\",\"cs.CL\",\"cs.PF\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:20:12Z\",\"updated_date\":\"2025-12-07T21:20:12Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"has_code\",\"target_id\":\"github:Danielohayon:Block-Sparse-Flash-Attention\",\"source_url\":\"https://github.com/Danielohayon/Block-Sparse-Flash-Attention\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.PF\",\"source_url\":\"https://arxiv.org/abs/cs.PF\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "d78ffc785f5b5d0b12e316bfd37ec019",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07011v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07010v1",
    "name": "Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation",
    "author": "Kevin Lee",
    "description": "Layer-wise Relevance Propagation (LRP) provides principled attribution for neural networks through conservation properties and foundations in Deep Taylor Decomposition. However, existing implementations operate at the module level, requiring architecture-specific propagation rules and modifications. These limit the generality of target model and sustainability of implementations as architectures evolve. We introduce DynamicLRP, a model-agnostic LRP framework operating at the tensor operation ...",
    "tags": [
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07010v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Layer-wise Relevance Propagation (LRP) provides principled attribution for neural networks through conservation properties and foundations in Deep Taylor Decomposition. However, existing implementations operate at the module level, requiring architecture-specific propagation rules and modifications. These limit the generality of target model and sustainability of implementations as architectures evolve. We introduce DynamicLRP, a model-agnostic LRP framework operating at the tensor operation level. By decomposing attribution to individual operations within computation graphs and introducing a novel mechanism for deferred activation resolution, named the Promise System, our approach achieves true architecture agnosticity while maintaining LRP's theoretical guarantees. This design operates independently of backpropagation machinery, enabling operation on arbitrary computation graphs without model modification and side-by-side execution with gradient backpropagation. Being based on computation graphs, this method is theoretically extensible to other deep learning libraries that support auto-differentiation. We demonstrate faithfulness matching or exceeding specialized implementations (1.77 vs 1.69 ABPC on VGG, equivalent performance on ViT, 93.70\\% and 95.06\\% top-1 attribution accuracy for explaining RoBERTa-large and Flan-T5-large answers on SQuADv2, respectively) while maintaining practical efficiency on models with hundreds of millions of parameters. We achieved 99.92\\% node coverage across 31,465 computation graph nodes from 15 diverse architectures, including state-space models (Mamba), audio transformers (Whisper), and multimodal systems (DePlot) without any model-specific code with rules for 47 fundamental operations implemented. Our operation-level decomposition and Promise System establish a sustainable, extensible foundation for LRP across evolving architectures.",
    "meta_json": "{\"arxiv_id\":\"2512.07010v1\",\"authors\":[\"Kevin Lee\",\"Pablo Millan Arias\"],\"categories\":[\"cs.LG\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:19:04Z\",\"updated_date\":\"2025-12-07T21:19:04Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "194cfcc0553403044e390ef1db415003",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07010v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07009v1",
    "name": "Optimizing video analytics inference pipelines: a case study",
    "author": "Saeid Ghafouri",
    "description": "Cost-effective and scalable video analytics are essential for precision livestock monitoring, where high-resolution footage and near-real-time monitoring needs from commercial farms generates substantial computational workloads. This paper presents a comprehensive case study on optimizing a poultry welfare monitoring system through system-level improvements across detection, tracking, clustering, and behavioral analysis modules. We introduce a set of optimizations, including multi-level paral...",
    "tags": [
      "arxiv:cs.DC",
      "arxiv:cs.AI",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07009v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Cost-effective and scalable video analytics are essential for precision livestock monitoring, where high-resolution footage and near-real-time monitoring needs from commercial farms generates substantial computational workloads. This paper presents a comprehensive case study on optimizing a poultry welfare monitoring system through system-level improvements across detection, tracking, clustering, and behavioral analysis modules. We introduce a set of optimizations, including multi-level parallelization, Optimizing code with substituting CPU code with GPU-accelerated code, vectorized clustering, and memory-efficient post-processing. Evaluated on real-world farm video footage, these changes deliver up to a 2x speedup across pipelines without compromising model accuracy. Our findings highlight practical strategies for building high-throughput, low-latency video inference systems that reduce infrastructure demands in agricultural and smart sensing deployments as well as other large-scale video analytics applications.",
    "meta_json": "{\"arxiv_id\":\"2512.07009v1\",\"authors\":[\"Saeid Ghafouri\",\"Yuming Ding\",\"Katerine Diaz Chito\",\"Jess Martinez del Rincn\",\"Niamh O'Connell\",\"Hans Vandierendonck\"],\"categories\":[\"cs.DC\",\"cs.AI\",\"cs.LG\"],\"primary_category\":\"cs.DC\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:17:53Z\",\"updated_date\":\"2025-12-07T21:17:53Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.DC\",\"source_url\":\"https://arxiv.org/abs/cs.DC\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "9a155c05ab8c3c107f5b1384f121d03a",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07009v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07005v1",
    "name": "Multi-Accent Mandarin Dry-Vocal Singing Dataset: Benchmark for Singing Accent Recognition",
    "author": "Zihao Wang",
    "description": "Singing accent research is underexplored compared to speech accent studies, primarily due to the scarcity of suitable datasets. Existing singing datasets often suffer from detail loss, frequently resulting from the vocal-instrumental separation process. Additionally, they often lack regional accent annotations. To address this, we introduce the Multi-Accent Mandarin Dry-Vocal Singing Dataset (MADVSD). MADVSD comprises over 670 hours of dry vocal recordings from 4,206 native Mandarin speakers ...",
    "tags": [
      "arxiv:cs.SD",
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07005v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Singing accent research is underexplored compared to speech accent studies, primarily due to the scarcity of suitable datasets. Existing singing datasets often suffer from detail loss, frequently resulting from the vocal-instrumental separation process. Additionally, they often lack regional accent annotations. To address this, we introduce the Multi-Accent Mandarin Dry-Vocal Singing Dataset (MADVSD). MADVSD comprises over 670 hours of dry vocal recordings from 4,206 native Mandarin speakers across nine distinct Chinese regions. In addition to each participant recording audio of three popular songs in their native accent, they also recorded phonetic exercises covering all Mandarin vowels and a full octave range. We validated MADVSD through benchmark experiments in singing accent recognition, demonstrating its utility for evaluating state-of-the-art speech models in singing contexts. Furthermore, we explored dialectal influences on singing accent and analyzed the role of vowels in accentual variations, leveraging MADVSD's unique phonetic exercises.",
    "meta_json": "{\"arxiv_id\":\"2512.07005v1\",\"authors\":[\"Zihao Wang\",\"Ruibin Yuan\",\"Ziqi Geng\",\"Hengjia Li\",\"Xingwei Qu\",\"Xinyi Li\",\"Songye Chen\",\"Haoying Fu\",\"Roger B. Dannenberg\",\"Kejun Zhang\"],\"categories\":[\"cs.SD\",\"cs.AI\"],\"primary_category\":\"cs.SD\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:14:26Z\",\"updated_date\":\"2025-12-07T21:14:26Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.SD\",\"source_url\":\"https://arxiv.org/abs/cs.SD\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "a414680335ea44c8dda89544bebaf0f1",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07005v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.07000v1",
    "name": "Benchmarking Deep Neural Networks for Modern Recommendation Systems",
    "author": "Abderaouf Bahi",
    "description": "This paper examines the deployment of seven different neural network architectures CNN, RNN, GNN, Autoencoder, Transformer, NCF, and Siamese Networks on three distinct datasets: Retail E-commerce, Amazon Products, and Netflix Prize. It evaluates their effectiveness through metrics such as accuracy, recall, F1-score, and diversity in recommendations. The results demonstrate that GNNs are particularly adept at managing complex item relationships in e-commerce environments, whereas RNNs are effe...",
    "tags": [
      "arxiv:cs.IR",
      "arxiv:cs.AI",
      "neural"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.07000v1",
    "image_url": null,
    "type": "paper",
    "body_content": "This paper examines the deployment of seven different neural network architectures CNN, RNN, GNN, Autoencoder, Transformer, NCF, and Siamese Networks on three distinct datasets: Retail E-commerce, Amazon Products, and Netflix Prize. It evaluates their effectiveness through metrics such as accuracy, recall, F1-score, and diversity in recommendations. The results demonstrate that GNNs are particularly adept at managing complex item relationships in e-commerce environments, whereas RNNs are effective in capturing the temporal dynamics that are essential for platforms such as Netflix.. Siamese Networks are emphasized for their contribution to the diversification of recommendations, particularly in retail settings. Despite their benefits, issues like computational demands, reliance on extensive data, and the challenge of balancing accurate and diverse recommendations are addressed. The study seeks to inform the advancement of recommendation systems by suggesting hybrid methods that merge the strengths of various models to better satisfy user preferences and accommodate the evolving demands of contemporary digital platforms.",
    "meta_json": "{\"arxiv_id\":\"2512.07000v1\",\"authors\":[\"Abderaouf Bahi\",\"Ibtissem Gasmi\"],\"categories\":[\"cs.IR\",\"cs.AI\"],\"primary_category\":\"cs.IR\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:06:24Z\",\"updated_date\":\"2025-12-07T21:06:24Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.IR\",\"source_url\":\"https://arxiv.org/abs/cs.IR\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "708f18fa549ce33ed6639326c238d208",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.07000v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06999v1",
    "name": "Singing Timbre Popularity Assessment Based on Multimodal Large Foundation Model",
    "author": "Zihao Wang",
    "description": "Automated singing assessment is crucial for education and entertainment. However, existing systems face two fundamental limitations: reliance on reference tracks, which stifles creative expression, and the simplification of complex performances into non-diagnostic scores based solely on pitch and rhythm. We advocate for a shift from discriminative to descriptive evaluation, creating a complete ecosystem for reference-free, multi-dimensional assessment. First, we introduce Sing-MD, a large-sca...",
    "tags": [
      "arxiv:cs.SD",
      "arxiv:cs.AI",
      "multimodal"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06999v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Automated singing assessment is crucial for education and entertainment. However, existing systems face two fundamental limitations: reliance on reference tracks, which stifles creative expression, and the simplification of complex performances into non-diagnostic scores based solely on pitch and rhythm. We advocate for a shift from discriminative to descriptive evaluation, creating a complete ecosystem for reference-free, multi-dimensional assessment. First, we introduce Sing-MD, a large-scale dataset annotated by experts across four dimensions: breath control, timbre quality, emotional expression, and vocal technique. Our analysis reveals significant annotation inconsistencies among experts, challenging the validity of traditional accuracy-based metrics. Second, addressing the memory limitations of Multimodal Large Language Models (MLLMs) in analyzing full-length songs, we propose VocalVerse. This efficient hybrid architecture leverages a lightweight acoustic encoder to model global performance features and long-term dependencies. Third, to address automated metric shortcomings, we establish the H-TPR (Human-in-the-loop Tiered Perceptual Ranking) benchmark, which evaluates a model's ability to generate perceptually valid rankings rather than predicting noisy ground-truth scores.",
    "meta_json": "{\"arxiv_id\":\"2512.06999v1\",\"authors\":[\"Zihao Wang\",\"Ruibin Yuan\",\"Ziqi Geng\",\"Hengjia Li\",\"Xingwei Qu\",\"Xinyi Li\",\"Songye Chen\",\"Haoying Fu\",\"Roger B. Dannenberg\",\"Kejun Zhang\"],\"categories\":[\"cs.SD\",\"cs.AI\"],\"primary_category\":\"cs.SD\",\"pdf_url\":null,\"published_date\":\"2025-12-07T21:06:16Z\",\"updated_date\":\"2025-12-07T21:06:16Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.SD\",\"source_url\":\"https://arxiv.org/abs/cs.SD\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "bb6b9f660ca419e56c6de9b784e3798d",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06999v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06993v1",
    "name": "Toward Reliable Machine Unlearning: Theory, Algorithms, and Evaluation",
    "author": "Ali Ebrahimpour-Boroojeny",
    "description": "We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on t...",
    "tags": [
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06993v1",
    "image_url": null,
    "type": "paper",
    "body_content": "We propose new methodologies for both unlearning random set of samples and class unlearning and show that they outperform existing methods. The main driver of our unlearning methods is the similarity of predictions to a retrained model on both the forget and remain samples. We introduce Adversarial Machine UNlearning (AMUN), which surpasses prior state-of-the-art methods for image classification based on SOTA MIA scores. AMUN lowers the model's confidence on forget samples by fine-tuning on their corresponding adversarial examples. Through theoretical analysis, we identify factors governing AMUN's performance, including smoothness. To facilitate training of smooth models with a controlled Lipschitz constant, we propose FastClip, a scalable method that performs layer-wise spectral-norm clipping of affine layers. In a separate study, we show that increased smoothness naturally improves adversarial example transfer, thereby supporting the second factor above. Following the same principles for class unlearning, we show that existing methods fail in replicating a retrained model's behavior by introducing a nearest-neighbor membership inference attack (MIA-NN) that uses the probabilities assigned to neighboring classes to detect unlearned samples and demonstrate the vulnerability of such methods. We then propose a fine-tuning objective that mitigates this leakage by approximating, for forget-class inputs, the distribution over remaining classes that a model retrained from scratch would produce. To construct this approximation, we estimate inter-class similarity and tilt the target model's distribution accordingly. The resulting Tilted ReWeighting(TRW) distribution serves as the desired target during fine-tuning. Across multiple benchmarks, TRW matches or surpasses existing unlearning methods on prior metrics.",
    "meta_json": "{\"arxiv_id\":\"2512.06993v1\",\"authors\":[\"Ali Ebrahimpour-Boroojeny\"],\"categories\":[\"cs.LG\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:57:25Z\",\"updated_date\":\"2025-12-07T20:57:25Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "a268caacd7a288fd508b080bb7b2857a",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06993v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06991v1",
    "name": "Prompting-in-a-Series: Psychology-Informed Contents and Embeddings for Personality Recognition With Decoder-Only Models",
    "author": "Jing Jie Tan",
    "description": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel \"Prompting-in-a-Series\" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition fun...",
    "tags": [
      "arxiv:cs.CL",
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06991v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel \"Prompting-in-a-Series\" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition functions as a personality feature extractor and a generator for personality-rich content. We conducted various experiments to provide evidence to justify the rationale behind the PICEPR algorithm. Meanwhile, we also explored closed-source models such as \\textit{gpt4o} from OpenAI and \\textit{gemini} from Google, along with open-source models like \\textit{mistral} from Mistral AI, to compare the quality of the generated content. The PICEPR algorithm has achieved a new state-of-the-art performance for personality recognition by 5-15\\% improvement. The work repository and models' weight can be found at https://research.jingjietan.com/?q=PICEPR.",
    "meta_json": "{\"arxiv_id\":\"2512.06991v1\",\"authors\":[\"Jing Jie Tan\",\"Ban-Hoe Kwan\",\"Danny Wee-Kiat Ng\",\"Yan-Chai Hum\",\"Anissa Mokraoui\",\"Shih-Yu Lo\"],\"categories\":[\"cs.CL\",\"cs.AI\"],\"primary_category\":\"cs.CL\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:52:00Z\",\"updated_date\":\"2025-12-07T20:52:00Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "bf876df6d8e84d6449bdc06dac6c158c",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06991v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06990v1",
    "name": "Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients",
    "author": "Krishna Arun",
    "description": "Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional ...",
    "tags": [
      "arxiv:cs.AI",
      "arxiv:cs.CV",
      "arxiv:eess.IV",
      "reinforcement"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06990v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional Neural Networks and Support Vector Machine) are used. Each model progressively classifies the patient's brain into increasingly specific categories, with the final step being named diagnosis. For treatment planning, an RL system consisting of 3 generative models is used. First, the resection model (diffusion model) analyzes the diagnosed GBM MRI and predicts a possible resection outcome. Second, the radiotherapy model (Spatio-Temporal Vision Transformer) generates an MRI of the brain's progression after a user-defined number of weeks. Third, the chemotherapy model (Diffusion Model) produces the post-treatment MRI. A survival rate calculator (Convolutional Neural Network) then checks if the generated post treatment MRI has a survival rate within 15% of the user defined target. If not, a feedback loop using proximal policy optimization iterates over this system until an optimal resection location is identified. When compared to existing solutions, this project found 3 key findings: (1) Using a sequential decision-making framework consisting of 4 small diagnostic models reduced computing costs by 22.28x, (2) Transformers regression capabilities decreased tumor progression inference time by 113 hours, and (3) Applying Augmentations resembling Real-life situations improved overall DICE scores by 2.9%. These results project to increase survival rates by 0.9%, potentially saving approximately 2,250 lives.",
    "meta_json": "{\"arxiv_id\":\"2512.06990v1\",\"authors\":[\"Krishna Arun\",\"Moinak Bhattachrya\",\"Paras Goel\"],\"categories\":[\"cs.AI\",\"cs.CV\",\"eess.IV\"],\"primary_category\":\"cs.AI\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:51:59Z\",\"updated_date\":\"2025-12-07T20:51:59Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:eess.IV\",\"source_url\":\"https://arxiv.org/abs/eess.IV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 75,
    "content_hash": "0acf8ba2c4a6f4e5955140567a384461",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06990v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06989v1",
    "name": "Flash Multi-Head Feed-Forward Network",
    "author": "Minshen Zhang",
    "description": "We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To addr...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI",
      "arxiv:cs.CL"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06989v1",
    "image_url": null,
    "type": "paper",
    "body_content": "We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To address these challenges, we propose Flash Multi-Head FFN (FlashMHF), with two key innovations: an I/O-aware fused kernel computing outputs online in SRAM akin to FlashAttention, and a design using dynamically weighted parallel sub-networks to maintain a balanced ratio between intermediate and head dimensions. Validated on models from 128M to 1.3B parameters, FlashMHF consistently improves perplexity and downstream task accuracy over SwiGLU FFNs, while reducing peak memory usage by 3-5x and accelerating inference by up to 1.08x. Our work establishes the multi-head design as a superior architectural principle for FFNs, presenting FlashMHF as a powerful, efficient, and scalable alternative to FFNs in Transformers.",
    "meta_json": "{\"arxiv_id\":\"2512.06989v1\",\"authors\":[\"Minshen Zhang\",\"Xiang Hu\",\"Jianguo Li\",\"Wei Wu\",\"Kewei Tu\"],\"categories\":[\"cs.LG\",\"cs.AI\",\"cs.CL\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:50:20Z\",\"updated_date\":\"2025-12-07T20:50:20Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CL\",\"source_url\":\"https://arxiv.org/abs/cs.CL\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "a40ce77efcea602627b005c108ea5d99",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06989v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06987v1",
    "name": "OXtal: An All-Atom Diffusion Model for Organic Crystal Structure Prediction",
    "author": "Emily Jin",
    "description": "Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion mo...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cond-mat.mtrl-sci",
      "diffusion",
      "gan"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06987v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Accurately predicting experimentally-realizable 3D molecular crystal structures from their 2D chemical graphs is a long-standing open challenge in computational chemistry called crystal structure prediction (CSP). Efficiently solving this problem has implications ranging from pharmaceuticals to organic semiconductors, as crystal packing directly governs the physical and chemical properties of organic solids. In this paper, we introduce OXtal, a large-scale 100M parameter all-atom diffusion model that directly learns the conditional joint distribution over intramolecular conformations and periodic packing. To efficiently scale OXtal, we abandon explicit equivariant architectures imposing inductive bias arising from crystal symmetries in favor of data augmentation strategies. We further propose a novel crystallization-inspired lattice-free training scheme, Stoichiometric Stochastic Shell Sampling ($S^4$), that efficiently captures long-range interactions while sidestepping explicit lattice parametrization -- thus enabling more scalable architectural choices at all-atom resolution. By leveraging a large dataset of 600K experimentally validated crystal structures (including rigid and flexible molecules, co-crystals, and solvates), OXtal achieves orders-of-magnitude improvements over prior ab initio machine learning CSP methods, while remaining orders of magnitude cheaper than traditional quantum-chemical approaches. Specifically, OXtal recovers experimental structures with conformer $\\text{RMSD}_1&lt;0.5$  and attains over 80\\% packing similarity rate, demonstrating its ability to model both thermodynamic and kinetic regularities of molecular crystallization.",
    "meta_json": "{\"arxiv_id\":\"2512.06987v1\",\"authors\":[\"Emily Jin\",\"Andrei Cristian Nica\",\"Mikhail Galkin\",\"Jarrid Rector-Brooks\",\"Kin Long Kelvin Lee\",\"Santiago Miret\",\"Frances H. Arnold\",\"Michael Bronstein\",\"Avishek Joey Bose\",\"Alexander Tong\",\"Cheng-Hao Liu\"],\"categories\":[\"cs.LG\",\"cond-mat.mtrl-sci\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:46:30Z\",\"updated_date\":\"2025-12-07T20:46:30Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cond-mat.mtrl-sci\",\"source_url\":\"https://arxiv.org/abs/cond-mat.mtrl-sci\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "4796cb2158c398cc0d26139d4562f765",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06987v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06983v1",
    "name": "On Memory: A comparison of memory mechanisms in world models",
    "author": "Eli J. Laird",
    "description": "World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models thro...",
    "tags": [
      "arxiv:cs.AI",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06983v1",
    "image_url": null,
    "type": "paper",
    "body_content": "World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.",
    "meta_json": "{\"arxiv_id\":\"2512.06983v1\",\"authors\":[\"Eli J. Laird\",\"Corey Clark\"],\"categories\":[\"cs.AI\",\"cs.LG\"],\"primary_category\":\"cs.AI\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:29:20Z\",\"updated_date\":\"2025-12-07T20:29:20Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "e0e902aa50fb0fdca0285745f56fd356",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06983v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06982v1",
    "name": "LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding",
    "author": "Yu Yu",
    "description": "Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate out...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:eess.SY",
      "llm",
      "neural"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06982v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Designing state encoders for reinforcement learning (RL) with multiple information sources -- such as sensor measurements, time-series signals, image observations, and textual instructions -- remains underexplored and often requires manual design. We formalize this challenge as a problem of composite neural architecture search (NAS), where multiple source-specific modules and a fusion module are jointly optimized. Existing NAS methods overlook useful side information from the intermediate outputs of these modules -- such as their representation quality -- limiting sample efficiency in multi-source RL settings. To address this, we propose an LLM-driven NAS pipeline that leverages language-model priors and intermediate-output signals to guide sample-efficient search for high-performing composite state encoders. On a mixed-autonomy traffic control task, our approach discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines and the LLM-based GENIUS framework.",
    "meta_json": "{\"arxiv_id\":\"2512.06982v1\",\"authors\":[\"Yu Yu\",\"Qian Xie\",\"Nairen Cao\",\"Li Jin\"],\"categories\":[\"cs.LG\",\"eess.SY\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:25:07Z\",\"updated_date\":\"2025-12-07T20:25:07Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:eess.SY\",\"source_url\":\"https://arxiv.org/abs/eess.SY\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "ebce4fae0f87c1b04827a5391148eb6c",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06982v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06981v1",
    "name": "Selective Masking based Self-Supervised Learning for Image Semantic Segmentation",
    "author": "Yuemin Wang",
    "description": "This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We ...",
    "tags": [
      "arxiv:cs.CV",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06981v1",
    "image_url": null,
    "type": "paper",
    "body_content": "This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We show on two general datasets (Pascal VOC and Cityscapes) and two weed segmentation datasets (Nassar 2020 and Sugarbeets 2016) that our proposed selective masking method outperforms the traditional random masking method and supervised ImageNet pretraining on downstream segmentation accuracy by 2.9% for general datasets and 2.5% for weed segmentation datasets. Furthermore, we found that our selective masking method significantly improves accuracy for the lowest-performing classes. Lastly, we show that using the same pretraining and downstream dataset yields the best result for low-budget self-supervised pretraining. Our proposed Selective Masking Image Reconstruction method provides an effective and practical solution to improve end-to-end semantic segmentation workflows, especially for scenarios that require limited model capacity to meet inference speed and computational resource requirements.",
    "meta_json": "{\"arxiv_id\":\"2512.06981v1\",\"authors\":[\"Yuemin Wang\",\"Ian Stavness\"],\"categories\":[\"cs.CV\",\"cs.LG\"],\"primary_category\":\"cs.CV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:21:26Z\",\"updated_date\":\"2025-12-07T20:21:26Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "14c6ce73518193ba3b93f684251f2e3e",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06981v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06977v1",
    "name": "Physics-Guided Diffusion Priors for Multi-Slice Reconstruction in Scientific Imaging",
    "author": "Laurentius Valdy",
    "description": "Accurate multi-slice reconstruction from limited measurement data is crucial to speed up the acquisition process in medical and scientific imaging. However, it remains challenging due to the ill-posed nature of the problem and the high computational and memory demands. We propose a framework that addresses these challenges by integrating partitioned diffusion priors with physics-based constraints. By doing so, we substantially reduce memory usage per GPU while preserving high reconstruction q...",
    "tags": [
      "arxiv:eess.IV",
      "arxiv:cs.LG",
      "diffusion"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06977v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Accurate multi-slice reconstruction from limited measurement data is crucial to speed up the acquisition process in medical and scientific imaging. However, it remains challenging due to the ill-posed nature of the problem and the high computational and memory demands. We propose a framework that addresses these challenges by integrating partitioned diffusion priors with physics-based constraints. By doing so, we substantially reduce memory usage per GPU while preserving high reconstruction quality, outperforming both physics-only and full multi-slice reconstruction baselines for different modalities, namely Magnetic Resonance Imaging (MRI) and four-dimensional Scanning Transmission Electron Microscopy (4D-STEM). Additionally, we show that the proposed method improves in-distribution accuracy as well as strong generalization to out-of-distribution datasets.",
    "meta_json": "{\"arxiv_id\":\"2512.06977v1\",\"authors\":[\"Laurentius Valdy\",\"Richard D. Paul\",\"Alessio Quercia\",\"Zhuo Cao\",\"Xuan Zhao\",\"Hanno Scharr\",\"Arya Bangun\"],\"categories\":[\"eess.IV\",\"cs.LG\"],\"primary_category\":\"eess.IV\",\"pdf_url\":null,\"published_date\":\"2025-12-07T20:07:12Z\",\"updated_date\":\"2025-12-07T20:07:12Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:eess.IV\",\"source_url\":\"https://arxiv.org/abs/eess.IV\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "2e7ca80f6a4f8d491002571bb6646565",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06977v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06973v1",
    "name": "Joint Learning of Feasibility-Aware Signal Temporal Logic and BarrierNet for Robust and Correct Control",
    "author": "Shuo Liu",
    "description": "Control Barrier Functions (CBFs) have emerged as a powerful tool for enforcing safety in optimization-based controllers, and their integration with Signal Temporal Logic (STL) has enabled the specification-driven synthesis of complex robotic behaviors. However, existing CBF-STL approaches typically rely on fixed hyperparameters and myopic, per-time step optimization, which can lead to overly conservative behavior, infeasibility near tight input limits, and difficulty satisfying long-horizon S...",
    "tags": [
      "arxiv:eess.SY",
      "arxiv:cs.LG"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06973v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Control Barrier Functions (CBFs) have emerged as a powerful tool for enforcing safety in optimization-based controllers, and their integration with Signal Temporal Logic (STL) has enabled the specification-driven synthesis of complex robotic behaviors. However, existing CBF-STL approaches typically rely on fixed hyperparameters and myopic, per-time step optimization, which can lead to overly conservative behavior, infeasibility near tight input limits, and difficulty satisfying long-horizon STL tasks. To address these limitations, we propose a feasibility-aware learning framework that embeds trainable, time-varying High Order Control Barrier Functions (HOCBFs) into a differentiable Quadratic Program (dQP). Our approach provides a systematic procedure for constructing time-varying HOCBF constraints for a broad fragment of STL and introduces a unified robustness measure that jointly captures STL satisfaction, QP feasibility, and control-bound compliance. Three neural networks-InitNet, RefNet, and an extended BarrierNet-collaborate to generate reference inputs and adapt constraint-related hyperparameters automatically over time and across initial conditions, reducing conservativeness while maximizing robustness. The resulting controller achieves STL satisfaction with strictly feasible dQPs and requires no manual tuning. Simulation results demonstrate that the proposed framework maintains high STL robustness under tight input bounds and significantly outperforms fixed-parameter and non-adaptive baselines in complex environments.",
    "meta_json": "{\"arxiv_id\":\"2512.06973v1\",\"authors\":[\"Shuo Liu\",\"Wenliang Liu\",\"Wei Xiao\",\"Calin A. Belta\"],\"categories\":[\"eess.SY\",\"cs.LG\"],\"primary_category\":\"eess.SY\",\"pdf_url\":null,\"published_date\":\"2025-12-07T19:52:27Z\",\"updated_date\":\"2025-12-07T19:52:27Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:eess.SY\",\"source_url\":\"https://arxiv.org/abs/eess.SY\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "8427f9200fbbb71a299a0690982a835e",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06973v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06971v1",
    "name": "Prediction with Expert Advice under Local Differential Privacy",
    "author": "Ben Jacobsen",
    "description": "We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.CR",
      "arxiv:cs.DS",
      "arxiv:stat.ML"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06971v1",
    "image_url": null,
    "type": "paper",
    "body_content": "We study the classic problem of prediction with expert advice under the constraint of local differential privacy (LDP). In this context, we first show that a classical algorithm naturally satisfies LDP and then design two new algorithms that improve it: RW-AdaBatch and RW-Meta. For RW-AdaBatch, we exploit the limited-switching behavior induced by LDP to provide a novel form of privacy amplification that grows stronger on easier data, analogous to the shuffle model in offline learning. Drawing on the theory of random walks, we prove that this improvement carries essentially no utility cost. For RW-Meta, we develop a general method for privately selecting between experts that are themselves non-trivial learning algorithms, and we show that in the context of LDP this carries no extra privacy cost. In contrast, prior work has only considered data-independent experts. We also derive formal regret bounds that scale inversely with the degree of independence between experts. Our analysis is supplemented by evaluation on real-world data reported by hospitals during the COVID-19 pandemic; RW-Meta outperforms both the classical baseline and a state-of-the-art \\textit{central} DP algorithm by 1.5-3$\\times$ on the task of predicting which hospital will report the highest density of COVID patients each week.",
    "meta_json": "{\"arxiv_id\":\"2512.06971v1\",\"authors\":[\"Ben Jacobsen\",\"Kassem Fawaz\"],\"categories\":[\"cs.LG\",\"cs.CR\",\"cs.DS\",\"stat.ML\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T19:31:35Z\",\"updated_date\":\"2025-12-07T19:31:35Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CR\",\"source_url\":\"https://arxiv.org/abs/cs.CR\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.DS\",\"source_url\":\"https://arxiv.org/abs/cs.DS\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.ML\",\"source_url\":\"https://arxiv.org/abs/stat.ML\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 70,
    "content_hash": "dab6afc465a531ce3c8ef3334ff9b0d5",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06971v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06969v1",
    "name": "Comparing BFGS and OGR for Second-Order Optimization",
    "author": "Adrian Przybysz",
    "description": "Estimating the Hessian matrix, especially for neural network training, is a challenging problem due to high dimensionality and cost. In this work, we compare the classical Sherman-Morrison update used in the popular BFGS method (Broy-den-Fletcher-Goldfarb-Shanno), which maintains a positive definite Hessian approximation under a convexity assumption, with a novel approach called Online Gradient Regression (OGR). OGR performs regression of gradients against positions using an exponential movin...",
    "tags": [
      "arxiv:cs.LG",
      "arxiv:cs.AI"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06969v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Estimating the Hessian matrix, especially for neural network training, is a challenging problem due to high dimensionality and cost. In this work, we compare the classical Sherman-Morrison update used in the popular BFGS method (Broy-den-Fletcher-Goldfarb-Shanno), which maintains a positive definite Hessian approximation under a convexity assumption, with a novel approach called Online Gradient Regression (OGR). OGR performs regression of gradients against positions using an exponential moving average to estimate second derivatives online, without requiring Hessian inversion. Unlike BFGS, OGR allows estimation of a general (not necessarily positive definite) Hessian and can thus handle non-convex structures. We evaluate both methods across standard test functions and demonstrate that OGR achieves faster convergence and improved loss, particularly in non-convex settings.",
    "meta_json": "{\"arxiv_id\":\"2512.06969v1\",\"authors\":[\"Adrian Przybysz\",\"Mikoaj Koek\",\"Franciszek Sobota\",\"Jarek Duda\"],\"categories\":[\"cs.LG\",\"cs.AI\"],\"primary_category\":\"cs.LG\",\"pdf_url\":null,\"published_date\":\"2025-12-07T19:26:26Z\",\"updated_date\":\"2025-12-07T19:26:26Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "da2757d2f3e62de96f68c4771115b8c8",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06969v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06963v1",
    "name": "VideoVLA: Video Generators Can Be Generalizable Robot Manipulators",
    "author": "Yichao Shen",
    "description": "Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation mod...",
    "tags": [
      "arxiv:cs.RO",
      "arxiv:cs.AI",
      "arxiv:cs.CV"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06963v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation models into robotic VLA manipulators. Given a language instruction and an image, VideoVLA predicts an action sequence as well as the future visual outcomes. Built on a multi-modal Diffusion Transformer, VideoVLA jointly models video, language, and action modalities, using pre-trained video generative models for joint visual and action forecasting. Our experiments show that high-quality imagined futures correlate with reliable action predictions and task success, highlighting the importance of visual imagination in manipulation. VideoVLA demonstrates strong generalization, including imitating other embodiments' skills and handling novel objects. This dual-prediction strategy - forecasting both actions and their visual consequences - explores a paradigm shift in robot learning and unlocks generalization capabilities in manipulation systems.",
    "meta_json": "{\"arxiv_id\":\"2512.06963v1\",\"authors\":[\"Yichao Shen\",\"Fangyun Wei\",\"Zhiying Du\",\"Yaobo Liang\",\"Yan Lu\",\"Jiaolong Yang\",\"Nanning Zheng\",\"Baining Guo\"],\"categories\":[\"cs.RO\",\"cs.AI\",\"cs.CV\"],\"primary_category\":\"cs.RO\",\"pdf_url\":null,\"published_date\":\"2025-12-07T18:57:15Z\",\"updated_date\":\"2025-12-07T18:57:15Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.RO\",\"source_url\":\"https://arxiv.org/abs/cs.RO\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.AI\",\"source_url\":\"https://arxiv.org/abs/cs.AI\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.CV\",\"source_url\":\"https://arxiv.org/abs/cs.CV\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 80,
    "content_hash": "36f5a61bd8988e8e2bdee5d5046565af",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06963v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06960v1",
    "name": "Learning Conditional Independence Differential Graphs From Time-Dependent Data",
    "author": "Jitendra K Tugnait",
    "description": "Estimation of differences in conditional independence graphs (CIGs) of two time series Gaussian graphical models (TSGGMs) is investigated where the two TSGGMs are known to have similar structure. The TSGGM structure is encoded in the inverse power spectral density (IPSD) of the time series. In several existing works, one is interested in estimating the difference in two precision matrices to characterize underlying changes in conditional dependencies of two sets of data consisting of independ...",
    "tags": [
      "arxiv:stat.ML",
      "arxiv:cs.LG",
      "arxiv:eess.SP"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06960v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Estimation of differences in conditional independence graphs (CIGs) of two time series Gaussian graphical models (TSGGMs) is investigated where the two TSGGMs are known to have similar structure. The TSGGM structure is encoded in the inverse power spectral density (IPSD) of the time series. In several existing works, one is interested in estimating the difference in two precision matrices to characterize underlying changes in conditional dependencies of two sets of data consisting of independent and identically distributed (i.i.d.) observations. In this paper we consider estimation of the difference in two IPSDs to characterize the underlying changes in conditional dependencies of two sets of time-dependent data. Our approach accounts for data time dependencies unlike past work. We analyze a penalized D-trace loss function approach in the frequency domain for differential graph learning, using Wirtinger calculus. We consider both convex (group lasso) and non-convex (log-sum and SCAD group penalties) penalty/regularization functions. An alternating direction method of multipliers (ADMM) algorithm is presented to optimize the objective function. We establish sufficient conditions in a high-dimensional setting for consistency (convergence of the inverse power spectral density to true value in the Frobenius norm) and graph recovery. Both synthetic and real data examples are presented in support of the proposed approaches. In synthetic data examples, our log-sum-penalized differential time-series graph estimator significantly outperformed our lasso based differential time-series graph estimator which, in turn, significantly outperformed an existing lasso-penalized i.i.d. modeling approach, with $F_1$ score as the performance metric.",
    "meta_json": "{\"arxiv_id\":\"2512.06960v1\",\"authors\":[\"Jitendra K Tugnait\"],\"categories\":[\"stat.ML\",\"cs.LG\",\"eess.SP\"],\"primary_category\":\"stat.ML\",\"pdf_url\":null,\"published_date\":\"2025-12-07T18:45:04Z\",\"updated_date\":\"2025-12-07T18:45:04Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.ML\",\"source_url\":\"https://arxiv.org/abs/stat.ML\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:eess.SP\",\"source_url\":\"https://arxiv.org/abs/eess.SP\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 65,
    "content_hash": "de4fc4a0f95ecf664067493be0ce309f",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06960v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  },
  {
    "id": "arxiv:2512.06956v1",
    "name": "Statistical analysis of Inverse Entropy-regularized Reinforcement Learning",
    "author": "Denis Belomestny",
    "description": "Inverse reinforcement learning aims to infer the reward function that explains expert behavior observed through trajectories of state--action pairs. A long-standing difficulty in classical IRL is the non-uniqueness of the recovered reward: many reward functions can induce the same optimal policy, rendering the inverse problem ill-posed. In this paper, we develop a statistical framework for Inverse Entropy-regularized Reinforcement Learning that resolves this ambiguity by combining entropy reg...",
    "tags": [
      "arxiv:stat.ML",
      "arxiv:cs.LG",
      "arxiv:math.ST",
      "reinforcement"
    ],
    "pipeline_tag": "other",
    "likes": 0,
    "downloads": 0,
    "source": "arxiv",
    "source_url": "https://arxiv.org/abs/2512.06956v1",
    "image_url": null,
    "type": "paper",
    "body_content": "Inverse reinforcement learning aims to infer the reward function that explains expert behavior observed through trajectories of state--action pairs. A long-standing difficulty in classical IRL is the non-uniqueness of the recovered reward: many reward functions can induce the same optimal policy, rendering the inverse problem ill-posed. In this paper, we develop a statistical framework for Inverse Entropy-regularized Reinforcement Learning that resolves this ambiguity by combining entropy regularization with a least-squares reconstruction of the reward from the soft Bellman residual. This combination yields a unique and well-defined so-called least-squares reward consistent with the expert policy. We model the expert demonstrations as a Markov chain with the invariant distribution defined by an unknown expert policy $^\\star$ and estimate the policy by a penalized maximum-likelihood procedure over a class of conditional distributions on the action space. We establish high-probability bounds for the excess Kullback--Leibler divergence between the estimated policy and the expert policy, accounting for statistical complexity through covering numbers of the policy class. These results lead to non-asymptotic minimax optimal convergence rates for the least-squares reward function, revealing the interplay between smoothing (entropy regularization), model complexity, and sample size. Our analysis bridges the gap between behavior cloning, inverse reinforcement learning, and modern statistical learning theory.",
    "meta_json": "{\"arxiv_id\":\"2512.06956v1\",\"authors\":[\"Denis Belomestny\",\"Alexey Naumov\",\"Sergey Samsonov\"],\"categories\":[\"stat.ML\",\"cs.LG\",\"math.ST\"],\"primary_category\":\"stat.ML\",\"pdf_url\":null,\"published_date\":\"2025-12-07T18:26:19Z\",\"updated_date\":\"2025-12-07T18:26:19Z\"}",
    "assets_json": "[]",
    "relations_json": "[{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:stat.ML\",\"source_url\":\"https://arxiv.org/abs/stat.ML\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:cs.LG\",\"source_url\":\"https://arxiv.org/abs/cs.LG\"},{\"type\":\"based_on_paper\",\"target_id\":\"arxiv:math.ST\",\"source_url\":\"https://arxiv.org/abs/math.ST\"}]",
    "canonical_id": null,
    "license_spdx": "arXiv",
    "compliance_status": "approved",
    "quality_score": 75,
    "content_hash": "3f46e164acf7829577a9f908c5deca69",
    "velocity": null,
    "raw_image_url": null,
    "source_trail": "[{\"source_platform\":\"arxiv\",\"source_url\":\"https://arxiv.org/abs/2512.06956v1\",\"fetched_at\":\"2025-12-10T01:31:39.563Z\",\"adapter_version\":\"3.2.0\"}]",
    "commercial_slots": null,
    "notebooklm_summary": null,
    "velocity_score": 0,
    "last_commercial_at": null
  }
]