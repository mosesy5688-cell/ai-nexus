{"id":"hf-model--meta-llama--llama-3.1-8b-instruct","type":"model","status":"active","_last_seen":"2026-02-08T06:39:06.734Z","_bootstrapped":true,"fni_score":48,"meta_json":"{\"pipeline_tag\":\"text-generation\",\"library_name\":\"transformers\",\"framework\":\"transformers\",\"params\":8030261248,\"storage_bytes\":32123357950,\"files_count\":0,\"spaces_count\":0,\"gated\":false,\"private\":false,\"config\":{\"architectures\":[\"LlamaForCausalLM\"],\"model_type\":\"llama\",\"tokenizer_config\":{\"bos_token\":\"<|begin_of_text|>\",\"chat_template\":\"{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \\\"26 Jul 2024\\\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0]['role'] == 'system' %}\\n    {%- set system_message = messages[0]['content']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \\\"\\\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \\\"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\\\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \\\"Environment: ipython\\\\n\\\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \\\"Tools: \\\" + builtin_tools | reject('equalto', 'code_interpreter') | join(\\\", \\\") + \\\"\\\\n\\\\n\\\"}}\\n{%- endif %}\\n{{- \\\"Cutting Knowledge Date: December 2023\\\\n\\\" }}\\n{{- \\\"Today Date: \\\" + date_string + \\\"\\\\n\\\\n\\\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \\\"You have access to the following functions. To call a function, please respond with JSON for a function call.\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \\\"<|eot_id|>\\\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0]['content']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\\\"Cannot put tools in the first user message when there's no first user message!\\\") }}\\n{%- endif %}\\n    {{- '<|start_header_id|>user<|end_header_id|>\\\\n\\\\n' -}}\\n    {{- \\\"Given the following functions, please respond with a JSON for a function call \\\" }}\\n    {{- \\\"with its proper arguments that best answers the given prompt.\\\\n\\\\n\\\" }}\\n    {{- 'Respond in the format {\\\"name\\\": function name, \\\"parameters\\\": dictionary of argument name and its value}.' }}\\n    {{- \\\"Do not use variables.\\\\n\\\\n\\\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \\\"\\\\n\\\\n\\\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \\\"<|eot_id|>\\\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\\n        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\\\n\\\\n'+ message['content'] | trim + '<|eot_id|>' }}\\n    {%- elif 'tool_calls' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\\\"This model only supports single tool-calls at once!\\\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- \\\"<|python_tag|>\\\" + tool_call.name + \\\".call(\\\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + '=\\\"' + arg_val + '\\\"' }}\\n                {%- if not loop.last %}\\n                    {{- \\\", \\\" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \\\")\\\" }}\\n        {%- else  %}\\n            {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' -}}\\n            {{- '{\\\"name\\\": \\\"' + tool_call.name + '\\\", ' }}\\n            {{- '\\\"parameters\\\": ' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\\"}\\\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we're in ipython mode #}\\n            {{- \\\"<|eom_id|>\\\" }}\\n        {%- else %}\\n            {{- \\\"<|eot_id|>\\\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\\"tool\\\" or message.role == \\\"ipython\\\" %}\\n        {{- \\\"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\\\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \\\"<|eot_id|>\\\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n' }}\\n{%- endif %}\\n\",\"eos_token\":\"<|eot_id|>\"}},\"params_billions\":8.03,\"architecture\":\"LlamaForCausalLM\"}","fni":0,"tags":["transformers","safetensors","llama","text-generation","facebook","meta","pytorch","llama-3","conversational","en","de","fr","it","pt","hi","es","th","arxiv:2204.05149","base_model:meta-llama/llama-3.1-8b","base_model:finetune:meta-llama/llama-3.1-8b","license:llama3.1","text-generation-inference","endpoints_compatible","region:us"],"likes":5103,"downloads":5361336,"source_trail":"[{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"},{\"source_platform\":\"huggingface\",\"source_url\":\"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\"fetched_at\":\"2025-12-10T01:31:39.544Z\",\"adapter_version\":\"3.2.0\"}]","percentile":17,"quality_score":50,"compliance_status":"pending","params_billions":8.03,"architecture":"LlamaForCausalLM","raw_image_url":"https://huggingface.co/api/users/meta-llama/avatar","image_url":"https://huggingface.co/api/users/meta-llama/avatar","category":"text-generation","name":"Llama-3.1-8B-Instruct","author":"meta-llama","source_url":"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct","vram_estimate_gb":7.3,"trend_7d":[],"use_cases":{"goodFor":["Chat & Dialogue"],"limits":["Experimental / High Latency"]},"quick_insights":[{"label":"FNI Score","value":48,"highlight":false,"badge":"Audited"},{"label":"Params","value":"8.03B","highlight":false,"badge":null},{"label":"Context","value":"-","highlight":false,"badge":null},{"label":"Downloads","value":"5.4M","badge":"Hot"},{"label":"Est. VRAM","value":"~8GB","highlight":true,"badge":"8G GPU"}],"display_description":"","_html_checksum":"d41d8cd98f00b204e9800998ecf8427e","_version":"16.11.1-stable-fusion","_updated":"2026-02-10T01:58:27.429Z","_checksum":"5529e597f590786be43db0c85230e9c7752b55b9702ba61801f879f4ea5d9f03","html_readme":"","mesh_profile":{"id":"hf-model--meta-llama--llama-3.1-8b-instruct","name":"llama-3.1-8b-instruct","type":"model","url":"/model/meta-llama/llama-3.1-8b-instruct","icon":"ðŸ“¦","relations":[{"target":"hf-tool--huggingface--transformers","type":"STACK","weight":0.8,"url":"/tool/huggingface/transformers","target_id":"hf-tool--huggingface--transformers","target_name":"transformers"},{"target":"knowledge--transformer-architecture","type":"EXPLAINS","weight":0.6,"url":"/knowledge/transformer","target_id":"knowledge--transformer-architecture","target_name":"transformer-architecture"},{"target":"knowledge--instruction-tuning","type":"EXPLAINS","weight":0.6,"url":"/knowledge/fine-tuning","target_id":"knowledge--instruction-tuning","target_name":"instruction-tuning"},{"target":"knowledge--direct-preference-optimization","type":"EXPLAINS","weight":0.6,"url":"/knowledge/fine-tuning","target_id":"knowledge--direct-preference-optimization","target_name":"direct-preference-optimization"}],"_generated_at":"2026-02-19T08:26:35.379Z","_version":"16.5.1-baked"},"_fused_at":"2026-02-19T08:30:04.659Z","_fusion_status":"raw"}