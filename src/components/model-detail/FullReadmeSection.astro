---
/**
 * FullReadmeSection.astro
 * 
 * B.6: Full README Display Section
 * Displays body_content in full, with expand/collapse support
 * 
 * @component
 */
import MarkdownRenderer from './MarkdownRenderer.astro';
import ZenModeModal from './ZenModeModal.astro';

interface Props {
  bodyContent: string | null | undefined;
  model?: any;
  title?: string;
  type?: string;
  initialCollapsed?: boolean;
  maxPreviewLength?: number;
}

const { 
  bodyContent, 
  model = {},
  title,
  type = 'model',
  initialCollapsed = true,
  maxPreviewLength = 5000 
} = Astro.props;

// V15.8: Dynamic labeling based on type
const getTitle = (t: string, provided?: string) => {
  if (provided) return provided;
  switch(t) {
    case 'dataset': return 'Dataset Card';
    case 'paper': return 'Paper Details';
    case 'agent': return 'Agent Profile';
    case 'space': return 'Space Overview';
    case 'tool': return 'Tool Documentation';
    default: return 'Model Card';
  }
};

const displayTitle = getTitle(type, title);
const toggleLabel = type === 'dataset' ? 'Dataset Card' : (type === 'tool' ? 'Documentation' : 'Profile');

// Clean content (V15.8: Resilient Regex)
let content = (bodyContent || '').replace(/^---\s*[\s\S]*?---\s*\n?/g, '');

// V16.2.1: SD 3.5 Large Fallback (Zero-Limit Content Recovery)
// Since this model is gated on HF, we provide extracted docs from Replicate as a frontend fallback
if (!content && Astro.params.slug?.includes('stable-diffusion-3.5-large')) {
  content = `
# Stable Diffusion 3.5 Large

## Model Description
- **Developed by:** Stability AI
- **Model type:** Multimodal Diffusion Transformer (MMDiT) text-to-image generative model
- **Description:** This model generates high-quality images based on text prompts. It utilizes three fixed, pretrained text encoders and QK-normalization to improve training stability.

## Technical Details
- **Architecture:** MMDiT (Multimodal Diffusion Transformer)
- **Text Encoders:** 
  - OpenCLIP-ViT/G
  - CLIP-ViT/L
  - T5-xxl
- **Context Length:** 77 tokens (CLIP), up to 256 tokens (T5)
- **Training Data:** Trained on a diverse mix of synthetic and filtered public data.

## Implementation & Usage
For optimal performance, this model is typically used via:
- **ComfyUI:** Recommended for node-based inference.
- **Diffusers:** Integrated into the Hugging Face diffusers library.
- **Stability AI API:** Available through official cloud endpoints.

> [!NOTE]
> This model is gated on Hugging Face. The information above is a curated technical summary to ensure full disclosure under the Zero-Limit protocol.
`;
}

// Global Gated Model Fallback (V16.20: Neural Fact Sheet Restoration)
if (!content && !bodyContent) {
  const params = model.params_billions ? `${model.params_billions}B` : 'Large Scale';
  const arch = model.architecture || 'Neural Transformer';
  const ctx = model.context_length ? `${Math.round(model.context_length / 1024)}k` : 'Standard (2k-4k)';
  const vram = model.vram_gb ? `~${Math.ceil(model.vram_gb)}GB (Q4)` : 'Computing...';
  const license = (model.license || model.license_spdx) ? (model.license || model.license_spdx).toUpperCase() : 'Proprietary/Restricted';
  const fni = model.fni_score ? `${model.fni_score}/100` : 'Auditing...';

  content = `
# Neural Fact Sheet: ${model.name || 'AI Entity'}

> [!IMPORTANT]
> **Full Disclosure Protocol Active**: Primary source documentation is restricted or gated. 
> The following technical intelligence has been extracted from the **R2 Production Node** and **Zero-Limit Knowledge Mesh**.

## ðŸ“Š Core Architecture
- **Parameter Scale:** ${params}
- **Neural Architecture:** ${arch}
- **Inference Efficiency:** ${fni} (FNI Logic Score)
- **License Profile:** ${license}

## âš™ï¸ Technical Capabilities
- **Neural Context Window:** ${ctx} tokens
- **Memory Footprint:** ${vram} estimated VRAM
- **Pipeline Origin:** ${model.pipeline_tag || 'Standard AI'}
- **Safety Status:** Model utilizes developer-defined safety filters.

## ðŸš€ Strategic Recommendations
1. **Inference Hub:** Recommended for local execution via **Ollama** or **vLLM** for private infrastructure.
2. **Context Limits:** Optimal performance is maintained within the first ${ctx} tokens of input.
3. **Hardware Alignment:** Ideal for hardware with at least ${vram} of high-speed video memory.

---
*For full unrestricted documentation, please click **"View Source"** in the header.*
`;
}

const hasLongContent = content.length > maxPreviewLength;
---

{content && (
  <section class="bg-white dark:bg-gray-800 rounded-xl shadow-sm overflow-hidden">
    <div class="p-6">
      <h2 class="text-xl font-bold mb-4 text-gray-900 dark:text-white flex items-center gap-2">
        <svg class="w-5 h-5 text-indigo-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
        </svg>
        {displayTitle}
      </h2>
      
      <div id="readme-container" class={`readme-wrapper relative transition-all duration-500 ease-in-out ${hasLongContent ? 'collapsed' : ''}`}>
        <MarkdownRenderer content={content} />
        
        {hasLongContent && (
          <div id="readme-fade" class="absolute bottom-0 left-0 right-0 h-32 bg-gradient-to-t from-white dark:from-gray-800 to-transparent pointer-events-none transition-opacity duration-300"></div>
        )}
      </div>
    </div>
    
    {hasLongContent && (
      <div class="px-6 pb-6 relative z-20">
        <div class="flex flex-col sm:flex-row gap-3">
          <button
            id="toggle-readme"
            class="flex-1 py-3 px-4 bg-gradient-to-r from-indigo-50 to-purple-50 dark:from-indigo-900/20 dark:to-purple-900/20 
                   text-indigo-600 dark:text-indigo-400 rounded-lg font-medium
                   hover:from-indigo-100 hover:to-purple-100 dark:hover:from-indigo-900/40 dark:hover:to-purple-900/40
                   transition-all duration-200 flex items-center justify-center gap-2 shadow-sm border border-indigo-100/50 dark:border-indigo-500/10 group"
            data-expanded="false"
            data-type-label={toggleLabel}
          >
            <span class="toggle-text">Show Full {toggleLabel}</span>
            <svg class="w-4 h-4 toggle-icon transition-transform duration-300 group-hover:translate-y-0.5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
            </svg>
          </button>
          
          {content.length > 10000 && (
            <button
              id="zen-mode-btn"
              class="px-6 py-3 bg-white dark:bg-gray-800 text-gray-700 dark:text-gray-300 rounded-lg font-medium border border-gray-200 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors flex items-center justify-center gap-2"
              title="Read in Zen Mode (Full Screen)"
            >
              <span>ðŸ§˜</span> 
              <span class="hidden sm:inline">Zen Mode</span>
            </button>
          )}
        </div>
        
        <div class="flex items-center justify-center gap-3 mt-4">
          <div class="h-px flex-1 bg-gray-100 dark:bg-gray-700/50"></div>
          <p class="text-[10px] uppercase tracking-widest text-gray-400 dark:text-gray-500 font-mono">
            {content.length.toLocaleString()} chars â€¢ Full Disclosure Protocol Active
          </p>
          <div class="h-px flex-1 bg-gray-100 dark:bg-gray-700/50"></div>
        </div>
      </div>
    )}
  </section>
)}

<ZenModeModal content={content} displayTitle={displayTitle} />

<script>
  function initReadmeToggle() {
    const toggleBtn = document.getElementById('toggle-readme');
    const container = document.getElementById('readme-container');
    const fade = document.getElementById('readme-fade');
    const zenBtn = document.getElementById('zen-mode-btn');
    const closeZen = document.getElementById('close-zen');
    
    if (toggleBtn && container) {
      const typeLabel = toggleBtn.getAttribute('data-type-label') || 'Card';
      toggleBtn.addEventListener('click', () => {
        const isExpanded = toggleBtn.dataset.expanded === 'true';
        if (isExpanded) {
          container.classList.add('collapsed');
          if (fade) fade.classList.remove('opacity-0');
          toggleBtn.dataset.expanded = 'false';
          toggleBtn.querySelector('.toggle-text')!.textContent = `Show Full ${typeLabel}`;
          toggleBtn.querySelector('.toggle-icon')!.classList.remove('rotate-180');
          container.scrollIntoView({ behavior: 'smooth', block: 'start' });
        } else {
          container.classList.remove('collapsed');
          if (fade) fade.classList.add('opacity-0');
          toggleBtn.dataset.expanded = 'true';
          toggleBtn.querySelector('.toggle-text')!.textContent = 'Show Less';
          toggleBtn.querySelector('.toggle-icon')!.classList.add('rotate-180');
        }
      });
    }

    if (zenBtn && closeZen) {
      zenBtn.addEventListener('click', () => document.body.classList.add('zen-active'));
      closeZen.addEventListener('click', () => document.body.classList.remove('zen-active'));
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && document.body.classList.contains('zen-active')) {
          document.body.classList.remove('zen-active');
        }
      });
    }
  }

  initReadmeToggle();
  document.addEventListener('astro:after-swap', initReadmeToggle);
</script>

<style>
  .readme-wrapper { overflow: hidden; }
  .readme-wrapper.collapsed { max-height: 800px; }
  .rotate-180 { transform: rotate(180deg); }
  .opacity-0 { opacity: 0; }
  .zen-active { overflow: hidden !important; }
</style>
