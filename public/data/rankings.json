{
  "hot": [
    {
      "id": "github-ollama-ollama",
      "name": "ollama",
      "author": "ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "task": "tool",
      "tags": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "likes": 312577,
      "downloads": 312577,
      "lastModified": "2025-11-20T15:51:00Z",
      "lastModifiedTimestamp": 1763653860000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ollama/ollama",
          "homepage": "https://ollama.com",
          "language": "Go",
          "forks": 13697,
          "open_issues": 2258,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/151674099?v=4",
      "velocity": 171916.8,
      "is_rising_star": true,
      "heatScore": 51578.675749888665,
      "popularityScore": 156288
    },
    {
      "id": "github-huggingface-transformers",
      "name": "transformers",
      "author": "huggingface",
      "description": "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
      "task": "tool",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "likes": 305558,
      "downloads": 305558,
      "lastModified": "2025-11-20T15:45:12Z",
      "lastModifiedTimestamp": 1763653512000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/transformers",
          "homepage": "https://huggingface.co/transformers",
          "language": "Python",
          "forks": 31187,
          "open_issues": 2121,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 168056.9,
      "is_rising_star": true,
      "heatScore": 50420.69884655398,
      "popularityScore": 152779
    },
    {
      "id": "github-langflow-ai-langflow",
      "name": "langflow",
      "author": "langflow-ai",
      "description": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
      "task": "tool",
      "tags": [
        "agents",
        "chatgpt",
        "generative-ai",
        "large-language-models",
        "multiagent",
        "react-flow"
      ],
      "likes": 277624,
      "downloads": 277624,
      "lastModified": "2025-11-20T15:36:15Z",
      "lastModifiedTimestamp": 1763652975000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langflow-ai/langflow",
          "homepage": "http://www.langflow.org",
          "language": "Python",
          "forks": 8027,
          "open_issues": 902,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85702467?v=4",
      "velocity": 152693.2,
      "is_rising_star": true,
      "heatScore": 45811.559701098144,
      "popularityScore": 138812
    },
    {
      "id": "github-f-awesome-chatgpt-prompts",
      "name": "awesome-chatgpt-prompts",
      "author": "f",
      "description": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
      "task": "tool",
      "tags": [
        "bots",
        "chatbot",
        "chatgpt",
        "chatgpt-api",
        "language",
        "general-dialogue-qa"
      ],
      "likes": 273424,
      "downloads": 273424,
      "lastModified": "2025-11-20T15:23:26Z",
      "lastModifiedTimestamp": 1763652206000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/f/awesome-chatgpt-prompts",
          "homepage": "https://prompts.chat",
          "language": "JavaScript",
          "forks": 18184,
          "open_issues": 290,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/196477?v=4",
      "velocity": 150383.2,
      "is_rising_star": true,
      "heatScore": 45118.55506686943,
      "popularityScore": 136712
    },
    {
      "id": "github-langchain-ai-langchain",
      "name": "langchain",
      "author": "langchain-ai",
      "description": "ü¶úüîó The platform for reliable agents.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "aiagentframework",
        "anthropic",
        "chatgpt",
        "enterprise",
        "framework",
        "gemini",
        "generative-ai",
        "langchain",
        "llm",
        "multiagent",
        "open-source",
        "openai",
        "pydantic",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 240248,
      "downloads": 240248,
      "lastModified": "2025-11-20T15:50:06Z",
      "lastModifiedTimestamp": 1763653806000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain-ai/langchain",
          "homepage": "https://docs.langchain.com/oss/python/langchain/",
          "language": "Python",
          "forks": 19786,
          "open_issues": 241,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
      "velocity": 132136.4,
      "is_rising_star": true,
      "heatScore": 39644.47574338047,
      "popularityScore": 120124
    },
    {
      "id": "github-langgenius-dify",
      "name": "dify",
      "author": "langgenius",
      "description": "Production-ready platform for agentic workflow development.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-ai",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "automation",
        "gemini",
        "genai",
        "gpt",
        "gpt-4",
        "llm",
        "low-code",
        "mcp",
        "nextjs",
        "no-code",
        "openai",
        "orchestration",
        "python",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 238804,
      "downloads": 238804,
      "lastModified": "2025-11-20T15:50:01Z",
      "lastModifiedTimestamp": 1763653801000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langgenius/dify",
          "homepage": "https://dify.ai",
          "language": "TypeScript",
          "forks": 18511,
          "open_issues": 682,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127165244?v=4",
      "velocity": 131342.2,
      "is_rising_star": true,
      "heatScore": 39406.21391066701,
      "popularityScore": 119402
    },
    {
      "id": "github-open-webui-open-webui",
      "name": "open-webui",
      "author": "open-webui",
      "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
      "task": "tool",
      "tags": [
        "ai",
        "llm",
        "llm-ui",
        "llm-webui",
        "llms",
        "mcp",
        "ollama",
        "ollama-webui",
        "open-webui",
        "openai",
        "openapi",
        "rag",
        "self-hosted",
        "ui",
        "webui",
        "rag-knowledge-base-qa"
      ],
      "likes": 231540,
      "downloads": 231540,
      "lastModified": "2025-11-20T15:46:30Z",
      "lastModifiedTimestamp": 1763653590000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/open-webui/open-webui",
          "homepage": "https://openwebui.com",
          "language": "JavaScript",
          "forks": 16219,
          "open_issues": 304,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/158137808?v=4",
      "velocity": 127347,
      "is_rising_star": true,
      "heatScore": 38207.64451984924,
      "popularityScore": 115770
    },
    {
      "id": "github-microsoft-generative-ai-for-beginners",
      "name": "generative-ai-for-beginners",
      "author": "microsoft",
      "description": "21 Lessons, Get Started Building with Generative AI ",
      "task": "tool",
      "tags": [
        "ai",
        "azure",
        "chatgpt",
        "dall-e",
        "generative-ai",
        "generativeai",
        "gpt",
        "language-model",
        "llms",
        "microsoft-for-beginners",
        "openai",
        "prompt-engineering",
        "semantic-search",
        "transformers"
      ],
      "likes": 204088,
      "downloads": 204088,
      "lastModified": "2025-11-20T15:11:49Z",
      "lastModifiedTimestamp": 1763651509000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/generative-ai-for-beginners",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 54251,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 112248.4,
      "is_rising_star": true,
      "heatScore": 33678.02615421101,
      "popularityScore": 102044
    },
    {
      "id": "github-x1xhlol-system-prompts-and-models-of-ai-tools",
      "name": "system-prompts-and-models-of-ai-tools",
      "author": "x1xhlol",
      "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
      "task": "tool",
      "tags": [
        "ai",
        "bolt",
        "cluely",
        "copilot",
        "cursor",
        "cursorai",
        "devin",
        "github-copilot",
        "lovable",
        "open-source",
        "perplexity",
        "replit",
        "system-prompts",
        "trae",
        "trae-ai",
        "trae-ide",
        "v0",
        "vscode",
        "windsurf",
        "windsurf-ai",
        "code-generation-assistance"
      ],
      "likes": 193011,
      "downloads": 193011,
      "lastModified": "2025-11-20T15:52:37Z",
      "lastModifiedTimestamp": 1763653957000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
          "homepage": "",
          "language": null,
          "forks": 25948,
          "open_issues": 94,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/185671340?v=4",
      "velocity": 106155.5,
      "is_rising_star": true,
      "heatScore": 31850.139188020687,
      "popularityScore": 96505
    },
    {
      "id": "github-ggml-org-llama.cpp",
      "name": "llama.cpp",
      "author": "ggml-org",
      "description": "LLM inference in C/C++",
      "task": "tool",
      "tags": [
        "ggml"
      ],
      "likes": 180265,
      "downloads": 180265,
      "lastModified": "2025-11-20T15:53:48Z",
      "lastModifiedTimestamp": 1763654028000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ggml-org/llama.cpp",
          "homepage": "",
          "language": "C++",
          "forks": 13769,
          "open_issues": 893,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134263123?v=4",
      "velocity": 99145.2,
      "is_rising_star": true,
      "heatScore": 29747.0284186785,
      "popularityScore": 90132
    },
    {
      "id": "github-google-gemini-gemini-cli",
      "name": "gemini-cli",
      "author": "google-gemini",
      "description": "An open-source AI agent that brings the power of Gemini directly into your terminal.",
      "task": "tool",
      "tags": [
        "gemini",
        "gemini-api"
      ],
      "likes": 167383,
      "downloads": 167383,
      "lastModified": "2025-11-20T15:52:04Z",
      "lastModifiedTimestamp": 1763653924000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/google-gemini/gemini-cli",
          "homepage": "https://geminicli.com",
          "language": "TypeScript",
          "forks": 9443,
          "open_issues": 3033,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/161781182?v=4",
      "velocity": 92060.1,
      "is_rising_star": true,
      "heatScore": 27621.47587876247,
      "popularityScore": 83691
    },
    {
      "id": "github-Shubhamsaboo-awesome-llm-apps",
      "name": "awesome-llm-apps",
      "author": "Shubhamsaboo",
      "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
      "task": "tool",
      "tags": [
        "llms",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 158413,
      "downloads": 158413,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
          "homepage": "https://www.theunwindai.com",
          "language": "Python",
          "forks": 10579,
          "open_issues": 3,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/31396011?v=4",
      "velocity": 87126.6,
      "is_rising_star": true,
      "heatScore": 26141.409134495156,
      "popularityScore": 79206
    },
    {
      "id": "github-rasbt-LLMs-from-scratch",
      "name": "LLMs-from-scratch",
      "author": "rasbt",
      "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "deep-learning",
        "from-scratch",
        "generative-ai",
        "gpt",
        "language-model",
        "large-language-models",
        "llm",
        "machine-learning",
        "neural-networks",
        "python",
        "pytorch",
        "transformers",
        "general-dialogue-qa"
      ],
      "likes": 158122,
      "downloads": 158122,
      "lastModified": "2025-11-20T15:46:33Z",
      "lastModifiedTimestamp": 1763653593000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/rasbt/LLMs-from-scratch",
          "homepage": "https://amzn.to/4fqvn0D",
          "language": "Jupyter Notebook",
          "forks": 11719,
          "open_issues": 0,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/5618407?v=4",
      "velocity": 86967.1,
      "is_rising_star": true,
      "heatScore": 26093.558577457425,
      "popularityScore": 79061
    },
    {
      "id": "github-nomic-ai-gpt4all",
      "name": "gpt4all",
      "author": "nomic-ai",
      "description": "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.",
      "task": "tool",
      "tags": [
        "ai-chat",
        "llm-inference"
      ],
      "likes": 153854,
      "downloads": 153854,
      "lastModified": "2025-11-20T11:59:23Z",
      "lastModifiedTimestamp": 1763639963000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nomic-ai/gpt4all",
          "homepage": "https://nomic.ai/gpt4all",
          "language": "C++",
          "forks": 8302,
          "open_issues": 744,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102670180?v=4",
      "velocity": 84619.7,
      "is_rising_star": true,
      "heatScore": 25389.330259109156,
      "popularityScore": 76927
    },
    {
      "id": "github-browser-use-browser-use",
      "name": "browser-use",
      "author": "browser-use",
      "description": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "ai-tools",
        "browser-automation",
        "browser-use",
        "llm",
        "playwright",
        "python"
      ],
      "likes": 145557,
      "downloads": 145557,
      "lastModified": "2025-11-20T15:54:22Z",
      "lastModifiedTimestamp": 1763654062000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/browser-use/browser-use",
          "homepage": "https://browser-use.com",
          "language": "Python",
          "forks": 8663,
          "open_issues": 232,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192012301?v=4",
      "velocity": 80055.8,
      "is_rising_star": true,
      "heatScore": 24020.143404258793,
      "popularityScore": 72778
    },
    {
      "id": "github-binary-husky-gpt_academic",
      "name": "gpt_academic",
      "author": "binary-husky",
      "description": "‰∏∫GPT/GLMÁ≠âLLMÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂÆûÁî®Âåñ‰∫§‰∫íÊé•Âè£ÔºåÁâπÂà´‰ºòÂåñËÆ∫ÊñáÈòÖËØª/Ê∂¶Ëâ≤/ÂÜô‰Ωú‰ΩìÈ™åÔºåÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆ&ÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅPythonÂíåC++Á≠âÈ°πÁõÆÂâñÊûê&Ëá™ËØëËß£ÂäüËÉΩÔºåPDF/LaTexËÆ∫ÊñáÁøªËØë&ÊÄªÁªìÂäüËÉΩÔºåÊîØÊåÅÂπ∂Ë°åÈóÆËØ¢Â§öÁßçLLMÊ®°ÂûãÔºåÊîØÊåÅchatglm3Á≠âÊú¨Âú∞Ê®°Âûã„ÄÇÊé•ÂÖ•ÈÄö‰πâÂçÉÈóÆ, deepseekcoder, ËÆØÈ£ûÊòüÁÅ´, ÊñáÂøÉ‰∏ÄË®Ä, llama2, rwkv, claude2, mossÁ≠â„ÄÇ",
      "task": "tool",
      "tags": [
        "academic",
        "chatglm-6b",
        "chatgpt",
        "gpt-4",
        "large-language-models",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 139408,
      "downloads": 139408,
      "lastModified": "2025-11-20T14:41:49Z",
      "lastModifiedTimestamp": 1763649709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/binary-husky/gpt_academic",
          "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
          "language": "Python",
          "forks": 8399,
          "open_issues": 291,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/96192199?v=4",
      "velocity": 76674.4,
      "is_rising_star": true,
      "heatScore": 23005.71028475207,
      "popularityScore": 69704
    },
    {
      "id": "github-firecrawl-firecrawl",
      "name": "firecrawl",
      "author": "firecrawl",
      "description": "üî• The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-crawler",
        "ai-scraping",
        "ai-search",
        "crawler",
        "data-extraction",
        "html-to-markdown",
        "llm",
        "markdown",
        "scraper",
        "scraping",
        "web-crawler",
        "web-data",
        "web-data-extraction",
        "web-scraper",
        "web-scraping",
        "web-search",
        "webscraping"
      ],
      "likes": 136343,
      "downloads": 136343,
      "lastModified": "2025-11-20T15:52:57Z",
      "lastModifiedTimestamp": 1763653977000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/firecrawl/firecrawl",
          "homepage": "https://firecrawl.dev",
          "language": "TypeScript",
          "forks": 5309,
          "open_issues": 134,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/135057108?v=4",
      "velocity": 74988.1,
      "is_rising_star": true,
      "heatScore": 22499.813524224726,
      "popularityScore": 68171
    },
    {
      "id": "github-infiniflow-ragflow",
      "name": "ragflow",
      "author": "infiniflow",
      "description": "RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs",
      "task": "tool",
      "tags": [
        "agent",
        "agentic",
        "agentic-ai",
        "agentic-workflow",
        "ai",
        "ai-search",
        "deep-learning",
        "deep-research",
        "deepseek",
        "deepseek-r1",
        "document-parser",
        "document-understanding",
        "graphrag",
        "llm",
        "mcp",
        "multi-agent",
        "ollama",
        "openai",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 136116,
      "downloads": 136116,
      "lastModified": "2025-11-20T14:42:49Z",
      "lastModifiedTimestamp": 1763649769000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/infiniflow/ragflow",
          "homepage": "https://ragflow.io",
          "language": "Python",
          "forks": 7305,
          "open_issues": 2876,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/69962740?v=4",
      "velocity": 74863.8,
      "is_rising_star": true,
      "heatScore": 22462.52301989456,
      "popularityScore": 68058
    },
    {
      "id": "github-lobehub-lobe-chat",
      "name": "lobe-chat",
      "author": "lobehub",
      "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artifacts",
        "chat",
        "chatgpt",
        "claude",
        "deepseek",
        "deepseek-r1",
        "function-calling",
        "gemini",
        "gpt",
        "knowledge-base",
        "mcp",
        "nextjs",
        "ollama",
        "openai",
        "rag",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 135771,
      "downloads": 135771,
      "lastModified": "2025-11-20T15:53:45Z",
      "lastModifiedTimestamp": 1763654025000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/lobehub/lobe-chat",
          "homepage": "https://lobechat.com",
          "language": "TypeScript",
          "forks": 13999,
          "open_issues": 993,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
      "velocity": 74673.5,
      "is_rising_star": true,
      "heatScore": 22405.432246153854,
      "popularityScore": 67885
    },
    {
      "id": "github-mlabonne-llm-course",
      "name": "llm-course",
      "author": "mlabonne",
      "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
      "task": "tool",
      "tags": [
        "course",
        "large-language-models",
        "llm",
        "machine-learning",
        "roadmap"
      ],
      "likes": 135657,
      "downloads": 135657,
      "lastModified": "2025-11-20T15:52:59Z",
      "lastModifiedTimestamp": 1763653979000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mlabonne/llm-course",
          "homepage": "https://mlabonne.github.io/blog/",
          "language": null,
          "forks": 7688,
          "open_issues": 76,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/81252890?v=4",
      "velocity": 74610.8,
      "is_rising_star": true,
      "heatScore": 22386.62199079003,
      "popularityScore": 67828
    },
    {
      "id": "github-ansible-ansible",
      "name": "ansible",
      "author": "ansible",
      "description": "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",
      "task": "tool",
      "tags": [
        "ansible",
        "python",
        "code-generation-assistance"
      ],
      "likes": 134117,
      "downloads": 134117,
      "lastModified": "2025-11-20T15:53:03Z",
      "lastModifiedTimestamp": 1763653983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ansible/ansible",
          "homepage": "https://www.ansible.com/",
          "language": "Python",
          "forks": 24129,
          "open_issues": 878,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1507452?v=4",
      "velocity": 73763.8,
      "is_rising_star": true,
      "heatScore": 22132.518519950987,
      "popularityScore": 67058
    },
    {
      "id": "github-dair-ai-Prompt-Engineering-Guide",
      "name": "Prompt-Engineering-Guide",
      "author": "dair-ai",
      "description": "üêô Guides, papers, lessons, notebooks and resources for prompt engineering, context engineering, RAG, and AI Agents.",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai-agents",
        "chatgpt",
        "deep-learning",
        "generative-ai",
        "language-model",
        "llms",
        "openai",
        "prompt-engineering",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 133184,
      "downloads": 133184,
      "lastModified": "2025-11-20T15:46:31Z",
      "lastModifiedTimestamp": 1763653591000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/dair-ai/Prompt-Engineering-Guide",
          "homepage": "https://www.promptingguide.ai/",
          "language": "MDX",
          "forks": 6951,
          "open_issues": 231,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/30384625?v=4",
      "velocity": 73251.2,
      "is_rising_star": true,
      "heatScore": 21978.73640000614,
      "popularityScore": 66592
    },
    {
      "id": "github-OpenHands-OpenHands",
      "name": "OpenHands",
      "author": "OpenHands",
      "description": "üôå OpenHands: Code Less, Make More",
      "task": "tool",
      "tags": [
        "agent",
        "artificial-intelligence",
        "chatgpt",
        "claude-ai",
        "cli",
        "developer-tools",
        "gpt",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 130236,
      "downloads": 130236,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenHands/OpenHands",
          "homepage": "https://all-hands.dev",
          "language": "Python",
          "forks": 7937,
          "open_issues": 211,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/225919603?v=4",
      "velocity": 71629.8,
      "is_rising_star": true,
      "heatScore": 21492.30959540588,
      "popularityScore": 65118
    },
    {
      "id": "github-PaddlePaddle-PaddleOCR",
      "name": "PaddleOCR",
      "author": "PaddlePaddle",
      "description": "Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.",
      "task": "tool",
      "tags": [
        "ai4science",
        "chineseocr",
        "document-parsing",
        "document-translation",
        "kie",
        "ocr",
        "paddleocr-vl",
        "pdf-extractor-rag",
        "pdf-parser",
        "pdf2markdown",
        "pp-ocr",
        "pp-structure",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 128822,
      "downloads": 128822,
      "lastModified": "2025-11-20T15:27:27Z",
      "lastModifiedTimestamp": 1763652447000,
      "readme": "<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"./docs/images/Banner.png\" alt=\"PaddleOCR Banner\">\n  </p>\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](./readme/README_cn.md) | [ÁπÅÈ´î‰∏≠Êñá](./readme/README_tcn.md) | [Êó•Êú¨Ë™û](./readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](./readme/README_ko.md) | [Fran√ßais](./readme/README_fr.md) | [–†—É—Å—Å–∫–∏–π](./readme/README_ru.md) | [Espa√±ol](./readme/README_es.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](./readme/README_ar.md)\n\n<!-- icon -->\n[![stars](https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf)](https://github.com/PaddlePaddle/PaddleOCR)\n[![forks](https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg)](https://github.com/PaddlePaddle/PaddleOCR)\n[![arXiv](https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2507.05595)\n[![arXiv](https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.14528)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr/month)](https://pepy.tech/projectsproject/paddleocr)\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr)](https://pepy.tech/projects/paddleocr)\n[![Used by](https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue)](https://github.com/PaddlePaddle/PaddleOCR/network/dependents)\n[![PyPI version](https://img.shields.io/pypi/v/paddleocr)](https://pypi.org/project/paddleocr/)\n![python](https://img.shields.io/badge/python-3.8~3.12-aff.svg)\n\n![os](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg)\n![hardware](https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg)\n[![License](https://img.shields.io/badge/license-Apache_2.0-green)](../LICENSE)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/PaddlePaddle/PaddleOCR)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://www.paddleocr.com)\n\n\n\n**PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding**\n\n</div>\n\n# PaddleOCR\n[![Framework](https://img.shields.io/badge/PaddlePaddle-3.0-orange)](https://www.paddlepaddle.org.cn/en)\n[![Accuracy](https://img.shields.io/badge/Recognition%20Accuracy-üèÜ-green)](#)\n[![Multi-Language](https://img.shields.io/badge/Support_Languages-100+-brightgreen)](#)\n[![Handwriting](https://img.shields.io/badge/Handwriting-‚úì-success)](#)\n[![Hardware](https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red)](#)\n\n> [!TIP]\n> PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to [PaddleOCR MCP Server](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html).\n>\n> The PaddleOCR 3.0 Technical Report is now available. See details at: [PaddleOCR 3.0 Technical Report](https://arxiv.org/abs/2507.05595).\n>\n> The PaddleOCR-VL Technical Report is now available. See details at [PaddleOCR-VL Technical Report](https://arxiv.org/abs/2510.14528).\n>\n> The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the [PaddleOCR official website](https://www.paddleocr.com).\n\n\n**PaddleOCR** converts documents and images into **structured, AI-friendly data** (like JSON and Markdown) with **industry-leading accuracy**‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over **60,000 stars** and deep integration into leading projects like **MinerU, RAGFlow, pathway and cherry-studio**, PaddleOCR has become the **premier solution** for developers building intelligent document applications in the **AI era**.\n\n### PaddleOCR 3.0 Core Features\n\n[![HuggingFace](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&labelColor=white)](https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/application/detail/98365)\n[![ModelScope](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&labelColor=white)](https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n\n[![AI Studio](https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n\n- **PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM**  \n  **The SOTA and resource-efficient model tailored for document parsing**, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.\n\n- **PP-OCRv5 ‚Äî Universal Scene Text Recognition**  \n  **Single model supports five text types** (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with **13% accuracy improvement**. Solves multilingual mixed document recognition challenges.\n\n- **PP-StructureV3 ‚Äî Complex Document Parsing**  \n  Intelligently converts complex PDFs and document images into **Markdown and JSON files that preserve original structure**. **Outperforms** numerous commercial solutions in public benchmarks. **Perfectly maintains document layout and hierarchical structure**.\n\n- **PP-ChatOCRv4 ‚Äî Intelligent Information Extraction**  \n  Natively integrates ERNIE 4.5 to **precisely extract key information** from massive documents, with 15% accuracy improvement over previous generation. Makes documents \"**understand**\" your questions and provide accurate answers.\n\nIn addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg\" alt=\"PaddleOCR Architecture\">\n  </p>\n</div>\n\n**Special Note**: PaddleOCR 3.x introduces several significant interface changes. **Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x**. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. [This document](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html) explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.\n\n## üì£ Recent updates\n\n### üî•üî• 2025.10.16: PaddleOCR 3.3.0 released, includes:\n\n- Released PaddleOCR-VL:\n    - **Model Introduction**:\n        - **PaddleOCR-VL** is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. **This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption**. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on [HuggingFace](https://huggingface.co/PaddlePaddle/PaddleOCR-VL). Everyone is welcome to download and use it! More introduction infomation can be found in [PaddleOCR-VL](https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html).\n\n    - **Core Features**:\n        - **Compact yet Powerful VLM Architecture**: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.\n        - **SOTA Performance on Document Parsing**: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.\n        - **Multilingual Support**: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.\n\n- Released PP-OCRv5 Multilingual Recognition Model:\n    - Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.\n\n\n<details>\n<summary><strong>2025.08.21: Release of PaddleOCR 3.2.0</strong></summary>\n\n- **Significant Model Additions:**\n    - Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. **The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.**\n\n- **Deployment Capability Upgrades:**\n    - **Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.**\n    - **Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.**\n    - **High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.**\n    - **The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.**\n    - The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.\n\n- **Benchmark Support:**\n    - **All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. [Here's](docs/version3.x/pipeline_usage/instructions/benchmark.en.md) how to set up and use the benchmark feature.**\n    - **Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.**\n\n- **Bug Fixes:**\n    - Resolved the issue of failed log saving during model training.\n    - Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.\n    - Fixed inconsistencies in switch behaviors (e.g., `use_chart_parsing`) in the PP-StructureV3 configuration files compared to other pipelines.\n\n- **Other Enhancements:**\n    - **Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.**\n    - **Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the [installation guide](docs/version3.x/installation.en.md) for the corresponding PaddlePaddle framework versions.**\n    - **PP-OCR series models now support returning single-character coordinates.**\n    - Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.\n    - Added support for chart-to-table conversion via the PP-Chart2Table module.\n    - Optimized documentation descriptions to improve usability.\n</details>\n\n<details>\n<summary><strong>2025.08.15: PaddleOCR 3.1.1 Released</strong></summary>\n\n- **Bug Fixes:**\n  - Added the missing methods `save_vector`, `save_visual_info_list`, `load_vector`, and `load_visual_info_list` in the `PP-ChatOCRv4` class.\n  - Added the missing parameters `glossary` and `llm_request_interval` to the `translate` method in the `PPDocTranslation` class.\n\n- **Documentation Improvements:**\n  - Added a demo to the MCP documentation.\n  - Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.\n  - Fixed errors and omissions in the production line document translation.\n\n- **Others:**\n  - Changed the MCP server dependency to use the pure Python library `puremagic` instead of `python-magic` to reduce installation issues.\n  - Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.\n\n</details>\n\n<details>\n<summary><strong>2025.06.29: PaddleOCR 3.1.0 Released</strong></summary>\n\n- **Key Models and Pipelines:**\n  - **Added PP-OCRv5 Multilingual Text Recognition Model**, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. **Average accuracy improved by over 30%.** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html)\n  - Upgraded the **PP-Chart2Table model** in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) **increased by 9.36 percentage points (71.24% -> 80.60%).**\n  - Newly launched **document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5**, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html)\n\n\n- **New MCP server:** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)\n  - **Supports both OCR and PP-StructureV3 pipelines.**\n  - Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.\n  - Supports invoking local services via stdio and remote services via Streamable HTTP.\n\n- **Documentation Optimization:** Improved the descriptions in some user guides for a smoother reading experience.\n\n</details>\n\n<details>\n    <summary><strong>2025.06.26: PaddleOCR 3.0.3 Released</strong></summary>\n- Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference.\n</details>\n\n<details>\n    <summary><strong>2025.06.19: PaddleOCR 3.0.2 Released</strong></summary>\n- **New Features:**\n\n  - The default download source has been changed from `BOS` to `HuggingFace`. Users can also change the environment variable `PADDLE_PDX_MODEL_SOURCE` to `BOS` to set the model download source back to Baidu Object Storage (BOS).\n  - Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.\n  - Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.\n  - Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language. \n  - Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.\n  - Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.\n  - Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.\n  - Added Android example for PP-OCRv5. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html).\n\n- **Bug Fixes:**\n  - Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.\n  - Resolved an issue where `export_paddlex_config_to_yaml` would not function correctly in certain cases.\n  - Corrected the discrepancy between the actual behavior of `save_path` and its documentation description.\n  - Fixed potential multithreading errors when using MKL-DNN in basic service deployment.\n  - Corrected channel order errors in image preprocessing for the Latex-OCR model.\n  - Fixed channel order errors in saving visualized images within the text recognition module.\n  - Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.\n  - Fixed an overflow issue in the calculation of `overlap_ratio` under extremely special circumstances in the PP-StructureV3 pipeline.\n\n- **Documentation Improvements:**\n  - Updated the description of the `enable_mkldnn` parameter in the documentation to accurately reflect the program's actual behavior.\n  - Fixed errors in the documentation regarding the `lang` and `ocr_version` parameters.\n  - Added instructions for exporting pipeline configuration files via CLI.\n  - Fixed missing columns in the performance data table for PP-OCRv5.\n  - Refined benchmark metrics for PP-StructureV3 across different configurations.\n\n- **Others:**\n\n  - Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.\n</details>\n\n<details>\n    <summary><strong>History Log</strong></summary>\n\n2025.06.05: **PaddleOCR 3.0.1 Released**, includes:\n\n- **Optimisation of certain models and model configurations:**\n  - Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter `limit_side_len` in the configuration has been changed from 736 to 64.\n  - Added a new text line orientation classification model `PP-LCNet_x1_0_textline_ori` with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.\n  - Optimized the text line orientation classification model `PP-LCNet_x0_25_textline_ori`, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.\n- **Optimizations and fixes for some issues in version 3.0.0, [details](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)**\n\nüî•üî•2025.05.20: Official Release of **PaddleOCR v3.0**, including:\n- **PP-OCRv5**: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.\n   1. üåê Single-model support for **five** text types - Seamlessly process **Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English** and **Japanese** within a single model.\n   2. ‚úçÔ∏è Improved **handwriting recognition**: Significantly better at complex cursive scripts and non-standard handwriting.\n   3. üéØ **13-point accuracy gain** over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.\n\n- **PP-StructureV3**: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios! \n   1. üßÆ **High-Accuracy multi-scene PDF parsing**, leading both open- and closed-source solutions on the OmniDocBench benchmark.\n   2. üß† Specialized capabilities include **seal recognition**, **chart-to-table conversion**, **table recognition with nested formulas/images**, **vertical text document parsing**, and **complex table structure analysis**.\n\n- **PP-ChatOCRv4**: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.\n   1. üî• **15-point accuracy gain** in key-information extraction on PDF/PNG/JPG files over the previous generation.\n   2. üíª Native support for **ERNIE 4.5**, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.\n   3. ü§ù Integrated [PP-DocBee2](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2), enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.\n\n[History Log](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)\n\n</details>\n\n## ‚ö° Quick Start\n### 1. Run online demo \n[![AI Studio](https://img.shields.io/badge/PP_OCRv5-AI_Studio-green)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_StructureV3-AI_Studio-green)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n### 2. Installation\n\nInstall PaddlePaddle refer to [Installation Guide](https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html), after then, install the PaddleOCR toolkit.\n\n```bash\n# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\"\n```\n\nStarting from version 3.2.0, in addition to the `all` dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:\n\n| Dependency Group Name | Corresponding Functionality |\n| - | - |\n| `doc-parser` | Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL |\n| `ie` | Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4 |\n| `trans` | Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation |\n| `all` | Complete functionality |\n\n### 3. Run inference by CLI\n```bash\n# Run PP-OCRv5 inference\npaddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  \n\n# Run PP-StructureV3 inference\npaddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False\n\n# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference\npaddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False \n\n# Run PaddleOCR-VL inference\npaddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\n\n# Get more information about \"paddleocr ocr\"\npaddleocr ocr --help\n```\n\n### 4. Run inference by API\n**4.1 PP-OCRv5 Example**\n```python\n# Initialize PaddleOCR instance\nfrom paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\n\n# Run OCR inference on a sample image \nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")\n\n# Visualize the results and save the JSON results\nfor res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")\n```\n\n<details>\n    <summary><strong>4.2 PP-StructureV3 Example</strong></summary>\n\n```python\nfrom pathlib import Path\nfrom paddleocr import PPStructureV3\n\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\n# For Image\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\n\n# Visualize the results and save the JSON results\nfor res in output:\n    res.print() \n    res.save_to_json(save_path=\"output\") \n    res.save_to_markdown(save_path=\"output\")           \n```\n\n</details>\n\n<details>\n   <summary><strong>4.3 PP-ChatOCRv4 Example</strong></summary>\n\n```python\nfrom paddleocr import PPChatOCRv4Doc\n\nchat_bot_config = {\n    \"module_name\": \"chat_bot\",\n    \"model_name\": \"ernie-3.5-8k\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"openai\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\nretriever_config = {\n    \"module_name\": \"retriever\",\n    \"model_name\": \"embedding-v1\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"qianfan\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\npipeline = PPChatOCRv4Doc(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\nvisual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)\n\nmllm_predict_info = None\nuse_mllm = False\n# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.\nif use_mllm:\n    mllm_chat_bot_config = {\n        \"module_name\": \"chat_bot\",\n        \"model_name\": \"PP-DocBee\",\n        \"base_url\": \"http://127.0.0.1:8080/\",  # your local mllm service url\n        \"api_type\": \"openai\",\n        \"api_key\": \"api_key\",  # your api_key\n    }\n\n    mllm_predict_res = pipeline.mllm_pred(\n        input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n        key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n        mllm_chat_bot_config=mllm_chat_bot_config,\n    )\n    mllm_predict_info = mllm_predict_res[\"mllm_res\"]\n\nvisual_info_list = []\nfor res in visual_predict_res:\n    visual_info_list.append(res[\"visual_info\"])\n    layout_parsing_result = res[\"layout_parsing_result\"]\n\nvector_info = pipeline.build_vector(\n    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config\n)\nchat_result = pipeline.chat(\n    key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n    visual_info=visual_info_list,\n    vector_info=vector_info,\n    mllm_predict_info=mllm_predict_info,\n    chat_bot_config=chat_bot_config,\n    retriever_config=retriever_config,\n)\nprint(chat_result)\n```\n\n</details>\n\n<details>\n   <summary><strong>4.4 PaddleOCR-VL Example</strong></summary>\n\n```python\nfrom paddleocr import PaddleOCRVL\n\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")\n```\n\n</details>\n\n### 5. Chinese Heterogeneous AI Accelerators\n- [Huawei Ascend](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html)\n- [KUNLUNXIN](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html)\n\n## üß© More Features\n\n- Convert models to ONNX format: [Obtaining ONNX Models](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html).\n- Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: [High-Performance Inference](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html).\n- Accelerate inference using multi-GPU and multi-process: [Parallel Inference for Pipelines](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html).\n- Integrate PaddleOCR into applications written in C++, C#, Java, etc.: [Serving](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html).\n\n## ‚õ∞Ô∏è Advanced Tutorials\n\n- [PP-OCRv5 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html)\n- [PP-StructureV3 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html)\n- [PP-ChatOCRv4 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html)\n- [PaddleOCR-VL Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html)\n\n## üîÑ Quick Overview of Execution Results\n\n### PP-OCRv5\n\n<div align=\"center\">\n  <p>\n       <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif\" alt=\"PP-OCRv5 Demo\">\n  </p>\n</div>\n\n\n\n### PP-StructureV3\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n### PaddleOCR-VL\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n\n## ‚ú® Stay Tuned\n\n‚≠ê **Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!** ‚≠ê\n\n<div align=\"center\">\n  <p>\n       <img width=\"1200\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif\" alt=\"Star-Project\">\n  </p>\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community\n\n<div align=\"center\">\n\n| PaddlePaddle WeChat official account |  Join the tech discussion group |\n| :---: | :---: |\n| <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg\" width=\"150\"> | <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg\" width=\"150\"> |\n</div>\n\n\n## üòÉ Awesome Projects Leveraging PaddleOCR\nPaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!\n\n<div align=\"center\">\n\n| Project Name | Description |\n| ------------ | ----------- |\n| [RAGFlow](https://github.com/infiniflow/ragflow) <a href=\"https://github.com/infiniflow/ragflow\"><img src=\"https://img.shields.io/github/stars/infiniflow/ragflow\"></a>|RAG engine based on deep document understanding.|\n| [pathway](https://github.com/pathwaycom/pathway) <a href=\"https://github.com/pathwaycom/pathway\"><img src=\"https://img.shields.io/github/stars/pathwaycom/pathway\"></a>|Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.|\n| [MinerU](https://github.com/opendatalab/MinerU) <a href=\"https://github.com/opendatalab/MinerU\"><img src=\"https://img.shields.io/github/stars/opendatalab/MinerU\"></a>|Multi-type Document to Markdown Conversion Tool|\n| [Umi-OCR](https://github.com/hiroi-sora/Umi-OCR) <a href=\"https://github.com/hiroi-sora/Umi-OCR\"><img src=\"https://img.shields.io/github/stars/hiroi-sora/Umi-OCR\"></a>|Free, Open-source, Batch Offline OCR Software.|\n| [cherry-studio](https://github.com/CherryHQ/cherry-studio) <a href=\"https://github.com/CherryHQ/cherry-studio\"><img src=\"https://img.shields.io/github/stars/CherryHQ/cherry-studio\"></a>|A desktop client that supports for multiple LLM providers.|\n| [OmniParser](https://github.com/microsoft/OmniParser)<a href=\"https://github.com/microsoft/OmniParser\"><img src=\"https://img.shields.io/github/stars/microsoft/OmniParser\"></a> |OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.|\n| [QAnything](https://github.com/netease-youdao/QAnything)<a href=\"https://github.com/netease-youdao/QAnything\"><img src=\"https://img.shields.io/github/stars/netease-youdao/QAnything\"></a> |Question and Answer based on Anything.|\n| [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit) <a href=\"https://github.com/opendatalab/PDF-Extract-Kit\"><img src=\"https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit\"></a>|A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.|\n| [Dango-Translator](https://github.com/PantsuDango/Dango-Translator)<a href=\"https://github.com/PantsuDango/Dango-Translator\"><img src=\"https://img.shields.io/github/stars/PantsuDango/Dango-Translator\"></a> |Recognize text on the screen, translate it and show the translation results in real time.|\n| [Learn more projects](./awesome_projects.md) | [More projects based on PaddleOCR](./awesome_projects.md)|\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors\n\n<div align=\"center\">\n<a href=\"https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&max=400&columns=20\"  width=\"800\"/>\n</a>\n</div>\n\n## üåü Star\n\n<div align=\"center\">\n  <p>\n      <img width=\"800\" src=\"https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&type=Date\" alt=\"Star-history\">\n  </p>\n</div>\n\n\n## üìÑ License\nThis project is released under the [Apache 2.0 license](LICENSE).\n\n## üéì Citation\n\n```bibtex\n@misc{cui2025paddleocr30technicalreport,\n      title={PaddleOCR 3.0 Technical Report}, \n      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2507.05595},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2507.05595}, \n}\n\n@misc{cui2025paddleocrvlboostingmultilingualdocument,\n      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, \n      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2510.14528},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2510.14528}, \n}\n```\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/PaddlePaddle/PaddleOCR",
          "homepage": "https://www.paddleocr.ai",
          "language": "Python",
          "forks": 9368,
          "open_issues": 280,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23534030?v=4",
      "velocity": 70852.1,
      "is_rising_star": true,
      "heatScore": 21258.99627674898,
      "popularityScore": 64411
    },
    {
      "id": "github-vllm-project-vllm",
      "name": "vllm",
      "author": "vllm-project",
      "description": "A high-throughput and memory-efficient inference and serving engine for LLMs",
      "task": "tool",
      "tags": [
        "amd",
        "blackwell",
        "cuda",
        "deepseek",
        "deepseek-v3",
        "gpt",
        "gpt-oss",
        "inference",
        "kimi",
        "llama",
        "llm",
        "llm-serving",
        "model-serving",
        "moe",
        "openai",
        "pytorch",
        "qwen",
        "qwen3",
        "tpu",
        "transformer"
      ],
      "likes": 127100,
      "downloads": 127100,
      "lastModified": "2025-11-20T15:22:49Z",
      "lastModifiedTimestamp": 1763652169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/vllm-project/vllm",
          "homepage": "https://docs.vllm.ai",
          "language": "Python",
          "forks": 11425,
          "open_issues": 3142,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/136984999?v=4",
      "velocity": 69905,
      "is_rising_star": true,
      "heatScore": 20974.86218567212,
      "popularityScore": 63550
    },
    {
      "id": "github-hiyouga-LLaMA-Factory",
      "name": "LLaMA-Factory",
      "author": "hiyouga",
      "description": "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "deepseek",
        "fine-tuning",
        "gemma",
        "gpt",
        "instruction-tuning",
        "large-language-models",
        "llama",
        "llama3",
        "llm",
        "lora",
        "moe",
        "nlp",
        "peft",
        "qlora",
        "quantization",
        "qwen",
        "rlhf",
        "transformers"
      ],
      "likes": 125604,
      "downloads": 125604,
      "lastModified": "2025-11-20T15:04:01Z",
      "lastModifiedTimestamp": 1763651041000,
      "readme": "![# LLaMA Factory](assets/logo.png)\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)\n[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)\n[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)\n[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)\n[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)\n[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)\n[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)\n\n[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)\n[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)\n[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)\n[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/en/)\n\n[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)\n[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)\n[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)\n[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)\n[![Open in Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)\n[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)\n[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)\n\n### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.\n\n<div align=\"center\" markdown=\"1\">\n\n### Supporters ‚ù§Ô∏è\n\n| <div style=\"text-align: center;\"><a href=\"https://warp.dev/llama-factory\"><img alt=\"Warp sponsorship\" width=\"400\" src=\"assets/sponsors/warp.jpg\"></a><br><a href=\"https://warp.dev/llama-factory\" style=\"font-size:larger;\">Warp, the agentic terminal for developers</a><br><a href=\"https://warp.dev/llama-factory\">Available for MacOS, Linux, & Windows</a> | <a href=\"https://serpapi.com\"><img alt=\"SerpAPI sponsorship\" width=\"250\" src=\"assets/sponsors/serpapi.svg\"> </a> |\n| ---- | ---- |\n\n----\n\n### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n\n![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)\n\n</div>\n\nüëã Join our [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg), [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg), [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg), [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg) user group.\n\n\\[ English | [‰∏≠Êñá](README_zh.md) \\]\n\n**Fine-tuning a large language model can be easy as...**\n\nhttps://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e\n\nStart local training:\n- Please refer to [usage](#getting-started)\n\nStart cloud training:\n- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing\n- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory\n- **LLaMA Factory Online**: https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory\n- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory\n\nRead technical notes:\n- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/\n- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html\n- **Official Blog**: https://blog.llamafactory.net/en/\n- **Official Course**: https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory\n\n> [!NOTE]\n> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.\n\n## Table of Contents\n\n- [Features](#features)\n- [Blogs](#blogs)\n- [Changelog](#changelog)\n- [Supported Models](#supported-models)\n- [Supported Training Approaches](#supported-training-approaches)\n- [Provided Datasets](#provided-datasets)\n- [Requirement](#requirement)\n- [Getting Started](#getting-started)\n  - [Installation](#installation)\n  - [Data Preparation](#data-preparation)\n  - [Quickstart](#quickstart)\n  - [Fine-Tuning with LLaMA Board GUI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n  - [LLaMA Factory Online](#llama-factory-online)\n  - [Build Docker](#build-docker)\n  - [Deploy with OpenAI-style API and vLLM](#deploy-with-openai-style-api-and-vllm)\n  - [Download from ModelScope Hub](#download-from-modelscope-hub)\n  - [Download from Modelers Hub](#download-from-modelers-hub)\n  - [Use W&B Logger](#use-wb-logger)\n  - [Use SwanLab Logger](#use-swanlab-logger)\n- [Projects using LLaMA Factory](#projects-using-llama-factory)\n- [License](#license)\n- [Citation](#citation)\n- [Acknowledgement](#acknowledgement)\n\n## Features\n\n- **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.\n- **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.\n- **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n- **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), [Muon](https://github.com/KellerJordan/Muon), [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.\n- **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [KTransformers](https://github.com/kvcache-ai/ktransformers/), RoPE scaling, NEFTune and rsLoRA.\n- **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.\n- **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, [SwanLab](https://github.com/SwanHubX/SwanLab), etc.\n- **Faster inference**: OpenAI-style API, Gradio UI and CLI with [vLLM worker](https://github.com/vllm-project/vllm) or [SGLang worker](https://github.com/sgl-project/sglang).\n\n### Day-N Support for Fine-Tuning Cutting-Edge Models\n\n| Support Date | Model Name                                                           |\n| ------------ | -------------------------------------------------------------------- |\n| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |\n| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |\n\n## Blogs\n\n> [!TIP]\n> Now we have a dedicated blog for LLaMA Factory!\n>\n> Website: https://blog.llamafactory.net/en/\n\n- üí° [KTransformers Fine-Tuning √ó LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/) (English)\n- üí° [Easy Dataset √ó LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g) (English)\n- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory) (Chinese)\n- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/) (Chinese)\n- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/) (English)\n\n<details><summary>All Blogs</summary>\n\n- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory) (Chinese)\n- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b) (Chinese)\n- [A One-Stop Code-Free Model Fine-Tuning \\& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/) (Chinese)\n- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl) (Chinese)\n- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory) (Chinese)\n\n</details>\n\n## Changelog\n\n[25/10/26] We support Megatron-core training backend with [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter). See [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237) to get started.\n\n[25/08/22] We supported **[OFT](https://arxiv.org/abs/2306.07280)** and **[OFTv2](https://arxiv.org/abs/2506.19847)**. See [examples](examples/README.md) for usage.\n\n[25/08/20] We supported fine-tuning the **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** models. See [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) to get started.\n\n[25/08/06] We supported fine-tuning the **[GPT-OSS](https://github.com/openai/gpt-oss)** models. See [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) to get started.\n\n<details><summary>Full Changelog</summary>\n\n[25/07/02] We supported fine-tuning the **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** model.\n\n[25/04/28] We supported fine-tuning the **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** model family.\n\n[25/04/21] We supported the **[Muon](https://github.com/KellerJordan/Muon)** optimizer. See [examples](examples/README.md) for usage. Thank [@tianshijing](https://github.com/tianshijing)'s PR.\n\n[25/04/16] We supported fine-tuning the **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** model. See [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) to get started.\n\n[25/04/14] We supported fine-tuning the **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** and **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** models.\n\n[25/04/06] We supported fine-tuning the **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** model. See [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) to get started.\n\n[25/03/31] We supported fine-tuning the **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** model. See [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) to get started.\n\n[25/03/15] We supported **[SGLang](https://github.com/sgl-project/sglang)** as inference backend. Try `infer_backend: sglang` to accelerate inference.\n\n[25/03/12] We supported fine-tuning the **[Gemma 3](https://huggingface.co/blog/gemma3)** model.\n\n[25/02/24] Announcing **[EasyR1](https://github.com/hiyouga/EasyR1)**, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.\n\n[25/02/11] We supported saving the **[Ollama](https://github.com/ollama/ollama)** modelfile when exporting the model checkpoints. See [examples](examples/README.md) for usage.\n\n[25/02/05] We supported fine-tuning the **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** and **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** on audio understanding tasks.\n\n[25/01/31] We supported fine-tuning the **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** and **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** models.\n\n[25/01/15] We supported **[APOLLO](https://arxiv.org/abs/2412.05270)** optimizer. See [examples](examples/README.md) for usage.\n\n[25/01/14] We supported fine-tuning the **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** and **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** models. Thank [@BUAADreamer](https://github.com/BUAADreamer)'s PR.\n\n[25/01/14] We supported fine-tuning the **[InternLM 3](https://huggingface.co/collections/internlm/)** models. Thank [@hhaAndroid](https://github.com/hhaAndroid)'s PR.\n\n[25/01/10] We supported fine-tuning the **[Phi-4](https://huggingface.co/microsoft/phi-4)** model.\n\n[24/12/21] We supported using **[SwanLab](https://github.com/SwanHubX/SwanLab)** for experiment tracking and visualization. See [this section](#use-swanlab-logger) for details.\n\n[24/11/27] We supported fine-tuning the **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** model and the **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** dataset.\n\n[24/10/09] We supported downloading pre-trained models and datasets from the **[Modelers Hub](https://modelers.cn/models)**. See [this tutorial](#download-from-modelers-hub) for usage.\n\n[24/09/19] We supported fine-tuning the **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** models.\n\n[24/08/30] We supported fine-tuning the **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** models. Thank [@simonJJJ](https://github.com/simonJJJ)'s PR.\n\n[24/08/27] We supported **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**. Try `enable_liger_kernel: true` for efficient training.\n\n[24/08/09] We supported **[Adam-mini](https://github.com/zyushun/Adam-mini)** optimizer. See [examples](examples/README.md) for usage. Thank [@relic-yuexi](https://github.com/relic-yuexi)'s PR.\n\n[24/07/04] We supported [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing). Use `neat_packing: true` to activate it. Thank [@chuan298](https://github.com/chuan298)'s PR.\n\n[24/06/16] We supported **[PiSSA](https://arxiv.org/abs/2404.02948)** algorithm. See [examples](examples/README.md) for usage.\n\n[24/06/07] We supported fine-tuning the **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** and **[GLM-4](https://github.com/THUDM/GLM-4)** models.\n\n[24/05/26] We supported **[SimPO](https://arxiv.org/abs/2405.14734)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/20] We supported fine-tuning the **PaliGemma** series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with `paligemma` template for chat completion.\n\n[24/05/18] We supported **[KTO](https://arxiv.org/abs/2402.01306)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/14] We supported training and inference on the Ascend NPU devices. Check [installation](#installation) section for details.\n\n[24/04/26] We supported fine-tuning the **LLaVA-1.5** multimodal LLMs. See [examples](examples/README.md) for usage.\n\n[24/04/22] We provided a **[Colab notebook](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)** for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) and [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese) for details.\n\n[24/04/21] We supported **[Mixture-of-Depths](https://arxiv.org/abs/2404.02258)** according to [AstraMindAI's implementation](https://github.com/astramind-ai/Mixture-of-depths). See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[BAdam](https://arxiv.org/abs/2404.02827)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves **117%** speed and **50%** memory compared with FlashAttention-2, more benchmarks can be found in [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison).\n\n[24/03/31] We supported **[ORPO](https://arxiv.org/abs/2403.07691)**. See [examples](examples/README.md) for usage.\n\n[24/03/21] Our paper \"[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)\" is available at arXiv!\n\n[24/03/20] We supported **FSDP+QLoRA** that fine-tunes a 70B model on 2x24GB GPUs. See [examples](examples/README.md) for usage.\n\n[24/03/13] We supported **[LoRA+](https://arxiv.org/abs/2402.12354)**. See [examples](examples/README.md) for usage.\n\n[24/03/07] We supported **[GaLore](https://arxiv.org/abs/2403.03507)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/03/07] We integrated **[vLLM](https://github.com/vllm-project/vllm)** for faster and concurrent inference. Try `infer_backend: vllm` to enjoy **270%** inference speed.\n\n[24/02/28] We supported weight-decomposed LoRA (**[DoRA](https://arxiv.org/abs/2402.09353)**). Try `use_dora: true` to activate DoRA training.\n\n[24/02/15] We supported **block expansion** proposed by [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro). See [examples](examples/README.md) for usage.\n\n[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this [blog post](https://qwenlm.github.io/blog/qwen1.5/) for details.\n\n[24/01/18] We supported **agent tuning** for most models, equipping model with tool using abilities by fine-tuning with `dataset: glaive_toolcall_en`.\n\n[23/12/23] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try `use_unsloth: true` argument to activate unsloth patch. It achieves **170%** speed in our benchmark, check [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison) for details.\n\n[23/12/12] We supported fine-tuning the latest MoE model **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)** in our framework. See hardware requirement [here](#hardware-requirement).\n\n[23/12/01] We supported downloading pre-trained models and datasets from the **[ModelScope Hub](https://modelscope.cn/models)**. See [this tutorial](#download-from-modelscope-hub) for usage.\n\n[23/10/21] We supported **[NEFTune](https://arxiv.org/abs/2310.05914)** trick for fine-tuning. Try `neftune_noise_alpha: 5` argument to activate NEFTune.\n\n[23/09/27] We supported **$S^2$-Attn** proposed by [LongLoRA](https://github.com/dvlab-research/LongLoRA) for the LLaMA models. Try `shift_attn: true` argument to enable shift short attention.\n\n[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See [examples](examples/README.md) for usage.\n\n[23/09/10] We supported **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**. Try `flash_attn: fa2` argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.\n\n[23/08/12] We supported **RoPE scaling** to extend the context length of the LLaMA models. Try `rope_scaling: linear` argument in training and `rope_scaling: dynamic` argument at inference to extrapolate the position embeddings.\n\n[23/08/11] We supported **[DPO training](https://arxiv.org/abs/2305.18290)** for instruction-tuned models. See [examples](examples/README.md) for usage.\n\n[23/07/31] We supported **dataset streaming**. Try `streaming: true` and `max_steps: 10000` arguments to load your dataset in streaming mode.\n\n[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ([LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)) for details.\n\n[23/07/18] We developed an **all-in-one Web UI** for training, evaluation and inference. Try `train_web.py` to fine-tune models in your Web browser. Thank [@KanadeSiina](https://github.com/KanadeSiina) and [@codemayq](https://github.com/codemayq) for their efforts in the development.\n\n[23/07/09] We released **[FastEdit](https://github.com/hiyouga/FastEdit)** ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow [FastEdit](https://github.com/hiyouga/FastEdit) if you are interested.\n\n[23/06/29] We provided a **reproducible example** of training a chat model using instruction-following datasets, see [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft) for details.\n\n[23/06/22] We aligned the [demo API](src/api_demo.py) with the [OpenAI's](https://platform.openai.com/docs/api-reference/chat) format where you can insert the fine-tuned model in **arbitrary ChatGPT-based applications**.\n\n[23/06/03] We supported quantized training and inference (aka **[QLoRA](https://github.com/artidoro/qlora)**). See [examples](examples/README.md) for usage.\n\n</details>\n\n> [!TIP]\n> If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.\n\n## Supported Models\n\n| Model                                                             | Model size                       | Template             |\n| ----------------------------------------------------------------- | -------------------------------- | -------------------- |\n| [Baichuan 2](https://huggingface.co/baichuan-inc)                 | 7B/13B                           | baichuan2            |\n| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |\n| [ChatGLM3](https://huggingface.co/THUDM)                          | 6B                               | chatglm3             |\n| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |\n| [DeepSeek (Code/MoE)](https://huggingface.co/deepseek-ai)         | 7B/16B/67B/236B                  | deepseek             |\n| [DeepSeek 2.5/3](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |\n| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |\n| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |\n| [Falcon](https://huggingface.co/tiiuae)                           | 7B/11B/40B/180B                  | falcon               |\n| [Falcon-H1](https://huggingface.co/tiiuae)                        | 0.5B/1.5B/3B/7B/34B              | falcon_h1            |\n| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |\n| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |\n| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |\n| [GLM-4.1V](https://huggingface.co/zai-org)                        | 9B                               | glm4v                |\n| [GLM-4.5/GLM-4.5V](https://huggingface.co/zai-org)                | 106B/355B                        | glm4_moe/glm4v_moe   |\n| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |\n| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt                  |\n| [Granite 3.0-3.3](https://huggingface.co/ibm-granite)             | 1B/2B/3B/8B                      | granite3             |\n| [Granite 4](https://huggingface.co/ibm-granite)                   | 7B                               | granite4             |\n| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |\n| [Index](https://huggingface.co/IndexTeam)                         | 1.9B                             | index                |\n| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |\n| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |\n| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |\n| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |\n| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |\n| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |\n| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |\n| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |\n| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |\n| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |\n| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |\n| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |\n| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |\n| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B                               | mimo                 |\n| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |\n| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |\n| [Ministral/Mistral-Nemo](https://huggingface.co/mistralai)        | 8B/12B                           | ministral            |\n| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |\n| [Mistral Small](https://huggingface.co/mistralai)                 | 24B                              | mistral_small        |\n| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |\n| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |\n| [Phi-1.5/Phi-2](https://huggingface.co/microsoft)                 | 1.3B/2.7B                        | -                    |\n| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |\n| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |\n| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |\n| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |\n| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |\n| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |\n| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |\n| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |\n| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |\n| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |\n| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |\n| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |\n| [Skywork o1](https://huggingface.co/Skywork)                      | 8B                               | skywork_o1           |\n| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |\n| [TeleChat2](https://huggingface.co/Tele-AI)                       | 3B/7B/35B/115B                   | telechat2            |\n| [XVERSE](https://huggingface.co/xverse)                           | 7B/13B/65B                       | xverse               |\n| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |\n| [Yi-VL](https://huggingface.co/01-ai)                             | 6B/34B                           | yi_vl                |\n| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |\n\n> [!NOTE]\n> For the \"base\" models, the `template` argument can be chosen from `default`, `alpaca`, `vicuna` etc. But make sure to use the **corresponding template** for the \"instruct/chat\" models.\n>\n> If the model has both reasoning and non-reasoning versions, please use the `_nothink` suffix to distinguish between them. For example, `qwen3` and `qwen3_nothink`.\n>\n> Remember to use the **SAME** template in training and inference.\n>\n> \\*: You should install the `transformers` from main branch and use `DISABLE_VERSION_CHECK=1` to skip version check.\n>\n> \\*\\*: You need to install a specific version of `transformers` to use the corresponding model.\n\nPlease refer to [constants.py](src/llamafactory/extras/constants.py) for a full list of models we supported.\n\nYou also can add a custom chat template to [template.py](src/llamafactory/data/template.py).\n\n## Supported Training Approaches\n\n| Approach               |     Full-tuning    |    Freeze-tuning   |       LoRA         |       QLoRA        |        OFT         |        QOFT        |\n| ---------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |\n| Pre-Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Supervised Fine-Tuning | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Reward Modeling        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| PPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| DPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| KTO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| ORPO Training          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| SimPO Training         | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n\n> [!TIP]\n> The implementation details of PPO can be found in [this blog](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html).\n\n## Provided Datasets\n\n<details><summary>Pre-training datasets</summary>\n\n- [Wiki Demo (en)](data/wiki_demo.txt)\n- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)\n- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)\n- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)\n- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)\n- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)\n- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)\n- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)\n- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)\n- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)\n- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)\n- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)\n- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)\n- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)\n- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)\n- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)\n\n</details>\n\n<details><summary>Supervised fine-tuning datasets</summary>\n\n- [Identity (en&zh)](data/identity.json)\n- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)\n- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)\n- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)\n- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)\n- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)\n- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)\n- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)\n- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)\n- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)\n- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)\n- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)\n- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)\n- [UltraChat (en)](https://github.com/thunlp/UltraChat)\n- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)\n- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)\n- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)\n- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)\n- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)\n- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)\n- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)\n- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)\n- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)\n- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)\n- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)\n- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)\n- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)\n- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)\n- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)\n- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)\n- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)\n- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)\n- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)\n- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)\n- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)\n- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)\n- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)\n- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)\n- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)\n- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)\n- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)\n- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)\n- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)\n- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)\n- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)\n- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)\n- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)\n- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)\n- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)\n- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)\n- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)\n- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)\n- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)\n\n</details>\n\n<details><summary>Preference datasets</summary>\n\n- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)\n- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)\n- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)\n- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)\n- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)\n- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)\n- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)\n- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)\n- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)\n\n</details>\n\nSome datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.\n\n```bash\npip install \"huggingface_hub<1.0.0\"\nhuggingface-cli login\n```\n\n## Requirement\n\n| Mandatory    | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| python       | 3.9     | 3.10      |\n| torch        | 2.0.0   | 2.6.0     |\n| torchvision  | 0.15.0  | 0.21.0    |\n| transformers | 4.49.0  | 4.50.0    |\n| datasets     | 2.16.0  | 3.2.0     |\n| accelerate   | 0.34.0  | 1.2.1     |\n| peft         | 0.14.0  | 0.15.1    |\n| trl          | 0.8.6   | 0.9.6     |\n\n| Optional     | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| CUDA         | 11.6    | 12.2      |\n| deepspeed    | 0.10.0  | 0.16.4    |\n| bitsandbytes | 0.39.0  | 0.43.1    |\n| vllm         | 0.4.3   | 0.8.2     |\n| flash-attn   | 2.5.6   | 2.7.2     |\n\n### Hardware Requirement\n\n\\* *estimated*\n\n| Method                              | Bits |   7B  |  14B  |  30B  |   70B  |   `x`B  |\n| ----------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |\n| Full (`bf16` or `fp16`)             |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |\n| Full (`pure_bf16`)                  |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |\n| Freeze/LoRA/GaLore/APOLLO/BAdam/OFT |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |\n| QLoRA / QOFT                        |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |\n| QLoRA / QOFT                        |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |\n| QLoRA / QOFT                        |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |\n\n## Getting Started\n\n### Installation\n\n> [!IMPORTANT]\n> Installation is mandatory.\n\n#### Install from Source\n\n```bash\ngit clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\npip install -e \".[torch,metrics]\" --no-build-isolation\n```\n\nExtra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev\n\n#### Install from Docker Image\n\n```bash\ndocker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest\n```\n\nThis image is built on Ubuntu 22.04 (x86\\_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.\n\nFind the pre-built images: https://hub.docker.com/r/hiyouga/llamafactory/tags\n\nPlease refer to [build docker](#build-docker) to build the image yourself.\n\n<details><summary>Setting up a virtual environment with <b>uv</b></summary>\n\nCreate an isolated Python environment with [uv](https://github.com/astral-sh/uv):\n\n```bash\nuv sync --extra torch --extra metrics --prerelease=allow\n```\n\nRun LLaMA-Factory in the isolated environment:\n\n```bash\nuv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml\n```\n\n</details>\n\n<details><summary>For Windows users</summary>\n\n#### Install PyTorch\n\nYou need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the [official website](https://pytorch.org/get-started/locally/) and the following command to install PyTorch with CUDA support:\n\n```bash\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\npython -c \"import torch; print(torch.cuda.is_available())\"\n```\n\nIf you see `True` then you have successfully installed PyTorch with CUDA support.\n\nTry `dataloader_num_workers: 0` if you encounter `Can't pickle local object` error.\n\n#### Install BitsAndBytes\n\nIf you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of `bitsandbytes` library, which supports CUDA 11.1 to 12.2, please select the appropriate [release version](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels) based on your CUDA version.\n\n```bash\npip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl\n```\n\n#### Install Flash Attention-2\n\nTo enable FlashAttention-2 on the Windows platform, please use the script from [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) to compile and install it by yourself.\n\n</details>\n\n<details><summary>For Ascend NPU users</summary>\n\nTo install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: `pip install -e \".[torch-npu,metrics]\"`. Additionally, you need to install the **[Ascend CANN Toolkit and Kernels](https://www.hiascend.com/developer/download/community/result?module=cann)**. Please follow the [installation tutorial](https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html) or use the following commands:\n\n```bash\n# replace the url according to your CANN version and devices\n# install CANN Toolkit\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# install CANN Kernels\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# set env variables\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n| Requirement  | Minimum | Recommend      |\n| ------------ | ------- | -------------- |\n| CANN         | 8.0.RC1 | 8.0.0.alpha002 |\n| torch        | 2.1.0   | 2.4.0          |\n| torch-npu    | 2.1.0   | 2.4.0.post2    |\n| deepspeed    | 0.13.2  | 0.13.2         |\n| vllm-ascend  | -       | 0.7.3          |\n\nRemember to use `ASCEND_RT_VISIBLE_DEVICES` instead of `CUDA_VISIBLE_DEVICES` to specify the device to use.\n\nIf you cannot infer model on NPU devices, try setting `do_sample: false` in the configurations.\n\nDownload the pre-built Docker images: [32GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html) | [64GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html)\n\n#### Install BitsAndBytes\n\nTo use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:\n\n1. Manually compile bitsandbytes: Refer to [the installation documentation](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU) for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.\n\n```bash\n# Install bitsandbytes from source\n# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch\ngit clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git\ncd bitsandbytes/\n\n# Install dependencies\npip install -r requirements-dev.txt\n\n# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference\napt-get install -y build-essential cmake\n\n# Compile & install  \ncmake -DCOMPUTE_BACKEND=npu -S .\nmake\npip install .\n```\n\n2. Install transformers from the main branch.\n\n```bash\ngit clone -b main https://github.com/huggingface/transformers.git\ncd transformers\npip install .\n```\n\n3. Set `double_quantization: false` in the configuration. You can refer to the [example](examples/train_qlora/llama3_lora_sft_bnb_npu.yaml).\n\n</details>\n\n### Data Preparation\n\nPlease refer to [data/README.md](data/README.md) for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.\n\n> [!NOTE]\n> Please update `data/dataset_info.json` to use your custom dataset.\n\nYou can also use **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**, **[DataFlow](https://github.com/OpenDCAI/DataFlow)** and **[GraphGen](https://github.com/open-sciencelab/GraphGen)** to create synthetic data for fine-tuning.\n\n### Quickstart\n\nUse the following 3 commands to run LoRA **fine-tuning**, **inference** and **merging** of the Llama3-8B-Instruct model, respectively.\n\n```bash\nllamafactory-cli train examples/train_lora/llama3_lora_sft.yaml\nllamafactory-cli chat examples/inference/llama3_lora_sft.yaml\nllamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml\n```\n\nSee [examples/README.md](examples/README.md) for advanced usage (including distributed training).\n\n> [!TIP]\n> Use `llamafactory-cli help` to show help information.\n>\n> Read [FAQs](https://github.com/hiyouga/LLaMA-Factory/issues/4614) first if you encounter any problems.\n\n### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))\n\n```bash\nllamafactory-cli webui\n```\n\n### LLaMA Factory Online\n\nRead our [documentation](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory).\n\n### Build Docker\n\nFor CUDA users:\n\n```bash\ncd docker/docker-cuda/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ncd docker/docker-npu/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ncd docker/docker-rocm/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\n<details><summary>Build without Docker Compose</summary>\n\nFor CUDA users:\n\n```bash\ndocker build -f ./docker/docker-cuda/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host --gpus=all \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ndocker build -f ./docker/docker-npu/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=torch-npu,metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -v /usr/local/dcmi:/usr/local/dcmi \\\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n    -v /etc/ascend_install.info:/etc/ascend_install.info \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/davinci0 \\\n    --device /dev/davinci_manager \\\n    --device /dev/devmm_svm \\\n    --device /dev/hisi_hdc \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ndocker build -f ./docker/docker-rocm/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/kfd \\\n    --device /dev/dri \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\n</details>\n\n<details><summary>Use Docker volumes</summary>\n\nYou can uncomment `VOLUME [ \"/root/.cache/huggingface\", \"/app/shared_data\", \"/app/output\" ]` in the Dockerfile to use data volumes.\n\nWhen building the Docker image, use `-v ./hf_cache:/root/.cache/huggingface` argument to mount the local directory to the container. The following data volumes are available.\n\n- `hf_cache`: Utilize Hugging Face cache on the host machine.\n- `shared_data`: The directionary to store datasets on the host machine.\n- `output`: Set export dir to this location so that the merged result can be accessed directly on the host machine.\n\n</details>\n\n### Deploy with OpenAI-style API and vLLM\n\n```bash\nAPI_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true\n```\n\n> [!TIP]\n> Visit [this page](https://platform.openai.com/docs/api-reference/chat/create) for API document.\n>\n> Examples: [Image understanding](scripts/api_example/test_image.py) | [Function calling](scripts/api_example/test_toolcall.py)\n\n### Download from ModelScope Hub\n\nIf you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.\n\n```bash\nexport USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the ModelScope Hub as the `model_name_or_path`. You can find a full list of model IDs at [ModelScope Hub](https://modelscope.cn/models), e.g., `LLM-Research/Meta-Llama-3-8B-Instruct`.\n\n### Download from Modelers Hub\n\nYou can also use Modelers Hub to download models and datasets.\n\n```bash\nexport USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the Modelers Hub as the `model_name_or_path`. You can find a full list of model IDs at [Modelers Hub](https://modelers.cn/models), e.g., `TeleAI/TeleChat-7B-pt`.\n\n### Use W&B Logger\n\nTo use [Weights & Biases](https://wandb.ai) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nreport_to: wandb\nrun_name: test_run # optional\n```\n\nSet `WANDB_API_KEY` to [your key](https://wandb.ai/authorize) when launching training tasks to log in with your W&B account.\n\n### Use SwanLab Logger\n\nTo use [SwanLab](https://github.com/SwanHubX/SwanLab) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nuse_swanlab: true\nswanlab_run_name: test_run # optional\n```\n\nWhen launching training tasks, you can log in to SwanLab in three ways:\n\n1. Add `swanlab_api_key=<your_api_key>` to the yaml file, and set it to your [API key](https://swanlab.cn/settings).\n2. Set the environment variable `SWANLAB_API_KEY` to your [API key](https://swanlab.cn/settings).\n3. Use the `swanlab login` command to complete the login.\n\n## Projects using LLaMA Factory\n\nIf you have a project that should be incorporated, please contact via email or create a pull request.\n\n<details><summary>Click to show</summary>\n\n1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)\n1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)\n1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)\n1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)\n1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)\n1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)\n1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)\n1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)\n1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)\n1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)\n1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)\n1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)\n1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)\n1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)\n1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)\n1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)\n1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)\n1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)\n1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)\n1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)\n1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)\n1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)\n1. Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)\n1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)\n1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)\n1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)\n1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)\n1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)\n1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)\n1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)\n1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)\n1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)\n1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)\n1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)\n1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)\n1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)\n1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)\n1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)\n1. Dammu et al. \"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)\n1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)\n1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)\n1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)\n1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)\n1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)\n1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)\n1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)\n1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)\n1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)\n1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)\n1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)\n1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)\n1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)\n1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)\n1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)\n1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)\n1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)\n1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)\n1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)\n1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)\n1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)\n1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)\n1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)\n1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)\n1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)\n1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)\n1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)\n1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)\n1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)\n1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)\n1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)\n1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)\n1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)\n1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)\n1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)\n1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)\n1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)\n1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)\n1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)\n1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)\n1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)\n1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)\n1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)\n1. Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. [[paper]](https://aclanthology.org/2024.findings-acl.830.pdf)\n1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.\n1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.\n1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.\n1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.\n1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.\n1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**: A large language model specialized in generate metadata for stable diffusion. [[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)\n1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.\n1. **[AutoRE](https://github.com/THUDM/AutoRE)**: A document-level relation extraction system based on large language models.\n1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.\n1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.\n1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [[blog]](https://zhuanlan.zhihu.com/p/987727357)\n1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**: A modified library that supports long sequence SFT & DPO using ring attention.\n1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**: An o1-like model fine-tuned by NovaSky AI with very small cost.\n1. **[WeClone](https://github.com/xming521/WeClone)**: One-stop solution for creating your digital avatar from chat logs.\n1. **[EmoLLM](https://github.com/SmartFlowAI/EmoLLM)**: A project about large language models (LLMs) and mental health.\n</details>\n\n## License\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n\nPlease follow the model licenses to use the corresponding model weights: [Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)\n\n## Citation\n\nIf this work is helpful, please kindly cite as:\n\n```bibtex\n@inproceedings{zheng2024llamafactory,\n  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},\n  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},\n  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},\n  address={Bangkok, Thailand},\n  publisher={Association for Computational Linguistics},\n  year={2024},\n  url={http://arxiv.org/abs/2403.13372}\n}\n```\n\n## Acknowledgement\n\nThis repo benefits from [PEFT](https://github.com/huggingface/peft), [TRL](https://github.com/huggingface/trl), [QLoRA](https://github.com/artidoro/qlora) and [FastChat](https://github.com/lm-sys/FastChat). Thanks for their wonderful works.\n\n## Star History\n\n![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/hiyouga/LLaMA-Factory",
          "homepage": "https://llamafactory.readthedocs.io",
          "language": "Python",
          "forks": 7601,
          "open_issues": 783,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/16256802?v=4",
      "velocity": 69082.2,
      "is_rising_star": true,
      "heatScore": 20728.018586272854,
      "popularityScore": 62802
    },
    {
      "id": "github-FoundationAgents-MetaGPT",
      "name": "MetaGPT",
      "author": "FoundationAgents",
      "description": "üåü The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
      "task": "tool",
      "tags": [
        "agent",
        "gpt",
        "llm",
        "metagpt",
        "multi-agent"
      ],
      "likes": 119174,
      "downloads": 119174,
      "lastModified": "2025-11-20T13:55:30Z",
      "lastModifiedTimestamp": 1763646930000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FoundationAgents/MetaGPT",
          "homepage": "https://mgx.dev/",
          "language": "Python",
          "forks": 7283,
          "open_issues": 57,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/198047230?v=4",
      "velocity": 65545.7,
      "is_rising_star": true,
      "heatScore": 19667.052611166364,
      "popularityScore": 59587
    },
    {
      "id": "github-unclecode-crawl4ai",
      "name": "crawl4ai",
      "author": "unclecode",
      "description": "üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN",
      "task": "tool",
      "tags": [],
      "likes": 112306,
      "downloads": 112306,
      "lastModified": "2025-11-20T15:20:08Z",
      "lastModifiedTimestamp": 1763652008000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unclecode/crawl4ai",
          "homepage": "https://crawl4ai.com",
          "language": "Python",
          "forks": 5636,
          "open_issues": 263,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/12494079?v=4",
      "velocity": 61768.3,
      "is_rising_star": true,
      "heatScore": 18533.814566488363,
      "popularityScore": 56153
    },
    {
      "id": "github-OpenBB-finance-OpenBB",
      "name": "OpenBB",
      "author": "OpenBB-finance",
      "description": "Financial data platform for analysts, quants and AI agents.",
      "task": "tool",
      "tags": [
        "ai",
        "crypto",
        "derivatives",
        "economics",
        "equity",
        "finance",
        "fixed-income",
        "machine-learning",
        "openbb",
        "options",
        "python",
        "quantitative-finance",
        "stocks"
      ],
      "likes": 109330,
      "downloads": 109330,
      "lastModified": "2025-11-20T13:41:09Z",
      "lastModifiedTimestamp": 1763646069000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBB-finance/OpenBB",
          "homepage": "https://openbb.co",
          "language": "Python",
          "forks": 5288,
          "open_issues": 52,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/80064875?v=4",
      "velocity": 60131.5,
      "is_rising_star": true,
      "heatScore": 18042.766402107914,
      "popularityScore": 54665
    },
    {
      "id": "github-wshobson-agents",
      "name": "agents",
      "author": "wshobson",
      "description": "Intelligent automation and multi-agent orchestration for Claude Code",
      "task": "tool",
      "tags": [
        "agents",
        "ai-agents",
        "anthropic",
        "anthropic-claude",
        "automation",
        "claude",
        "claude-code",
        "claude-code-cli",
        "claude-code-commands",
        "claude-code-plugin",
        "claude-code-plugins",
        "claude-code-subagents",
        "claude-skills",
        "claudecode",
        "claudecode-config",
        "claudecode-subagents",
        "orchestration",
        "sub-agents",
        "subagents",
        "workflows",
        "agent-computer-interface",
        "computer-automation",
        "computer-use",
        "computer-use-agent",
        "cua",
        "grounding",
        "gui-agents",
        "in-context-reinforcement-learning",
        "memory",
        "mllm",
        "planning",
        "retrieval-augmented-generation",
        "ai",
        "openai",
        "real-time",
        "video",
        "voice",
        "autonomous-agents",
        "language-model",
        "llm",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 106916,
      "downloads": 106916,
      "lastModified": "2025-11-20T15:44:42Z",
      "lastModifiedTimestamp": 1763653482000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/wshobson/agents",
          "homepage": "https://sethhobson.com",
          "language": "Python",
          "forks": 2352,
          "open_issues": 4,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/contains-studio/agents",
          "homepage": null,
          "language": null,
          "forks": 2129,
          "open_issues": 9,
          "license": "No license"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/simular-ai/Agent-S",
          "homepage": "https://www.simular.ai",
          "language": "Python",
          "forks": 907,
          "open_issues": 13,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/livekit/agents",
          "homepage": "https://docs.livekit.io/agents",
          "language": "Python",
          "forks": 1776,
          "open_issues": 448,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/aiwaves-cn/agents",
          "homepage": "",
          "language": "Python",
          "forks": 452,
          "open_issues": 39,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
      "velocity": 58803.8,
      "is_rising_star": true,
      "heatScore": 17644.44961458143,
      "popularityScore": 53458
    },
    {
      "id": "github-cline-cline",
      "name": "cline",
      "author": "cline",
      "description": "Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 105064,
      "downloads": 105064,
      "lastModified": "2025-11-20T15:39:22Z",
      "lastModifiedTimestamp": 1763653162000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/cline/cline",
          "homepage": "https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev",
          "language": "TypeScript",
          "forks": 5246,
          "open_issues": 895,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/184127137?v=4",
      "velocity": 57785.2,
      "is_rising_star": true,
      "heatScore": 17338.864302541922,
      "popularityScore": 52532
    },
    {
      "id": "github-microsoft-autogen",
      "name": "autogen",
      "author": "microsoft",
      "description": "A programming framework for agentic AI",
      "task": "tool",
      "tags": [
        "agentic",
        "agentic-agi",
        "agents",
        "ai",
        "autogen",
        "autogen-ecosystem",
        "chatgpt",
        "framework",
        "llm-agent",
        "llm-framework"
      ],
      "likes": 103658,
      "downloads": 103658,
      "lastModified": "2025-11-20T14:57:51Z",
      "lastModifiedTimestamp": 1763650671000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/autogen",
          "homepage": "https://microsoft.github.io/autogen/",
          "language": "Python",
          "forks": 7872,
          "open_issues": 511,
          "license": "Creative Commons Attribution 4.0 International"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 57011.9,
      "is_rising_star": true,
      "heatScore": 17106.870206846186,
      "popularityScore": 51829
    },
    {
      "id": "github-Mintplex-Labs-anything-llm",
      "name": "anything-llm",
      "author": "Mintplex-Labs",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 102482,
      "downloads": 102482,
      "lastModified": "2025-11-20T15:24:23Z",
      "lastModifiedTimestamp": 1763652263000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Mintplex-Labs/anything-llm",
          "homepage": "https://anythingllm.com",
          "language": "JavaScript",
          "forks": 5428,
          "open_issues": 331,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134426827?v=4",
      "velocity": 56365.1,
      "is_rising_star": true,
      "heatScore": 16912.82673825049,
      "popularityScore": 51241
    },
    {
      "id": "github-openai-codex",
      "name": "codex",
      "author": "openai",
      "description": "Lightweight coding agent that runs in your terminal",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 101932,
      "downloads": 101932,
      "lastModified": "2025-11-20T15:27:31Z",
      "lastModifiedTimestamp": 1763652451000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/openai/codex",
          "homepage": "",
          "language": "Rust",
          "forks": 6392,
          "open_issues": 1067,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/14957082?v=4",
      "velocity": 56062.6,
      "is_rising_star": true,
      "heatScore": 16822.075102349743,
      "popularityScore": 50966
    },
    {
      "id": "github-pathwaycom-pathway",
      "name": "pathway",
      "author": "pathwaycom",
      "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
      "task": "tool",
      "tags": [
        "batch-processing",
        "data-analytics",
        "data-pipelines",
        "data-processing",
        "dataflow",
        "etl",
        "etl-framework",
        "iot-analytics",
        "kafka",
        "machine-learning-algorithms",
        "pathway",
        "python",
        "real-time",
        "rust",
        "stream-processing",
        "streaming",
        "time-series-analysis",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 100330,
      "downloads": 100330,
      "lastModified": "2025-11-20T15:47:22Z",
      "lastModifiedTimestamp": 1763653642000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/pathway",
          "homepage": "https://pathway.com",
          "language": "Python",
          "forks": 1454,
          "open_issues": 39,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 55181.5,
      "is_rising_star": true,
      "heatScore": 16557.740286631673,
      "popularityScore": 50165
    },
    {
      "id": "github-opendatalab-MinerU",
      "name": "MinerU",
      "author": "opendatalab",
      "description": "Transforms complex documents like PDFs into LLM-ready markdown/JSON for your Agentic workflows.",
      "task": "tool",
      "tags": [
        "ai4science",
        "document-analysis",
        "extract-data",
        "layout-analysis",
        "ocr",
        "parser",
        "pdf",
        "pdf-converter",
        "pdf-extractor-llm",
        "pdf-extractor-pretrain",
        "pdf-extractor-rag",
        "pdf-parser",
        "python"
      ],
      "likes": 98356,
      "downloads": 98356,
      "lastModified": "2025-11-20T15:21:22Z",
      "lastModifiedTimestamp": 1763652082000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/opendatalab/MinerU",
          "homepage": "https://opendatalab.github.io/MinerU/",
          "language": "Python",
          "forks": 4080,
          "open_issues": 128,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/97503431?v=4",
      "velocity": 54095.8,
      "is_rising_star": true,
      "heatScore": 16232.02424578552,
      "popularityScore": 49178
    },
    {
      "id": "github-unslothai-unsloth",
      "name": "unsloth",
      "author": "unslothai",
      "description": "Fine-tuning & Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.",
      "task": "tool",
      "tags": [
        "agent",
        "deepseek",
        "deepseek-r1",
        "fine-tuning",
        "gemma",
        "gemma3",
        "gpt-oss",
        "llama",
        "llama3",
        "llm",
        "llms",
        "mistral",
        "openai",
        "qwen",
        "qwen3",
        "reinforcement-learning",
        "text-to-speech",
        "tts",
        "unsloth",
        "voice-cloning"
      ],
      "likes": 96990,
      "downloads": 96990,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unslothai/unsloth",
          "homepage": "https://docs.unsloth.ai/",
          "language": "Python",
          "forks": 3989,
          "open_issues": 856,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/150920049?v=4",
      "velocity": 53344.5,
      "is_rising_star": true,
      "heatScore": 16006.629994143315,
      "popularityScore": 48495
    },
    {
      "id": "github-huginn-huginn",
      "name": "huginn",
      "author": "huginn",
      "description": "Create agents that monitor and act on your behalf.  Your agents are standing by!",
      "task": "tool",
      "tags": [
        "agent",
        "automation",
        "feed",
        "feedgenerator",
        "huginn",
        "monitoring",
        "notifications",
        "rss",
        "scraper",
        "twitter",
        "twitter-streaming",
        "webscraping"
      ],
      "likes": 96214,
      "downloads": 96214,
      "lastModified": "2025-11-20T14:23:03Z",
      "lastModifiedTimestamp": 1763648583000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huginn/huginn",
          "homepage": "",
          "language": "Ruby",
          "forks": 4197,
          "open_issues": 691,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23225142?v=4",
      "velocity": 52917.7,
      "is_rising_star": true,
      "heatScore": 15878.587552111607,
      "popularityScore": 48107
    },
    {
      "id": "github-harry0703-MoneyPrinterTurbo",
      "name": "MoneyPrinterTurbo",
      "author": "harry0703",
      "description": "Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.",
      "task": "tool",
      "tags": [
        "ai",
        "automation",
        "chatgpt",
        "moviepy",
        "python",
        "shortvideo",
        "tiktok"
      ],
      "likes": 95706,
      "downloads": 95706,
      "lastModified": "2025-11-20T15:49:59Z",
      "lastModifiedTimestamp": 1763653799000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/harry0703/MoneyPrinterTurbo",
          "homepage": "",
          "language": "Python",
          "forks": 6701,
          "open_issues": 218,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4928832?v=4",
      "velocity": 52638.3,
      "is_rising_star": true,
      "heatScore": 15794.765942771677,
      "popularityScore": 47853
    },
    {
      "id": "github-pathwaycom-llm-app",
      "name": "llm-app",
      "author": "pathwaycom",
      "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
      "task": "tool",
      "tags": [
        "chatbot",
        "hugging-face",
        "llm",
        "llm-local",
        "llm-prompting",
        "llm-security",
        "llmops",
        "machine-learning",
        "open-ai",
        "pathway",
        "rag",
        "real-time",
        "retrieval-augmented-generation",
        "vector-database",
        "vector-index",
        "general-dialogue-qa",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 94666,
      "downloads": 94666,
      "lastModified": "2025-11-20T15:46:47Z",
      "lastModifiedTimestamp": 1763653607000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/llm-app",
          "homepage": "https://pathway.com/developers/templates/",
          "language": "Jupyter Notebook",
          "forks": 1214,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 52066.3,
      "is_rising_star": true,
      "heatScore": 15623.16262124451,
      "popularityScore": 47333
    },
    {
      "id": "github-FlowiseAI-Flowise",
      "name": "Flowise",
      "author": "FlowiseAI",
      "description": "Build AI Agents, Visually",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-workflow",
        "agents",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "javascript",
        "langchain",
        "large-language-models",
        "low-code",
        "multiagent-systems",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript",
        "workflow-automation",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 93412,
      "downloads": 93412,
      "lastModified": "2025-11-20T15:27:35Z",
      "lastModifiedTimestamp": 1763652455000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FlowiseAI/Flowise",
          "homepage": "https://flowiseai.com",
          "language": "TypeScript",
          "forks": 23141,
          "open_issues": 728,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128289781?v=4",
      "velocity": 51376.6,
      "is_rising_star": true,
      "heatScore": 15416.248567381353,
      "popularityScore": 46706
    },
    {
      "id": "github-run-llama-llama_index",
      "name": "llama_index",
      "author": "run-llama",
      "description": "LlamaIndex is the leading framework for building LLM-powered agents over your data.",
      "task": "tool",
      "tags": [
        "agents",
        "application",
        "data",
        "fine-tuning",
        "framework",
        "llamaindex",
        "llm",
        "multi-agents",
        "rag",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 90664,
      "downloads": 90664,
      "lastModified": "2025-11-20T15:48:18Z",
      "lastModifiedTimestamp": 1763653698000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/run-llama/llama_index",
          "homepage": "https://developers.llamaindex.ai",
          "language": "Python",
          "forks": 6534,
          "open_issues": 268,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/130722866?v=4",
      "velocity": 49865.2,
      "is_rising_star": true,
      "heatScore": 14962.819490122205,
      "popularityScore": 45332
    },
    {
      "id": "github-microsoft-ai-agents-for-beginners",
      "name": "ai-agents-for-beginners",
      "author": "microsoft",
      "description": "12 Lessons to Get Started Building AI Agents",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-framework",
        "agentic-rag",
        "ai-agents",
        "ai-agents-framework",
        "autogen",
        "generative-ai",
        "semantic-kernel"
      ],
      "likes": 90478,
      "downloads": 90478,
      "lastModified": "2025-11-20T15:42:34Z",
      "lastModifiedTimestamp": 1763653354000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/ai-agents-for-beginners",
          "homepage": "https://aka.ms/ai-agents-beginners",
          "language": "Jupyter Notebook",
          "forks": 15356,
          "open_issues": 11,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 49762.9,
      "is_rising_star": true,
      "heatScore": 14932.128865817376,
      "popularityScore": 45239
    },
    {
      "id": "github-jeecgboot-JeecgBoot",
      "name": "JeecgBoot",
      "author": "jeecgboot",
      "description": "üî•AI‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÔºåÂä©Âäõ‰ºÅ‰∏öÂø´ÈÄüÂÆûÁé∞‰Ωé‰ª£Á†ÅÂºÄÂèëÂíåÊûÑÂª∫AIÂ∫îÁî®ÔºÅ ÈõÜÊàê‰∏ÄÂ•óÂÆåÊï¥AIÂ∫îÁî®Âπ≥Âè∞ÔºöÊ∂µÁõñAIÂ∫îÁî®„ÄÅAIÊ®°Âûã„ÄÅAIËÅäÂ§©Âä©Êâã„ÄÅÁü•ËØÜÂ∫ì„ÄÅAIÊµÅÁ®ãÁºñÊéíÁ≠âÔºåÂÖºÂÆπÂ§öÁßçÂ§ßÊ®°ÂûãÔºõÊèê‰æõÂº∫Â§ß‰ª£Á†ÅÁîüÊàêÂô®ÔºöÂÆûÁé∞ÂâçÂêéÁ´Ø‰∏ÄÈîÆÁîüÊàêÔºåÊó†ÈúÄÊâãÂÜô‰ª£Á†Å! ÂºïÈ¢ÜAIÂºÄÂèëÊ®°ÂºèÔºöAIÁîüÊàê‚ÜíÂú®Á∫øÈÖçÁΩÆ‚Üí‰ª£Á†ÅÁîüÊàê‚ÜíÊâãÂ∑•ÂêàÂπ∂ÔºåËß£ÂÜ≥JavaÈ°πÁõÆ80%ÈáçÂ§çÂ∑•‰ΩúÔºåÊèêÂçáÊïàÁéáËäÇÁúÅÊàêÊú¨ÔºåÂèà‰∏çÂ§±ÁÅµÊ¥ª~",
      "task": "tool",
      "tags": [
        "activiti",
        "agent",
        "ai",
        "aiflow",
        "ant-design-vue",
        "antd",
        "codegenerator",
        "deepseek",
        "flowable",
        "langchain4j",
        "llm",
        "low-code",
        "mcp",
        "mybatis-plus",
        "rag",
        "spring-ai",
        "springboot",
        "springboot3",
        "springcloud",
        "vue3",
        "rag-knowledge-base-qa"
      ],
      "likes": 88836,
      "downloads": 88836,
      "lastModified": "2025-11-20T14:22:51Z",
      "lastModifiedTimestamp": 1763648571000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/jeecgboot/JeecgBoot",
          "homepage": "https://jeecgboot.github.io/JeecgBoot/",
          "language": "Java",
          "forks": 15659,
          "open_issues": 54,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/86360035?v=4",
      "velocity": 48859.8,
      "is_rising_star": true,
      "heatScore": 14661.19329814397,
      "popularityScore": 44418
    },
    {
      "id": "github-mem0ai-mem0",
      "name": "mem0",
      "author": "mem0ai",
      "description": "Universal memory layer for AI Agents",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "application",
        "chatbots",
        "chatgpt",
        "genai",
        "hacktoberfest",
        "llm",
        "long-term-memory",
        "memory",
        "memory-management",
        "python",
        "rag",
        "state-management",
        "rag-knowledge-base-qa"
      ],
      "likes": 86706,
      "downloads": 86706,
      "lastModified": "2025-11-20T14:45:27Z",
      "lastModifiedTimestamp": 1763649927000,
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"docs/images/banner-sm.png\" width=\"800px\" alt=\"Mem0 - The Memory Layer for Personalized AI\">\n  </a>\n</p>\n<p align=\"center\" style=\"display: flex; justify-content: center; gap: 20px; align-items: center;\">\n  <a href=\"https://trendshift.io/repositories/11194\" target=\"blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/11194\" alt=\"mem0ai%2Fmem0 | Trendshift\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai\">Learn more</a>\n  ¬∑\n  <a href=\"https://mem0.dev/DiG\">Join Discord</a>\n  ¬∑\n  <a href=\"https://mem0.dev/demo\">Demo</a>\n  ¬∑\n  <a href=\"https://mem0.dev/openmemory\">OpenMemory</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.dev/DiG\">\n    <img src=\"https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white\" alt=\"Mem0 Discord\">\n  </a>\n  <a href=\"https://pepy.tech/project/mem0ai\">\n    <img src=\"https://img.shields.io/pypi/dm/mem0ai\" alt=\"Mem0 PyPI - Downloads\">\n  </a>\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square\" alt=\"GitHub commit activity\">\n  </a>\n  <a href=\"https://pypi.org/project/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/pypi/v/mem0ai?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/npm/v/mem0ai\" alt=\"Npm package\">\n  </a>\n  <a href=\"https://www.ycombinator.com/companies/mem0\">\n    <img src=\"https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square\" alt=\"Y Combinator S24\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai/research\"><strong>üìÑ Building Production-Ready AI Agents with Scalable Long-Term Memory ‚Üí</strong></a>\n</p>\n<p align=\"center\">\n  <strong>‚ö° +26% Accuracy vs. OpenAI Memory ‚Ä¢ üöÄ 91% Faster ‚Ä¢ üí∞ 90% Fewer Tokens</strong>\n</p>\n\n> **üéâ mem0ai v1.0.0 is now available!** This major release includes API modernization, improved vector store support, and enhanced GCP integration. [See migration guide ‚Üí](MIGRATION_GUIDE_v1.0.md)\n\n##  üî• Research Highlights\n- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark\n- **91% Faster Responses** than full-context, ensuring low-latency at scale\n- **90% Lower Token Usage** than full-context, cutting costs without compromise\n- [Read the full paper](https://mem0.ai/research)\n\n# Introduction\n\n[Mem0](https://mem0.ai) (\"mem-zero\") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time‚Äîideal for customer support chatbots, AI assistants, and autonomous systems.\n\n### Key Features & Use Cases\n\n**Core Capabilities:**\n- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization\n- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option\n\n**Applications:**\n- **AI Assistants**: Consistent, context-rich conversations\n- **Customer Support**: Recall past tickets and user history for tailored help\n- **Healthcare**: Track patient preferences and history for personalized care\n- **Productivity & Gaming**: Adaptive workflows and environments based on user behavior\n\n## üöÄ Quickstart Guide <a name=\"quickstart\"></a>\n\nChoose between our hosted platform or self-hosted package:\n\n### Hosted Platform\n\nGet up and running in minutes with automatic updates, analytics, and enterprise security.\n\n1. Sign up on [Mem0 Platform](https://app.mem0.ai)\n2. Embed the memory layer via SDK or API keys\n\n### Self-Hosted (Open Source)\n\nInstall the sdk via pip:\n\n```bash\npip install mem0ai\n```\n\nInstall sdk via npm:\n```bash\nnpm install mem0ai\n```\n\n### Basic Usage\n\nMem0 requires an LLM to function, with `gpt-4.1-nano-2025-04-14 from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).\n\nFirst step is to instantiate the memory:\n\n```python\nfrom openai import OpenAI\nfrom mem0 import Memory\n\nopenai_client = OpenAI()\nmemory = Memory()\n\ndef chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n    # Retrieve relevant memories\n    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n\n    # Generate Assistant response\n    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n    response = openai_client.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n    assistant_response = response.choices[0].message.content\n\n    # Create new memories from the conversation\n    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n    memory.add(messages, user_id=user_id)\n\n    return assistant_response\n\ndef main():\n    print(\"Chat with AI (type 'exit' to quit)\")\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'exit':\n            print(\"Goodbye!\")\n            break\n        print(f\"AI: {chat_with_memories(user_input)}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFor detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).\n\n## üîó Integrations & Demos\n\n- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))\n- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))\n- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))\n- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))\n\n## üìö Documentation & Support\n\n- Full docs: https://docs.mem0.ai\n- Community: [Discord](https://mem0.dev/DiG) ¬∑ [Twitter](https://x.com/mem0ai)\n- Contact: founders@mem0.ai\n\n## Citation\n\nWe now have a paper you can cite:\n\n```bibtex\n@article{mem0,\n  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},\n  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},\n  journal={arXiv preprint arXiv:2504.19413},\n  year={2025}\n}\n```\n\n## ‚öñÔ∏è License\n\nApache 2.0 ‚Äî see the [LICENSE](https://github.com/mem0ai/mem0/blob/main/LICENSE) file for details.",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mem0ai/mem0",
          "homepage": "https://mem0.ai",
          "language": "Python",
          "forks": 4697,
          "open_issues": 520,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/137054526?v=4",
      "velocity": 47688.3,
      "is_rising_star": true,
      "heatScore": 14309.73592042129,
      "popularityScore": 43353
    },
    {
      "id": "github-anthropics-claude-code",
      "name": "claude-code",
      "author": "anthropics",
      "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 85919,
      "downloads": 85919,
      "lastModified": "2025-11-20T15:52:02Z",
      "lastModifiedTimestamp": 1763653922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/anthropics/claude-code",
          "homepage": "https://code.claude.com/docs/en/overview",
          "language": "Shell",
          "forks": 2910,
          "open_issues": 5342,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/76263028?v=4",
      "velocity": 47254.9,
      "is_rising_star": true,
      "heatScore": 14179.713144990883,
      "popularityScore": 42959
    },
    {
      "id": "github-sst-opencode",
      "name": "opencode",
      "author": "sst",
      "description": "The AI coding agent built for the terminal.",
      "task": "tool",
      "tags": [
        "ai",
        "claude",
        "code",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 85846,
      "downloads": 85846,
      "lastModified": "2025-11-20T15:54:52Z",
      "lastModifiedTimestamp": 1763654092000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sst/opencode",
          "homepage": "https://opencode.ai",
          "language": "TypeScript",
          "forks": 2685,
          "open_issues": 1494,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/opencode-ai/opencode",
          "homepage": "",
          "language": "Go",
          "forks": 807,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/66570915?v=4",
      "velocity": 47215.3,
      "is_rising_star": true,
      "heatScore": 14167.832890130338,
      "popularityScore": 42923
    },
    {
      "id": "github-crewAIInc-crewAI",
      "name": "crewAI",
      "author": "crewAIInc",
      "description": "Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "aiagentframework",
        "llms"
      ],
      "likes": 81234,
      "downloads": 81234,
      "lastModified": "2025-11-20T14:32:49Z",
      "lastModifiedTimestamp": 1763649169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/crewAIInc/crewAI",
          "homepage": "https://crewai.com",
          "language": "Python",
          "forks": 5422,
          "open_issues": 197,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/170677839?v=4",
      "velocity": 44678.7,
      "is_rising_star": true,
      "heatScore": 13406.83610297468,
      "popularityScore": 40617
    },
    {
      "id": "github-ray-project-ray",
      "name": "ray",
      "author": "ray-project",
      "description": "Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.",
      "task": "tool",
      "tags": [
        "data-science",
        "deep-learning",
        "deployment",
        "distributed",
        "hyperparameter-optimization",
        "hyperparameter-search",
        "large-language-models",
        "llm",
        "llm-inference",
        "llm-serving",
        "machine-learning",
        "optimization",
        "parallel",
        "python",
        "pytorch",
        "ray",
        "reinforcement-learning",
        "rllib",
        "serving",
        "tensorflow"
      ],
      "likes": 79862,
      "downloads": 79862,
      "lastModified": "2025-11-20T15:50:42Z",
      "lastModifiedTimestamp": 1763653842000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ray-project/ray",
          "homepage": "https://ray.io",
          "language": "Python",
          "forks": 6924,
          "open_issues": 3226,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/22125274?v=4",
      "velocity": 43923,
      "is_rising_star": true,
      "heatScore": 13180.120917130518,
      "popularityScore": 39930
    },
    {
      "id": "github-zhayujie-chatgpt-on-wechat",
      "name": "chatgpt-on-wechat",
      "author": "zhayujie",
      "description": "Âü∫‰∫éÂ§ßÊ®°ÂûãÊê≠Âª∫ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂêåÊó∂ÊîØÊåÅ ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ Á≠âÊé•ÂÖ•ÔºåÂèØÈÄâÊã©ChatGPT/Claude/DeepSeek/ÊñáÂøÉ‰∏ÄË®Ä/ËÆØÈ£ûÊòüÁÅ´/ÈÄö‰πâÂçÉÈóÆ/ Gemini/GLM-4/Kimi/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥ÂíåÂõæÁâáÔºåËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíå‰∫íËÅîÁΩëÔºåÊîØÊåÅÂü∫‰∫éËá™ÊúâÁü•ËØÜÂ∫ìËøõË°åÂÆöÂà∂‰ºÅ‰∏öÊô∫ËÉΩÂÆ¢Êúç„ÄÇ",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agent",
        "chatgpt",
        "claude-4",
        "deepseek",
        "dingtalk",
        "feishu-bot",
        "gemini",
        "gpt-4",
        "kimi",
        "linkai",
        "llm",
        "mcp",
        "multi-agent",
        "openai",
        "python3",
        "qwen",
        "rag",
        "wechat",
        "wechat-bot",
        "rag-knowledge-base-qa",
        "general-dialogue-qa"
      ],
      "likes": 79540,
      "downloads": 79540,
      "lastModified": "2025-11-20T15:05:28Z",
      "lastModifiedTimestamp": 1763651128000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/zhayujie/chatgpt-on-wechat",
          "homepage": "https://link-ai.tech",
          "language": "Python",
          "forks": 9502,
          "open_issues": 355,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/26161723?v=4",
      "velocity": 43747,
      "is_rising_star": true,
      "heatScore": 13127.3196965577,
      "popularityScore": 39770
    },
    {
      "id": "github-milvus-io-milvus",
      "name": "milvus",
      "author": "milvus-io",
      "description": "Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search",
      "task": "tool",
      "tags": [
        "anns",
        "cloud-native",
        "diskann",
        "distributed",
        "embedding-database",
        "embedding-similarity",
        "embedding-store",
        "faiss",
        "golang",
        "hnsw",
        "image-search",
        "llm",
        "nearest-neighbor-search",
        "rag",
        "vector-database",
        "vector-search",
        "vector-similarity",
        "vector-store",
        "rag-knowledge-base-qa"
      ],
      "likes": 79350,
      "downloads": 79350,
      "lastModified": "2025-11-20T15:45:07Z",
      "lastModifiedTimestamp": 1763653507000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/milvus-io/milvus",
          "homepage": "https://milvus.io",
          "language": "Go",
          "forks": 3586,
          "open_issues": 905,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/51735404?v=4",
      "velocity": 43642.5,
      "is_rising_star": true,
      "heatScore": 13095.968969517113,
      "popularityScore": 39675
    },
    {
      "id": "github-janhq-jan",
      "name": "jan",
      "author": "janhq",
      "description": "Jan is an open source alternative to ChatGPT that runs 100% offline on your computer.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "gpt",
        "llamacpp",
        "llm",
        "localai",
        "open-source",
        "self-hosted",
        "tauri",
        "general-dialogue-qa"
      ],
      "likes": 78750,
      "downloads": 78750,
      "lastModified": "2025-11-20T13:35:09Z",
      "lastModifiedTimestamp": 1763645709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/janhq/jan",
          "homepage": "https://jan.ai/",
          "language": "TypeScript",
          "forks": 2401,
          "open_issues": 191,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102363196?v=4",
      "velocity": 43312.5,
      "is_rising_star": true,
      "heatScore": 12996.966662117451,
      "popularityScore": 39375
    },
    {
      "id": "github-mudler-LocalAI",
      "name": "LocalAI",
      "author": "mudler",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "likes": 77768,
      "downloads": 77768,
      "lastModified": "2025-11-20T15:54:00Z",
      "lastModifiedTimestamp": 1763654040000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mudler/LocalAI",
          "homepage": "https://localai.io",
          "language": "Go",
          "forks": 3085,
          "open_issues": 244,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/2420543?v=4",
      "velocity": 42771.3,
      "is_rising_star": true,
      "heatScore": 12834.602839654122,
      "popularityScore": 38883
    },
    {
      "id": "github-QuivrHQ-quivr",
      "name": "quivr",
      "author": "QuivrHQ",
      "description": "Opiniated RAG for integrating GenAI in your apps üß†   Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want. ",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "chatbot",
        "chatgpt",
        "database",
        "docker",
        "framework",
        "frontend",
        "groq",
        "html",
        "javascript",
        "llm",
        "openai",
        "postgresql",
        "privacy",
        "rag",
        "react",
        "security",
        "typescript",
        "vector",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 77264,
      "downloads": 77264,
      "lastModified": "2025-11-20T12:53:10Z",
      "lastModifiedTimestamp": 1763643190000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/QuivrHQ/quivr",
          "homepage": "https://core.quivr.com",
          "language": "Python",
          "forks": 3689,
          "open_issues": 16,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/159330290?v=4",
      "velocity": 42495.2,
      "is_rising_star": true,
      "heatScore": 12751.770870903854,
      "popularityScore": 38632
    },
    {
      "id": "github-2noise-ChatTTS",
      "name": "ChatTTS",
      "author": "2noise",
      "description": "A generative speech model for daily dialogue.",
      "task": "tool",
      "tags": [
        "agent",
        "chat",
        "chatgpt",
        "chattts",
        "chinese",
        "chinese-language",
        "english",
        "english-language",
        "gpt",
        "llm",
        "llm-agent",
        "natural-language-inference",
        "python",
        "text-to-speech",
        "torch",
        "torchaudio",
        "tts",
        "general-dialogue-qa"
      ],
      "likes": 76366,
      "downloads": 76366,
      "lastModified": "2025-11-20T14:57:26Z",
      "lastModifiedTimestamp": 1763650646000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/2noise/ChatTTS",
          "homepage": "https://2noise.com",
          "language": "Python",
          "forks": 4148,
          "open_issues": 67,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/164844019?v=4",
      "velocity": 42001.3,
      "is_rising_star": true,
      "heatScore": 12603.597316994952,
      "popularityScore": 38183
    },
    {
      "id": "github-upstash-context7",
      "name": "context7",
      "author": "upstash",
      "description": "Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors",
      "task": "tool",
      "tags": [
        "llm",
        "mcp",
        "mcp-server",
        "vibe-coding",
        "code-generation-assistance"
      ],
      "likes": 75160,
      "downloads": 75160,
      "lastModified": "2025-11-20T15:36:23Z",
      "lastModifiedTimestamp": 1763652983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/upstash/context7",
          "homepage": "https://context7.com",
          "language": "JavaScript",
          "forks": 1863,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/74989412?v=4",
      "velocity": 41338,
      "is_rising_star": true,
      "heatScore": 12404.602477832499,
      "popularityScore": 37580
    },
    {
      "id": "github-chatboxai-chatbox",
      "name": "chatbox",
      "author": "chatboxai",
      "description": "User-friendly Desktop Client App for AI Models/LLMs (GPT, Claude, Gemini, Ollama...)",
      "task": "tool",
      "tags": [
        "assistant",
        "chatbot",
        "chatgpt",
        "claude",
        "copilot",
        "deepseek",
        "gemini",
        "gpt",
        "gpt-5",
        "ollama",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 74948,
      "downloads": 74948,
      "lastModified": "2025-11-20T14:27:41Z",
      "lastModifiedTimestamp": 1763648861000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatboxai/chatbox",
          "homepage": "https://chatboxai.app?utm_medium=github",
          "language": "TypeScript",
          "forks": 3786,
          "open_issues": 969,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/199570308?v=4",
      "velocity": 41221.4,
      "is_rising_star": true,
      "heatScore": 12369.621619149064,
      "popularityScore": 37474
    },
    {
      "id": "github-ToolJet-ToolJet",
      "name": "ToolJet",
      "author": "ToolJet",
      "description": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building internal tools, dashboard, business applications, workflows and AI agents üöÄ",
      "task": "tool",
      "tags": [
        "ai-app-builder",
        "docker",
        "hacktoberfest",
        "internal-applications",
        "internal-project",
        "internal-tool",
        "internal-tools",
        "javascript",
        "kubernetes",
        "low-code",
        "low-code-development-platform",
        "low-code-framework",
        "no-code",
        "nodejs",
        "reactjs",
        "self-hosted",
        "typescript",
        "web-development-tools",
        "workflow-automation"
      ],
      "likes": 73858,
      "downloads": 73858,
      "lastModified": "2025-11-20T10:01:22Z",
      "lastModifiedTimestamp": 1763632882000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ToolJet/ToolJet",
          "homepage": "https://tooljet.ai",
          "language": "JavaScript",
          "forks": 4877,
          "open_issues": 951,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/82193554?v=4",
      "velocity": 40621.9,
      "is_rising_star": true,
      "heatScore": 12189.767165515355,
      "popularityScore": 36929
    },
    {
      "id": "github-alibaba-arthas",
      "name": "arthas",
      "author": "alibaba",
      "description": "Alibaba Java Diagnostic Tool Arthas/Alibaba JavaËØäÊñ≠Âà©Âô®Arthas",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "arthas",
        "classloader",
        "diagnosis",
        "java",
        "jvm",
        "trace",
        "trouble-shooting"
      ],
      "likes": 73704,
      "downloads": 73704,
      "lastModified": "2025-11-20T11:33:25Z",
      "lastModifiedTimestamp": 1763638405000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/alibaba/arthas",
          "homepage": "https://arthas.aliyun.com/",
          "language": "Java",
          "forks": 7604,
          "open_issues": 455,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1961952?v=4",
      "velocity": 40537.2,
      "is_rising_star": true,
      "heatScore": 12164.356530993009,
      "popularityScore": 36852
    },
    {
      "id": "github-chatchat-space-Langchain-Chatchat",
      "name": "Langchain-Chatchat",
      "author": "chatchat-space",
      "description": "Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langchain ‰∏é ChatGLM, Qwen ‰∏é Llama Á≠âËØ≠Ë®ÄÊ®°ÂûãÁöÑ RAG ‰∏é Agent Â∫îÁî® | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain ",
      "task": "tool",
      "tags": [
        "chatbot",
        "chatchat",
        "chatglm",
        "chatgpt",
        "embedding",
        "faiss",
        "fastchat",
        "gpt",
        "knowledge-base",
        "langchain",
        "langchain-chatglm",
        "llama",
        "llm",
        "milvus",
        "ollama",
        "qwen",
        "rag",
        "retrieval-augmented-generation",
        "streamlit",
        "xinference",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 73208,
      "downloads": 73208,
      "lastModified": "2025-11-20T14:18:54Z",
      "lastModifiedTimestamp": 1763648334000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatchat-space/Langchain-Chatchat",
          "homepage": "",
          "language": "Python",
          "forks": 6070,
          "open_issues": 28,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/139558948?v=4",
      "velocity": 40264.4,
      "is_rising_star": true,
      "heatScore": 12082.514478287832,
      "popularityScore": 36604
    },
    {
      "id": "github-CherryHQ-cherry-studio",
      "name": "cherry-studio",
      "author": "CherryHQ",
      "description": "üçí Cherry Studio is a desktop client that supports for multiple LLM providers.",
      "task": "tool",
      "tags": [
        "agent",
        "anthropic",
        "assistant",
        "chatbot",
        "chatbotai",
        "electron",
        "llm",
        "mcp-client",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 71276,
      "downloads": 71276,
      "lastModified": "2025-11-20T13:54:08Z",
      "lastModifiedTimestamp": 1763646848000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CherryHQ/cherry-studio",
          "homepage": "https://cherry-ai.com",
          "language": "TypeScript",
          "forks": 3235,
          "open_issues": 542,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/187777663?v=4",
      "velocity": 39201.8,
      "is_rising_star": true,
      "heatScore": 11763.726347856722,
      "popularityScore": 35638
    },
    {
      "id": "github-karpathy-LLM101n",
      "name": "LLM101n",
      "author": "karpathy",
      "description": "LLM101n: Let's build a Storyteller",
      "task": "tool",
      "tags": [],
      "likes": 71188,
      "downloads": 71188,
      "lastModified": "2025-11-20T15:19:34Z",
      "lastModifiedTimestamp": 1763651974000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/LLM101n",
          "homepage": "",
          "language": null,
          "forks": 1937,
          "open_issues": 19,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 39153.4,
      "is_rising_star": true,
      "heatScore": 11749.205972298092,
      "popularityScore": 35594
    },
    {
      "id": "github-agno-agi-agno",
      "name": "agno",
      "author": "agno-agi",
      "description": "Multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "developer-tools",
        "python"
      ],
      "likes": 70800,
      "downloads": 70800,
      "lastModified": "2025-11-20T15:16:06Z",
      "lastModifiedTimestamp": 1763651766000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/agno-agi/agno",
          "homepage": "https://docs.agno.com",
          "language": "Python",
          "forks": 4648,
          "open_issues": 294,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/104874993?v=4",
      "velocity": 38940,
      "is_rising_star": true,
      "heatScore": 11685.18431087104,
      "popularityScore": 35400
    },
    {
      "id": "github-Alibaba-NLP-DeepResearch",
      "name": "DeepResearch",
      "author": "Alibaba-NLP",
      "description": "Tongyi Deep Research, the Leading Open-source Deep Research Agent",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "artificial-intelligence",
        "deep-research",
        "deepresearch",
        "information-seeking",
        "llm",
        "tongyi",
        "web-agent",
        "ai",
        "gpt",
        "o3-mini",
        "research"
      ],
      "likes": 70728,
      "downloads": 70728,
      "lastModified": "2025-11-20T14:51:54Z",
      "lastModifiedTimestamp": 1763650314000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Alibaba-NLP/DeepResearch",
          "homepage": "https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/",
          "language": "Python",
          "forks": 1314,
          "open_issues": 66,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/dzhng/deep-research",
          "homepage": "",
          "language": "TypeScript",
          "forks": 1867,
          "open_issues": 77,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/64211549?v=4",
      "velocity": 38900.4,
      "is_rising_star": true,
      "heatScore": 11673.304001563694,
      "popularityScore": 35364
    },
    {
      "id": "github-reworkd-AgentGPT",
      "name": "AgentGPT",
      "author": "reworkd",
      "description": "ü§ñ Assemble, configure, and deploy autonomous AI Agents in your browser.",
      "task": "tool",
      "tags": [
        "agent",
        "agentgpt",
        "agi",
        "autogpt",
        "baby-agi",
        "gpt",
        "langchain",
        "next",
        "openai",
        "t3",
        "t3-stack"
      ],
      "likes": 70512,
      "downloads": 70512,
      "lastModified": "2025-11-20T10:00:19Z",
      "lastModifiedTimestamp": 1763632819000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/reworkd/AgentGPT",
          "homepage": "https://agentgpt.reworkd.ai",
          "language": "TypeScript",
          "forks": 9487,
          "open_issues": 214,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/120154269?v=4",
      "velocity": 38781.6,
      "is_rising_star": true,
      "heatScore": 11637.663071748948,
      "popularityScore": 35256
    },
    {
      "id": "github-microsoft-qlib",
      "name": "qlib",
      "author": "microsoft",
      "description": "Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.",
      "task": "tool",
      "tags": [
        "algorithmic-trading",
        "auto-quant",
        "deep-learning",
        "finance",
        "fintech",
        "investment",
        "machine-learning",
        "paper",
        "platform",
        "python",
        "quant",
        "quant-dataset",
        "quant-models",
        "quantitative-finance",
        "quantitative-trading",
        "research",
        "research-paper",
        "stock-data"
      ],
      "likes": 67791,
      "downloads": 67791,
      "lastModified": "2025-11-20T15:50:29Z",
      "lastModifiedTimestamp": 1763653829000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/qlib",
          "homepage": "https://qlib.readthedocs.io/en/latest/",
          "language": "Python",
          "forks": 5248,
          "open_issues": 306,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 37284.5,
      "is_rising_star": true,
      "heatScore": 11188.521103915695,
      "popularityScore": 33895
    },
    {
      "id": "github-1Panel-dev-1Panel",
      "name": "1Panel",
      "author": "1Panel-dev",
      "description": "üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.",
      "task": "tool",
      "tags": [
        "1panel",
        "cockpit",
        "docker",
        "docker-ui",
        "lamp",
        "linux",
        "lnmp",
        "ollama",
        "webmin"
      ],
      "likes": 64204,
      "downloads": 64204,
      "lastModified": "2025-11-20T15:40:23Z",
      "lastModifiedTimestamp": 1763653223000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/1Panel-dev/1Panel",
          "homepage": "https://1panel.pro",
          "language": "Go",
          "forks": 2842,
          "open_issues": 302,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/109613420?v=4",
      "velocity": 35312.2,
      "is_rising_star": true,
      "heatScore": 10596.814581933142,
      "popularityScore": 32102
    },
    {
      "id": "github-danny-avila-LibreChat",
      "name": "LibreChat",
      "author": "danny-avila",
      "description": "Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "artifacts",
        "aws",
        "azure",
        "chatgpt",
        "chatgpt-clone",
        "claude",
        "clone",
        "deepseek",
        "gemini",
        "google",
        "gpt-5",
        "librechat",
        "mcp",
        "o1",
        "openai",
        "responses-api",
        "vision",
        "webui",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 63636,
      "downloads": 63636,
      "lastModified": "2025-11-20T15:49:34Z",
      "lastModifiedTimestamp": 1763653774000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/danny-avila/LibreChat",
          "homepage": "https://librechat.ai/",
          "language": "TypeScript",
          "forks": 6245,
          "open_issues": 354,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110412045?v=4",
      "velocity": 34999.8,
      "is_rising_star": true,
      "heatScore": 10503.091880568634,
      "popularityScore": 31818
    },
    {
      "id": "github-khoj-ai-khoj",
      "name": "khoj",
      "author": "khoj-ai",
      "description": "Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "assistant",
        "chat",
        "chatgpt",
        "emacs",
        "image-generation",
        "llama3",
        "llamacpp",
        "llm",
        "obsidian",
        "obsidian-md",
        "offline-llm",
        "productivity",
        "rag",
        "research",
        "self-hosted",
        "semantic-search",
        "stt",
        "whatsapp-ai",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 63230,
      "downloads": 63230,
      "lastModified": "2025-11-20T14:35:37Z",
      "lastModifiedTimestamp": 1763649337000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/khoj-ai/khoj",
          "homepage": "https://khoj.dev",
          "language": "Python",
          "forks": 1863,
          "open_issues": 85,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134046886?v=4",
      "velocity": 34776.5,
      "is_rising_star": true,
      "heatScore": 10436.099934846034,
      "popularityScore": 31615
    },
    {
      "id": "github-BerriAI-litellm",
      "name": "litellm",
      "author": "BerriAI",
      "description": "Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]",
      "task": "tool",
      "tags": [
        "ai-gateway",
        "anthropic",
        "azure-openai",
        "bedrock",
        "gateway",
        "langchain",
        "litellm",
        "llm",
        "llm-gateway",
        "llmops",
        "mcp-gateway",
        "openai",
        "openai-proxy",
        "vertex-ai"
      ],
      "likes": 62736,
      "downloads": 62736,
      "lastModified": "2025-11-20T14:16:45Z",
      "lastModifiedTimestamp": 1763648205000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/BerriAI/litellm",
          "homepage": "https://docs.litellm.ai/docs/",
          "language": "Python",
          "forks": 4769,
          "open_issues": 1382,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/121462774?v=4",
      "velocity": 34504.8,
      "is_rising_star": true,
      "heatScore": 10354.587550471952,
      "popularityScore": 31368
    },
    {
      "id": "github-continuedev-continue",
      "name": "continue",
      "author": "continuedev",
      "description": "‚è© Ship faster with Continuous AI. Open-source CLI that can be used in TUI mode as a coding agent or Headless mode to run background agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "background-agents",
        "claude",
        "cli",
        "continuous-ai",
        "developer-tools",
        "gemini",
        "gpt",
        "hacktoberfest",
        "jetbrains",
        "llm",
        "open-source",
        "qwen",
        "vscode",
        "workflows",
        "code-generation-assistance"
      ],
      "likes": 59846,
      "downloads": 59846,
      "lastModified": "2025-11-20T15:50:10Z",
      "lastModifiedTimestamp": 1763653810000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/continuedev/continue",
          "homepage": "https://docs.continue.dev/",
          "language": "TypeScript",
          "forks": 3805,
          "open_issues": 667,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127876214?v=4",
      "velocity": 32915.3,
      "is_rising_star": true,
      "heatScore": 9877.72321375225,
      "popularityScore": 29923
    },
    {
      "id": "github-JushBJJ-Mr.-Ranedeer-AI-Tutor",
      "name": "Mr.-Ranedeer-AI-Tutor",
      "author": "JushBJJ",
      "description": "A GPT-4 AI Tutor Prompt for customizable personalized learning experiences.",
      "task": "tool",
      "tags": [
        "ai",
        "education",
        "gpt-4",
        "llm"
      ],
      "likes": 59336,
      "downloads": 59336,
      "lastModified": "2025-11-20T02:26:40Z",
      "lastModifiedTimestamp": 1763605600000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor",
          "homepage": "https://Mr-Ranedeer.com",
          "language": null,
          "forks": 3373,
          "open_issues": 14,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/36951064?v=4",
      "velocity": 32634.8,
      "is_rising_star": true,
      "heatScore": 9793.570612036001,
      "popularityScore": 29668
    },
    {
      "id": "github-microsoft-graphrag",
      "name": "graphrag",
      "author": "microsoft",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "task": "tool",
      "tags": [
        "gpt",
        "gpt-4",
        "gpt4",
        "graphrag",
        "llm",
        "llms",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 58536,
      "downloads": 58536,
      "lastModified": "2025-11-20T15:31:55Z",
      "lastModifiedTimestamp": 1763652715000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/graphrag",
          "homepage": "https://microsoft.github.io/graphrag/",
          "language": "Python",
          "forks": 3081,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 32194.8,
      "is_rising_star": true,
      "heatScore": 9661.566485519254,
      "popularityScore": 29268
    },
    {
      "id": "github-feder-cr-Jobs_Applier_AI_Agent_AIHawk",
      "name": "Jobs_Applier_AI_Agent_AIHawk",
      "author": "feder-cr",
      "description": "AIHawk aims to easy job hunt process by automating the job application process. Utilizing artificial intelligence, it enables users to apply for multiple jobs in a tailored way.",
      "task": "tool",
      "tags": [
        "agent",
        "application-resume",
        "artificial-intelligence",
        "automate",
        "automation",
        "bot",
        "chatgpt",
        "chrome",
        "gpt",
        "human-resources",
        "job",
        "jobs",
        "jobsearch",
        "jobseeker",
        "opeai",
        "python",
        "resume",
        "scraper",
        "scraping",
        "selenium"
      ],
      "likes": 58162,
      "downloads": 58162,
      "lastModified": "2025-11-20T14:18:17Z",
      "lastModifiedTimestamp": 1763648297000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/feder-cr/Jobs_Applier_AI_Agent_AIHawk",
          "homepage": "",
          "language": "Python",
          "forks": 4424,
          "open_issues": 13,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85809106?v=4",
      "velocity": 31989.1,
      "is_rising_star": true,
      "heatScore": 9599.854536989074,
      "popularityScore": 29081
    },
    {
      "id": "github-666ghj-BettaFish",
      "name": "BettaFish",
      "author": "666ghj",
      "description": "ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ",
      "task": "tool",
      "tags": [
        "agent-framework",
        "data-analysis",
        "deep-research",
        "deep-search",
        "llms",
        "multi-agent-system",
        "nlp",
        "public-opinion-analysis",
        "python3",
        "sentiment-analysis",
        "data-analysis-insights"
      ],
      "likes": 57118,
      "downloads": 57118,
      "lastModified": "2025-11-20T15:53:38Z",
      "lastModifiedTimestamp": 1763654018000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/666ghj/BettaFish",
          "homepage": "",
          "language": "Python",
          "forks": 5502,
          "open_issues": 69,
          "license": "GNU General Public License v2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110395318?v=4",
      "velocity": 31413.8,
      "is_rising_star": true,
      "heatScore": 9427.259020097514,
      "popularityScore": 28558
    },
    {
      "id": "github-karpathy-llm.c",
      "name": "llm.c",
      "author": "karpathy",
      "description": "LLM training in simple, raw C/CUDA",
      "task": "tool",
      "tags": [],
      "likes": 56400,
      "downloads": 56400,
      "lastModified": "2025-11-20T14:42:34Z",
      "lastModifiedTimestamp": 1763649754000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/llm.c",
          "homepage": "",
          "language": "Cuda",
          "forks": 3291,
          "open_issues": 215,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 31020,
      "is_rising_star": true,
      "heatScore": 9309.115185155992,
      "popularityScore": 28200
    },
    {
      "id": "github-songquanpeng-one-api",
      "name": "one-api",
      "author": "songquanpeng",
      "description": "LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.",
      "task": "tool",
      "tags": [
        "api",
        "api-gateway",
        "azure-openai-api",
        "chatgpt",
        "claude",
        "ernie-bot",
        "gemini",
        "gpt",
        "openai",
        "openai-api",
        "proxy",
        "general-dialogue-qa"
      ],
      "likes": 56137,
      "downloads": 56137,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/songquanpeng/one-api",
          "homepage": "https://openai.justsong.cn/",
          "language": "JavaScript",
          "forks": 5528,
          "open_issues": 969,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/39998050?v=4",
      "velocity": 30874.8,
      "is_rising_star": true,
      "heatScore": 9265.553758858363,
      "popularityScore": 28068
    },
    {
      "id": "github-OpenBMB-ChatDev",
      "name": "ChatDev",
      "author": "OpenBMB",
      "description": "Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)",
      "task": "tool",
      "tags": [],
      "likes": 55500,
      "downloads": 55500,
      "lastModified": "2025-11-20T09:53:36Z",
      "lastModifiedTimestamp": 1763632416000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBMB/ChatDev",
          "homepage": "https://arxiv.org/abs/2307.07924",
          "language": "Python",
          "forks": 3489,
          "open_issues": 50,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/89920203?v=4",
      "velocity": 30525,
      "is_rising_star": true,
      "heatScore": 9160.6102950462,
      "popularityScore": 27750
    },
    {
      "id": "github-stanford-oval-storm",
      "name": "storm",
      "author": "stanford-oval",
      "description": "An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.",
      "task": "tool",
      "tags": [
        "agentic-rag",
        "deep-research",
        "emnlp2024",
        "knowledge-curation",
        "large-language-models",
        "naacl",
        "nlp",
        "report-generation",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 55244,
      "downloads": 55244,
      "lastModified": "2025-11-20T11:29:33Z",
      "lastModifiedTimestamp": 1763638173000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/stanford-oval/storm",
          "homepage": "http://storm.genie.stanford.edu",
          "language": "Python",
          "forks": 2505,
          "open_issues": 87,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13667124?v=4",
      "velocity": 30384.2,
      "is_rising_star": true,
      "heatScore": 9118.368889590394,
      "popularityScore": 27622
    },
    {
      "id": "github-voideditor-void",
      "name": "void",
      "author": "voideditor",
      "description": "An AI tool from GitHub.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "claude",
        "copilot",
        "cursor",
        "developer-tools",
        "editor",
        "llm",
        "open-source",
        "openai",
        "visual-studio-code",
        "vscode",
        "vscode-extension"
      ],
      "likes": 55124,
      "downloads": 55124,
      "lastModified": "2025-11-20T14:53:51Z",
      "lastModifiedTimestamp": 1763650431000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/voideditor/void",
          "homepage": "https://voideditor.com",
          "language": "TypeScript",
          "forks": 2149,
          "open_issues": 303,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/181171420?v=4",
      "velocity": 30318.2,
      "is_rising_star": true,
      "heatScore": 9098.568228539569,
      "popularityScore": 27562
    },
    {
      "id": "github-nrwl-nx",
      "name": "nx",
      "author": "nrwl",
      "description": "Get to green PRs in half the time. Nx optimizes your builds, scales your CI, and fixes failed PRs. Built for developers and AI agents.",
      "task": "tool",
      "tags": [
        "angular",
        "build",
        "build-system",
        "build-tool",
        "building-tool",
        "cli",
        "cypress",
        "hacktoberfest",
        "javascript",
        "monorepo",
        "nextjs",
        "nodejs",
        "nx",
        "nx-workspaces",
        "react",
        "storybook",
        "typescript"
      ],
      "likes": 55054,
      "downloads": 55054,
      "lastModified": "2025-11-20T15:43:56Z",
      "lastModifiedTimestamp": 1763653436000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nrwl/nx",
          "homepage": "https://nx.dev",
          "language": "TypeScript",
          "forks": 2623,
          "open_issues": 789,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23692104?v=4",
      "velocity": 30279.7,
      "is_rising_star": true,
      "heatScore": 9087.017842261728,
      "popularityScore": 27527
    },
    {
      "id": "github-microsoft-semantic-kernel",
      "name": "semantic-kernel",
      "author": "microsoft",
      "description": "Integrate cutting-edge LLM technology quickly and easily into your apps",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "llm",
        "openai",
        "sdk"
      ],
      "likes": 53406,
      "downloads": 53406,
      "lastModified": "2025-11-20T12:07:50Z",
      "lastModifiedTimestamp": 1763640470000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/semantic-kernel",
          "homepage": "https://aka.ms/semantic-kernel",
          "language": "C#",
          "forks": 4352,
          "open_issues": 570,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 29373.3,
      "is_rising_star": true,
      "heatScore": 8815.088603423534,
      "popularityScore": 26703
    },
    {
      "id": "github-labring-FastGPT",
      "name": "FastGPT",
      "author": "labring",
      "description": "FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.",
      "task": "tool",
      "tags": [
        "agent",
        "claude",
        "deepseek",
        "llm",
        "mcp",
        "nextjs",
        "openai",
        "qwen",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 52648,
      "downloads": 52648,
      "lastModified": "2025-11-20T15:45:26Z",
      "lastModifiedTimestamp": 1763653526000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/labring/FastGPT",
          "homepage": "https://fastgpt.io",
          "language": "TypeScript",
          "forks": 6777,
          "open_issues": 653,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102226726?v=4",
      "velocity": 28956.4,
      "is_rising_star": true,
      "heatScore": 8690.0142578659,
      "popularityScore": 26324
    },
    {
      "id": "github-ComposioHQ-composio",
      "name": "composio",
      "author": "ComposioHQ",
      "description": "Composio equips your AI agents & LLMs with 100+ high-quality integrations via function calling",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "aiagents",
        "developer-tools",
        "function-calling",
        "gpt-4",
        "javascript",
        "js",
        "llm",
        "llmops",
        "mcp",
        "python",
        "remote-mcp-server",
        "sse",
        "typescript"
      ],
      "likes": 52338,
      "downloads": 52338,
      "lastModified": "2025-11-20T13:33:16Z",
      "lastModifiedTimestamp": 1763645596000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ComposioHQ/composio",
          "homepage": "https://docs.composio.dev",
          "language": "TypeScript",
          "forks": 4399,
          "open_issues": 28,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128464815?v=4",
      "velocity": 28785.9,
      "is_rising_star": true,
      "heatScore": 8638.862462605848,
      "popularityScore": 26169
    },
    {
      "id": "github-datawhalechina-self-llm",
      "name": "self-llm",
      "author": "datawhalechina",
      "description": "„ÄäÂºÄÊ∫êÂ§ßÊ®°ÂûãÈ£üÁî®ÊåáÂçó„ÄãÈíàÂØπ‰∏≠ÂõΩÂÆùÂÆùÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫‰∫éLinuxÁéØÂ¢ÉÂø´ÈÄüÂæÆË∞ÉÔºàÂÖ®ÂèÇÊï∞/LoraÔºâ„ÄÅÈÉ®ÁΩ≤ÂõΩÂÜÖÂ§ñÂºÄÊ∫êÂ§ßÊ®°ÂûãÔºàLLMÔºâ/Â§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÔºàMLLMÔºâÊïôÁ®ã",
      "task": "tool",
      "tags": [
        "chatglm",
        "chatglm3",
        "gemma-2b-it",
        "glm-4",
        "internlm2",
        "llama3",
        "llm",
        "lora",
        "minicpm",
        "q-wen",
        "qwen",
        "qwen1-5",
        "qwen2"
      ],
      "likes": 52152,
      "downloads": 52152,
      "lastModified": "2025-11-20T15:48:41Z",
      "lastModifiedTimestamp": 1763653721000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/datawhalechina/self-llm",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2629,
          "open_issues": 147,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/46047812?v=4",
      "velocity": 28683.6,
      "is_rising_star": true,
      "heatScore": 8608.1713803389,
      "popularityScore": 26076
    },
    {
      "id": "github-Hannibal046-Awesome-LLM",
      "name": "Awesome-LLM",
      "author": "Hannibal046",
      "description": "Awesome-LLM: a curated list of Large Language Model",
      "task": "tool",
      "tags": [],
      "likes": 51190,
      "downloads": 51190,
      "lastModified": "2025-11-20T15:23:28Z",
      "lastModifiedTimestamp": 1763652208000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Hannibal046/Awesome-LLM",
          "homepage": "",
          "language": null,
          "forks": 2192,
          "open_issues": 51,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/38466901?v=4",
      "velocity": 28154.5,
      "is_rising_star": true,
      "heatScore": 8449.435720471049,
      "popularityScore": 25595
    },
    {
      "id": "github-warpdotdev-Warp",
      "name": "Warp",
      "author": "warpdotdev",
      "description": "Warp is the agentic development environment, built for coding with multiple AI agents.",
      "task": "tool",
      "tags": [
        "bash",
        "linux",
        "macos",
        "rust",
        "shell",
        "terminal",
        "wasm",
        "zsh",
        "code-generation-assistance"
      ],
      "likes": 50620,
      "downloads": 50620,
      "lastModified": "2025-11-20T15:49:51Z",
      "lastModifiedTimestamp": 1763653791000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/warpdotdev/Warp",
          "homepage": "https://warp.dev",
          "language": null,
          "forks": 581,
          "open_issues": 3958,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/71840468?v=4",
      "velocity": 27841,
      "is_rising_star": true,
      "heatScore": 8355.382316512678,
      "popularityScore": 25310
    },
    {
      "id": "github-TauricResearch-TradingAgents",
      "name": "TradingAgents",
      "author": "TauricResearch",
      "description": "TradingAgents: Multi-Agents LLM Financial Trading Framework",
      "task": "tool",
      "tags": [
        "agent",
        "finance",
        "llm",
        "multiagent",
        "trading"
      ],
      "likes": 50536,
      "downloads": 50536,
      "lastModified": "2025-11-20T15:34:43Z",
      "lastModifiedTimestamp": 1763652883000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/TauricResearch/TradingAgents",
          "homepage": "https://arxiv.org/pdf/2412.20138",
          "language": "Python",
          "forks": 4718,
          "open_issues": 200,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192884433?v=4",
      "velocity": 27794.8,
      "is_rising_star": true,
      "heatScore": 8341.521811638786,
      "popularityScore": 25268
    },
    {
      "id": "github-CopilotKit-CopilotKit",
      "name": "CopilotKit",
      "author": "CopilotKit",
      "description": "React UI + elegant infrastructure for AI Copilots, AI chatbots, and in-app AI agents. The Agentic last-mile ü™Å",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai",
        "ai-agent",
        "ai-assistant",
        "assistant",
        "copilot",
        "copilot-chat",
        "hacktoberfest",
        "langchain",
        "langgraph",
        "llm",
        "nextjs",
        "open-source",
        "react",
        "reactjs",
        "ts",
        "typescript",
        "general-dialogue-qa"
      ],
      "likes": 50076,
      "downloads": 50076,
      "lastModified": "2025-11-20T14:45:22Z",
      "lastModifiedTimestamp": 1763649922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CopilotKit/CopilotKit",
          "homepage": "https://docs.copilotkit.ai",
          "language": "TypeScript",
          "forks": 3341,
          "open_issues": 435,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131273140?v=4",
      "velocity": 27541.8,
      "is_rising_star": true,
      "heatScore": 8265.619031886114,
      "popularityScore": 25038
    },
    {
      "id": "github-chroma-core-chroma",
      "name": "chroma",
      "author": "chroma-core",
      "description": "Open-source search and retrieval database for AI applications.",
      "task": "tool",
      "tags": [
        "ai",
        "database",
        "document-retrieval",
        "embeddings",
        "llm",
        "llms",
        "rag",
        "rust",
        "rust-lang",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 49026,
      "downloads": 49026,
      "lastModified": "2025-11-20T14:11:20Z",
      "lastModifiedTimestamp": 1763647880000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chroma-core/chroma",
          "homepage": "https://www.trychroma.com/",
          "language": "Rust",
          "forks": 1926,
          "open_issues": 491,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/105881770?v=4",
      "velocity": 26964.3,
      "is_rising_star": true,
      "heatScore": 8092.362589927232,
      "popularityScore": 24513
    },
    {
      "id": "github-microsoft-JARVIS",
      "name": "JARVIS",
      "author": "microsoft",
      "description": "JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf",
      "task": "tool",
      "tags": [
        "deep-learning",
        "platform",
        "pytorch"
      ],
      "likes": 48902,
      "downloads": 48902,
      "lastModified": "2025-11-20T11:10:51Z",
      "lastModifiedTimestamp": 1763637051000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/JARVIS",
          "homepage": "",
          "language": "Python",
          "forks": 2052,
          "open_issues": 344,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26896.1,
      "is_rising_star": true,
      "heatScore": 8071.901820070982,
      "popularityScore": 24451
    },
    {
      "id": "github-microsoft-BitNet",
      "name": "BitNet",
      "author": "microsoft",
      "description": "Official inference framework for 1-bit LLMs",
      "task": "tool",
      "tags": [],
      "likes": 48820,
      "downloads": 48820,
      "lastModified": "2025-11-20T12:29:27Z",
      "lastModifiedTimestamp": 1763641767000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/BitNet",
          "homepage": "",
          "language": "Python",
          "forks": 1895,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26851,
      "is_rising_star": true,
      "heatScore": 8058.3713098995,
      "popularityScore": 24410
    },
    {
      "id": "github-assafelovic-gpt-researcher",
      "name": "gpt-researcher",
      "author": "assafelovic",
      "description": "An LLM agent that conducts deep research (local and web) on any given topic and generates a long report with citations.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "automation",
        "deepresearch",
        "llms",
        "mcp",
        "mcp-server",
        "python",
        "research",
        "search",
        "webscraping"
      ],
      "likes": 48440,
      "downloads": 48440,
      "lastModified": "2025-11-20T15:20:31Z",
      "lastModifiedTimestamp": 1763652031000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/assafelovic/gpt-researcher",
          "homepage": "https://gptr.dev",
          "language": "Python",
          "forks": 3202,
          "open_issues": 149,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13554167?v=4",
      "velocity": 26642,
      "is_rising_star": true,
      "heatScore": 7995.668934448769,
      "popularityScore": 24220
    },
    {
      "id": "github-e2b-dev-awesome-ai-agents",
      "name": "awesome-ai-agents",
      "author": "e2b-dev",
      "description": "A list of AI autonomous agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artificial-intelligence",
        "autogpt",
        "autonomous-agents",
        "awesome",
        "babyagi",
        "copilot",
        "gpt",
        "gpt-4",
        "gpt-engineer",
        "openai",
        "python"
      ],
      "likes": 48438,
      "downloads": 48438,
      "lastModified": "2025-11-20T14:47:26Z",
      "lastModifiedTimestamp": 1763650046000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/e2b-dev/awesome-ai-agents",
          "homepage": "https://e2b.dev/docs",
          "language": null,
          "forks": 2026,
          "open_issues": 78,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/129434473?v=4",
      "velocity": 26640.9,
      "is_rising_star": true,
      "heatScore": 7995.338921897165,
      "popularityScore": 24219
    },
    {
      "id": "github-huggingface-smolagents",
      "name": "smolagents",
      "author": "huggingface",
      "description": "ü§ó smolagents: a barebones library for agents that think in code.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 48104,
      "downloads": 48104,
      "lastModified": "2025-11-20T15:45:37Z",
      "lastModifiedTimestamp": 1763653537000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/smolagents",
          "homepage": "https://huggingface.co/docs/smolagents",
          "language": "Python",
          "forks": 2139,
          "open_issues": 316,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 26457.2,
      "is_rising_star": true,
      "heatScore": 7940.226818475895,
      "popularityScore": 24052
    },
    {
      "id": "github-gitleaks-gitleaks",
      "name": "gitleaks",
      "author": "gitleaks",
      "description": "Find secrets with Gitleaks üîë",
      "task": "tool",
      "tags": [
        "ai-powered",
        "ci-cd",
        "cicd",
        "cli",
        "data-loss-prevention",
        "devsecops",
        "dlp",
        "git",
        "gitleaks",
        "go",
        "golang",
        "hacktoberfest",
        "llm",
        "llm-inference",
        "llm-training",
        "nhi",
        "open-source",
        "secret",
        "security",
        "security-tools"
      ],
      "likes": 47960,
      "downloads": 47960,
      "lastModified": "2025-11-20T15:12:36Z",
      "lastModifiedTimestamp": 1763651556000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/gitleaks/gitleaks",
          "homepage": "https://gitleaks.io",
          "language": "Go",
          "forks": 1834,
          "open_issues": 315,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/90395851?v=4",
      "velocity": 26378,
      "is_rising_star": true,
      "heatScore": 7916.465907102356,
      "popularityScore": 23980
    },
    {
      "id": "github-microsoft-OmniParser",
      "name": "OmniParser",
      "author": "microsoft",
      "description": "A simple screen parsing tool towards pure vision based GUI agent",
      "task": "tool",
      "tags": [],
      "likes": 47784,
      "downloads": 47784,
      "lastModified": "2025-11-20T14:47:44Z",
      "lastModifiedTimestamp": 1763650064000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/OmniParser",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2048,
          "open_issues": 225,
          "license": "Creative Commons Attribution 4.0 International"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26281.2,
      "is_rising_star": true,
      "heatScore": 7887.424789478167,
      "popularityScore": 23892
    },
    {
      "id": "github-HKUDS-LightRAG",
      "name": "LightRAG",
      "author": "HKUDS",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "task": "tool",
      "tags": [
        "genai",
        "gpt",
        "gpt-4",
        "graphrag",
        "knowledge-graph",
        "large-language-models",
        "llm",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 47760,
      "downloads": 47760,
      "lastModified": "2025-11-20T15:47:31Z",
      "lastModifiedTimestamp": 1763653651000,
      "readme": "<div align=\"center\">\n\n<div style=\"margin: 20px 0;\">\n  <img src=\"./assets/logo.png\" width=\"120\" height=\"120\" alt=\"LightRAG Logo\" style=\"border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);\">\n</div>\n\n# üöÄ LightRAG: Simple and Fast Retrieval-Augmented Generation\n\n<div align=\"center\">\n    <a href=\"https://trendshift.io/repositories/13043\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13043\" alt=\"HKUDS%2FLightRAG | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);\"></div>\n</div>\n\n<div align=\"center\">\n  <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;\">\n    <p>\n      <a href='https://github.com/HKUDS/LightRAG'><img src='https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&logo=github&logoColor=white&labelColor=1a1a2e'></a>\n      <a href='https://arxiv.org/abs/2410.05779'><img src='https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&logo=arxiv&logoColor=white&labelColor=1a1a2e'></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/stargazers\"><img src='https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&style=for-the-badge&logo=star&logoColor=white&labelColor=1a1a2e' /></a>\n    </p>\n    <p>\n      <img src=\"https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&logo=python&logoColor=white&labelColor=1a1a2e\">\n      <a href=\"https://pypi.org/project/lightrag-hku/\"><img src=\"https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&logo=pypi&logoColor=white&labelColor=1a1a2e&color=ff6b6b\"></a>\n    </p>\n    <p>\n      <a href=\"https://discord.gg/yF2MmDJyGJ\"><img src=\"https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&logo=discord&logoColor=white&labelColor=1a1a2e\"></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/issues/285\"><img src=\"https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&logo=wechat&logoColor=white&labelColor=1a1a2e\"></a>\n    </p>\n    <p>\n      <a href=\"README-zh.md\"><img src=\"https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge\"></a>\n      <a href=\"README.md\"><img src=\"https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge\"></a>\n    </p>\n    <p>\n      <a href=\"https://pepy.tech/projects/lightrag-hku\"><img src=\"https://static.pepy.tech/personalized-badge/lightrag-hku?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=GREEN&left_text=downloads\"></a>\n    </p>\n  </div>\n</div>\n\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n  <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"800\">\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n    <img src=\"./README.assets/b2aaf634151b4706892693ffb43d9093.png\" width=\"800\" alt=\"LightRAG Diagram\">\n</div>\n\n---\n## üéâ News\n- [2025.11.05]üéØAdd **RAGAS-based** Evaluation Framework and **Langfuse** observability for LightRAG (API can return retrieved contexts with query results).\n- [2025.10.22]üéØEliminate bottlenecks in processing **large-scale datasets**.\n- [2025.09.15]üéØSignificantly enhances KG extraction accuracy for **small LLMs** like Qwen3-30B-A3B.\n- [2025.08.29]üéØ**Reranker** is supported now , significantly boosting performance for mixed queries(Set as default query mode now).\n- [2025.08.04]üéØ**Document deletion** with KG regeneration to ensure query performance.\n- [2025.06.16]üéØOur team has released [RAG-Anything](https://github.com/HKUDS/RAG-Anything) an All-in-One Multimodal RAG System for seamless text, image, table, and equation processing.\n- [2025.06.05]üéØLightRAG now supports comprehensive multimodal data handling through [RAG-Anything](https://github.com/HKUDS/RAG-Anything) integration, enabling seamless document parsing and RAG capabilities across diverse formats including PDFs, images, Office documents, tables, and formulas. Please refer to the new [multimodal section](https://github.com/HKUDS/LightRAG/?tab=readme-ov-file#multimodal-document-processing-rag-anything-integration) for details.\n- [2025.03.18]üéØLightRAG now supports citation functionality, enabling proper source attribution.\n- [2025.02.12]üéØYou can now use MongoDB as all in-one Storage.\n- [2025.02.05]üéØOur team has released [VideoRAG](https://github.com/HKUDS/VideoRAG) understanding extremely long-context videos.\n- [2025.01.13]üéØOur team has released [MiniRAG](https://github.com/HKUDS/MiniRAG) making RAG simpler with small models.\n- [2025.01.06]üéØYou can now use PostgreSQL as all in-one Storage.\n- [2024.11.19]üéØA comprehensive guide to LightRAG is now available on [LearnOpenCV](https://learnopencv.com/lightrag). Many thanks to the blog author.\n- [2024.11.09]üéØIntroducing the LightRAG Webui, which allows you to insert, query, visualize LightRAG knowledge.\n- [2024.11.04]üéØYou can now [use Neo4J for Storage](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage).\n- [2024.10.18]üéØWe've added a link to a [LightRAG Introduction Video](https://youtu.be/oageL-1I0GE). Thanks to the author!\n- [2024.10.17]üéØWe have created a [Discord channel](https://discord.gg/yF2MmDJyGJ)! Welcome to join for sharing and discussions! üéâüéâ\n- [2024.10.16]üéØLightRAG now supports [Ollama models](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start)!\n\n<details>\n  <summary style=\"font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;\">\n    Algorithm Flowchart\n  </summary>\n\n![LightRAG Indexing Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg)\n*Figure 1: LightRAG Indexing Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n![LightRAG Retrieval and Querying Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg)\n*Figure 2: LightRAG Retrieval and Querying Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n\n</details>\n\n## Installation\n\n> **üí° Using uv for Package Management**: This project uses [uv](https://docs.astral.sh/uv/) for fast and reliable Python package management.\n> Install uv first: `curl -LsSf https://astral.sh/uv/install.sh | sh` (Unix/macOS) or `powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"` (Windows)\n>\n> **Note**: You can also use pip if you prefer, but uv is recommended for better performance and more reliable dependency management.\n>\n> **üì¶ Offline Deployment**: For offline or air-gapped environments, see the [Offline Deployment Guide](./docs/OfflineDeployment.md) for instructions on pre-installing all dependencies and cache files.\n\n### Install LightRAG Server\n\nThe LightRAG Server is designed to provide Web UI and API support. The Web UI facilitates document indexing, knowledge graph exploration, and a simple RAG query interface. LightRAG Server also provide an Ollama compatible interfaces, aiming to emulate LightRAG as an Ollama chat model. This allows AI chat bot, such as Open WebUI, to access LightRAG easily.\n\n* Install from PyPI\n\n```bash\n# Using uv (recommended)\nuv pip install \"lightrag-hku[api]\"\n# Or using pip\n# pip install \"lightrag-hku[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\nlightrag-server\n```\n\n* Installation from Source\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\n\n# Using uv (recommended)\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync --extra api\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or using pip with virtual environment\n# python -m venv .venv\n# source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n# pip install -e \".[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\n# Build front-end artifacts\ncd lightrag_webui\nbun install --frozen-lockfile\nbun run build\ncd ..\n\nlightrag-server\n```\n\n* Launching the LightRAG Server with Docker Compose\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n# modify LLM and Embedding settings in .env\ndocker compose up\n```\n\n> Historical versions of LightRAG docker images can be found here: [LightRAG Docker Images]( https://github.com/HKUDS/LightRAG/pkgs/container/lightrag)\n\n### Install  LightRAG Core\n\n* Install from source (Recommended)\n\n```bash\ncd LightRAG\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or: pip install -e .\n```\n\n* Install from PyPI\n\n```bash\nuv pip install lightrag-hku\n# Or: pip install lightrag-hku\n```\n\n## Quick Start\n\n### LLM and Technology Stack Requirements for LightRAG\n\nLightRAG's demands on the capabilities of Large Language Models (LLMs) are significantly higher than those of traditional RAG, as it requires the LLM to perform entity-relationship extraction tasks from documents. Configuring appropriate Embedding and Reranker models is also crucial for improving query performance.\n\n- **LLM Selection**:\n  - It is recommended to use an LLM with at least 32 billion parameters.\n  - The context length should be at least 32KB, with 64KB being recommended.\n  - It is not recommended to choose reasoning models during the document indexing stage.\n  - During the query stage, it is recommended to choose models with stronger capabilities than those used in the indexing stage to achieve better query results.\n- **Embedding Model**:\n  - A high-performance Embedding model is essential for RAG.\n  - We recommend using mainstream multilingual Embedding models, such as: `BAAI/bge-m3` and `text-embedding-3-large`.\n  - **Important Note**: The Embedding model must be determined before document indexing, and the same model must be used during the document query phase. For certain storage solutions (e.g., PostgreSQL), the vector dimension must be defined upon initial table creation. Therefore, when changing embedding models, it is necessary to delete the existing vector-related tables and allow LightRAG to recreate them with the new dimensions.\n- **Reranker Model Configuration**:\n  - Configuring a Reranker model can significantly enhance LightRAG's retrieval performance.\n  - When a Reranker model is enabled, it is recommended to set the \"mix mode\" as the default query mode.\n  - We recommend using mainstream Reranker models, such as: `BAAI/bge-reranker-v2-m3` or models provided by services like Jina.\n\n### Quick Start for LightRAG Server\n\n* For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).\n\n### Quick Start for LightRAG core\n\nTo get started with LightRAG core, refer to the sample codes available in the `examples` folder. Additionally, a [video demo](https://www.youtube.com/watch?v=g21royNJ4fw) demonstration is provided to guide you through the local setup process. If you already possess an OpenAI API key, you can run the demo right away:\n\n```bash\n### you should run the demo code with project folder\ncd LightRAG\n### provide your API-KEY for OpenAI\nexport OPENAI_API_KEY=\"sk-...your_opeai_key...\"\n### download the demo document of \"A Christmas Carol\" by Charles Dickens\ncurl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt > ./book.txt\n### run the demo code\npython examples/lightrag_openai_demo.py\n```\n\nFor a streaming response implementation example, please see `examples/lightrag_openai_compatible_demo.py`. Prior to execution, ensure you modify the sample code's LLM and embedding configurations accordingly.\n\n**Note 1**: When running the demo program, please be aware that different test scripts may use different embedding models. If you switch to a different embedding model, you must clear the data directory (`./dickens`); otherwise, the program may encounter errors. If you wish to retain the LLM cache, you can preserve the `kv_store_llm_response_cache.json` file while clearing the data directory.\n\n**Note 2**: Only `lightrag_openai_demo.py` and `lightrag_openai_compatible_demo.py` are officially supported sample codes. Other sample files are community contributions that haven't undergone full testing and optimization.\n\n## Programing with LightRAG Core\n\n> ‚ö†Ô∏è **If you would like to integrate LightRAG into your project, we recommend utilizing the REST API provided by the LightRAG Server**. LightRAG Core is typically intended for embedded applications or for researchers who wish to conduct studies and evaluations.\n\n### ‚ö†Ô∏è Important: Initialization Requirements\n\n**LightRAG requires explicit initialization before use.** You must call `await rag.initialize_storages()` after creating a LightRAG instance, otherwise you will encounter errors.\n\n### A Simple Program\n\nUse the below Python snippet to initialize LightRAG, insert text to it, and perform queries:\n\n```python\nimport os\nimport asyncio\nfrom lightrag import LightRAG, QueryParam\nfrom lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed\nfrom lightrag.utils import setup_logger\n\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nWORKING_DIR = \"./rag_storage\"\nif not os.path.exists(WORKING_DIR):\n    os.mkdir(WORKING_DIR)\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        embedding_func=openai_embed,\n        llm_model_func=gpt_4o_mini_complete,\n    )\n    # IMPORTANT: Both initialization calls are required!\n    await rag.initialize_storages()  # Initialize storage backends    return rag\n\nasync def main():\n    try:\n        # Initialize RAG instance\n        rag = await initialize_rag()\n        await rag.ainsert(\"Your text\")\n\n        # Perform hybrid search\n        mode = \"hybrid\"\n        print(\n          await rag.aquery(\n              \"What are the top themes in this story?\",\n              param=QueryParam(mode=mode)\n          )\n        )\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        if rag:\n            await rag.finalize_storages()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nImportant notes for the above snippet:\n\n- Export your OPENAI_API_KEY environment variable before running the script.\n- This program uses the default storage settings for LightRAG, so all data will be persisted to WORKING_DIR/rag_storage.\n- This program demonstrates only the simplest way to initialize a LightRAG object: Injecting the embedding and LLM functions, and initializing storage and pipeline status after creating the LightRAG object.\n\n### LightRAG init parameters\n\nA full list of LightRAG init parameters:\n\n<details>\n<summary> Parameters </summary>\n\n| **Parameter** | **Type** | **Explanation** | **Default** |\n|--------------|----------|-----------------|-------------|\n| **working_dir** | `str` | Directory where the cache will be stored | `lightrag_cache+timestamp` |\n| **workspace** | str | Workspace name for data isolation between different LightRAG Instances |  |\n| **kv_storage** | `str` | Storage type for documents and text chunks. Supported types: `JsonKVStorage`,`PGKVStorage`,`RedisKVStorage`,`MongoKVStorage` | `JsonKVStorage` |\n| **vector_storage** | `str` | Storage type for embedding vectors. Supported types: `NanoVectorDBStorage`,`PGVectorStorage`,`MilvusVectorDBStorage`,`ChromaVectorDBStorage`,`FaissVectorDBStorage`,`MongoVectorDBStorage`,`QdrantVectorDBStorage` | `NanoVectorDBStorage` |\n| **graph_storage** | `str` | Storage type for graph edges and nodes. Supported types: `NetworkXStorage`,`Neo4JStorage`,`PGGraphStorage`,`AGEStorage` | `NetworkXStorage` |\n| **doc_status_storage** | `str` | Storage type for documents process status. Supported types: `JsonDocStatusStorage`,`PGDocStatusStorage`,`MongoDocStatusStorage` | `JsonDocStatusStorage` |\n| **chunk_token_size** | `int` | Maximum token size per chunk when splitting documents | `1200` |\n| **chunk_overlap_token_size** | `int` | Overlap token size between two chunks when splitting documents | `100` |\n| **tokenizer** | `Tokenizer` | The function used to convert text into tokens (numbers) and back using .encode() and .decode() functions following `TokenizerInterface` protocol. If you don't specify one, it will use the default Tiktoken tokenizer. | `TiktokenTokenizer` |\n| **tiktoken_model_name** | `str` | If you're using the default Tiktoken tokenizer, this is the name of the specific Tiktoken model to use. This setting is ignored if you provide your own tokenizer. | `gpt-4o-mini` |\n| **entity_extract_max_gleaning** | `int` | Number of loops in the entity extraction process, appending history messages | `1` |\n| **node_embedding_algorithm** | `str` | Algorithm for node embedding (currently not used) | `node2vec` |\n| **node2vec_params** | `dict` | Parameters for node embedding | `{\"dimensions\": 1536,\"num_walks\": 10,\"walk_length\": 40,\"window_size\": 2,\"iterations\": 3,\"random_seed\": 3,}` |\n| **embedding_func** | `EmbeddingFunc` | Function to generate embedding vectors from text | `openai_embed` |\n| **embedding_batch_num** | `int` | Maximum batch size for embedding processes (multiple texts sent per batch) | `32` |\n| **embedding_func_max_async** | `int` | Maximum number of concurrent asynchronous embedding processes | `16` |\n| **llm_model_func** | `callable` | Function for LLM generation | `gpt_4o_mini_complete` |\n| **llm_model_name** | `str` | LLM model name for generation | `meta-llama/Llama-3.2-1B-Instruct` |\n| **summary_context_size** | `int` | Maximum tokens send to LLM to generate summaries for entity relation merging | `10000`Ôºàconfigured by env var SUMMARY_CONTEXT_SIZE) |\n| **summary_max_tokens** | `int` | Maximum token size for entity/relation description | `500`Ôºàconfigured by env var SUMMARY_MAX_TOKENS) |\n| **llm_model_max_async** | `int` | Maximum number of concurrent asynchronous LLM processes | `4`Ôºàdefault value changed by env var MAX_ASYNC) |\n| **llm_model_kwargs** | `dict` | Additional parameters for LLM generation | |\n| **vector_db_storage_cls_kwargs** | `dict` | Additional parameters for vector database, like setting the threshold for nodes and relations retrieval | cosine_better_than_threshold: 0.2Ôºàdefault value changed by env var COSINE_THRESHOLD) |\n| **enable_llm_cache** | `bool` | If `TRUE`, stores LLM results in cache; repeated prompts return cached responses | `TRUE` |\n| **enable_llm_cache_for_entity_extract** | `bool` | If `TRUE`, stores LLM results in cache for entity extraction; Good for beginners to debug your application | `TRUE` |\n| **addon_params** | `dict` | Additional parameters, e.g., `{\"language\": \"Simplified Chinese\", \"entity_types\": [\"organization\", \"person\", \"location\", \"event\"]}`: sets example limit, entiy/relation extraction output language | language: English` |\n| **embedding_cache_config** | `dict` | Configuration for question-answer caching. Contains three parameters: `enabled`: Boolean value to enable/disable cache lookup functionality. When enabled, the system will check cached responses before generating new answers. `similarity_threshold`: Float value (0-1), similarity threshold. When a new question's similarity with a cached question exceeds this threshold, the cached answer will be returned directly without calling the LLM. `use_llm_check`: Boolean value to enable/disable LLM similarity verification. When enabled, LLM will be used as a secondary check to verify the similarity between questions before returning cached answers. | Default: `{\"enabled\": False, \"similarity_threshold\": 0.95, \"use_llm_check\": False}` |\n\n</details>\n\n### Query Param\n\nUse QueryParam to control the behavior your query:\n\n```python\nclass QueryParam:\n    \"\"\"Configuration parameters for query execution in LightRAG.\"\"\"\n\n    mode: Literal[\"local\", \"global\", \"hybrid\", \"naive\", \"mix\", \"bypass\"] = \"global\"\n    \"\"\"Specifies the retrieval mode:\n    - \"local\": Focuses on context-dependent information.\n    - \"global\": Utilizes global knowledge.\n    - \"hybrid\": Combines local and global retrieval methods.\n    - \"naive\": Performs a basic search without advanced techniques.\n    - \"mix\": Integrates knowledge graph and vector retrieval.\n    \"\"\"\n\n    only_need_context: bool = False\n    \"\"\"If True, only returns the retrieved context without generating a response.\"\"\"\n\n    only_need_prompt: bool = False\n    \"\"\"If True, only returns the generated prompt without producing a response.\"\"\"\n\n    response_type: str = \"Multiple Paragraphs\"\n    \"\"\"Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'.\"\"\"\n\n    stream: bool = False\n    \"\"\"If True, enables streaming output for real-time responses.\"\"\"\n\n    top_k: int = int(os.getenv(\"TOP_K\", \"60\"))\n    \"\"\"Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode.\"\"\"\n\n    chunk_top_k: int = int(os.getenv(\"CHUNK_TOP_K\", \"20\"))\n    \"\"\"Number of text chunks to retrieve initially from vector search and keep after reranking.\n    If None, defaults to top_k value.\n    \"\"\"\n\n    max_entity_tokens: int = int(os.getenv(\"MAX_ENTITY_TOKENS\", \"6000\"))\n    \"\"\"Maximum number of tokens allocated for entity context in unified token control system.\"\"\"\n\n    max_relation_tokens: int = int(os.getenv(\"MAX_RELATION_TOKENS\", \"8000\"))\n    \"\"\"Maximum number of tokens allocated for relationship context in unified token control system.\"\"\"\n\n    max_total_tokens: int = int(os.getenv(\"MAX_TOTAL_TOKENS\", \"30000\"))\n    \"\"\"Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt).\"\"\"\n\n    # History mesages is only send to LLM for context, not used for retrieval\n    conversation_history: list[dict[str, str]] = field(default_factory=list)\n    \"\"\"Stores past conversation history to maintain context.\n    Format: [{\"role\": \"user/assistant\", \"content\": \"message\"}].\n    \"\"\"\n\n    ids: list[str] | None = None\n    \"\"\"List of ids to filter the results.\"\"\"\n\n    model_func: Callable[..., object] | None = None\n    \"\"\"Optional override for the LLM model function to use for this specific query.\n    If provided, this will be used instead of the global model function.\n    This allows using different models for different query modes.\n    \"\"\"\n\n    user_prompt: str | None = None\n    \"\"\"User-provided prompt for the query.\n    Addition instructions for LLM. If provided, this will be inject into the prompt template.\n    It's purpose is the let user customize the way LLM generate the response.\n    \"\"\"\n\n    enable_rerank: bool = True\n    \"\"\"Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.\n    Default is True to enable reranking when rerank model is available.\n    \"\"\"\n```\n\n> default value of Top_k can be change by environment  variables  TOP_K.\n\n### LLM and Embedding Injection\n\nLightRAG requires the utilization of LLM and Embedding models to accomplish document indexing and querying tasks. During the initialization phase, it is necessary to inject the invocation methods of the relevant models into LightRAGÔºö\n\n<details>\n<summary> <b>Using Open AI-like APIs</b> </summary>\n\n* LightRAG also supports Open AI-like chat/embeddings APIs:\n\n```python\nasync def llm_model_func(\n    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n) -> str:\n    return await openai_complete_if_cache(\n        \"solar-mini\",\n        prompt,\n        system_prompt=system_prompt,\n        history_messages=history_messages,\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\",\n        **kwargs\n    )\n\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    return await openai_embed(\n        texts,\n        model=\"solar-embedding-1-large-query\",\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\"\n    )\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=llm_model_func,\n        embedding_func=EmbeddingFunc(\n            embedding_dim=4096,\n            func=embedding_func\n        )\n    )\n\n    await rag.initialize_storages()\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using Hugging Face Models</b> </summary>\n\n* If you want to use Hugging Face models, you only need to set LightRAG as follows:\n\nSee `lightrag_hf_demo.py`\n\n```python\n# Initialize LightRAG with Hugging Face model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=hf_model_complete,  # Use Hugging Face model for text generation\n    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face\n    # Use Hugging Face embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=lambda texts: hf_embed(\n            texts,\n            tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n            embed_model=AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n        )\n    ),\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Ollama Models</b> </summary>\n**Overview**\n\nIf you want to use Ollama models, you need to pull model you plan to use and embedding model, for example `nomic-embed-text`.\n\nThen you only need to set LightRAG as follows:\n\n```python\n# Initialize LightRAG with Ollama model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Increasing context size**\n\nIn order for LightRAG to work context should be at least 32k tokens. By default Ollama models have context size of 8k. You can achieve this using one of two ways:\n\n* **Increasing the `num_ctx` parameter in Modelfile**\n\n1. Pull the model:\n\n```bash\nollama pull qwen2\n```\n\n2. Display the model file:\n\n```bash\nollama show --modelfile qwen2 > Modelfile\n```\n\n3. Edit the Modelfile by adding the following line:\n\n```bash\nPARAMETER num_ctx 32768\n```\n\n4. Create the modified model:\n\n```bash\nollama create -f Modelfile qwen2m\n```\n\n* **Setup `num_ctx` via Ollama API**\n\nTiy can use `llm_model_kwargs` param to configure ollama:\n\n```python\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    llm_model_kwargs={\"options\": {\"num_ctx\": 32768}},\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Low RAM GPUs**\n\nIn order to run this experiment on low RAM GPU you should select small model and tune context window (increasing context increase memory consumption). For example, running this ollama example on repurposed mining GPU with 6Gb of RAM required to set context size to 26k while using `gemma2:2b`. It was able to find 197 entities and 19 relations on `book.txt`.\n\n</details>\n<details>\n<summary> <b>LlamaIndex</b> </summary>\n\nLightRAG supports integration with LlamaIndex (`llm/llama_index_impl.py`):\n\n- Integrates with OpenAI and other providers through LlamaIndex\n- See [LlamaIndex Documentation](lightrag/llm/Readme.md) for detailed setup and examples\n\n**Example Usage**\n\n```python\n# Using LlamaIndex with direct OpenAI access\nimport asyncio\nfrom lightrag import LightRAG\nfrom lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom lightrag.utils import setup_logger\n\n# Setup log handler for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=\"your/path\",\n        llm_model_func=llama_index_complete_if_cache,  # LlamaIndex-compatible completion function\n        embedding_func=EmbeddingFunc(    # LlamaIndex-compatible embedding function\n            embedding_dim=1536,\n            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)\n        ),\n    )\n\n    await rag.initialize_storages()\n    return rag\n\ndef main():\n    # Initialize RAG instance\n    rag = asyncio.run(initialize_rag())\n\n    with open(\"./book.txt\", \"r\", encoding=\"utf-8\") as f:\n        rag.insert(f.read())\n\n    # Perform naive search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\n    )\n\n    # Perform local search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\n    )\n\n    # Perform global search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\n    )\n\n    # Perform hybrid search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**For detailed documentation and examples, see:**\n\n- [LlamaIndex Documentation](lightrag/llm/Readme.md)\n- [Direct OpenAI Example](examples/lightrag_llamaindex_direct_demo.py)\n- [LiteLLM Proxy Example](examples/lightrag_llamaindex_litellm_demo.py)\n\n</details>\n\n### Rerank Function Injection\n\nTo enhance retrieval quality, documents can be re-ranked based on a more effective relevance scoring model. The `rerank.py` file provides three Reranker provider driver functions:\n\n* **Cohere / vLLM**: `cohere_rerank`\n* **Jina AI**: `jina_rerank`\n* **Aliyun**: `ali_rerank`\n\nYou can inject one of these functions into the `rerank_model_func` attribute of the LightRAG object. This will enable LightRAG's query function to re-order retrieved text blocks using the injected function. For detailed usage, please refer to the `examples/rerank_example.py` file.\n\n### User Prompt vs. Query\n\nWhen using LightRAG for content queries, avoid combining the search process with unrelated output processing, as this significantly impacts query effectiveness. The `user_prompt` parameter in Query Param is specifically designed to address this issue ‚Äî it does not participate in the RAG retrieval phase, but rather guides the LLM on how to process the retrieved results after the query is completed. Here's how to use it:\n\n```python\n# Create query parameters\nquery_param = QueryParam(\n    mode = \"hybrid\",  # Other modesÔºölocal, global, hybrid, mix, naive\n    user_prompt = \"For diagrams, use mermaid format with English/Pinyin node names and Chinese display labels\",\n)\n\n# Query and process\nresponse_default = rag.query(\n    \"Please draw a character relationship diagram for Scrooge\",\n    param=query_param\n)\nprint(response_default)\n```\n\n### Insert\n\n<details>\n  <summary> <b> Basic Insert </b></summary>\n\n```python\n# Basic Insert\nrag.insert(\"Text\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Batch Insert </b></summary>\n\n```python\n# Basic Batch Insert: Insert multiple texts at once\nrag.insert([\"TEXT1\", \"TEXT2\",...])\n\n# Batch Insert with custom batch size configuration\nrag = LightRAG(\n    ...\n    working_dir=WORKING_DIR,\n    max_parallel_insert = 4\n)\n\nrag.insert([\"TEXT1\", \"TEXT2\", \"TEXT3\", ...])  # Documents will be processed in batches of 4\n```\n\nThe `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.The `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.\n\n</details>\n\n<details>\n  <summary> <b> Insert with ID </b></summary>\n\nIf you want to provide your own IDs for your documents, number of documents and number of IDs must be the same.\n\n```python\n# Insert single text, and provide ID for it\nrag.insert(\"TEXT1\", ids=[\"ID_FOR_TEXT1\"])\n\n# Insert multiple texts, and provide IDs for them\nrag.insert([\"TEXT1\", \"TEXT2\",...], ids=[\"ID_FOR_TEXT1\", \"ID_FOR_TEXT2\"])\n```\n\n</details>\n\n<details>\n  <summary><b>Insert using Pipeline</b></summary>\n\nThe `apipeline_enqueue_documents` and `apipeline_process_enqueue_documents` functions allow you to perform incremental insertion of documents into the graph.\n\nThis is useful for scenarios where you want to process documents in the background while still allowing the main thread to continue executing.\n\nAnd using a routine to process new documents.\n\n```python\nrag = LightRAG(..)\n\nawait rag.apipeline_enqueue_documents(input)\n# Your routine in loop\nawait rag.apipeline_process_enqueue_documents(input)\n```\n\n</details>\n\n<details>\n  <summary><b>Insert Multi-file Type Support</b></summary>\n\nThe `textract` supports reading file types such as TXT, DOCX, PPTX, CSV, and PDF.\n\n```python\nimport textract\n\nfile_path = 'TEXT.pdf'\ntext_content = textract.process(file_path)\n\nrag.insert(text_content.decode('utf-8'))\n```\n\n</details>\n\n<details>\n  <summary><b>Citation Functionality</b></summary>\n\nBy providing file paths, the system ensures that sources can be traced back to their original documents.\n\n```python\n# Define documents and their file paths\ndocuments = [\"Document content 1\", \"Document content 2\"]\nfile_paths = [\"path/to/doc1.txt\", \"path/to/doc2.txt\"]\n\n# Insert documents with file paths\nrag.insert(documents, file_paths=file_paths)\n```\n\n</details>\n\n### Storage\n\nLightRAG uses 4 types of storage for different purposes:\n\n* KV_STORAGE: llm response cache, text chunks, document information\n* VECTOR_STORAGE: entities vectors, relation vectors, chunks vectors\n* GRAPH_STORAGE: entity relation graph\n* DOC_STATUS_STORAGE: document indexing status\n\nEach storage type has several implementations:\n\n* KV_STORAGE supported implementations:\n\n```\nJsonKVStorage    JsonFile (default)\nPGKVStorage      Postgres\nRedisKVStorage   Redis\nMongoKVStorage   MongoDB\n```\n\n* GRAPH_STORAGE supported implementations:\n\n```\nNetworkXStorage      NetworkX (default)\nNeo4JStorage         Neo4J\nPGGraphStorage       PostgreSQL with AGE plugin\nMemgraphStorage.     Memgraph\n```\n\n> Testing has shown that Neo4J delivers superior performance in production environments compared to PostgreSQL with AGE plugin.\n\n* VECTOR_STORAGE supported implementations:\n\n```\nNanoVectorDBStorage         NanoVector (default)\nPGVectorStorage             Postgres\nMilvusVectorDBStorage       Milvus\nFaissVectorDBStorage        Faiss\nQdrantVectorDBStorage       Qdrant\nMongoVectorDBStorage        MongoDB\n```\n\n* DOC_STATUS_STORAGE: supported implementations:\n\n```\nJsonDocStatusStorage        JsonFile (default)\nPGDocStatusStorage          Postgres\nMongoDocStatusStorage       MongoDB\n```\n\nExample connection configurations for each storage type can be found in the `env.example` file. The database instance in the connection string needs to be created by you on the database server beforehand. LightRAG is only responsible for creating tables within the database instance, not for creating the database instance itself. If using Redis as storage, remember to configure automatic data persistence rules for Redis, otherwise data will be lost after the Redis service restarts. If using PostgreSQL, it is recommended to use version 16.6 or above.\n\n<details>\n<summary> <b>Using Neo4J Storage</b> </summary>\n\n* For production level scenarios you will most likely want to leverage an enterprise solution\n* for KG storage. Running Neo4J in Docker is recommended for seamless local testing.\n* See: https://hub.docker.com/_/neo4j\n\n```python\nexport NEO4J_URI=\"neo4j://localhost:7687\"\nexport NEO4J_USERNAME=\"neo4j\"\nexport NEO4J_PASSWORD=\"password\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project be sure to override the default KG: NetworkX\n# by specifying kg=\"Neo4JStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Neo4J implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"Neo4JStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\nsee test_neo4j.py for a working example.\n\n</details>\n\n<details>\n<summary> <b>Using PostgreSQL Storage</b> </summary>\n\nFor production level scenarios you will most likely want to leverage an enterprise solution. PostgreSQL can provide a one-stop solution for you as KV store, VectorDB (pgvector) and GraphDB (apache AGE). PostgreSQL version 16.6 or higher is supported.\n\n* PostgreSQL is lightweight,the whole binary distribution including all necessary plugins can be zipped to 40MB: Ref to [Windows Release](https://github.com/ShanGor/apache-age-windows/releases/tag/PG17%2Fv1.5.0-rc0) as it is easy to install for Linux/Mac.\n* If you prefer docker, please start with this image if you are a beginner to avoid hiccups (Default user password:rag/rag): https://hub.docker.com/r/gzdaniel/postgres-for-rag\n* How to start? Ref to: [examples/lightrag_zhipu_postgres_demo.py](https://github.com/HKUDS/LightRAG/blob/main/examples/lightrag_zhipu_postgres_demo.py)\n* For high-performance graph database requirements, Neo4j is recommended as Apache AGE's performance is not as competitive.\n\n</details>\n\n<details>\n<summary> <b>Using Faiss Storage</b> </summary>\nBefore using Faiss vector database, you must manually install `faiss-cpu` or `faiss-gpu`.\n\n- Install the required dependencies:\n\n```\npip install faiss-cpu\n```\n\nYou can also install `faiss-gpu` if you have GPU support.\n\n- Here we are using `sentence-transformers` but you can also use `OpenAIEmbedding` model with `3072` dimensions.\n\n```python\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    embeddings = model.encode(texts, convert_to_numpy=True)\n    return embeddings\n\n# Initialize LightRAG with the LLM model function and embedding function\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=llm_model_func,\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=embedding_func,\n    ),\n    vector_storage=\"FaissVectorDBStorage\",\n    vector_db_storage_cls_kwargs={\n        \"cosine_better_than_threshold\": 0.3  # Your desired threshold\n    }\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Memgraph for Storage</b> </summary>\n\n* Memgraph is a high-performance, in-memory graph database compatible with the Neo4j Bolt protocol.\n* You can run Memgraph locally using Docker for easy testing:\n* See: https://memgraph.com/download\n\n```python\nexport MEMGRAPH_URI=\"bolt://localhost:7687\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project, override the default KG: NetworkX\n# by specifying kg=\"MemgraphStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Memgraph implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"MemgraphStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using MongoDB Storage</b> </summary>\n\nMongoDB provides a one-stop storage solution for LightRAG. MongoDB offers native KV storage and vector storage. LightRAG uses MongoDB collections to implement a simple graph storage. MongoDB's official vector search functionality (`$vectorSearch`) currently requires their official cloud service MongoDB Atlas. This functionality cannot be used on self-hosted MongoDB Community/Enterprise versions.\n\n</details>\n\n<details>\n<summary> <b>Using Redis Storage</b> </summary>\n\nLightRAG supports using Redis as KV storage. When using Redis storage, attention should be paid to persistence configuration and memory usage configuration. The following is the recommended Redis configuration:\n\n```\nsave 900 1\nsave 300 10\nsave 60 1000\nstop-writes-on-bgsave-error yes\nmaxmemory 4gb\nmaxmemory-policy noeviction\nmaxclients 500\n```\n\n</details>\n\n### Data Isolation Between LightRAG Instances\n\nThe `workspace` parameter ensures data isolation between different LightRAG instances. Once initialized, the `workspace` is immutable and cannot be changed.Here is how workspaces are implemented for different types of storage:\n\n- **For local file-based databases, data isolation is achieved through workspace subdirectories:** `JsonKVStorage`, `JsonDocStatusStorage`, `NetworkXStorage`, `NanoVectorDBStorage`, `FaissVectorDBStorage`.\n- **For databases that store data in collections, it's done by adding a workspace prefix to the collection name:** `RedisKVStorage`, `RedisDocStatusStorage`, `MilvusVectorDBStorage`, `MongoKVStorage`, `MongoDocStatusStorage`, `MongoVectorDBStorage`, `MongoGraphStorage`, `PGGraphStorage`.\n- **For Qdrant vector database, data isolation is achieved through payload-based partitioning (Qdrant's recommended multitenancy approach):** `QdrantVectorDBStorage` uses shared collections with payload filtering for unlimited workspace scalability.\n- **For relational databases, data isolation is achieved by adding a `workspace` field to the tables for logical data separation:** `PGKVStorage`, `PGVectorStorage`, `PGDocStatusStorage`.\n- **For the Neo4j graph database, logical data isolation is achieved through labels:** `Neo4JStorage`\n\nTo maintain compatibility with legacy data, the default workspace for PostgreSQL non-graph storage is `default` and, for PostgreSQL AGE graph storage is null, for Neo4j graph storage is `base` when no workspace is configured. For all external storages, the system provides dedicated workspace environment variables to override the common `WORKSPACE` environment variable configuration. These storage-specific workspace environment variables are: `REDIS_WORKSPACE`, `MILVUS_WORKSPACE`, `QDRANT_WORKSPACE`, `MONGODB_WORKSPACE`, `POSTGRES_WORKSPACE`, `NEO4J_WORKSPACE`.\n\n### AGENTS.md -- Guiding Coding Agents\n\nAGENTS.md is a simple, open format for guiding coding agents (https://agents.md/). It is a dedicated, predictable place to provide the context and instructions to help AI coding agents work on LightRAG project. Different AI coders should not maintain separate guidance files individually. If any AI coder cannot automatically recognize AGENTS.md, symbolic links can be used as a solution. After establishing symbolic links, you can prevent them from being committed to the Git repository by configuring your local `.gitignore_global`.\n\n## Edit Entities and Relations\n\nLightRAG now supports comprehensive knowledge graph management capabilities, allowing you to create, edit, and delete entities and relationships within your knowledge graph.\n\n<details>\n  <summary> <b> Create Entities and Relations </b></summary>\n\n```python\n# Create new entity\nentity = rag.create_entity(\"Google\", {\n    \"description\": \"Google is a multinational technology company specializing in internet-related services and products.\",\n    \"entity_type\": \"company\"\n})\n\n# Create another entity\nproduct = rag.create_entity(\"Gmail\", {\n    \"description\": \"Gmail is an email service developed by Google.\",\n    \"entity_type\": \"product\"\n})\n\n# Create relation between entities\nrelation = rag.create_relation(\"Google\", \"Gmail\", {\n    \"description\": \"Google develops and operates Gmail.\",\n    \"keywords\": \"develops operates service\",\n    \"weight\": 2.0\n})\n```\n\n</details>\n\n<details>\n  <summary> <b> Edit Entities and Relations </b></summary>\n\n```python\n# Edit an existing entity\nupdated_entity = rag.edit_entity(\"Google\", {\n    \"description\": \"Google is a subsidiary of Alphabet Inc., founded in 1998.\",\n    \"entity_type\": \"tech_company\"\n})\n\n# Rename an entity (with all its relationships properly migrated)\nrenamed_entity = rag.edit_entity(\"Gmail\", {\n    \"entity_name\": \"Google Mail\",\n    \"description\": \"Google Mail (formerly Gmail) is an email service.\"\n})\n\n# Edit a relation between entities\nupdated_relation = rag.edit_relation(\"Google\", \"Google Mail\", {\n    \"description\": \"Google created and maintains Google Mail service.\",\n    \"keywords\": \"creates maintains email service\",\n    \"weight\": 3.0\n})\n```\n\nAll operations are available in both synchronous and asynchronous versions. The asynchronous versions have the prefix \"a\" (e.g., `acreate_entity`, `aedit_relation`).\n\n</details>\n\n<details>\n  <summary> <b> Insert Custom KG </b></summary>\n\n```python\ncustom_kg = {\n        \"chunks\": [\n            {\n                \"content\": \"Alice and Bob are collaborating on quantum computing research.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\",\n            }\n        ],\n        \"entities\": [\n            {\n                \"entity_name\": \"Alice\",\n                \"entity_type\": \"person\",\n                \"description\": \"Alice is a researcher specializing in quantum physics.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Bob\",\n                \"entity_type\": \"person\",\n                \"description\": \"Bob is a mathematician.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Quantum Computing\",\n                \"entity_type\": \"technology\",\n                \"description\": \"Quantum computing utilizes quantum mechanical phenomena for computation.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ],\n        \"relationships\": [\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Bob\",\n                \"description\": \"Alice and Bob are research partners.\",\n                \"keywords\": \"collaboration research\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Alice conducts research on quantum computing.\",\n                \"keywords\": \"research expertise\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Bob\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Bob researches quantum computing.\",\n                \"keywords\": \"research application\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ]\n    }\n\nrag.insert_custom_kg(custom_kg)\n```\n\n</details>\n\n<details>\n  <summary> <b>Other Entity and Relation Operations</b></summary>\n\n- **create_entity**: Creates a new entity with specified attributes\n- **edit_entity**: Updates an existing entity's attributes or renames it\n\n\n- **create_relation**: Creates a new relation between existing entities\n- **edit_relation**: Updates an existing relation's attributes\n\nThese operations maintain data consistency across both the graph database and vector database components, ensuring your knowledge graph remains coherent.\n\n</details>\n\n## Delete Functions\n\nLightRAG provides comprehensive deletion capabilities, allowing you to delete documents, entities, and relationships.\n\n<details>\n<summary> <b>Delete Entities</b> </summary>\n\nYou can delete entities by their name along with all associated relationships:\n\n```python\n# Delete entity and all its relationships (synchronous version)\nrag.delete_by_entity(\"Google\")\n\n# Asynchronous version\nawait rag.adelete_by_entity(\"Google\")\n```\n\nWhen deleting an entity:\n- Removes the entity node from the knowledge graph\n- Deletes all associated relationships\n- Removes related embedding vectors from the vector database\n- Maintains knowledge graph integrity\n\n</details>\n\n<details>\n<summary> <b>Delete Relations</b> </summary>\n\nYou can delete relationships between two specific entities:\n\n```python\n# Delete relationship between two entities (synchronous version)\nrag.delete_by_relation(\"Google\", \"Gmail\")\n\n# Asynchronous version\nawait rag.adelete_by_relation(\"Google\", \"Gmail\")\n```\n\nWhen deleting a relationship:\n- Removes the specified relationship edge\n- Deletes the relationship's embedding vector from the vector database\n- Preserves both entity nodes and their other relationships\n\n</details>\n\n<details>\n<summary> <b>Delete by Document ID</b> </summary>\n\nYou can delete an entire document and all its related knowledge through document ID:\n\n```python\n# Delete by document ID (asynchronous version)\nawait rag.adelete_by_doc_id(\"doc-12345\")\n```\n\nOptimized processing when deleting by document ID:\n- **Smart Cleanup**: Automatically identifies and removes entities and relationships that belong only to this document\n- **Preserve Shared Knowledge**: If entities or relationships exist in other documents, they are preserved and their descriptions are rebuilt\n- **Cache Optimization**: Clears related LLM cache to reduce storage overhead\n- **Incremental Rebuilding**: Reconstructs affected entity and relationship descriptions from remaining documents\n\nThe deletion process includes:\n1. Delete all text chunks related to the document\n2. Identify and delete entities and relationships that belong only to this document\n3. Rebuild entities and relationships that still exist in other documents\n4. Update all related vector indexes\n5. Clean up document status records\n\nNote: Deletion by document ID is an asynchronous operation as it involves complex knowledge graph reconstruction processes.\n\n</details>\n\n**Important Reminders:**\n\n1. **Irreversible Operations**: All deletion operations are irreversible, please use with caution\n2. **Performance Considerations**: Deleting large amounts of data may take some time, especially deletion by document ID\n3. **Data Consistency**: Deletion operations automatically maintain consistency between the knowledge graph and vector database\n4. **Backup Recommendations**: Consider backing up data before performing important deletion operations\n\n**Batch Deletion Recommendations:**\n- For batch deletion operations, consider using asynchronous methods for better performance\n- For large-scale deletions, consider processing in batches to avoid excessive system load\n\n## Entity Merging\n\n<details>\n<summary> <b>Merge Entities and Their Relationships</b> </summary>\n\nLightRAG now supports merging multiple entities into a single entity, automatically handling all relationships:\n\n```python\n# Basic entity merging\nrag.merge_entities(\n    source_entities=[\"Artificial Intelligence\", \"AI\", \"Machine Intelligence\"],\n    target_entity=\"AI Technology\"\n)\n```\n\nWith custom merge strategy:\n\n```python\n# Define custom merge strategy for different fields\nrag.merge_entities(\n    source_entities=[\"John Smith\", \"Dr. Smith\", \"J. Smith\"],\n    target_entity=\"John Smith\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"entity_type\": \"keep_first\",   # Keep the entity type from the first entity\n        \"source_id\": \"join_unique\"     # Combine all unique source IDs\n    }\n)\n```\n\nWith custom target entity data:\n\n```python\n# Specify exact values for the merged entity\nrag.merge_entities(\n    source_entities=[\"New York\", \"NYC\", \"Big Apple\"],\n    target_entity=\"New York City\",\n    target_entity_data={\n        \"entity_type\": \"LOCATION\",\n        \"description\": \"New York City is the most populous city in the United States.\",\n    }\n)\n```\n\nAdvanced usage combining both approaches:\n\n```python\n# Merge company entities with both strategy and custom data\nrag.merge_entities(\n    source_entities=[\"Microsoft Corp\", \"Microsoft Corporation\", \"MSFT\"],\n    target_entity=\"Microsoft\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"source_id\": \"join_unique\"     # Combine source IDs\n    },\n    target_entity_data={\n        \"entity_type\": \"ORGANIZATION\",\n    }\n)\n```\n\nWhen merging entities:\n\n* All relationships from source entities are redirected to the target entity\n* Duplicate relationships are intelligently merged\n* Self-relationships (loops) are prevented\n* Source entities are removed after merging\n* Relationship weights and attributes are preserved\n\n</details>\n\n## Multimodal Document Processing (RAG-Anything Integration)\n\nLightRAG now seamlessly integrates with [RAG-Anything](https://github.com/HKUDS/RAG-Anything), a comprehensive **All-in-One Multimodal Document Processing RAG system** built specifically for LightRAG. RAG-Anything enables advanced parsing and retrieval-augmented generation (RAG) capabilities, allowing you to handle multimodal documents seamlessly and extract structured content‚Äîincluding text, images, tables, and formulas‚Äîfrom various document formats for integration into your RAG pipeline.\n\n**Key Features:**\n- **End-to-End Multimodal Pipeline**: Complete workflow from document ingestion and parsing to intelligent multimodal query answering\n- **Universal Document Support**: Seamless processing of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse file formats\n- **Specialized Content Analysis**: Dedicated processors for images, tables, mathematical equations, and heterogeneous content types\n- **Multimodal Knowledge Graph**: Automatic entity extraction and cross-modal relationship discovery for enhanced understanding\n- **Hybrid Intelligent Retrieval**: Advanced search capabilities spanning textual and multimodal content with contextual understanding\n\n**Quick Start:**\n1. Install RAG-Anything:\n   ```bash\n   pip install raganything\n   ```\n2. Process multimodal documents:\n    <details>\n    <summary> <b> RAGAnything Usage Example </b></summary>\n\n    ```python\n        import asyncio\n        from raganything import RAGAnything\n        from lightrag import LightRAG\n        from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n        from lightrag.utils import EmbeddingFunc\n        import os\n\n        async def load_existing_lightrag():\n            # First, create or load an existing LightRAG instance\n            lightrag_working_dir = \"./existing_lightrag_storage\"\n\n            # Check if previous LightRAG instance exists\n            if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):\n                print(\"‚úÖ Found existing LightRAG instance, loading...\")\n            else:\n                print(\"‚ùå No existing LightRAG instance found, will create new one\")\n\n            # Create/Load LightRAG instance with your configurations\n            lightrag_instance = LightRAG(\n                working_dir=lightrag_working_dir,\n                llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ),\n                embedding_func=EmbeddingFunc(\n                    embedding_dim=3072,\n                    func=lambda texts: openai_embed(\n                        texts,\n                        model=\"text-embedding-3-large\",\n                        api_key=api_key,\n                        base_url=base_url,\n                    ),\n                )\n            )\n\n            # Initialize storage (this will load existing data if available)\n            await lightrag_instance.initialize_storages()\n\n            # Now initialize RAGAnything with the existing LightRAG instance\n            rag = RAGAnything(\n                lightrag=lightrag_instance,  # Pass the existing LightRAG instance\n                # Only need vision model for multimodal processing\n                vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(\n                    \"gpt-4o\",\n                    \"\",\n                    system_prompt=None,\n                    history_messages=[],\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_prompt} if system_prompt else None,\n                        {\"role\": \"user\", \"content\": [\n                            {\"type\": \"text\", \"text\": prompt},\n                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n                        ]} if image_data else {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ) if image_data else openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                )\n                # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance\n            )\n\n            # Query the existing knowledge base\n            result = await rag.query_with_multimodal(\n                \"What data has been processed in this LightRAG instance?\",\n                mode=\"hybrid\"\n            )\n            print(\"Query result:\", result)\n\n            # Add new multimodal documents to the existing LightRAG instance\n            await rag.process_document_complete(\n                file_path=\"path/to/new/multimodal_document.pdf\",\n                output_dir=\"./output\"\n            )\n\n        if __name__ == \"__main__\":\n            asyncio.run(load_existing_lightrag())\n    ```\n    </details>\n\nFor detailed documentation and advanced usage, please refer to the [RAG-Anything repository](https://github.com/HKUDS/RAG-Anything).\n\n## Token Usage Tracking\n\n<details>\n<summary> <b>Overview and Usage</b> </summary>\n\nLightRAG provides a TokenTracker tool to monitor and manage token consumption by large language models. This feature is particularly useful for controlling API costs and optimizing performance.\n\n### Usage\n\n```python\nfrom lightrag.utils import TokenTracker\n\n# Create TokenTracker instance\ntoken_tracker = TokenTracker()\n\n# Method 1: Using context manager (Recommended)\n# Suitable for scenarios requiring automatic token usage tracking\nwith token_tracker:\n    result1 = await llm_model_func(\"your question 1\")\n    result2 = await llm_model_func(\"your question 2\")\n\n# Method 2: Manually adding token usage records\n# Suitable for scenarios requiring more granular control over token statistics\ntoken_tracker.reset()\n\nrag.insert()\n\nrag.query(\"your question 1\", param=QueryParam(mode=\"naive\"))\nrag.query(\"your question 2\", param=QueryParam(mode=\"mix\"))\n\n# Display total token usage (including insert and query operations)\nprint(\"Token usage:\", token_tracker.get_usage())\n```\n\n### Usage Tips\n- Use context managers for long sessions or batch operations to automatically track all token consumption\n- For scenarios requiring segmented statistics, use manual mode and call reset() when appropriate\n- Regular checking of token usage helps detect abnormal consumption early\n- Actively use this feature during development and testing to optimize production costs\n\n### Practical Examples\nYou can refer to these examples for implementing token tracking:\n- `examples/lightrag_gemini_track_token_demo.py`: Token tracking example using Google Gemini model\n- `examples/lightrag_siliconcloud_track_token_demo.py`: Token tracking example using SiliconCloud model\n\nThese examples demonstrate how to effectively use the TokenTracker feature with different models and scenarios.\n\n</details>\n\n## Data Export Functions\n\n### Overview\n\nLightRAG allows you to export your knowledge graph data in various formats for analysis, sharing, and backup purposes. The system supports exporting entities, relations, and relationship data.\n\n### Export Functions\n\n<details>\n  <summary> <b> Basic Usage </b></summary>\n\n```python\n# Basic CSV export (default format)\nrag.export_data(\"knowledge_graph.csv\")\n\n# Specify any format\nrag.export_data(\"output.xlsx\", file_format=\"excel\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Different File Formats supported </b></summary>\n\n```python\n#Export data in CSV format\nrag.export_data(\"graph_data.csv\", file_format=\"csv\")\n\n# Export data in Excel sheet\nrag.export_data(\"graph_data.xlsx\", file_format=\"excel\")\n\n# Export data in markdown format\nrag.export_data(\"graph_data.md\", file_format=\"md\")\n\n# Export data in Text\nrag.export_data(\"graph_data.txt\", file_format=\"txt\")\n```\n</details>\n\n<details>\n  <summary> <b> Additional Options </b></summary>\n\nInclude vector embeddings in the export (optional):\n\n```python\nrag.export_data(\"complete_data.csv\", include_vector_data=True)\n```\n</details>\n\n### Data Included in Export\n\nAll exports include:\n\n* Entity information (names, IDs, metadata)\n* Relation data (connections between entities)\n* Relationship information from vector database\n\n## Cache\n\n<details>\n  <summary> <b>Clear Cache</b> </summary>\n\nYou can clear the LLM response cache with different modes:\n\n```python\n# Clear all cache\nawait rag.aclear_cache()\n\n# Clear local mode cache\nawait rag.aclear_cache(modes=[\"local\"])\n\n# Clear extraction cache\nawait rag.aclear_cache(modes=[\"default\"])\n\n# Clear multiple modes\nawait rag.aclear_cache(modes=[\"local\", \"global\", \"hybrid\"])\n\n# Synchronous version\nrag.clear_cache(modes=[\"local\"])\n```\n\nValid modes are:\n\n- `\"default\"`: Extraction cache\n- `\"naive\"`: Naive search cache\n- `\"local\"`: Local search cache\n- `\"global\"`: Global search cache\n- `\"hybrid\"`: Hybrid search cache\n- `\"mix\"`: Mix search cache\n\n</details>\n\n## Troubleshooting\n\n### Common Initialization Errors\n\nIf you encounter these errors when using LightRAG:\n\n1. **`AttributeError: __aenter__`**\n   - **Cause**: Storage backends not initialized\n   - **Solution**: Call `await rag.initialize_storages()` after creating the LightRAG instance\n\n2. **`KeyError: 'history_messages'`**\n   - **Cause**: Pipeline status not initialized\n   - **Solution**: Call `\n3. **Both errors in sequence**\n   - **Cause**: Neither initialization method was called\n   - **Solution**: Always follow this pattern:\n   ```python\n   rag = LightRAG(...)\n   await rag.initialize_storages()   ```\n\n### Model Switching Issues\n\nWhen switching between different embedding models, you must clear the data directory to avoid errors. The only file you may want to preserve is `kv_store_llm_response_cache.json` if you wish to retain the LLM cache.\n\n## LightRAG API\n\nThe LightRAG Server is designed to provide Web UI and API support.  **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n## Graph Visualization\n\nThe LightRAG Server offers a comprehensive knowledge graph visualization feature. It supports various gravity layouts, node queries, subgraph filtering, and more. **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n![iShot_2025-03-23_12.40.08](./README.assets/iShot_2025-03-23_12.40.08.png)\n\n## Langfuse observability integration\n\nLangfuse provides a drop-in replacement for the OpenAI client that automatically tracks all LLM interactions, enabling developers to monitor, debug, and optimize their RAG systems without code changes.\n\n### Installation with Langfuse option\n\n```\npip install lightrag-hku\npip install lightrag-hku[observability]\n\n# Or install from souce code with debug mode enabled\npip install -e .\npip install -e \".[observability]\"\n```\n\n### Config Langfuse env vars\n\nmodify .env file:\n\n```\n## Langfuse Observability (Optional)\n# LLM observability and tracing platform\n# Install with: pip install lightrag-hku[observability]\n# Sign up at: https://cloud.langfuse.com or self-host\nLANGFUSE_SECRET_KEY=\"\"\nLANGFUSE_PUBLIC_KEY=\"\"\nLANGFUSE_HOST=\"https://cloud.langfuse.com\"  # or your self-hosted instance\nLANGFUSE_ENABLE_TRACE=true\n```\n\n### Langfuse Usage\n\nOnce installed and configured, Langfuse automatically traces all OpenAI LLM calls. Langfuse dashboard features include:\n\n- **Tracing**: View complete LLM call chains\n- **Analytics**: Token usage, latency, cost metrics\n- **Debugging**: Inspect prompts and responses\n- **Evaluation**: Compare model outputs\n- **Monitoring**: Real-time alerting\n\n### Important Notice\n\n**Note**: LightRAG currently only integrates OpenAI-compatible API calls with Langfuse. APIs such as Ollama, Azure, and AWS Bedrock are not yet supported for Langfuse observability.\n\n## RAGAS-based Evaluation\n\n**RAGAS** (Retrieval Augmented Generation Assessment) is a framework for reference-free evaluation of RAG systems using LLMs. There is an evaluation script based on RAGAS. For detailed information, please refer to [RAGAS-based Evaluation Framework](lightrag/evaluation/README.md).\n\n## Evaluation\n\n### Dataset\n\nThe dataset used in LightRAG can be downloaded from [TommyChien/UltraDomain](https://huggingface.co/datasets/TommyChien/UltraDomain).\n\n### Generate Query\n\nLightRAG uses the following prompt to generate high-level queries, with the corresponding code in `examples/generate_query.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\nGiven the following description of a dataset:\n\n{description}\n\nPlease identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.\n\nOutput the results in the following structure:\n- User 1: [user description]\n    - Task 1: [task description]\n        - Question 1:\n        - Question 2:\n        - Question 3:\n        - Question 4:\n        - Question 5:\n    - Task 2: [task description]\n        ...\n    - Task 5: [task description]\n- User 2: [user description]\n    ...\n- User 5: [user description]\n    ...\n```\n\n</details>\n\n### Batch Eval\n\nTo evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt, with the specific code available in `reproduce/batch_eval.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\n---Role---\nYou are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n---Goal---\nYou will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n\n- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?\n- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?\n- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?\n\nFor each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.\n\nHere is the question:\n{query}\n\nHere are the two answers:\n\n**Answer 1:**\n{answer1}\n\n**Answer 2:**\n{answer2}\n\nEvaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.\n\nOutput your evaluation in the following JSON format:\n\n{{\n    \"Comprehensiveness\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Empowerment\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Overall Winner\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Summarize why this answer is the overall winner based on the three criteria]\"\n    }}\n}}\n```\n\n</details>\n\n### Overall Performance Table\n\n|                      |**Agriculture**|            |**CS**|            |**Legal**|            |**Mix**|            |\n|----------------------|---------------|------------|------|------------|---------|------------|-------|------------|\n|                      |NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|\n|**Comprehensiveness**|32.4%|**67.6%**|38.4%|**61.6%**|16.4%|**83.6%**|38.8%|**61.2%**|\n|**Diversity**|23.6%|**76.4%**|38.0%|**62.0%**|13.6%|**86.4%**|32.4%|**67.6%**|\n|**Empowerment**|32.4%|**67.6%**|38.8%|**61.2%**|16.4%|**83.6%**|42.8%|**57.2%**|\n|**Overall**|32.4%|**67.6%**|38.8%|**61.2%**|15.2%|**84.8%**|40.0%|**60.0%**|\n|                      |RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|\n|**Comprehensiveness**|31.6%|**68.4%**|38.8%|**61.2%**|15.2%|**84.8%**|39.2%|**60.8%**|\n|**Diversity**|29.2%|**70.8%**|39.2%|**60.8%**|11.6%|**88.4%**|30.8%|**69.2%**|\n|**Empowerment**|31.6%|**68.4%**|36.4%|**63.6%**|15.2%|**84.8%**|42.4%|**57.6%**|\n|**Overall**|32.4%|**67.6%**|38.0%|**62.0%**|14.4%|**85.6%**|40.0%|**60.0%**|\n|                      |HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|\n|**Comprehensiveness**|26.0%|**74.0%**|41.6%|**58.4%**|26.8%|**73.2%**|40.4%|**59.6%**|\n|**Diversity**|24.0%|**76.0%**|38.8%|**61.2%**|20.0%|**80.0%**|32.4%|**67.6%**|\n|**Empowerment**|25.2%|**74.8%**|40.8%|**59.2%**|26.0%|**74.0%**|46.0%|**54.0%**|\n|**Overall**|24.8%|**75.2%**|41.6%|**58.4%**|26.4%|**73.6%**|42.4%|**57.6%**|\n|                      |GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|\n|**Comprehensiveness**|45.6%|**54.4%**|48.4%|**51.6%**|48.4%|**51.6%**|**50.4%**|49.6%|\n|**Diversity**|22.8%|**77.2%**|40.8%|**59.2%**|26.4%|**73.6%**|36.0%|**64.0%**|\n|**Empowerment**|41.2%|**58.8%**|45.2%|**54.8%**|43.6%|**56.4%**|**50.8%**|49.2%|\n|**Overall**|45.2%|**54.8%**|48.0%|**52.0%**|47.2%|**52.8%**|**50.4%**|49.6%|\n\n## Reproduce\n\nAll the code can be found in the `./reproduce` directory.\n\n### Step-0 Extract Unique Contexts\n\nFirst, we need to extract unique contexts in the datasets.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_unique_contexts(input_directory, output_directory):\n\n    os.makedirs(output_directory, exist_ok=True)\n\n    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))\n    print(f\"Found {len(jsonl_files)} JSONL files.\")\n\n    for file_path in jsonl_files:\n        filename = os.path.basename(file_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_unique_contexts.json\"\n        output_path = os.path.join(output_directory, output_filename)\n\n        unique_contexts_dict = {}\n\n        print(f\"Processing file: {filename}\")\n\n        try:\n            with open(file_path, 'r', encoding='utf-8') as infile:\n                for line_number, line in enumerate(infile, start=1):\n                    line = line.strip()\n                    if not line:\n                        continue\n                    try:\n                        json_obj = json.loads(line)\n                        context = json_obj.get('context')\n                        if context and context not in unique_contexts_dict:\n                            unique_contexts_dict[context] = None\n                    except json.JSONDecodeError as e:\n                        print(f\"JSON decoding error in file {filename} at line {line_number}: {e}\")\n        except FileNotFoundError:\n            print(f\"File not found: {filename}\")\n            continue\n        except Exception as e:\n            print(f\"An error occurred while processing file {filename}: {e}\")\n            continue\n\n        unique_contexts_list = list(unique_contexts_dict.keys())\n        print(f\"There are {len(unique_contexts_list)} unique `context` entries in the file {filename}.\")\n\n        try:\n            with open(output_path, 'w', encoding='utf-8') as outfile:\n                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)\n            print(f\"Unique `context` entries have been saved to: {output_filename}\")\n        except Exception as e:\n            print(f\"An error occurred while saving to the file {output_filename}: {e}\")\n\n    print(\"All files have been processed.\")\n\n```\n\n</details>\n\n### Step-1 Insert Contexts\n\nFor the extracted contexts, we insert them into the LightRAG system.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef insert_text(rag, file_path):\n    with open(file_path, mode='r') as f:\n        unique_contexts = json.load(f)\n\n    retries = 0\n    max_retries = 3\n    while retries < max_retries:\n        try:\n            rag.insert(unique_contexts)\n            break\n        except Exception as e:\n            retries += 1\n            print(f\"Insertion failed, retrying ({retries}/{max_retries}), error: {e}\")\n            time.sleep(10)\n    if retries == max_retries:\n        print(\"Insertion failed after exceeding the maximum number of retries\")\n```\n\n</details>\n\n### Step-2 Generate Queries\n\nWe extract tokens from the first and the second half of each context in the dataset, then combine them as dataset descriptions to generate queries.\n\n<details>\n<summary> Code </summary>\n\n```python\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\ndef get_summary(context, tot_tokens=2000):\n    tokens = tokenizer.tokenize(context)\n    half_tokens = tot_tokens // 2\n\n    start_tokens = tokens[1000:1000 + half_tokens]\n    end_tokens = tokens[-(1000 + half_tokens):1000]\n\n    summary_tokens = start_tokens + end_tokens\n    summary = tokenizer.convert_tokens_to_string(summary_tokens)\n\n    return summary\n```\n\n</details>\n\n### Step-3 Query\n\nFor the queries generated in Step-2, we will extract them and query LightRAG.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_queries(file_path):\n    with open(file_path, 'r') as f:\n        data = f.read()\n\n    data = data.replace('**', '')\n\n    queries = re.findall(r'- Question \\d+: (.+)', data)\n\n    return queries\n```\n\n</details>\n\n## üîó Related Projects\n\n*Ecosystem & Extensions*\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/RAG-Anything\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üì∏</span>\n          </div>\n          <b>RAG-Anything</b><br>\n          <sub>Multimodal RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/VideoRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üé•</span>\n          </div>\n          <b>VideoRAG</b><br>\n          <sub>Extreme Long-Context Video RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/MiniRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">‚ú®</span>\n          </div>\n          <b>MiniRAG</b><br>\n          <sub>Extremely Simple RAG</sub>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## ‚≠ê Star History\n\n<a href=\"https://star-history.com/#HKUDS/LightRAG&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n </picture>\n</a>\n\n## ü§ù Contribution\n\n<div align=\"center\">\n  We thank all our contributors for their valuable contributions.\n</div>\n\n<div align=\"center\">\n  <a href=\"https://github.com/HKUDS/LightRAG/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=HKUDS/LightRAG\" style=\"border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);\" />\n  </a>\n</div>\n\n---\n\n\n## üìñ Citation\n\n```python\n@article{guo2024lightrag,\ntitle={LightRAG: Simple and Fast Retrieval-Augmented Generation},\nauthor={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},\nyear={2024},\neprint={2410.05779},\narchivePrefix={arXiv},\nprimaryClass={cs.IR}\n}\n```\n\n---\n\n<div align=\"center\" style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;\">\n  <div>\n    <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"500\">\n  </div>\n  <div style=\"margin-top: 20px;\">\n    <a href=\"https://github.com/HKUDS/LightRAG\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/issues\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/discussions\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n  </div>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);\">\n    <div style=\"display: flex; justify-content: center; align-items: center; gap: 15px;\">\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n      <span style=\"color: #00d9ff; font-size: 18px;\">Thank you for visiting LightRAG!</span>\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n    </div>\n  </div>\n</div>\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/HKUDS/LightRAG",
          "homepage": "https://arxiv.org/abs/2410.05779",
          "language": "Python",
          "forks": 3507,
          "open_issues": 170,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/118165258?v=4",
      "velocity": 26268,
      "is_rising_star": true,
      "heatScore": 7883.464636756028,
      "popularityScore": 23880
    },
    {
      "id": "github-asgeirtj-system_prompts_leaks",
      "name": "system_prompts_leaks",
      "author": "asgeirtj",
      "description": "Collection of extracted System Prompts from popular chatbots like ChatGPT, Claude & Gemini",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "chatbots",
        "chatgpt",
        "claude",
        "gemini",
        "generative-ai",
        "google-deepmind",
        "large-language-models",
        "llm",
        "openai",
        "prompt-engineering",
        "prompt-injection",
        "prompts",
        "general-dialogue-qa"
      ],
      "likes": 47548,
      "downloads": 47548,
      "lastModified": "2025-11-20T14:37:50Z",
      "lastModifiedTimestamp": 1763649470000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/asgeirtj/system_prompts_leaks",
          "homepage": "",
          "language": "JavaScript",
          "forks": 3636,
          "open_issues": 22,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/27446620?v=4",
      "velocity": 26151.4,
      "is_rising_star": true,
      "heatScore": 7848.483284367927,
      "popularityScore": 23774
    },
    {
      "id": "github-Fosowl-agenticSeek",
      "name": "agenticSeek",
      "author": "Fosowl",
      "description": "Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "autonomous-agents",
        "deepseek-r1",
        "llm",
        "llm-agents",
        "voice-assistant",
        "code-generation-assistance"
      ],
      "likes": 47425,
      "downloads": 47425,
      "lastModified": "2025-11-20T15:52:39Z",
      "lastModifiedTimestamp": 1763653959000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Fosowl/agenticSeek",
          "homepage": "http://agenticseek.tech",
          "language": "Python",
          "forks": 2570,
          "open_issues": 36,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/49105846?v=4",
      "velocity": 26083.2,
      "is_rising_star": true,
      "heatScore": 7828.022490550911,
      "popularityScore": 23712
    }
  ],
  "trending": [
    {
      "id": "github-ollama-ollama",
      "name": "ollama",
      "author": "ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "task": "tool",
      "tags": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "likes": 312577,
      "downloads": 312577,
      "lastModified": "2025-11-20T15:51:00Z",
      "lastModifiedTimestamp": 1763653860000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ollama/ollama",
          "homepage": "https://ollama.com",
          "language": "Go",
          "forks": 13697,
          "open_issues": 2258,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/151674099?v=4",
      "velocity": 171916.8,
      "is_rising_star": true,
      "heatScore": 51578.675749888665,
      "popularityScore": 156288
    },
    {
      "id": "github-huggingface-transformers",
      "name": "transformers",
      "author": "huggingface",
      "description": "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
      "task": "tool",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "likes": 305558,
      "downloads": 305558,
      "lastModified": "2025-11-20T15:45:12Z",
      "lastModifiedTimestamp": 1763653512000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/transformers",
          "homepage": "https://huggingface.co/transformers",
          "language": "Python",
          "forks": 31187,
          "open_issues": 2121,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 168056.9,
      "is_rising_star": true,
      "heatScore": 50420.69884655398,
      "popularityScore": 152779
    },
    {
      "id": "github-langflow-ai-langflow",
      "name": "langflow",
      "author": "langflow-ai",
      "description": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
      "task": "tool",
      "tags": [
        "agents",
        "chatgpt",
        "generative-ai",
        "large-language-models",
        "multiagent",
        "react-flow"
      ],
      "likes": 277624,
      "downloads": 277624,
      "lastModified": "2025-11-20T15:36:15Z",
      "lastModifiedTimestamp": 1763652975000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langflow-ai/langflow",
          "homepage": "http://www.langflow.org",
          "language": "Python",
          "forks": 8027,
          "open_issues": 902,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85702467?v=4",
      "velocity": 152693.2,
      "is_rising_star": true,
      "heatScore": 45811.559701098144,
      "popularityScore": 138812
    },
    {
      "id": "github-f-awesome-chatgpt-prompts",
      "name": "awesome-chatgpt-prompts",
      "author": "f",
      "description": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
      "task": "tool",
      "tags": [
        "bots",
        "chatbot",
        "chatgpt",
        "chatgpt-api",
        "language",
        "general-dialogue-qa"
      ],
      "likes": 273424,
      "downloads": 273424,
      "lastModified": "2025-11-20T15:23:26Z",
      "lastModifiedTimestamp": 1763652206000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/f/awesome-chatgpt-prompts",
          "homepage": "https://prompts.chat",
          "language": "JavaScript",
          "forks": 18184,
          "open_issues": 290,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/196477?v=4",
      "velocity": 150383.2,
      "is_rising_star": true,
      "heatScore": 45118.55506686943,
      "popularityScore": 136712
    },
    {
      "id": "allenai/wildguard",
      "name": "wildguard",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "mistral",
        "text-generation",
        "classifier",
        "safety",
        "moderation",
        "llm",
        "lm",
        "en",
        "dataset:allenai/wildguardmix",
        "arxiv:2406.18495",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "likes": 350,
      "downloads": 241340,
      "lastModifiedTimestamp": null,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/allenai/wildguard",
          "files": [],
          "modelId": "allenai/wildguard"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/allenai/wildguard",
          "files": [],
          "modelId": "allenai/wildguard"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/allenai/wildguard",
          "files": [],
          "modelId": "allenai/wildguard"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/allenai/wildguard",
          "files": [],
          "modelId": "allenai/wildguard"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/allenai/wildguard",
          "files": [],
          "modelId": "allenai/wildguard"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 48373
    },
    {
      "id": "github-langchain-ai-langchain",
      "name": "langchain",
      "author": "langchain-ai",
      "description": "ü¶úüîó The platform for reliable agents.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "aiagentframework",
        "anthropic",
        "chatgpt",
        "enterprise",
        "framework",
        "gemini",
        "generative-ai",
        "langchain",
        "llm",
        "multiagent",
        "open-source",
        "openai",
        "pydantic",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 240248,
      "downloads": 240248,
      "lastModified": "2025-11-20T15:50:06Z",
      "lastModifiedTimestamp": 1763653806000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain-ai/langchain",
          "homepage": "https://docs.langchain.com/oss/python/langchain/",
          "language": "Python",
          "forks": 19786,
          "open_issues": 241,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
      "velocity": 132136.4,
      "is_rising_star": true,
      "heatScore": 39644.47574338047,
      "popularityScore": 120124
    },
    {
      "id": "github-langgenius-dify",
      "name": "dify",
      "author": "langgenius",
      "description": "Production-ready platform for agentic workflow development.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-ai",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "automation",
        "gemini",
        "genai",
        "gpt",
        "gpt-4",
        "llm",
        "low-code",
        "mcp",
        "nextjs",
        "no-code",
        "openai",
        "orchestration",
        "python",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 238804,
      "downloads": 238804,
      "lastModified": "2025-11-20T15:50:01Z",
      "lastModifiedTimestamp": 1763653801000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langgenius/dify",
          "homepage": "https://dify.ai",
          "language": "TypeScript",
          "forks": 18511,
          "open_issues": 682,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127165244?v=4",
      "velocity": 131342.2,
      "is_rising_star": true,
      "heatScore": 39406.21391066701,
      "popularityScore": 119402
    },
    {
      "id": "github-open-webui-open-webui",
      "name": "open-webui",
      "author": "open-webui",
      "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
      "task": "tool",
      "tags": [
        "ai",
        "llm",
        "llm-ui",
        "llm-webui",
        "llms",
        "mcp",
        "ollama",
        "ollama-webui",
        "open-webui",
        "openai",
        "openapi",
        "rag",
        "self-hosted",
        "ui",
        "webui",
        "rag-knowledge-base-qa"
      ],
      "likes": 231540,
      "downloads": 231540,
      "lastModified": "2025-11-20T15:46:30Z",
      "lastModifiedTimestamp": 1763653590000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/open-webui/open-webui",
          "homepage": "https://openwebui.com",
          "language": "JavaScript",
          "forks": 16219,
          "open_issues": 304,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/158137808?v=4",
      "velocity": 127347,
      "is_rising_star": true,
      "heatScore": 38207.64451984924,
      "popularityScore": 115770
    },
    {
      "id": "github-microsoft-generative-ai-for-beginners",
      "name": "generative-ai-for-beginners",
      "author": "microsoft",
      "description": "21 Lessons, Get Started Building with Generative AI ",
      "task": "tool",
      "tags": [
        "ai",
        "azure",
        "chatgpt",
        "dall-e",
        "generative-ai",
        "generativeai",
        "gpt",
        "language-model",
        "llms",
        "microsoft-for-beginners",
        "openai",
        "prompt-engineering",
        "semantic-search",
        "transformers"
      ],
      "likes": 204088,
      "downloads": 204088,
      "lastModified": "2025-11-20T15:11:49Z",
      "lastModifiedTimestamp": 1763651509000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/generative-ai-for-beginners",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 54251,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 112248.4,
      "is_rising_star": true,
      "heatScore": 33678.02615421101,
      "popularityScore": 102044
    },
    {
      "id": "github-x1xhlol-system-prompts-and-models-of-ai-tools",
      "name": "system-prompts-and-models-of-ai-tools",
      "author": "x1xhlol",
      "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
      "task": "tool",
      "tags": [
        "ai",
        "bolt",
        "cluely",
        "copilot",
        "cursor",
        "cursorai",
        "devin",
        "github-copilot",
        "lovable",
        "open-source",
        "perplexity",
        "replit",
        "system-prompts",
        "trae",
        "trae-ai",
        "trae-ide",
        "v0",
        "vscode",
        "windsurf",
        "windsurf-ai",
        "code-generation-assistance"
      ],
      "likes": 193011,
      "downloads": 193011,
      "lastModified": "2025-11-20T15:52:37Z",
      "lastModifiedTimestamp": 1763653957000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
          "homepage": "",
          "language": null,
          "forks": 25948,
          "open_issues": 94,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/185671340?v=4",
      "velocity": 106155.5,
      "is_rising_star": true,
      "heatScore": 31850.139188020687,
      "popularityScore": 96505
    },
    {
      "id": "PokeeAI/pokee_research_7b",
      "name": "pokee_research_7b",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "agent",
        "deepresearch",
        "llm",
        "rl",
        "reinforcementlearning",
        "conversational",
        "en",
        "dataset:miromind-ai/MiroRL-GenQA",
        "arxiv:2510.15862",
        "base_model:Qwen/Qwen2.5-7B-Instruct",
        "base_model:finetune:Qwen/Qwen2.5-7B-Instruct",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us",
        "general-dialogue-qa"
      ],
      "likes": 990,
      "downloads": 191670,
      "lastModifiedTimestamp": null,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
          "files": [],
          "modelId": "PokeeAI/pokee_research_7b"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
          "files": [],
          "modelId": "PokeeAI/pokee_research_7b"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
          "files": [],
          "modelId": "PokeeAI/pokee_research_7b"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
          "files": [],
          "modelId": "PokeeAI/pokee_research_7b"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
          "files": [],
          "modelId": "PokeeAI/pokee_research_7b"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 38631
    },
    {
      "id": "github-ggml-org-llama.cpp",
      "name": "llama.cpp",
      "author": "ggml-org",
      "description": "LLM inference in C/C++",
      "task": "tool",
      "tags": [
        "ggml"
      ],
      "likes": 180265,
      "downloads": 180265,
      "lastModified": "2025-11-20T15:53:48Z",
      "lastModifiedTimestamp": 1763654028000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ggml-org/llama.cpp",
          "homepage": "",
          "language": "C++",
          "forks": 13769,
          "open_issues": 893,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134263123?v=4",
      "velocity": 99145.2,
      "is_rising_star": true,
      "heatScore": 29747.0284186785,
      "popularityScore": 90132
    },
    {
      "id": "github-google-gemini-gemini-cli",
      "name": "gemini-cli",
      "author": "google-gemini",
      "description": "An open-source AI agent that brings the power of Gemini directly into your terminal.",
      "task": "tool",
      "tags": [
        "gemini",
        "gemini-api"
      ],
      "likes": 167383,
      "downloads": 167383,
      "lastModified": "2025-11-20T15:52:04Z",
      "lastModifiedTimestamp": 1763653924000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/google-gemini/gemini-cli",
          "homepage": "https://geminicli.com",
          "language": "TypeScript",
          "forks": 9443,
          "open_issues": 3033,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/161781182?v=4",
      "velocity": 92060.1,
      "is_rising_star": true,
      "heatScore": 27621.47587876247,
      "popularityScore": 83691
    },
    {
      "id": "github-Shubhamsaboo-awesome-llm-apps",
      "name": "awesome-llm-apps",
      "author": "Shubhamsaboo",
      "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
      "task": "tool",
      "tags": [
        "llms",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 158413,
      "downloads": 158413,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
          "homepage": "https://www.theunwindai.com",
          "language": "Python",
          "forks": 10579,
          "open_issues": 3,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/31396011?v=4",
      "velocity": 87126.6,
      "is_rising_star": true,
      "heatScore": 26141.409134495156,
      "popularityScore": 79206
    },
    {
      "id": "github-rasbt-LLMs-from-scratch",
      "name": "LLMs-from-scratch",
      "author": "rasbt",
      "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "deep-learning",
        "from-scratch",
        "generative-ai",
        "gpt",
        "language-model",
        "large-language-models",
        "llm",
        "machine-learning",
        "neural-networks",
        "python",
        "pytorch",
        "transformers",
        "general-dialogue-qa"
      ],
      "likes": 158122,
      "downloads": 158122,
      "lastModified": "2025-11-20T15:46:33Z",
      "lastModifiedTimestamp": 1763653593000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/rasbt/LLMs-from-scratch",
          "homepage": "https://amzn.to/4fqvn0D",
          "language": "Jupyter Notebook",
          "forks": 11719,
          "open_issues": 0,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/5618407?v=4",
      "velocity": 86967.1,
      "is_rising_star": true,
      "heatScore": 26093.558577457425,
      "popularityScore": 79061
    },
    {
      "id": "github-nomic-ai-gpt4all",
      "name": "gpt4all",
      "author": "nomic-ai",
      "description": "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.",
      "task": "tool",
      "tags": [
        "ai-chat",
        "llm-inference"
      ],
      "likes": 153854,
      "downloads": 153854,
      "lastModified": "2025-11-20T11:59:23Z",
      "lastModifiedTimestamp": 1763639963000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nomic-ai/gpt4all",
          "homepage": "https://nomic.ai/gpt4all",
          "language": "C++",
          "forks": 8302,
          "open_issues": 744,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102670180?v=4",
      "velocity": 84619.7,
      "is_rising_star": true,
      "heatScore": 25389.330259109156,
      "popularityScore": 76927
    },
    {
      "id": "h2oai/h2o-danube3-500m-chat",
      "name": "h2o-danube3-500m-chat",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "onnx",
        "safetensors",
        "llama",
        "text-generation",
        "gpt",
        "llm",
        "large language model",
        "h2o-llmstudio",
        "conversational",
        "en",
        "arxiv:2407.09276",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us",
        "general-dialogue-qa"
      ],
      "likes": 380,
      "downloads": 153250,
      "lastModifiedTimestamp": null,
      "readme": "---\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- gpt\n- llm\n- large language model\n- h2o-llmstudio\nthumbnail: >-\n  https://h2o.ai/etc.clientlibs/h2o/clientlibs/clientlib-site/resources/images/favicon.ico\npipeline_tag: text-generation\n---\n\n\n\n<div style=\"width: 90%; max-width: 600px; margin: 0 auto; overflow: hidden; background-color: white\">\n    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/636d18755aaed143cd6698ef/LAzQu_f5WOX7vqKl4yDsY.png\" \n         alt=\"Slightly cropped image\" \n         style=\"width: 102%; height: 102%; object-fit: cover; object-position: center; margin: -5% -5% -5% -5%;\">\n</div>\n\n## Summary\n\n\nh2o-danube3-500m-chat is a chat fine-tuned model by H2O.ai with 500 million parameters. We release two versions of this model:\n\n| Model Name                                                                         |  Description    |\n|:-----------------------------------------------------------------------------------|:----------------|\n|  [h2oai/h2o-danube3-500m-base](https://huggingface.co/h2oai/h2o-danube3-500m-base) | Base model      |\n|  [h2oai/h2o-danube3-500m-chat](https://huggingface.co/h2oai/h2o-danube3-500m-chat) | Chat model |\n\nThis model was trained using [H2O LLM Studio](https://github.com/h2oai/h2o-llmstudio).\n\nCan be run natively and fully offline on phones - try it yourself with [H2O AI Personal GPT](https://h2o.ai/platform/danube/personal-gpt/).\n\n## Model Architecture\n\nWe adjust the Llama 2 architecture for a total of around 500m parameters. For details, please refer to our [Technical Report](https://arxiv.org/abs/2407.09276). We use the Mistral tokenizer with a vocabulary size of 32,000 and train our model up to a context length of 8,192.\n\nThe details of the model architecture are:\n\n| Hyperparameter  |  Value |\n|:----------------|:-------|\n|    n_layers     |     16 |\n|     n_heads     |     16 |\n|  n_query_groups |      8 |\n|     n_embd      |   1536 |\n|   vocab size    |  32000 |\n| sequence length |   8192 |\n\n## Usage\n\nTo use the model with the `transformers` library on a machine with GPUs, first make sure you have the `transformers` library installed.\n\n```bash\npip install transformers>=4.42.3\n```\n\n```python\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(\n    \"text-generation\",\n    model=\"h2oai/h2o-danube3-500m-chat\",\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)\n\n# We use the HF Tokenizer chat template to format each message\n# https://huggingface.co/docs/transformers/main/en/chat_templating\nmessages = [\n    {\"role\": \"user\", \"content\": \"Why is drinking water so healthy?\"},\n]\nprompt = pipe.tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\nres = pipe(\n    prompt,\n    return_full_text=False,\n    max_new_tokens=256,\n)\nprint(res[0][\"generated_text\"])\n```\n\nThis will apply and run the correct prompt format out of the box:\n\n```\n<|prompt|>Why is drinking water so healthy?</s><|answer|>\n```\n\nAlternatively, one can also run it via:\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"h2oai/h2o-danube3-500m-chat\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Why is drinking water so healthy?\"},\n]\nprompt = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n)\ninputs = tokenizer(\n    prompt, return_tensors=\"pt\", add_special_tokens=False\n).to(\"cuda\")\n\n# generate configuration can be modified to your needs\ntokens = model.generate(\n    input_ids=inputs[\"input_ids\"],\n    attention_mask=inputs[\"attention_mask\"],\n    min_new_tokens=2,\n    max_new_tokens=256,\n)[0]\n\ntokens = tokens[inputs[\"input_ids\"].shape[1]:]\nanswer = tokenizer.decode(tokens, skip_special_tokens=True)\nprint(answer)\n```\n\n## Quantization and sharding\n\nYou can load the models using quantization by specifying ```load_in_8bit=True``` or ```load_in_4bit=True```. Also, sharding on multiple GPUs is possible by setting ```device_map=auto```.\n\n## Model Architecture\n\n```\nLlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32000, 1536, padding_idx=0)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=1536, out_features=1536, bias=False)\n          (k_proj): Linear(in_features=1536, out_features=768, bias=False)\n          (v_proj): Linear(in_features=1536, out_features=768, bias=False)\n          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=1536, out_features=4096, bias=False)\n          (up_proj): Linear(in_features=1536, out_features=4096, bias=False)\n          (down_proj): Linear(in_features=4096, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm()\n        (post_attention_layernorm): LlamaRMSNorm()\n      )\n    )\n    (norm): LlamaRMSNorm()\n  )\n  (lm_head): Linear(in_features=1536, out_features=32000, bias=False)\n)\n```\n\n## Benchmarks\n\n### ü§ó Open LLM Leaderboard v1\n\n| Benchmark     |   acc_n  |\n|:--------------|:--------:|\n| Average       |   40.71  |\n| ARC-challenge |   39.25  |\n| Hellaswag     |   61.02  |\n| MMLU          |   26.33  |\n| TruthfulQA    |   39.96  |\n| Winogrande    |   61.72  |\n| GSM8K         |   16.00  |\n\n### MT-Bench\n\n```\nFirst Turn: 4.16\nSecond Turn: 2.40\nAverage: 3.28\n```\n\n## Disclaimer\n\nPlease read this disclaimer carefully before using the large language model provided in this repository. Your use of the model signifies your agreement to the following terms and conditions.\n\n- Biases and Offensiveness: The large language model is trained on a diverse range of internet text data, which may contain biased, racist, offensive, or otherwise inappropriate content. By using this model, you acknowledge and accept that the generated content may sometimes exhibit biases or produce content that is offensive or inappropriate. The developers of this repository do not endorse, support, or promote any such content or viewpoints.\n- Limitations: The large language model is an AI-based tool and not a human. It may produce incorrect, nonsensical, or irrelevant responses. It is the user's responsibility to critically evaluate the generated content and use it at their discretion.\n- Use at Your Own Risk: Users of this large language model must assume full responsibility for any consequences that may arise from their use of the tool. The developers and contributors of this repository shall not be held liable for any damages, losses, or harm resulting from the use or misuse of the provided model.\n- Ethical Considerations: Users are encouraged to use the large language model responsibly and ethically. By using this model, you agree not to use it for purposes that promote hate speech, discrimination, harassment, or any form of illegal or harmful activities.\n- Reporting Issues: If you encounter any biased, offensive, or otherwise inappropriate content generated by the large language model, please report it to the repository maintainers through the provided channels. Your feedback will help improve the model and mitigate potential issues.\n- Changes to this Disclaimer: The developers of this repository reserve the right to modify or update this disclaimer at any time without prior notice. It is the user's responsibility to periodically review the disclaimer to stay informed about any changes.\n\nBy using the large language model provided in this repository, you agree to accept and comply with the terms and conditions outlined in this disclaimer. If you do not agree with any part of this disclaimer, you should refrain from using the model and any content generated by it.",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2o-danube3-500m-chat",
          "files": [],
          "modelId": "h2oai/h2o-danube3-500m-chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2o-danube3-500m-chat",
          "files": [],
          "modelId": "h2oai/h2o-danube3-500m-chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2o-danube3-500m-chat",
          "files": [],
          "modelId": "h2oai/h2o-danube3-500m-chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2o-danube3-500m-chat",
          "files": [],
          "modelId": "h2oai/h2o-danube3-500m-chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2o-danube3-500m-chat",
          "files": [],
          "modelId": "h2oai/h2o-danube3-500m-chat"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 30764
    },
    {
      "id": "github-browser-use-browser-use",
      "name": "browser-use",
      "author": "browser-use",
      "description": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "ai-tools",
        "browser-automation",
        "browser-use",
        "llm",
        "playwright",
        "python"
      ],
      "likes": 145557,
      "downloads": 145557,
      "lastModified": "2025-11-20T15:54:22Z",
      "lastModifiedTimestamp": 1763654062000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/browser-use/browser-use",
          "homepage": "https://browser-use.com",
          "language": "Python",
          "forks": 8663,
          "open_issues": 232,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192012301?v=4",
      "velocity": 80055.8,
      "is_rising_star": true,
      "heatScore": 24020.143404258793,
      "popularityScore": 72778
    },
    {
      "id": "github-binary-husky-gpt_academic",
      "name": "gpt_academic",
      "author": "binary-husky",
      "description": "‰∏∫GPT/GLMÁ≠âLLMÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂÆûÁî®Âåñ‰∫§‰∫íÊé•Âè£ÔºåÁâπÂà´‰ºòÂåñËÆ∫ÊñáÈòÖËØª/Ê∂¶Ëâ≤/ÂÜô‰Ωú‰ΩìÈ™åÔºåÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆ&ÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅPythonÂíåC++Á≠âÈ°πÁõÆÂâñÊûê&Ëá™ËØëËß£ÂäüËÉΩÔºåPDF/LaTexËÆ∫ÊñáÁøªËØë&ÊÄªÁªìÂäüËÉΩÔºåÊîØÊåÅÂπ∂Ë°åÈóÆËØ¢Â§öÁßçLLMÊ®°ÂûãÔºåÊîØÊåÅchatglm3Á≠âÊú¨Âú∞Ê®°Âûã„ÄÇÊé•ÂÖ•ÈÄö‰πâÂçÉÈóÆ, deepseekcoder, ËÆØÈ£ûÊòüÁÅ´, ÊñáÂøÉ‰∏ÄË®Ä, llama2, rwkv, claude2, mossÁ≠â„ÄÇ",
      "task": "tool",
      "tags": [
        "academic",
        "chatglm-6b",
        "chatgpt",
        "gpt-4",
        "large-language-models",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 139408,
      "downloads": 139408,
      "lastModified": "2025-11-20T14:41:49Z",
      "lastModifiedTimestamp": 1763649709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/binary-husky/gpt_academic",
          "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
          "language": "Python",
          "forks": 8399,
          "open_issues": 291,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/96192199?v=4",
      "velocity": 76674.4,
      "is_rising_star": true,
      "heatScore": 23005.71028475207,
      "popularityScore": 69704
    },
    {
      "id": "github-firecrawl-firecrawl",
      "name": "firecrawl",
      "author": "firecrawl",
      "description": "üî• The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-crawler",
        "ai-scraping",
        "ai-search",
        "crawler",
        "data-extraction",
        "html-to-markdown",
        "llm",
        "markdown",
        "scraper",
        "scraping",
        "web-crawler",
        "web-data",
        "web-data-extraction",
        "web-scraper",
        "web-scraping",
        "web-search",
        "webscraping"
      ],
      "likes": 136343,
      "downloads": 136343,
      "lastModified": "2025-11-20T15:52:57Z",
      "lastModifiedTimestamp": 1763653977000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/firecrawl/firecrawl",
          "homepage": "https://firecrawl.dev",
          "language": "TypeScript",
          "forks": 5309,
          "open_issues": 134,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/135057108?v=4",
      "velocity": 74988.1,
      "is_rising_star": true,
      "heatScore": 22499.813524224726,
      "popularityScore": 68171
    },
    {
      "id": "github-infiniflow-ragflow",
      "name": "ragflow",
      "author": "infiniflow",
      "description": "RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs",
      "task": "tool",
      "tags": [
        "agent",
        "agentic",
        "agentic-ai",
        "agentic-workflow",
        "ai",
        "ai-search",
        "deep-learning",
        "deep-research",
        "deepseek",
        "deepseek-r1",
        "document-parser",
        "document-understanding",
        "graphrag",
        "llm",
        "mcp",
        "multi-agent",
        "ollama",
        "openai",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 136116,
      "downloads": 136116,
      "lastModified": "2025-11-20T14:42:49Z",
      "lastModifiedTimestamp": 1763649769000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/infiniflow/ragflow",
          "homepage": "https://ragflow.io",
          "language": "Python",
          "forks": 7305,
          "open_issues": 2876,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/69962740?v=4",
      "velocity": 74863.8,
      "is_rising_star": true,
      "heatScore": 22462.52301989456,
      "popularityScore": 68058
    },
    {
      "id": "github-lobehub-lobe-chat",
      "name": "lobe-chat",
      "author": "lobehub",
      "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artifacts",
        "chat",
        "chatgpt",
        "claude",
        "deepseek",
        "deepseek-r1",
        "function-calling",
        "gemini",
        "gpt",
        "knowledge-base",
        "mcp",
        "nextjs",
        "ollama",
        "openai",
        "rag",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 135771,
      "downloads": 135771,
      "lastModified": "2025-11-20T15:53:45Z",
      "lastModifiedTimestamp": 1763654025000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/lobehub/lobe-chat",
          "homepage": "https://lobechat.com",
          "language": "TypeScript",
          "forks": 13999,
          "open_issues": 993,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
      "velocity": 74673.5,
      "is_rising_star": true,
      "heatScore": 22405.432246153854,
      "popularityScore": 67885
    },
    {
      "id": "github-mlabonne-llm-course",
      "name": "llm-course",
      "author": "mlabonne",
      "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
      "task": "tool",
      "tags": [
        "course",
        "large-language-models",
        "llm",
        "machine-learning",
        "roadmap"
      ],
      "likes": 135657,
      "downloads": 135657,
      "lastModified": "2025-11-20T15:52:59Z",
      "lastModifiedTimestamp": 1763653979000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mlabonne/llm-course",
          "homepage": "https://mlabonne.github.io/blog/",
          "language": null,
          "forks": 7688,
          "open_issues": 76,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/81252890?v=4",
      "velocity": 74610.8,
      "is_rising_star": true,
      "heatScore": 22386.62199079003,
      "popularityScore": 67828
    },
    {
      "id": "github-ansible-ansible",
      "name": "ansible",
      "author": "ansible",
      "description": "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",
      "task": "tool",
      "tags": [
        "ansible",
        "python",
        "code-generation-assistance"
      ],
      "likes": 134117,
      "downloads": 134117,
      "lastModified": "2025-11-20T15:53:03Z",
      "lastModifiedTimestamp": 1763653983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ansible/ansible",
          "homepage": "https://www.ansible.com/",
          "language": "Python",
          "forks": 24129,
          "open_issues": 878,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1507452?v=4",
      "velocity": 73763.8,
      "is_rising_star": true,
      "heatScore": 22132.518519950987,
      "popularityScore": 67058
    },
    {
      "id": "github-dair-ai-Prompt-Engineering-Guide",
      "name": "Prompt-Engineering-Guide",
      "author": "dair-ai",
      "description": "üêô Guides, papers, lessons, notebooks and resources for prompt engineering, context engineering, RAG, and AI Agents.",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai-agents",
        "chatgpt",
        "deep-learning",
        "generative-ai",
        "language-model",
        "llms",
        "openai",
        "prompt-engineering",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 133184,
      "downloads": 133184,
      "lastModified": "2025-11-20T15:46:31Z",
      "lastModifiedTimestamp": 1763653591000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/dair-ai/Prompt-Engineering-Guide",
          "homepage": "https://www.promptingguide.ai/",
          "language": "MDX",
          "forks": 6951,
          "open_issues": 231,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/30384625?v=4",
      "velocity": 73251.2,
      "is_rising_star": true,
      "heatScore": 21978.73640000614,
      "popularityScore": 66592
    },
    {
      "id": "github-OpenHands-OpenHands",
      "name": "OpenHands",
      "author": "OpenHands",
      "description": "üôå OpenHands: Code Less, Make More",
      "task": "tool",
      "tags": [
        "agent",
        "artificial-intelligence",
        "chatgpt",
        "claude-ai",
        "cli",
        "developer-tools",
        "gpt",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 130236,
      "downloads": 130236,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenHands/OpenHands",
          "homepage": "https://all-hands.dev",
          "language": "Python",
          "forks": 7937,
          "open_issues": 211,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/225919603?v=4",
      "velocity": 71629.8,
      "is_rising_star": true,
      "heatScore": 21492.30959540588,
      "popularityScore": 65118
    },
    {
      "id": "github-PaddlePaddle-PaddleOCR",
      "name": "PaddleOCR",
      "author": "PaddlePaddle",
      "description": "Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.",
      "task": "tool",
      "tags": [
        "ai4science",
        "chineseocr",
        "document-parsing",
        "document-translation",
        "kie",
        "ocr",
        "paddleocr-vl",
        "pdf-extractor-rag",
        "pdf-parser",
        "pdf2markdown",
        "pp-ocr",
        "pp-structure",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 128822,
      "downloads": 128822,
      "lastModified": "2025-11-20T15:27:27Z",
      "lastModifiedTimestamp": 1763652447000,
      "readme": "<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"./docs/images/Banner.png\" alt=\"PaddleOCR Banner\">\n  </p>\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](./readme/README_cn.md) | [ÁπÅÈ´î‰∏≠Êñá](./readme/README_tcn.md) | [Êó•Êú¨Ë™û](./readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](./readme/README_ko.md) | [Fran√ßais](./readme/README_fr.md) | [–†—É—Å—Å–∫–∏–π](./readme/README_ru.md) | [Espa√±ol](./readme/README_es.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](./readme/README_ar.md)\n\n<!-- icon -->\n[![stars](https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf)](https://github.com/PaddlePaddle/PaddleOCR)\n[![forks](https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg)](https://github.com/PaddlePaddle/PaddleOCR)\n[![arXiv](https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2507.05595)\n[![arXiv](https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.14528)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr/month)](https://pepy.tech/projectsproject/paddleocr)\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr)](https://pepy.tech/projects/paddleocr)\n[![Used by](https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue)](https://github.com/PaddlePaddle/PaddleOCR/network/dependents)\n[![PyPI version](https://img.shields.io/pypi/v/paddleocr)](https://pypi.org/project/paddleocr/)\n![python](https://img.shields.io/badge/python-3.8~3.12-aff.svg)\n\n![os](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg)\n![hardware](https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg)\n[![License](https://img.shields.io/badge/license-Apache_2.0-green)](../LICENSE)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/PaddlePaddle/PaddleOCR)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://www.paddleocr.com)\n\n\n\n**PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding**\n\n</div>\n\n# PaddleOCR\n[![Framework](https://img.shields.io/badge/PaddlePaddle-3.0-orange)](https://www.paddlepaddle.org.cn/en)\n[![Accuracy](https://img.shields.io/badge/Recognition%20Accuracy-üèÜ-green)](#)\n[![Multi-Language](https://img.shields.io/badge/Support_Languages-100+-brightgreen)](#)\n[![Handwriting](https://img.shields.io/badge/Handwriting-‚úì-success)](#)\n[![Hardware](https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red)](#)\n\n> [!TIP]\n> PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to [PaddleOCR MCP Server](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html).\n>\n> The PaddleOCR 3.0 Technical Report is now available. See details at: [PaddleOCR 3.0 Technical Report](https://arxiv.org/abs/2507.05595).\n>\n> The PaddleOCR-VL Technical Report is now available. See details at [PaddleOCR-VL Technical Report](https://arxiv.org/abs/2510.14528).\n>\n> The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the [PaddleOCR official website](https://www.paddleocr.com).\n\n\n**PaddleOCR** converts documents and images into **structured, AI-friendly data** (like JSON and Markdown) with **industry-leading accuracy**‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over **60,000 stars** and deep integration into leading projects like **MinerU, RAGFlow, pathway and cherry-studio**, PaddleOCR has become the **premier solution** for developers building intelligent document applications in the **AI era**.\n\n### PaddleOCR 3.0 Core Features\n\n[![HuggingFace](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&labelColor=white)](https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAMAAADDpiTIAAAABlBMVEU2P+X///+1KuUwAAAHKklEQVR42u3dS5bjOAwEwALvf2fMavZum6IAImI7b2yYSqU+1Zb//gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADKCR/+fzly7rD92yVg69xh8zeLwOa5w+ZvFYHtc4ft3ykB++cOm79PAp6YO2z/Ngl4ZO5l+9+yT4QAvLqS748VF33Ylzdvzpl72f6z53YIGJ6SZdPeNHcIwOycaADdLgCSIgAIgCOAACAAykIAEAAEAAFAABCAT+WQuQVgeBqXhXQIQAAYegowLQBpbg3gZGFyAC6vgBQAMREA2/YfDPxyaDQNyTNz+3Zwn5J4ZG7PB2h0kHhi7plPCImmJwkPzO0RMa3OET0i5uGlzHFze0xcu0vE2Dq3J4U2vEPgSaHbFzPNDQAAAAAAAMBNovdw+cP/ny+uaf7w/+eYADy8kE+F4Offdjn6zZXhAXgiA78G4MNNsmnu1Xr7b3mbOL8T5Ja5bw/A35EC2LiWpzt1y9jRugBy30fLg3NvHPvnuZcC2NsCUXA/aRmA89V07Fwgt37uH8deCmBr6N44pP4UgaUATpdA7v/cMbIB8okliY65/SW5HhJ1ehPmM+8edwXgpbu4R88FayR32Y/P7oZZbOx13/Zr//ZHx27bAPnkFoyewYlbAhD3TvBobr95gaUAtr1EdNx1lgI4OcTTuR3z6+FZMEDRcu9ZCuDgGCdyGxMa4EgBRMvcjrkM7NgBZw5c0TwAUWUhZwRXA2xaya65Xa3jO2qYZ8bu2AD5w38tG5V8aZpoGN6Tz0bOfa9bceyWAciTO0jWyO1Tc5cLwJmF/JfPnXVyu3/slgHIg1n79O2O5fZv+1cHV7sC2HYqmUdHysNzX3sVkMcjUK5Gc+dMs28E5bGtm0V3gloBOP9vgZv+4sYn3RUaYFMCol5uN77g6lUApc8pWs69Zn7snS9Z9Q8G0S0AUTVUUTG3A54R1KSvo/diLAv5fKzynZeN6xogC75u93+AtBTA47OlAFSv6qY/vp3DAjD8iv2ZdFYJwKynMhTK1rInPfzaxW81LnvSgFP9KxrATaCLA3DxHpbFX31ZyNm5XRZyXG5bNkAWfP0rcrsUwOgC6NIAzgBcBiqAWwPgLrAGuGBP6jr2sifdfiJ6QQM4Bbw4AK4B3129ZSFn53ZZyA/GyFty27IBFMDFAXAG8PbyLQv5xULGPRl0K3h2AbwcgCZPhs+LD1zLnjS6AN4NwMU/DVFh7LyhASreTbvqrxdr/J4XT4Swz4FrTS+AGJ7bNbwAYkxuWzZAVljHrJfbjb9wviYXwFO/FJ8Vli4vaICsEMFyBbA3tmtsAUS0zG1c/bj4YwsZH2/+Whd0+1Nb+S7IE2sfPw4RL0XmsR8Nqvz7qFngmPHF34EqjP15AAofAkosZKPC/K6FVoeP02Ehi540NG6AK/4pYP3cLgVwXwHkDQ1QcSGb/uF4WwCmfX8u/+4vgLINcMUlQIfcLgXwXAF0+BGkpQDuuJx7/hwgpu//cWVuO3wxJOz/z8297vgYBwaIO3O7Kn+c194578ltywbIgu8fl+Z2lS+APvnLjnOv8hsgSqxjgwL4Ln9LAezaj98tgPzy7ZcC+GQzxrWxXQpgx370dm6/H7v6jaBoso5dY1swAFlwHWvfBf5pxVa93fCtdx64+1dsgCy4joWvAfPX9VoKYMs6Zse9/8Mlvv7LILlhAfKFFdsSutJXAdFkL3qlADJPrXFcXAC5KYaH586jO9mtAch9S3T0GQJ726ZWAE49kjP3rlDJuetdaL/1zeqZY9c7CRz7s0wCUPxienQBnAuAAtAAlxaAAAxfyBQABSAACkAAFIAAKAABUAACMEkKwL170oh7V8ueNLoAjgTAXWAN4BRwcABcA2oABTA4AApAAyiAwQFQABpAAQwOgALQADMWUgCuEmNyu15fSIY3gFPAiwPgFFADKIDBAVAAGkABCIACmBqAUAAaQAHMDUCMWkgBuMWw3K43F5LhDeAU8OIAuAmkARTA4AAoAA2gAARAAUwNgLvAGkABDA6Au8AaoKOJuV0vLSTDG8Ap4MUBcBNIAyiAwQFQABpAAQwOgALQAApAABTA1AC4C6wBOhqb23V+IRneAE4BLw6Aa0ANoAAGB0ABaAAFMDgACkADKAABUABTA+AusAboKATAQs4trjV+IYcfuJYCcA6gAATAQk69dFkKQANYyLkFcLIBFIDLQAVwawDsSRrAEWBwAJwCagAFMDgACkADKIDBAVAAGkABCIACmBoAzwXWAApgcADsSRrg0iNACoACEADXgAIwdCFTACykALgGFIAfl0kBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBv/gN+IH8U6YveYgAAAABJRU5ErkJggg==&labelColor=white)](https://aistudio.baidu.com/application/detail/98365)\n[![ModelScope](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&labelColor=white)](https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n\n[![AI Studio](https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n\n- **PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM**  \n  **The SOTA and resource-efficient model tailored for document parsing**, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.\n\n- **PP-OCRv5 ‚Äî Universal Scene Text Recognition**  \n  **Single model supports five text types** (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with **13% accuracy improvement**. Solves multilingual mixed document recognition challenges.\n\n- **PP-StructureV3 ‚Äî Complex Document Parsing**  \n  Intelligently converts complex PDFs and document images into **Markdown and JSON files that preserve original structure**. **Outperforms** numerous commercial solutions in public benchmarks. **Perfectly maintains document layout and hierarchical structure**.\n\n- **PP-ChatOCRv4 ‚Äî Intelligent Information Extraction**  \n  Natively integrates ERNIE 4.5 to **precisely extract key information** from massive documents, with 15% accuracy improvement over previous generation. Makes documents \"**understand**\" your questions and provide accurate answers.\n\nIn addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg\" alt=\"PaddleOCR Architecture\">\n  </p>\n</div>\n\n**Special Note**: PaddleOCR 3.x introduces several significant interface changes. **Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x**. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. [This document](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html) explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.\n\n## üì£ Recent updates\n\n### üî•üî• 2025.10.16: PaddleOCR 3.3.0 released, includes:\n\n- Released PaddleOCR-VL:\n    - **Model Introduction**:\n        - **PaddleOCR-VL** is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. **This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption**. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on [HuggingFace](https://huggingface.co/PaddlePaddle/PaddleOCR-VL). Everyone is welcome to download and use it! More introduction infomation can be found in [PaddleOCR-VL](https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html).\n\n    - **Core Features**:\n        - **Compact yet Powerful VLM Architecture**: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.\n        - **SOTA Performance on Document Parsing**: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.\n        - **Multilingual Support**: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.\n\n- Released PP-OCRv5 Multilingual Recognition Model:\n    - Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.\n\n\n<details>\n<summary><strong>2025.08.21: Release of PaddleOCR 3.2.0</strong></summary>\n\n- **Significant Model Additions:**\n    - Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. **The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.**\n\n- **Deployment Capability Upgrades:**\n    - **Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.**\n    - **Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.**\n    - **High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.**\n    - **The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.**\n    - The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.\n\n- **Benchmark Support:**\n    - **All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. [Here's](docs/version3.x/pipeline_usage/instructions/benchmark.en.md) how to set up and use the benchmark feature.**\n    - **Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.**\n\n- **Bug Fixes:**\n    - Resolved the issue of failed log saving during model training.\n    - Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.\n    - Fixed inconsistencies in switch behaviors (e.g., `use_chart_parsing`) in the PP-StructureV3 configuration files compared to other pipelines.\n\n- **Other Enhancements:**\n    - **Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.**\n    - **Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the [installation guide](docs/version3.x/installation.en.md) for the corresponding PaddlePaddle framework versions.**\n    - **PP-OCR series models now support returning single-character coordinates.**\n    - Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.\n    - Added support for chart-to-table conversion via the PP-Chart2Table module.\n    - Optimized documentation descriptions to improve usability.\n</details>\n\n<details>\n<summary><strong>2025.08.15: PaddleOCR 3.1.1 Released</strong></summary>\n\n- **Bug Fixes:**\n  - Added the missing methods `save_vector`, `save_visual_info_list`, `load_vector`, and `load_visual_info_list` in the `PP-ChatOCRv4` class.\n  - Added the missing parameters `glossary` and `llm_request_interval` to the `translate` method in the `PPDocTranslation` class.\n\n- **Documentation Improvements:**\n  - Added a demo to the MCP documentation.\n  - Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.\n  - Fixed errors and omissions in the production line document translation.\n\n- **Others:**\n  - Changed the MCP server dependency to use the pure Python library `puremagic` instead of `python-magic` to reduce installation issues.\n  - Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.\n\n</details>\n\n<details>\n<summary><strong>2025.06.29: PaddleOCR 3.1.0 Released</strong></summary>\n\n- **Key Models and Pipelines:**\n  - **Added PP-OCRv5 Multilingual Text Recognition Model**, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. **Average accuracy improved by over 30%.** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html)\n  - Upgraded the **PP-Chart2Table model** in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) **increased by 9.36 percentage points (71.24% -> 80.60%).**\n  - Newly launched **document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5**, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html)\n\n\n- **New MCP server:** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)\n  - **Supports both OCR and PP-StructureV3 pipelines.**\n  - Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.\n  - Supports invoking local services via stdio and remote services via Streamable HTTP.\n\n- **Documentation Optimization:** Improved the descriptions in some user guides for a smoother reading experience.\n\n</details>\n\n<details>\n    <summary><strong>2025.06.26: PaddleOCR 3.0.3 Released</strong></summary>\n- Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference.\n</details>\n\n<details>\n    <summary><strong>2025.06.19: PaddleOCR 3.0.2 Released</strong></summary>\n- **New Features:**\n\n  - The default download source has been changed from `BOS` to `HuggingFace`. Users can also change the environment variable `PADDLE_PDX_MODEL_SOURCE` to `BOS` to set the model download source back to Baidu Object Storage (BOS).\n  - Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.\n  - Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.\n  - Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language. \n  - Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.\n  - Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.\n  - Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.\n  - Added Android example for PP-OCRv5. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html).\n\n- **Bug Fixes:**\n  - Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.\n  - Resolved an issue where `export_paddlex_config_to_yaml` would not function correctly in certain cases.\n  - Corrected the discrepancy between the actual behavior of `save_path` and its documentation description.\n  - Fixed potential multithreading errors when using MKL-DNN in basic service deployment.\n  - Corrected channel order errors in image preprocessing for the Latex-OCR model.\n  - Fixed channel order errors in saving visualized images within the text recognition module.\n  - Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.\n  - Fixed an overflow issue in the calculation of `overlap_ratio` under extremely special circumstances in the PP-StructureV3 pipeline.\n\n- **Documentation Improvements:**\n  - Updated the description of the `enable_mkldnn` parameter in the documentation to accurately reflect the program's actual behavior.\n  - Fixed errors in the documentation regarding the `lang` and `ocr_version` parameters.\n  - Added instructions for exporting pipeline configuration files via CLI.\n  - Fixed missing columns in the performance data table for PP-OCRv5.\n  - Refined benchmark metrics for PP-StructureV3 across different configurations.\n\n- **Others:**\n\n  - Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.\n</details>\n\n<details>\n    <summary><strong>History Log</strong></summary>\n\n2025.06.05: **PaddleOCR 3.0.1 Released**, includes:\n\n- **Optimisation of certain models and model configurations:**\n  - Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter `limit_side_len` in the configuration has been changed from 736 to 64.\n  - Added a new text line orientation classification model `PP-LCNet_x1_0_textline_ori` with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.\n  - Optimized the text line orientation classification model `PP-LCNet_x0_25_textline_ori`, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.\n- **Optimizations and fixes for some issues in version 3.0.0, [details](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)**\n\nüî•üî•2025.05.20: Official Release of **PaddleOCR v3.0**, including:\n- **PP-OCRv5**: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.\n   1. üåê Single-model support for **five** text types - Seamlessly process **Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English** and **Japanese** within a single model.\n   2. ‚úçÔ∏è Improved **handwriting recognition**: Significantly better at complex cursive scripts and non-standard handwriting.\n   3. üéØ **13-point accuracy gain** over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.\n\n- **PP-StructureV3**: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios! \n   1. üßÆ **High-Accuracy multi-scene PDF parsing**, leading both open- and closed-source solutions on the OmniDocBench benchmark.\n   2. üß† Specialized capabilities include **seal recognition**, **chart-to-table conversion**, **table recognition with nested formulas/images**, **vertical text document parsing**, and **complex table structure analysis**.\n\n- **PP-ChatOCRv4**: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.\n   1. üî• **15-point accuracy gain** in key-information extraction on PDF/PNG/JPG files over the previous generation.\n   2. üíª Native support for **ERNIE 4.5**, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.\n   3. ü§ù Integrated [PP-DocBee2](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2), enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.\n\n[History Log](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)\n\n</details>\n\n## ‚ö° Quick Start\n### 1. Run online demo \n[![AI Studio](https://img.shields.io/badge/PP_OCRv5-AI_Studio-green)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_StructureV3-AI_Studio-green)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n### 2. Installation\n\nInstall PaddlePaddle refer to [Installation Guide](https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html), after then, install the PaddleOCR toolkit.\n\n```bash\n# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\"\n```\n\nStarting from version 3.2.0, in addition to the `all` dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:\n\n| Dependency Group Name | Corresponding Functionality |\n| - | - |\n| `doc-parser` | Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL |\n| `ie` | Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4 |\n| `trans` | Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation |\n| `all` | Complete functionality |\n\n### 3. Run inference by CLI\n```bash\n# Run PP-OCRv5 inference\npaddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  \n\n# Run PP-StructureV3 inference\npaddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False\n\n# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference\npaddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False \n\n# Run PaddleOCR-VL inference\npaddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\n\n# Get more information about \"paddleocr ocr\"\npaddleocr ocr --help\n```\n\n### 4. Run inference by API\n**4.1 PP-OCRv5 Example**\n```python\n# Initialize PaddleOCR instance\nfrom paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\n\n# Run OCR inference on a sample image \nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")\n\n# Visualize the results and save the JSON results\nfor res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")\n```\n\n<details>\n    <summary><strong>4.2 PP-StructureV3 Example</strong></summary>\n\n```python\nfrom pathlib import Path\nfrom paddleocr import PPStructureV3\n\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\n# For Image\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\n\n# Visualize the results and save the JSON results\nfor res in output:\n    res.print() \n    res.save_to_json(save_path=\"output\") \n    res.save_to_markdown(save_path=\"output\")           \n```\n\n</details>\n\n<details>\n   <summary><strong>4.3 PP-ChatOCRv4 Example</strong></summary>\n\n```python\nfrom paddleocr import PPChatOCRv4Doc\n\nchat_bot_config = {\n    \"module_name\": \"chat_bot\",\n    \"model_name\": \"ernie-3.5-8k\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"openai\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\nretriever_config = {\n    \"module_name\": \"retriever\",\n    \"model_name\": \"embedding-v1\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"qianfan\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\npipeline = PPChatOCRv4Doc(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\nvisual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)\n\nmllm_predict_info = None\nuse_mllm = False\n# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.\nif use_mllm:\n    mllm_chat_bot_config = {\n        \"module_name\": \"chat_bot\",\n        \"model_name\": \"PP-DocBee\",\n        \"base_url\": \"http://127.0.0.1:8080/\",  # your local mllm service url\n        \"api_type\": \"openai\",\n        \"api_key\": \"api_key\",  # your api_key\n    }\n\n    mllm_predict_res = pipeline.mllm_pred(\n        input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n        key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n        mllm_chat_bot_config=mllm_chat_bot_config,\n    )\n    mllm_predict_info = mllm_predict_res[\"mllm_res\"]\n\nvisual_info_list = []\nfor res in visual_predict_res:\n    visual_info_list.append(res[\"visual_info\"])\n    layout_parsing_result = res[\"layout_parsing_result\"]\n\nvector_info = pipeline.build_vector(\n    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config\n)\nchat_result = pipeline.chat(\n    key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n    visual_info=visual_info_list,\n    vector_info=vector_info,\n    mllm_predict_info=mllm_predict_info,\n    chat_bot_config=chat_bot_config,\n    retriever_config=retriever_config,\n)\nprint(chat_result)\n```\n\n</details>\n\n<details>\n   <summary><strong>4.4 PaddleOCR-VL Example</strong></summary>\n\n```python\nfrom paddleocr import PaddleOCRVL\n\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")\n```\n\n</details>\n\n### 5. Chinese Heterogeneous AI Accelerators\n- [Huawei Ascend](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html)\n- [KUNLUNXIN](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html)\n\n## üß© More Features\n\n- Convert models to ONNX format: [Obtaining ONNX Models](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html).\n- Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: [High-Performance Inference](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html).\n- Accelerate inference using multi-GPU and multi-process: [Parallel Inference for Pipelines](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html).\n- Integrate PaddleOCR into applications written in C++, C#, Java, etc.: [Serving](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html).\n\n## ‚õ∞Ô∏è Advanced Tutorials\n\n- [PP-OCRv5 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html)\n- [PP-StructureV3 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html)\n- [PP-ChatOCRv4 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html)\n- [PaddleOCR-VL Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html)\n\n## üîÑ Quick Overview of Execution Results\n\n### PP-OCRv5\n\n<div align=\"center\">\n  <p>\n       <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif\" alt=\"PP-OCRv5 Demo\">\n  </p>\n</div>\n\n\n\n### PP-StructureV3\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n### PaddleOCR-VL\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n\n## ‚ú® Stay Tuned\n\n‚≠ê **Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!** ‚≠ê\n\n<div align=\"center\">\n  <p>\n       <img width=\"1200\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif\" alt=\"Star-Project\">\n  </p>\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community\n\n<div align=\"center\">\n\n| PaddlePaddle WeChat official account |  Join the tech discussion group |\n| :---: | :---: |\n| <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg\" width=\"150\"> | <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg\" width=\"150\"> |\n</div>\n\n\n## üòÉ Awesome Projects Leveraging PaddleOCR\nPaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!\n\n<div align=\"center\">\n\n| Project Name | Description |\n| ------------ | ----------- |\n| [RAGFlow](https://github.com/infiniflow/ragflow) <a href=\"https://github.com/infiniflow/ragflow\"><img src=\"https://img.shields.io/github/stars/infiniflow/ragflow\"></a>|RAG engine based on deep document understanding.|\n| [pathway](https://github.com/pathwaycom/pathway) <a href=\"https://github.com/pathwaycom/pathway\"><img src=\"https://img.shields.io/github/stars/pathwaycom/pathway\"></a>|Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.|\n| [MinerU](https://github.com/opendatalab/MinerU) <a href=\"https://github.com/opendatalab/MinerU\"><img src=\"https://img.shields.io/github/stars/opendatalab/MinerU\"></a>|Multi-type Document to Markdown Conversion Tool|\n| [Umi-OCR](https://github.com/hiroi-sora/Umi-OCR) <a href=\"https://github.com/hiroi-sora/Umi-OCR\"><img src=\"https://img.shields.io/github/stars/hiroi-sora/Umi-OCR\"></a>|Free, Open-source, Batch Offline OCR Software.|\n| [cherry-studio](https://github.com/CherryHQ/cherry-studio) <a href=\"https://github.com/CherryHQ/cherry-studio\"><img src=\"https://img.shields.io/github/stars/CherryHQ/cherry-studio\"></a>|A desktop client that supports for multiple LLM providers.|\n| [OmniParser](https://github.com/microsoft/OmniParser)<a href=\"https://github.com/microsoft/OmniParser\"><img src=\"https://img.shields.io/github/stars/microsoft/OmniParser\"></a> |OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.|\n| [QAnything](https://github.com/netease-youdao/QAnything)<a href=\"https://github.com/netease-youdao/QAnything\"><img src=\"https://img.shields.io/github/stars/netease-youdao/QAnything\"></a> |Question and Answer based on Anything.|\n| [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit) <a href=\"https://github.com/opendatalab/PDF-Extract-Kit\"><img src=\"https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit\"></a>|A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.|\n| [Dango-Translator](https://github.com/PantsuDango/Dango-Translator)<a href=\"https://github.com/PantsuDango/Dango-Translator\"><img src=\"https://img.shields.io/github/stars/PantsuDango/Dango-Translator\"></a> |Recognize text on the screen, translate it and show the translation results in real time.|\n| [Learn more projects](./awesome_projects.md) | [More projects based on PaddleOCR](./awesome_projects.md)|\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors\n\n<div align=\"center\">\n<a href=\"https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&max=400&columns=20\"  width=\"800\"/>\n</a>\n</div>\n\n## üåü Star\n\n<div align=\"center\">\n  <p>\n      <img width=\"800\" src=\"https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&type=Date\" alt=\"Star-history\">\n  </p>\n</div>\n\n\n## üìÑ License\nThis project is released under the [Apache 2.0 license](LICENSE).\n\n## üéì Citation\n\n```bibtex\n@misc{cui2025paddleocr30technicalreport,\n      title={PaddleOCR 3.0 Technical Report}, \n      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2507.05595},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2507.05595}, \n}\n\n@misc{cui2025paddleocrvlboostingmultilingualdocument,\n      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, \n      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2510.14528},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2510.14528}, \n}\n```\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/PaddlePaddle/PaddleOCR",
          "homepage": "https://www.paddleocr.ai",
          "language": "Python",
          "forks": 9368,
          "open_issues": 280,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23534030?v=4",
      "velocity": 70852.1,
      "is_rising_star": true,
      "heatScore": 21258.99627674898,
      "popularityScore": 64411
    },
    {
      "id": "github-vllm-project-vllm",
      "name": "vllm",
      "author": "vllm-project",
      "description": "A high-throughput and memory-efficient inference and serving engine for LLMs",
      "task": "tool",
      "tags": [
        "amd",
        "blackwell",
        "cuda",
        "deepseek",
        "deepseek-v3",
        "gpt",
        "gpt-oss",
        "inference",
        "kimi",
        "llama",
        "llm",
        "llm-serving",
        "model-serving",
        "moe",
        "openai",
        "pytorch",
        "qwen",
        "qwen3",
        "tpu",
        "transformer"
      ],
      "likes": 127100,
      "downloads": 127100,
      "lastModified": "2025-11-20T15:22:49Z",
      "lastModifiedTimestamp": 1763652169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/vllm-project/vllm",
          "homepage": "https://docs.vllm.ai",
          "language": "Python",
          "forks": 11425,
          "open_issues": 3142,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/136984999?v=4",
      "velocity": 69905,
      "is_rising_star": true,
      "heatScore": 20974.86218567212,
      "popularityScore": 63550
    },
    {
      "id": "github-hiyouga-LLaMA-Factory",
      "name": "LLaMA-Factory",
      "author": "hiyouga",
      "description": "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "deepseek",
        "fine-tuning",
        "gemma",
        "gpt",
        "instruction-tuning",
        "large-language-models",
        "llama",
        "llama3",
        "llm",
        "lora",
        "moe",
        "nlp",
        "peft",
        "qlora",
        "quantization",
        "qwen",
        "rlhf",
        "transformers"
      ],
      "likes": 125604,
      "downloads": 125604,
      "lastModified": "2025-11-20T15:04:01Z",
      "lastModifiedTimestamp": 1763651041000,
      "readme": "![# LLaMA Factory](assets/logo.png)\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)\n[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)\n[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)\n[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)\n[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)\n[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)\n[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)\n\n[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)\n[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)\n[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)\n[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/en/)\n\n[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)\n[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)\n[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)\n[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)\n[![Open in Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)\n[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)\n[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)\n\n### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.\n\n<div align=\"center\" markdown=\"1\">\n\n### Supporters ‚ù§Ô∏è\n\n| <div style=\"text-align: center;\"><a href=\"https://warp.dev/llama-factory\"><img alt=\"Warp sponsorship\" width=\"400\" src=\"assets/sponsors/warp.jpg\"></a><br><a href=\"https://warp.dev/llama-factory\" style=\"font-size:larger;\">Warp, the agentic terminal for developers</a><br><a href=\"https://warp.dev/llama-factory\">Available for MacOS, Linux, & Windows</a> | <a href=\"https://serpapi.com\"><img alt=\"SerpAPI sponsorship\" width=\"250\" src=\"assets/sponsors/serpapi.svg\"> </a> |\n| ---- | ---- |\n\n----\n\n### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n\n![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)\n\n</div>\n\nüëã Join our [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg), [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg), [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg), [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg) user group.\n\n\\[ English | [‰∏≠Êñá](README_zh.md) \\]\n\n**Fine-tuning a large language model can be easy as...**\n\nhttps://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e\n\nStart local training:\n- Please refer to [usage](#getting-started)\n\nStart cloud training:\n- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing\n- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory\n- **LLaMA Factory Online**: https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory\n- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory\n\nRead technical notes:\n- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/\n- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html\n- **Official Blog**: https://blog.llamafactory.net/en/\n- **Official Course**: https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory\n\n> [!NOTE]\n> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.\n\n## Table of Contents\n\n- [Features](#features)\n- [Blogs](#blogs)\n- [Changelog](#changelog)\n- [Supported Models](#supported-models)\n- [Supported Training Approaches](#supported-training-approaches)\n- [Provided Datasets](#provided-datasets)\n- [Requirement](#requirement)\n- [Getting Started](#getting-started)\n  - [Installation](#installation)\n  - [Data Preparation](#data-preparation)\n  - [Quickstart](#quickstart)\n  - [Fine-Tuning with LLaMA Board GUI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n  - [LLaMA Factory Online](#llama-factory-online)\n  - [Build Docker](#build-docker)\n  - [Deploy with OpenAI-style API and vLLM](#deploy-with-openai-style-api-and-vllm)\n  - [Download from ModelScope Hub](#download-from-modelscope-hub)\n  - [Download from Modelers Hub](#download-from-modelers-hub)\n  - [Use W&B Logger](#use-wb-logger)\n  - [Use SwanLab Logger](#use-swanlab-logger)\n- [Projects using LLaMA Factory](#projects-using-llama-factory)\n- [License](#license)\n- [Citation](#citation)\n- [Acknowledgement](#acknowledgement)\n\n## Features\n\n- **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.\n- **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.\n- **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n- **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), [Muon](https://github.com/KellerJordan/Muon), [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.\n- **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [KTransformers](https://github.com/kvcache-ai/ktransformers/), RoPE scaling, NEFTune and rsLoRA.\n- **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.\n- **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, [SwanLab](https://github.com/SwanHubX/SwanLab), etc.\n- **Faster inference**: OpenAI-style API, Gradio UI and CLI with [vLLM worker](https://github.com/vllm-project/vllm) or [SGLang worker](https://github.com/sgl-project/sglang).\n\n### Day-N Support for Fine-Tuning Cutting-Edge Models\n\n| Support Date | Model Name                                                           |\n| ------------ | -------------------------------------------------------------------- |\n| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |\n| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |\n\n## Blogs\n\n> [!TIP]\n> Now we have a dedicated blog for LLaMA Factory!\n>\n> Website: https://blog.llamafactory.net/en/\n\n- üí° [KTransformers Fine-Tuning √ó LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/) (English)\n- üí° [Easy Dataset √ó LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g) (English)\n- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory) (Chinese)\n- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/) (Chinese)\n- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/) (English)\n\n<details><summary>All Blogs</summary>\n\n- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory) (Chinese)\n- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b) (Chinese)\n- [A One-Stop Code-Free Model Fine-Tuning \\& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/) (Chinese)\n- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl) (Chinese)\n- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory) (Chinese)\n\n</details>\n\n## Changelog\n\n[25/10/26] We support Megatron-core training backend with [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter). See [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237) to get started.\n\n[25/08/22] We supported **[OFT](https://arxiv.org/abs/2306.07280)** and **[OFTv2](https://arxiv.org/abs/2506.19847)**. See [examples](examples/README.md) for usage.\n\n[25/08/20] We supported fine-tuning the **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** models. See [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) to get started.\n\n[25/08/06] We supported fine-tuning the **[GPT-OSS](https://github.com/openai/gpt-oss)** models. See [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) to get started.\n\n<details><summary>Full Changelog</summary>\n\n[25/07/02] We supported fine-tuning the **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** model.\n\n[25/04/28] We supported fine-tuning the **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** model family.\n\n[25/04/21] We supported the **[Muon](https://github.com/KellerJordan/Muon)** optimizer. See [examples](examples/README.md) for usage. Thank [@tianshijing](https://github.com/tianshijing)'s PR.\n\n[25/04/16] We supported fine-tuning the **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** model. See [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) to get started.\n\n[25/04/14] We supported fine-tuning the **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** and **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** models.\n\n[25/04/06] We supported fine-tuning the **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** model. See [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) to get started.\n\n[25/03/31] We supported fine-tuning the **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** model. See [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) to get started.\n\n[25/03/15] We supported **[SGLang](https://github.com/sgl-project/sglang)** as inference backend. Try `infer_backend: sglang` to accelerate inference.\n\n[25/03/12] We supported fine-tuning the **[Gemma 3](https://huggingface.co/blog/gemma3)** model.\n\n[25/02/24] Announcing **[EasyR1](https://github.com/hiyouga/EasyR1)**, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.\n\n[25/02/11] We supported saving the **[Ollama](https://github.com/ollama/ollama)** modelfile when exporting the model checkpoints. See [examples](examples/README.md) for usage.\n\n[25/02/05] We supported fine-tuning the **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** and **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** on audio understanding tasks.\n\n[25/01/31] We supported fine-tuning the **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** and **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** models.\n\n[25/01/15] We supported **[APOLLO](https://arxiv.org/abs/2412.05270)** optimizer. See [examples](examples/README.md) for usage.\n\n[25/01/14] We supported fine-tuning the **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** and **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** models. Thank [@BUAADreamer](https://github.com/BUAADreamer)'s PR.\n\n[25/01/14] We supported fine-tuning the **[InternLM 3](https://huggingface.co/collections/internlm/)** models. Thank [@hhaAndroid](https://github.com/hhaAndroid)'s PR.\n\n[25/01/10] We supported fine-tuning the **[Phi-4](https://huggingface.co/microsoft/phi-4)** model.\n\n[24/12/21] We supported using **[SwanLab](https://github.com/SwanHubX/SwanLab)** for experiment tracking and visualization. See [this section](#use-swanlab-logger) for details.\n\n[24/11/27] We supported fine-tuning the **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** model and the **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** dataset.\n\n[24/10/09] We supported downloading pre-trained models and datasets from the **[Modelers Hub](https://modelers.cn/models)**. See [this tutorial](#download-from-modelers-hub) for usage.\n\n[24/09/19] We supported fine-tuning the **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** models.\n\n[24/08/30] We supported fine-tuning the **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** models. Thank [@simonJJJ](https://github.com/simonJJJ)'s PR.\n\n[24/08/27] We supported **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**. Try `enable_liger_kernel: true` for efficient training.\n\n[24/08/09] We supported **[Adam-mini](https://github.com/zyushun/Adam-mini)** optimizer. See [examples](examples/README.md) for usage. Thank [@relic-yuexi](https://github.com/relic-yuexi)'s PR.\n\n[24/07/04] We supported [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing). Use `neat_packing: true` to activate it. Thank [@chuan298](https://github.com/chuan298)'s PR.\n\n[24/06/16] We supported **[PiSSA](https://arxiv.org/abs/2404.02948)** algorithm. See [examples](examples/README.md) for usage.\n\n[24/06/07] We supported fine-tuning the **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** and **[GLM-4](https://github.com/THUDM/GLM-4)** models.\n\n[24/05/26] We supported **[SimPO](https://arxiv.org/abs/2405.14734)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/20] We supported fine-tuning the **PaliGemma** series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with `paligemma` template for chat completion.\n\n[24/05/18] We supported **[KTO](https://arxiv.org/abs/2402.01306)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/14] We supported training and inference on the Ascend NPU devices. Check [installation](#installation) section for details.\n\n[24/04/26] We supported fine-tuning the **LLaVA-1.5** multimodal LLMs. See [examples](examples/README.md) for usage.\n\n[24/04/22] We provided a **[Colab notebook](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)** for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) and [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese) for details.\n\n[24/04/21] We supported **[Mixture-of-Depths](https://arxiv.org/abs/2404.02258)** according to [AstraMindAI's implementation](https://github.com/astramind-ai/Mixture-of-depths). See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[BAdam](https://arxiv.org/abs/2404.02827)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves **117%** speed and **50%** memory compared with FlashAttention-2, more benchmarks can be found in [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison).\n\n[24/03/31] We supported **[ORPO](https://arxiv.org/abs/2403.07691)**. See [examples](examples/README.md) for usage.\n\n[24/03/21] Our paper \"[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)\" is available at arXiv!\n\n[24/03/20] We supported **FSDP+QLoRA** that fine-tunes a 70B model on 2x24GB GPUs. See [examples](examples/README.md) for usage.\n\n[24/03/13] We supported **[LoRA+](https://arxiv.org/abs/2402.12354)**. See [examples](examples/README.md) for usage.\n\n[24/03/07] We supported **[GaLore](https://arxiv.org/abs/2403.03507)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/03/07] We integrated **[vLLM](https://github.com/vllm-project/vllm)** for faster and concurrent inference. Try `infer_backend: vllm` to enjoy **270%** inference speed.\n\n[24/02/28] We supported weight-decomposed LoRA (**[DoRA](https://arxiv.org/abs/2402.09353)**). Try `use_dora: true` to activate DoRA training.\n\n[24/02/15] We supported **block expansion** proposed by [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro). See [examples](examples/README.md) for usage.\n\n[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this [blog post](https://qwenlm.github.io/blog/qwen1.5/) for details.\n\n[24/01/18] We supported **agent tuning** for most models, equipping model with tool using abilities by fine-tuning with `dataset: glaive_toolcall_en`.\n\n[23/12/23] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try `use_unsloth: true` argument to activate unsloth patch. It achieves **170%** speed in our benchmark, check [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison) for details.\n\n[23/12/12] We supported fine-tuning the latest MoE model **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)** in our framework. See hardware requirement [here](#hardware-requirement).\n\n[23/12/01] We supported downloading pre-trained models and datasets from the **[ModelScope Hub](https://modelscope.cn/models)**. See [this tutorial](#download-from-modelscope-hub) for usage.\n\n[23/10/21] We supported **[NEFTune](https://arxiv.org/abs/2310.05914)** trick for fine-tuning. Try `neftune_noise_alpha: 5` argument to activate NEFTune.\n\n[23/09/27] We supported **$S^2$-Attn** proposed by [LongLoRA](https://github.com/dvlab-research/LongLoRA) for the LLaMA models. Try `shift_attn: true` argument to enable shift short attention.\n\n[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See [examples](examples/README.md) for usage.\n\n[23/09/10] We supported **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**. Try `flash_attn: fa2` argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.\n\n[23/08/12] We supported **RoPE scaling** to extend the context length of the LLaMA models. Try `rope_scaling: linear` argument in training and `rope_scaling: dynamic` argument at inference to extrapolate the position embeddings.\n\n[23/08/11] We supported **[DPO training](https://arxiv.org/abs/2305.18290)** for instruction-tuned models. See [examples](examples/README.md) for usage.\n\n[23/07/31] We supported **dataset streaming**. Try `streaming: true` and `max_steps: 10000` arguments to load your dataset in streaming mode.\n\n[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ([LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)) for details.\n\n[23/07/18] We developed an **all-in-one Web UI** for training, evaluation and inference. Try `train_web.py` to fine-tune models in your Web browser. Thank [@KanadeSiina](https://github.com/KanadeSiina) and [@codemayq](https://github.com/codemayq) for their efforts in the development.\n\n[23/07/09] We released **[FastEdit](https://github.com/hiyouga/FastEdit)** ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow [FastEdit](https://github.com/hiyouga/FastEdit) if you are interested.\n\n[23/06/29] We provided a **reproducible example** of training a chat model using instruction-following datasets, see [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft) for details.\n\n[23/06/22] We aligned the [demo API](src/api_demo.py) with the [OpenAI's](https://platform.openai.com/docs/api-reference/chat) format where you can insert the fine-tuned model in **arbitrary ChatGPT-based applications**.\n\n[23/06/03] We supported quantized training and inference (aka **[QLoRA](https://github.com/artidoro/qlora)**). See [examples](examples/README.md) for usage.\n\n</details>\n\n> [!TIP]\n> If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.\n\n## Supported Models\n\n| Model                                                             | Model size                       | Template             |\n| ----------------------------------------------------------------- | -------------------------------- | -------------------- |\n| [Baichuan 2](https://huggingface.co/baichuan-inc)                 | 7B/13B                           | baichuan2            |\n| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |\n| [ChatGLM3](https://huggingface.co/THUDM)                          | 6B                               | chatglm3             |\n| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |\n| [DeepSeek (Code/MoE)](https://huggingface.co/deepseek-ai)         | 7B/16B/67B/236B                  | deepseek             |\n| [DeepSeek 2.5/3](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |\n| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |\n| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |\n| [Falcon](https://huggingface.co/tiiuae)                           | 7B/11B/40B/180B                  | falcon               |\n| [Falcon-H1](https://huggingface.co/tiiuae)                        | 0.5B/1.5B/3B/7B/34B              | falcon_h1            |\n| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |\n| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |\n| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |\n| [GLM-4.1V](https://huggingface.co/zai-org)                        | 9B                               | glm4v                |\n| [GLM-4.5/GLM-4.5V](https://huggingface.co/zai-org)                | 106B/355B                        | glm4_moe/glm4v_moe   |\n| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |\n| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt                  |\n| [Granite 3.0-3.3](https://huggingface.co/ibm-granite)             | 1B/2B/3B/8B                      | granite3             |\n| [Granite 4](https://huggingface.co/ibm-granite)                   | 7B                               | granite4             |\n| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |\n| [Index](https://huggingface.co/IndexTeam)                         | 1.9B                             | index                |\n| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |\n| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |\n| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |\n| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |\n| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |\n| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |\n| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |\n| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |\n| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |\n| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |\n| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |\n| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |\n| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |\n| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B                               | mimo                 |\n| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |\n| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |\n| [Ministral/Mistral-Nemo](https://huggingface.co/mistralai)        | 8B/12B                           | ministral            |\n| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |\n| [Mistral Small](https://huggingface.co/mistralai)                 | 24B                              | mistral_small        |\n| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |\n| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |\n| [Phi-1.5/Phi-2](https://huggingface.co/microsoft)                 | 1.3B/2.7B                        | -                    |\n| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |\n| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |\n| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |\n| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |\n| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |\n| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |\n| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |\n| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |\n| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |\n| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |\n| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |\n| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |\n| [Skywork o1](https://huggingface.co/Skywork)                      | 8B                               | skywork_o1           |\n| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |\n| [TeleChat2](https://huggingface.co/Tele-AI)                       | 3B/7B/35B/115B                   | telechat2            |\n| [XVERSE](https://huggingface.co/xverse)                           | 7B/13B/65B                       | xverse               |\n| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |\n| [Yi-VL](https://huggingface.co/01-ai)                             | 6B/34B                           | yi_vl                |\n| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |\n\n> [!NOTE]\n> For the \"base\" models, the `template` argument can be chosen from `default`, `alpaca`, `vicuna` etc. But make sure to use the **corresponding template** for the \"instruct/chat\" models.\n>\n> If the model has both reasoning and non-reasoning versions, please use the `_nothink` suffix to distinguish between them. For example, `qwen3` and `qwen3_nothink`.\n>\n> Remember to use the **SAME** template in training and inference.\n>\n> \\*: You should install the `transformers` from main branch and use `DISABLE_VERSION_CHECK=1` to skip version check.\n>\n> \\*\\*: You need to install a specific version of `transformers` to use the corresponding model.\n\nPlease refer to [constants.py](src/llamafactory/extras/constants.py) for a full list of models we supported.\n\nYou also can add a custom chat template to [template.py](src/llamafactory/data/template.py).\n\n## Supported Training Approaches\n\n| Approach               |     Full-tuning    |    Freeze-tuning   |       LoRA         |       QLoRA        |        OFT         |        QOFT        |\n| ---------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |\n| Pre-Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Supervised Fine-Tuning | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Reward Modeling        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| PPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| DPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| KTO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| ORPO Training          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| SimPO Training         | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n\n> [!TIP]\n> The implementation details of PPO can be found in [this blog](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html).\n\n## Provided Datasets\n\n<details><summary>Pre-training datasets</summary>\n\n- [Wiki Demo (en)](data/wiki_demo.txt)\n- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)\n- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)\n- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)\n- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)\n- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)\n- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)\n- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)\n- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)\n- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)\n- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)\n- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)\n- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)\n- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)\n- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)\n- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)\n\n</details>\n\n<details><summary>Supervised fine-tuning datasets</summary>\n\n- [Identity (en&zh)](data/identity.json)\n- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)\n- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)\n- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)\n- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)\n- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)\n- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)\n- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)\n- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)\n- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)\n- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)\n- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)\n- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)\n- [UltraChat (en)](https://github.com/thunlp/UltraChat)\n- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)\n- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)\n- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)\n- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)\n- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)\n- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)\n- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)\n- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)\n- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)\n- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)\n- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)\n- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)\n- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)\n- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)\n- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)\n- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)\n- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)\n- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)\n- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)\n- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)\n- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)\n- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)\n- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)\n- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)\n- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)\n- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)\n- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)\n- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)\n- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)\n- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)\n- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)\n- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)\n- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)\n- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)\n- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)\n- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)\n- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)\n- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)\n- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)\n\n</details>\n\n<details><summary>Preference datasets</summary>\n\n- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)\n- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)\n- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)\n- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)\n- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)\n- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)\n- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)\n- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)\n- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)\n\n</details>\n\nSome datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.\n\n```bash\npip install \"huggingface_hub<1.0.0\"\nhuggingface-cli login\n```\n\n## Requirement\n\n| Mandatory    | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| python       | 3.9     | 3.10      |\n| torch        | 2.0.0   | 2.6.0     |\n| torchvision  | 0.15.0  | 0.21.0    |\n| transformers | 4.49.0  | 4.50.0    |\n| datasets     | 2.16.0  | 3.2.0     |\n| accelerate   | 0.34.0  | 1.2.1     |\n| peft         | 0.14.0  | 0.15.1    |\n| trl          | 0.8.6   | 0.9.6     |\n\n| Optional     | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| CUDA         | 11.6    | 12.2      |\n| deepspeed    | 0.10.0  | 0.16.4    |\n| bitsandbytes | 0.39.0  | 0.43.1    |\n| vllm         | 0.4.3   | 0.8.2     |\n| flash-attn   | 2.5.6   | 2.7.2     |\n\n### Hardware Requirement\n\n\\* *estimated*\n\n| Method                              | Bits |   7B  |  14B  |  30B  |   70B  |   `x`B  |\n| ----------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |\n| Full (`bf16` or `fp16`)             |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |\n| Full (`pure_bf16`)                  |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |\n| Freeze/LoRA/GaLore/APOLLO/BAdam/OFT |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |\n| QLoRA / QOFT                        |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |\n| QLoRA / QOFT                        |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |\n| QLoRA / QOFT                        |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |\n\n## Getting Started\n\n### Installation\n\n> [!IMPORTANT]\n> Installation is mandatory.\n\n#### Install from Source\n\n```bash\ngit clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\npip install -e \".[torch,metrics]\" --no-build-isolation\n```\n\nExtra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev\n\n#### Install from Docker Image\n\n```bash\ndocker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest\n```\n\nThis image is built on Ubuntu 22.04 (x86\\_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.\n\nFind the pre-built images: https://hub.docker.com/r/hiyouga/llamafactory/tags\n\nPlease refer to [build docker](#build-docker) to build the image yourself.\n\n<details><summary>Setting up a virtual environment with <b>uv</b></summary>\n\nCreate an isolated Python environment with [uv](https://github.com/astral-sh/uv):\n\n```bash\nuv sync --extra torch --extra metrics --prerelease=allow\n```\n\nRun LLaMA-Factory in the isolated environment:\n\n```bash\nuv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml\n```\n\n</details>\n\n<details><summary>For Windows users</summary>\n\n#### Install PyTorch\n\nYou need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the [official website](https://pytorch.org/get-started/locally/) and the following command to install PyTorch with CUDA support:\n\n```bash\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\npython -c \"import torch; print(torch.cuda.is_available())\"\n```\n\nIf you see `True` then you have successfully installed PyTorch with CUDA support.\n\nTry `dataloader_num_workers: 0` if you encounter `Can't pickle local object` error.\n\n#### Install BitsAndBytes\n\nIf you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of `bitsandbytes` library, which supports CUDA 11.1 to 12.2, please select the appropriate [release version](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels) based on your CUDA version.\n\n```bash\npip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl\n```\n\n#### Install Flash Attention-2\n\nTo enable FlashAttention-2 on the Windows platform, please use the script from [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) to compile and install it by yourself.\n\n</details>\n\n<details><summary>For Ascend NPU users</summary>\n\nTo install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: `pip install -e \".[torch-npu,metrics]\"`. Additionally, you need to install the **[Ascend CANN Toolkit and Kernels](https://www.hiascend.com/developer/download/community/result?module=cann)**. Please follow the [installation tutorial](https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html) or use the following commands:\n\n```bash\n# replace the url according to your CANN version and devices\n# install CANN Toolkit\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# install CANN Kernels\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# set env variables\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n| Requirement  | Minimum | Recommend      |\n| ------------ | ------- | -------------- |\n| CANN         | 8.0.RC1 | 8.0.0.alpha002 |\n| torch        | 2.1.0   | 2.4.0          |\n| torch-npu    | 2.1.0   | 2.4.0.post2    |\n| deepspeed    | 0.13.2  | 0.13.2         |\n| vllm-ascend  | -       | 0.7.3          |\n\nRemember to use `ASCEND_RT_VISIBLE_DEVICES` instead of `CUDA_VISIBLE_DEVICES` to specify the device to use.\n\nIf you cannot infer model on NPU devices, try setting `do_sample: false` in the configurations.\n\nDownload the pre-built Docker images: [32GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html) | [64GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html)\n\n#### Install BitsAndBytes\n\nTo use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:\n\n1. Manually compile bitsandbytes: Refer to [the installation documentation](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU) for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.\n\n```bash\n# Install bitsandbytes from source\n# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch\ngit clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git\ncd bitsandbytes/\n\n# Install dependencies\npip install -r requirements-dev.txt\n\n# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference\napt-get install -y build-essential cmake\n\n# Compile & install  \ncmake -DCOMPUTE_BACKEND=npu -S .\nmake\npip install .\n```\n\n2. Install transformers from the main branch.\n\n```bash\ngit clone -b main https://github.com/huggingface/transformers.git\ncd transformers\npip install .\n```\n\n3. Set `double_quantization: false` in the configuration. You can refer to the [example](examples/train_qlora/llama3_lora_sft_bnb_npu.yaml).\n\n</details>\n\n### Data Preparation\n\nPlease refer to [data/README.md](data/README.md) for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.\n\n> [!NOTE]\n> Please update `data/dataset_info.json` to use your custom dataset.\n\nYou can also use **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**, **[DataFlow](https://github.com/OpenDCAI/DataFlow)** and **[GraphGen](https://github.com/open-sciencelab/GraphGen)** to create synthetic data for fine-tuning.\n\n### Quickstart\n\nUse the following 3 commands to run LoRA **fine-tuning**, **inference** and **merging** of the Llama3-8B-Instruct model, respectively.\n\n```bash\nllamafactory-cli train examples/train_lora/llama3_lora_sft.yaml\nllamafactory-cli chat examples/inference/llama3_lora_sft.yaml\nllamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml\n```\n\nSee [examples/README.md](examples/README.md) for advanced usage (including distributed training).\n\n> [!TIP]\n> Use `llamafactory-cli help` to show help information.\n>\n> Read [FAQs](https://github.com/hiyouga/LLaMA-Factory/issues/4614) first if you encounter any problems.\n\n### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))\n\n```bash\nllamafactory-cli webui\n```\n\n### LLaMA Factory Online\n\nRead our [documentation](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory).\n\n### Build Docker\n\nFor CUDA users:\n\n```bash\ncd docker/docker-cuda/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ncd docker/docker-npu/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ncd docker/docker-rocm/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\n<details><summary>Build without Docker Compose</summary>\n\nFor CUDA users:\n\n```bash\ndocker build -f ./docker/docker-cuda/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host --gpus=all \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ndocker build -f ./docker/docker-npu/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=torch-npu,metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -v /usr/local/dcmi:/usr/local/dcmi \\\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n    -v /etc/ascend_install.info:/etc/ascend_install.info \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/davinci0 \\\n    --device /dev/davinci_manager \\\n    --device /dev/devmm_svm \\\n    --device /dev/hisi_hdc \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ndocker build -f ./docker/docker-rocm/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/kfd \\\n    --device /dev/dri \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\n</details>\n\n<details><summary>Use Docker volumes</summary>\n\nYou can uncomment `VOLUME [ \"/root/.cache/huggingface\", \"/app/shared_data\", \"/app/output\" ]` in the Dockerfile to use data volumes.\n\nWhen building the Docker image, use `-v ./hf_cache:/root/.cache/huggingface` argument to mount the local directory to the container. The following data volumes are available.\n\n- `hf_cache`: Utilize Hugging Face cache on the host machine.\n- `shared_data`: The directionary to store datasets on the host machine.\n- `output`: Set export dir to this location so that the merged result can be accessed directly on the host machine.\n\n</details>\n\n### Deploy with OpenAI-style API and vLLM\n\n```bash\nAPI_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true\n```\n\n> [!TIP]\n> Visit [this page](https://platform.openai.com/docs/api-reference/chat/create) for API document.\n>\n> Examples: [Image understanding](scripts/api_example/test_image.py) | [Function calling](scripts/api_example/test_toolcall.py)\n\n### Download from ModelScope Hub\n\nIf you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.\n\n```bash\nexport USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the ModelScope Hub as the `model_name_or_path`. You can find a full list of model IDs at [ModelScope Hub](https://modelscope.cn/models), e.g., `LLM-Research/Meta-Llama-3-8B-Instruct`.\n\n### Download from Modelers Hub\n\nYou can also use Modelers Hub to download models and datasets.\n\n```bash\nexport USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the Modelers Hub as the `model_name_or_path`. You can find a full list of model IDs at [Modelers Hub](https://modelers.cn/models), e.g., `TeleAI/TeleChat-7B-pt`.\n\n### Use W&B Logger\n\nTo use [Weights & Biases](https://wandb.ai) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nreport_to: wandb\nrun_name: test_run # optional\n```\n\nSet `WANDB_API_KEY` to [your key](https://wandb.ai/authorize) when launching training tasks to log in with your W&B account.\n\n### Use SwanLab Logger\n\nTo use [SwanLab](https://github.com/SwanHubX/SwanLab) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nuse_swanlab: true\nswanlab_run_name: test_run # optional\n```\n\nWhen launching training tasks, you can log in to SwanLab in three ways:\n\n1. Add `swanlab_api_key=<your_api_key>` to the yaml file, and set it to your [API key](https://swanlab.cn/settings).\n2. Set the environment variable `SWANLAB_API_KEY` to your [API key](https://swanlab.cn/settings).\n3. Use the `swanlab login` command to complete the login.\n\n## Projects using LLaMA Factory\n\nIf you have a project that should be incorporated, please contact via email or create a pull request.\n\n<details><summary>Click to show</summary>\n\n1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)\n1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)\n1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)\n1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)\n1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)\n1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)\n1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)\n1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)\n1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)\n1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)\n1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)\n1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)\n1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)\n1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)\n1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)\n1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)\n1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)\n1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)\n1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)\n1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)\n1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)\n1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)\n1. Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)\n1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)\n1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)\n1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)\n1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)\n1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)\n1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)\n1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)\n1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)\n1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)\n1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)\n1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)\n1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)\n1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)\n1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)\n1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)\n1. Dammu et al. \"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)\n1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)\n1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)\n1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)\n1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)\n1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)\n1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)\n1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)\n1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)\n1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)\n1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)\n1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)\n1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)\n1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)\n1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)\n1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)\n1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)\n1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)\n1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)\n1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)\n1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)\n1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)\n1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)\n1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)\n1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)\n1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)\n1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)\n1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)\n1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)\n1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)\n1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)\n1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)\n1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)\n1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)\n1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)\n1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)\n1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)\n1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)\n1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)\n1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)\n1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)\n1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)\n1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)\n1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)\n1. Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. [[paper]](https://aclanthology.org/2024.findings-acl.830.pdf)\n1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.\n1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.\n1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.\n1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.\n1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.\n1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**: A large language model specialized in generate metadata for stable diffusion. [[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)\n1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.\n1. **[AutoRE](https://github.com/THUDM/AutoRE)**: A document-level relation extraction system based on large language models.\n1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.\n1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.\n1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [[blog]](https://zhuanlan.zhihu.com/p/987727357)\n1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**: A modified library that supports long sequence SFT & DPO using ring attention.\n1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**: An o1-like model fine-tuned by NovaSky AI with very small cost.\n1. **[WeClone](https://github.com/xming521/WeClone)**: One-stop solution for creating your digital avatar from chat logs.\n1. **[EmoLLM](https://github.com/SmartFlowAI/EmoLLM)**: A project about large language models (LLMs) and mental health.\n</details>\n\n## License\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n\nPlease follow the model licenses to use the corresponding model weights: [Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)\n\n## Citation\n\nIf this work is helpful, please kindly cite as:\n\n```bibtex\n@inproceedings{zheng2024llamafactory,\n  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},\n  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},\n  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},\n  address={Bangkok, Thailand},\n  publisher={Association for Computational Linguistics},\n  year={2024},\n  url={http://arxiv.org/abs/2403.13372}\n}\n```\n\n## Acknowledgement\n\nThis repo benefits from [PEFT](https://github.com/huggingface/peft), [TRL](https://github.com/huggingface/trl), [QLoRA](https://github.com/artidoro/qlora) and [FastChat](https://github.com/lm-sys/FastChat). Thanks for their wonderful works.\n\n## Star History\n\n![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/hiyouga/LLaMA-Factory",
          "homepage": "https://llamafactory.readthedocs.io",
          "language": "Python",
          "forks": 7601,
          "open_issues": 783,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/16256802?v=4",
      "velocity": 69082.2,
      "is_rising_star": true,
      "heatScore": 20728.018586272854,
      "popularityScore": 62802
    },
    {
      "id": "github-FoundationAgents-MetaGPT",
      "name": "MetaGPT",
      "author": "FoundationAgents",
      "description": "üåü The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
      "task": "tool",
      "tags": [
        "agent",
        "gpt",
        "llm",
        "metagpt",
        "multi-agent"
      ],
      "likes": 119174,
      "downloads": 119174,
      "lastModified": "2025-11-20T13:55:30Z",
      "lastModifiedTimestamp": 1763646930000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FoundationAgents/MetaGPT",
          "homepage": "https://mgx.dev/",
          "language": "Python",
          "forks": 7283,
          "open_issues": 57,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/198047230?v=4",
      "velocity": 65545.7,
      "is_rising_star": true,
      "heatScore": 19667.052611166364,
      "popularityScore": 59587
    },
    {
      "id": "github-unclecode-crawl4ai",
      "name": "crawl4ai",
      "author": "unclecode",
      "description": "üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN",
      "task": "tool",
      "tags": [],
      "likes": 112306,
      "downloads": 112306,
      "lastModified": "2025-11-20T15:20:08Z",
      "lastModifiedTimestamp": 1763652008000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unclecode/crawl4ai",
          "homepage": "https://crawl4ai.com",
          "language": "Python",
          "forks": 5636,
          "open_issues": 263,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/12494079?v=4",
      "velocity": 61768.3,
      "is_rising_star": true,
      "heatScore": 18533.814566488363,
      "popularityScore": 56153
    },
    {
      "id": "github-OpenBB-finance-OpenBB",
      "name": "OpenBB",
      "author": "OpenBB-finance",
      "description": "Financial data platform for analysts, quants and AI agents.",
      "task": "tool",
      "tags": [
        "ai",
        "crypto",
        "derivatives",
        "economics",
        "equity",
        "finance",
        "fixed-income",
        "machine-learning",
        "openbb",
        "options",
        "python",
        "quantitative-finance",
        "stocks"
      ],
      "likes": 109330,
      "downloads": 109330,
      "lastModified": "2025-11-20T13:41:09Z",
      "lastModifiedTimestamp": 1763646069000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBB-finance/OpenBB",
          "homepage": "https://openbb.co",
          "language": "Python",
          "forks": 5288,
          "open_issues": 52,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/80064875?v=4",
      "velocity": 60131.5,
      "is_rising_star": true,
      "heatScore": 18042.766402107914,
      "popularityScore": 54665
    },
    {
      "id": "github-wshobson-agents",
      "name": "agents",
      "author": "wshobson",
      "description": "Intelligent automation and multi-agent orchestration for Claude Code",
      "task": "tool",
      "tags": [
        "agents",
        "ai-agents",
        "anthropic",
        "anthropic-claude",
        "automation",
        "claude",
        "claude-code",
        "claude-code-cli",
        "claude-code-commands",
        "claude-code-plugin",
        "claude-code-plugins",
        "claude-code-subagents",
        "claude-skills",
        "claudecode",
        "claudecode-config",
        "claudecode-subagents",
        "orchestration",
        "sub-agents",
        "subagents",
        "workflows",
        "agent-computer-interface",
        "computer-automation",
        "computer-use",
        "computer-use-agent",
        "cua",
        "grounding",
        "gui-agents",
        "in-context-reinforcement-learning",
        "memory",
        "mllm",
        "planning",
        "retrieval-augmented-generation",
        "ai",
        "openai",
        "real-time",
        "video",
        "voice",
        "autonomous-agents",
        "language-model",
        "llm",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 106916,
      "downloads": 106916,
      "lastModified": "2025-11-20T15:44:42Z",
      "lastModifiedTimestamp": 1763653482000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/wshobson/agents",
          "homepage": "https://sethhobson.com",
          "language": "Python",
          "forks": 2352,
          "open_issues": 4,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/contains-studio/agents",
          "homepage": null,
          "language": null,
          "forks": 2129,
          "open_issues": 9,
          "license": "No license"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/simular-ai/Agent-S",
          "homepage": "https://www.simular.ai",
          "language": "Python",
          "forks": 907,
          "open_issues": 13,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/livekit/agents",
          "homepage": "https://docs.livekit.io/agents",
          "language": "Python",
          "forks": 1776,
          "open_issues": 448,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/aiwaves-cn/agents",
          "homepage": "",
          "language": "Python",
          "forks": 452,
          "open_issues": 39,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
      "velocity": 58803.8,
      "is_rising_star": true,
      "heatScore": 17644.44961458143,
      "popularityScore": 53458
    },
    {
      "id": "github-cline-cline",
      "name": "cline",
      "author": "cline",
      "description": "Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 105064,
      "downloads": 105064,
      "lastModified": "2025-11-20T15:39:22Z",
      "lastModifiedTimestamp": 1763653162000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/cline/cline",
          "homepage": "https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev",
          "language": "TypeScript",
          "forks": 5246,
          "open_issues": 895,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/184127137?v=4",
      "velocity": 57785.2,
      "is_rising_star": true,
      "heatScore": 17338.864302541922,
      "popularityScore": 52532
    },
    {
      "id": "github-microsoft-autogen",
      "name": "autogen",
      "author": "microsoft",
      "description": "A programming framework for agentic AI",
      "task": "tool",
      "tags": [
        "agentic",
        "agentic-agi",
        "agents",
        "ai",
        "autogen",
        "autogen-ecosystem",
        "chatgpt",
        "framework",
        "llm-agent",
        "llm-framework"
      ],
      "likes": 103658,
      "downloads": 103658,
      "lastModified": "2025-11-20T14:57:51Z",
      "lastModifiedTimestamp": 1763650671000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/autogen",
          "homepage": "https://microsoft.github.io/autogen/",
          "language": "Python",
          "forks": 7872,
          "open_issues": 511,
          "license": "Creative Commons Attribution 4.0 International"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 57011.9,
      "is_rising_star": true,
      "heatScore": 17106.870206846186,
      "popularityScore": 51829
    },
    {
      "id": "github-Mintplex-Labs-anything-llm",
      "name": "anything-llm",
      "author": "Mintplex-Labs",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 102482,
      "downloads": 102482,
      "lastModified": "2025-11-20T15:24:23Z",
      "lastModifiedTimestamp": 1763652263000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Mintplex-Labs/anything-llm",
          "homepage": "https://anythingllm.com",
          "language": "JavaScript",
          "forks": 5428,
          "open_issues": 331,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134426827?v=4",
      "velocity": 56365.1,
      "is_rising_star": true,
      "heatScore": 16912.82673825049,
      "popularityScore": 51241
    },
    {
      "id": "github-openai-codex",
      "name": "codex",
      "author": "openai",
      "description": "Lightweight coding agent that runs in your terminal",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 101932,
      "downloads": 101932,
      "lastModified": "2025-11-20T15:27:31Z",
      "lastModifiedTimestamp": 1763652451000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/openai/codex",
          "homepage": "",
          "language": "Rust",
          "forks": 6392,
          "open_issues": 1067,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/14957082?v=4",
      "velocity": 56062.6,
      "is_rising_star": true,
      "heatScore": 16822.075102349743,
      "popularityScore": 50966
    },
    {
      "id": "github-pathwaycom-pathway",
      "name": "pathway",
      "author": "pathwaycom",
      "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
      "task": "tool",
      "tags": [
        "batch-processing",
        "data-analytics",
        "data-pipelines",
        "data-processing",
        "dataflow",
        "etl",
        "etl-framework",
        "iot-analytics",
        "kafka",
        "machine-learning-algorithms",
        "pathway",
        "python",
        "real-time",
        "rust",
        "stream-processing",
        "streaming",
        "time-series-analysis",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 100330,
      "downloads": 100330,
      "lastModified": "2025-11-20T15:47:22Z",
      "lastModifiedTimestamp": 1763653642000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/pathway",
          "homepage": "https://pathway.com",
          "language": "Python",
          "forks": 1454,
          "open_issues": 39,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 55181.5,
      "is_rising_star": true,
      "heatScore": 16557.740286631673,
      "popularityScore": 50165
    },
    {
      "id": "github-opendatalab-MinerU",
      "name": "MinerU",
      "author": "opendatalab",
      "description": "Transforms complex documents like PDFs into LLM-ready markdown/JSON for your Agentic workflows.",
      "task": "tool",
      "tags": [
        "ai4science",
        "document-analysis",
        "extract-data",
        "layout-analysis",
        "ocr",
        "parser",
        "pdf",
        "pdf-converter",
        "pdf-extractor-llm",
        "pdf-extractor-pretrain",
        "pdf-extractor-rag",
        "pdf-parser",
        "python"
      ],
      "likes": 98356,
      "downloads": 98356,
      "lastModified": "2025-11-20T15:21:22Z",
      "lastModifiedTimestamp": 1763652082000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/opendatalab/MinerU",
          "homepage": "https://opendatalab.github.io/MinerU/",
          "language": "Python",
          "forks": 4080,
          "open_issues": 128,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/97503431?v=4",
      "velocity": 54095.8,
      "is_rising_star": true,
      "heatScore": 16232.02424578552,
      "popularityScore": 49178
    },
    {
      "id": "github-unslothai-unsloth",
      "name": "unsloth",
      "author": "unslothai",
      "description": "Fine-tuning & Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.",
      "task": "tool",
      "tags": [
        "agent",
        "deepseek",
        "deepseek-r1",
        "fine-tuning",
        "gemma",
        "gemma3",
        "gpt-oss",
        "llama",
        "llama3",
        "llm",
        "llms",
        "mistral",
        "openai",
        "qwen",
        "qwen3",
        "reinforcement-learning",
        "text-to-speech",
        "tts",
        "unsloth",
        "voice-cloning"
      ],
      "likes": 96990,
      "downloads": 96990,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unslothai/unsloth",
          "homepage": "https://docs.unsloth.ai/",
          "language": "Python",
          "forks": 3989,
          "open_issues": 856,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/150920049?v=4",
      "velocity": 53344.5,
      "is_rising_star": true,
      "heatScore": 16006.629994143315,
      "popularityScore": 48495
    },
    {
      "id": "github-huginn-huginn",
      "name": "huginn",
      "author": "huginn",
      "description": "Create agents that monitor and act on your behalf.  Your agents are standing by!",
      "task": "tool",
      "tags": [
        "agent",
        "automation",
        "feed",
        "feedgenerator",
        "huginn",
        "monitoring",
        "notifications",
        "rss",
        "scraper",
        "twitter",
        "twitter-streaming",
        "webscraping"
      ],
      "likes": 96214,
      "downloads": 96214,
      "lastModified": "2025-11-20T14:23:03Z",
      "lastModifiedTimestamp": 1763648583000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huginn/huginn",
          "homepage": "",
          "language": "Ruby",
          "forks": 4197,
          "open_issues": 691,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23225142?v=4",
      "velocity": 52917.7,
      "is_rising_star": true,
      "heatScore": 15878.587552111607,
      "popularityScore": 48107
    },
    {
      "id": "github-harry0703-MoneyPrinterTurbo",
      "name": "MoneyPrinterTurbo",
      "author": "harry0703",
      "description": "Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.",
      "task": "tool",
      "tags": [
        "ai",
        "automation",
        "chatgpt",
        "moviepy",
        "python",
        "shortvideo",
        "tiktok"
      ],
      "likes": 95706,
      "downloads": 95706,
      "lastModified": "2025-11-20T15:49:59Z",
      "lastModifiedTimestamp": 1763653799000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/harry0703/MoneyPrinterTurbo",
          "homepage": "",
          "language": "Python",
          "forks": 6701,
          "open_issues": 218,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4928832?v=4",
      "velocity": 52638.3,
      "is_rising_star": true,
      "heatScore": 15794.765942771677,
      "popularityScore": 47853
    },
    {
      "id": "github-pathwaycom-llm-app",
      "name": "llm-app",
      "author": "pathwaycom",
      "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
      "task": "tool",
      "tags": [
        "chatbot",
        "hugging-face",
        "llm",
        "llm-local",
        "llm-prompting",
        "llm-security",
        "llmops",
        "machine-learning",
        "open-ai",
        "pathway",
        "rag",
        "real-time",
        "retrieval-augmented-generation",
        "vector-database",
        "vector-index",
        "general-dialogue-qa",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 94666,
      "downloads": 94666,
      "lastModified": "2025-11-20T15:46:47Z",
      "lastModifiedTimestamp": 1763653607000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/llm-app",
          "homepage": "https://pathway.com/developers/templates/",
          "language": "Jupyter Notebook",
          "forks": 1214,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 52066.3,
      "is_rising_star": true,
      "heatScore": 15623.16262124451,
      "popularityScore": 47333
    },
    {
      "id": "github-FlowiseAI-Flowise",
      "name": "Flowise",
      "author": "FlowiseAI",
      "description": "Build AI Agents, Visually",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-workflow",
        "agents",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "javascript",
        "langchain",
        "large-language-models",
        "low-code",
        "multiagent-systems",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript",
        "workflow-automation",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 93412,
      "downloads": 93412,
      "lastModified": "2025-11-20T15:27:35Z",
      "lastModifiedTimestamp": 1763652455000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FlowiseAI/Flowise",
          "homepage": "https://flowiseai.com",
          "language": "TypeScript",
          "forks": 23141,
          "open_issues": 728,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128289781?v=4",
      "velocity": 51376.6,
      "is_rising_star": true,
      "heatScore": 15416.248567381353,
      "popularityScore": 46706
    },
    {
      "id": "github-run-llama-llama_index",
      "name": "llama_index",
      "author": "run-llama",
      "description": "LlamaIndex is the leading framework for building LLM-powered agents over your data.",
      "task": "tool",
      "tags": [
        "agents",
        "application",
        "data",
        "fine-tuning",
        "framework",
        "llamaindex",
        "llm",
        "multi-agents",
        "rag",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 90664,
      "downloads": 90664,
      "lastModified": "2025-11-20T15:48:18Z",
      "lastModifiedTimestamp": 1763653698000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/run-llama/llama_index",
          "homepage": "https://developers.llamaindex.ai",
          "language": "Python",
          "forks": 6534,
          "open_issues": 268,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/130722866?v=4",
      "velocity": 49865.2,
      "is_rising_star": true,
      "heatScore": 14962.819490122205,
      "popularityScore": 45332
    },
    {
      "id": "github-microsoft-ai-agents-for-beginners",
      "name": "ai-agents-for-beginners",
      "author": "microsoft",
      "description": "12 Lessons to Get Started Building AI Agents",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-framework",
        "agentic-rag",
        "ai-agents",
        "ai-agents-framework",
        "autogen",
        "generative-ai",
        "semantic-kernel"
      ],
      "likes": 90478,
      "downloads": 90478,
      "lastModified": "2025-11-20T15:42:34Z",
      "lastModifiedTimestamp": 1763653354000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/ai-agents-for-beginners",
          "homepage": "https://aka.ms/ai-agents-beginners",
          "language": "Jupyter Notebook",
          "forks": 15356,
          "open_issues": 11,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 49762.9,
      "is_rising_star": true,
      "heatScore": 14932.128865817376,
      "popularityScore": 45239
    },
    {
      "id": "github-jeecgboot-JeecgBoot",
      "name": "JeecgBoot",
      "author": "jeecgboot",
      "description": "üî•AI‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÔºåÂä©Âäõ‰ºÅ‰∏öÂø´ÈÄüÂÆûÁé∞‰Ωé‰ª£Á†ÅÂºÄÂèëÂíåÊûÑÂª∫AIÂ∫îÁî®ÔºÅ ÈõÜÊàê‰∏ÄÂ•óÂÆåÊï¥AIÂ∫îÁî®Âπ≥Âè∞ÔºöÊ∂µÁõñAIÂ∫îÁî®„ÄÅAIÊ®°Âûã„ÄÅAIËÅäÂ§©Âä©Êâã„ÄÅÁü•ËØÜÂ∫ì„ÄÅAIÊµÅÁ®ãÁºñÊéíÁ≠âÔºåÂÖºÂÆπÂ§öÁßçÂ§ßÊ®°ÂûãÔºõÊèê‰æõÂº∫Â§ß‰ª£Á†ÅÁîüÊàêÂô®ÔºöÂÆûÁé∞ÂâçÂêéÁ´Ø‰∏ÄÈîÆÁîüÊàêÔºåÊó†ÈúÄÊâãÂÜô‰ª£Á†Å! ÂºïÈ¢ÜAIÂºÄÂèëÊ®°ÂºèÔºöAIÁîüÊàê‚ÜíÂú®Á∫øÈÖçÁΩÆ‚Üí‰ª£Á†ÅÁîüÊàê‚ÜíÊâãÂ∑•ÂêàÂπ∂ÔºåËß£ÂÜ≥JavaÈ°πÁõÆ80%ÈáçÂ§çÂ∑•‰ΩúÔºåÊèêÂçáÊïàÁéáËäÇÁúÅÊàêÊú¨ÔºåÂèà‰∏çÂ§±ÁÅµÊ¥ª~",
      "task": "tool",
      "tags": [
        "activiti",
        "agent",
        "ai",
        "aiflow",
        "ant-design-vue",
        "antd",
        "codegenerator",
        "deepseek",
        "flowable",
        "langchain4j",
        "llm",
        "low-code",
        "mcp",
        "mybatis-plus",
        "rag",
        "spring-ai",
        "springboot",
        "springboot3",
        "springcloud",
        "vue3",
        "rag-knowledge-base-qa"
      ],
      "likes": 88836,
      "downloads": 88836,
      "lastModified": "2025-11-20T14:22:51Z",
      "lastModifiedTimestamp": 1763648571000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/jeecgboot/JeecgBoot",
          "homepage": "https://jeecgboot.github.io/JeecgBoot/",
          "language": "Java",
          "forks": 15659,
          "open_issues": 54,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/86360035?v=4",
      "velocity": 48859.8,
      "is_rising_star": true,
      "heatScore": 14661.19329814397,
      "popularityScore": 44418
    },
    {
      "id": "github-mem0ai-mem0",
      "name": "mem0",
      "author": "mem0ai",
      "description": "Universal memory layer for AI Agents",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "application",
        "chatbots",
        "chatgpt",
        "genai",
        "hacktoberfest",
        "llm",
        "long-term-memory",
        "memory",
        "memory-management",
        "python",
        "rag",
        "state-management",
        "rag-knowledge-base-qa"
      ],
      "likes": 86706,
      "downloads": 86706,
      "lastModified": "2025-11-20T14:45:27Z",
      "lastModifiedTimestamp": 1763649927000,
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"docs/images/banner-sm.png\" width=\"800px\" alt=\"Mem0 - The Memory Layer for Personalized AI\">\n  </a>\n</p>\n<p align=\"center\" style=\"display: flex; justify-content: center; gap: 20px; align-items: center;\">\n  <a href=\"https://trendshift.io/repositories/11194\" target=\"blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/11194\" alt=\"mem0ai%2Fmem0 | Trendshift\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai\">Learn more</a>\n  ¬∑\n  <a href=\"https://mem0.dev/DiG\">Join Discord</a>\n  ¬∑\n  <a href=\"https://mem0.dev/demo\">Demo</a>\n  ¬∑\n  <a href=\"https://mem0.dev/openmemory\">OpenMemory</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.dev/DiG\">\n    <img src=\"https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white\" alt=\"Mem0 Discord\">\n  </a>\n  <a href=\"https://pepy.tech/project/mem0ai\">\n    <img src=\"https://img.shields.io/pypi/dm/mem0ai\" alt=\"Mem0 PyPI - Downloads\">\n  </a>\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square\" alt=\"GitHub commit activity\">\n  </a>\n  <a href=\"https://pypi.org/project/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/pypi/v/mem0ai?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/npm/v/mem0ai\" alt=\"Npm package\">\n  </a>\n  <a href=\"https://www.ycombinator.com/companies/mem0\">\n    <img src=\"https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square\" alt=\"Y Combinator S24\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai/research\"><strong>üìÑ Building Production-Ready AI Agents with Scalable Long-Term Memory ‚Üí</strong></a>\n</p>\n<p align=\"center\">\n  <strong>‚ö° +26% Accuracy vs. OpenAI Memory ‚Ä¢ üöÄ 91% Faster ‚Ä¢ üí∞ 90% Fewer Tokens</strong>\n</p>\n\n> **üéâ mem0ai v1.0.0 is now available!** This major release includes API modernization, improved vector store support, and enhanced GCP integration. [See migration guide ‚Üí](MIGRATION_GUIDE_v1.0.md)\n\n##  üî• Research Highlights\n- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark\n- **91% Faster Responses** than full-context, ensuring low-latency at scale\n- **90% Lower Token Usage** than full-context, cutting costs without compromise\n- [Read the full paper](https://mem0.ai/research)\n\n# Introduction\n\n[Mem0](https://mem0.ai) (\"mem-zero\") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time‚Äîideal for customer support chatbots, AI assistants, and autonomous systems.\n\n### Key Features & Use Cases\n\n**Core Capabilities:**\n- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization\n- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option\n\n**Applications:**\n- **AI Assistants**: Consistent, context-rich conversations\n- **Customer Support**: Recall past tickets and user history for tailored help\n- **Healthcare**: Track patient preferences and history for personalized care\n- **Productivity & Gaming**: Adaptive workflows and environments based on user behavior\n\n## üöÄ Quickstart Guide <a name=\"quickstart\"></a>\n\nChoose between our hosted platform or self-hosted package:\n\n### Hosted Platform\n\nGet up and running in minutes with automatic updates, analytics, and enterprise security.\n\n1. Sign up on [Mem0 Platform](https://app.mem0.ai)\n2. Embed the memory layer via SDK or API keys\n\n### Self-Hosted (Open Source)\n\nInstall the sdk via pip:\n\n```bash\npip install mem0ai\n```\n\nInstall sdk via npm:\n```bash\nnpm install mem0ai\n```\n\n### Basic Usage\n\nMem0 requires an LLM to function, with `gpt-4.1-nano-2025-04-14 from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).\n\nFirst step is to instantiate the memory:\n\n```python\nfrom openai import OpenAI\nfrom mem0 import Memory\n\nopenai_client = OpenAI()\nmemory = Memory()\n\ndef chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n    # Retrieve relevant memories\n    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n\n    # Generate Assistant response\n    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n    response = openai_client.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n    assistant_response = response.choices[0].message.content\n\n    # Create new memories from the conversation\n    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n    memory.add(messages, user_id=user_id)\n\n    return assistant_response\n\ndef main():\n    print(\"Chat with AI (type 'exit' to quit)\")\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'exit':\n            print(\"Goodbye!\")\n            break\n        print(f\"AI: {chat_with_memories(user_input)}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFor detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).\n\n## üîó Integrations & Demos\n\n- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))\n- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))\n- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))\n- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))\n\n## üìö Documentation & Support\n\n- Full docs: https://docs.mem0.ai\n- Community: [Discord](https://mem0.dev/DiG) ¬∑ [Twitter](https://x.com/mem0ai)\n- Contact: founders@mem0.ai\n\n## Citation\n\nWe now have a paper you can cite:\n\n```bibtex\n@article{mem0,\n  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},\n  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},\n  journal={arXiv preprint arXiv:2504.19413},\n  year={2025}\n}\n```\n\n## ‚öñÔ∏è License\n\nApache 2.0 ‚Äî see the [LICENSE](https://github.com/mem0ai/mem0/blob/main/LICENSE) file for details.",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mem0ai/mem0",
          "homepage": "https://mem0.ai",
          "language": "Python",
          "forks": 4697,
          "open_issues": 520,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/137054526?v=4",
      "velocity": 47688.3,
      "is_rising_star": true,
      "heatScore": 14309.73592042129,
      "popularityScore": 43353
    },
    {
      "id": "github-anthropics-claude-code",
      "name": "claude-code",
      "author": "anthropics",
      "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 85919,
      "downloads": 85919,
      "lastModified": "2025-11-20T15:52:02Z",
      "lastModifiedTimestamp": 1763653922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/anthropics/claude-code",
          "homepage": "https://code.claude.com/docs/en/overview",
          "language": "Shell",
          "forks": 2910,
          "open_issues": 5342,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/76263028?v=4",
      "velocity": 47254.9,
      "is_rising_star": true,
      "heatScore": 14179.713144990883,
      "popularityScore": 42959
    },
    {
      "id": "github-sst-opencode",
      "name": "opencode",
      "author": "sst",
      "description": "The AI coding agent built for the terminal.",
      "task": "tool",
      "tags": [
        "ai",
        "claude",
        "code",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 85846,
      "downloads": 85846,
      "lastModified": "2025-11-20T15:54:52Z",
      "lastModifiedTimestamp": 1763654092000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sst/opencode",
          "homepage": "https://opencode.ai",
          "language": "TypeScript",
          "forks": 2685,
          "open_issues": 1494,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/opencode-ai/opencode",
          "homepage": "",
          "language": "Go",
          "forks": 807,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/66570915?v=4",
      "velocity": 47215.3,
      "is_rising_star": true,
      "heatScore": 14167.832890130338,
      "popularityScore": 42923
    },
    {
      "id": "OrionStarAI/Orion-14B-Chat",
      "name": "Orion-14B-Chat",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "gguf",
        "orion",
        "text-generation",
        "code",
        "model",
        "llm",
        "conversational",
        "custom_code",
        "en",
        "zh",
        "ja",
        "ko",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us",
        "code-generation-assistance",
        "general-dialogue-qa"
      ],
      "likes": 670,
      "downloads": 85840,
      "lastModifiedTimestamp": null,
      "readme": "---\nlanguage:\n- en\n- zh\n- ja\n- ko\nmetrics:\n- accuracy\npipeline_tag: text-generation\ntags:\n- code\n- model\n- llm\n---\n\n<!-- markdownlint-disable first-line-h1 -->\n<!-- markdownlint-disable html -->\n<div align=\"center\">\n  <img src=\"./assets/imgs/orion_start.PNG\" alt=\"logo\" width=\"50%\" />\n</div>\n\n<div align=\"center\">\n<h1>\n  Orion-14B\n</h1>\n</div>\n\n<div align=\"center\">\n\n<div align=\"center\">\n     <b>üåêEnglish</b> | <a href=\"https://huggingface.co/OrionStarAI/Orion-14B-Chat/blob/main/README_zh.md\" target=\"_blank\">üá®üá≥‰∏≠Êñá</a> | <a href=\"https://huggingface.co/OrionStarAI/Orion-14B-Chat/blob/main/README_ja.md\" target=\"_blank\">üáØüáµÊó•Êú¨Ë™û</a> | <a href=\"https://huggingface.co/OrionStarAI/Orion-14B-Chat/blob/main/README_ko.md\" target=\"_blank\">üá∞üá∑ÌïúÍµ≠Ïñ¥</a>\n</div>\n\n<h4 align=\"center\">\n    <p>\n        ü§ó <a href=\"https://huggingface.co/OrionStarAI\" target=\"_blank\">HuggingFace Mainpage</a> | ü§ñ <a href=\"https://modelscope.cn/organization/OrionStarAI\" target=\"_blank\">ModelScope Mainpage</a><br>üé¨ <a href=\"https://huggingface.co/spaces/OrionStarAI/Orion-14B-App-Demo\" target=\"_blank\">HuggingFace Demo</a> | üé´ <a href=\"https://modelscope.cn/studios/OrionStarAI/Orion-14B-App-Demo/summary\" target=\"_blank\">ModelScope Demo</a><br>üò∫ <a href=\"https://github.com/OrionStarAI/Orion\" target=\"_blank\">GitHub</a><br>üìñ <a href=\"https://github.com/OrionStarAI/Orion/blob/master/doc/Orion14B_v3.pdf\" target=\"_blank\">Tech Report</a>\n    <p>\n</h4>\n\n</div>\n\n\n\n# Table of Contents\n\n- [üìñ Model Introduction](#model-introduction)\n- [üîó Model Download](#model-download)\n- [üîñ Model Benchmark](#model-benchmark)\n- [üìä Model Inference](#model-inference)[<img src=\"./assets/imgs/vllm_1.png\" alt=\"vllm\" style=\"margin: 0;display: initial;\" height=\"20\" />](#vllm) [<img src=\"./assets/imgs/llama_cpp_1.png\" alt=\"llamacpp\" style=\"margin: 0;display: initial;\" height=\"20\" />](#llama-cpp)\n- [üìú Declarations & License](#declarations-license)\n- [ü•á Company Introduction](#company-introduction)\n\n<a name=\"model-introduction\"></a><br>\n# 1. Model Introduction\n\n- Orion-14B series models are open-source multilingual large language models trained from scratch by OrionStarAI.  The base model is trained on 2.5T multilingual corpus, including Chinese, English, Japanese, Korean, etc, and it exhibits superior performance in these languages.  For details, please refer to [tech report](https://github.com/OrionStarAI/Orion/blob/master/doc/Orion14B_v3.pdf).\n\n- The Orion-14B series models exhibit the following features:\n  - Among models with 20B-parameter scale level, Orion-14B-Base model shows outstanding performance in comprehensive evaluations.\n  - Strong multilingual capabilities, significantly outperforming in Japanese and Korean testsets.\n  - The fine-tuned models demonstrate strong adaptability, excelling in human-annotated blind tests.\n  - The long-chat version supports extremely long texts, performing exceptionally well at a token length of 200k and can support up to a maximum of 320k.\n  - The quantized versions reduce model size by 70%, improve inference speed by 30%, with performance loss less than 1%.\n <table style=\"border-collapse: collapse; width: 100%;\">\n   <tr>\n     <td style=\"border: none; padding: 10px; box-sizing: border-box;\">\n       <img src=\"./assets/imgs/opencompass_en.png\" alt=\"opencompass\" style=\"width: 100%; height: auto;\">\n     </td>\n     <td style=\"border: none; padding: 10px; box-sizing: border-box;\">\n       <img src=\"./assets/imgs/model_cap_en.png\" alt=\"modelcap\" style=\"width: 100%; height: auto;\">\n     </td>\n   </tr>\n </table>\n\n- Orion-14B series models including:\n  - **Orion-14B-Base:**  A multilingual large language foundational model with 14 billion parameters, pretrained on a diverse dataset of 2.5 trillion tokens.\n  - **Orion-14B-Chat:**  A chat-model fine-tuned on a high-quality corpus aims to provide an excellence interactive experience for users in the large model community.\n  - **Orion-14B-LongChat:**  The long-context version excels at handling extremely lengthy texts, performing exceptionally well at a token length of 200k and can support up to a maximum of 320k.\n  - **Orion-14B-Chat-RAG:**  A chat-model fine-tuned on a custom retrieval augmented generation dataset, achieving superior performance in retrieval augmented generation tasks.\n  - **Orion-14B-Chat-Plugin:**  A chat-model specifically tailored for plugin and function calling tasks, ideal for agent-related scenarios where the LLM acts as a plugin and function call system.\n  - **Orion-14B-Base-Int4:**  A quantized base model utilizing 4-bit integer weights. It significantly reduces the model size by 70% and increases the inference speed by 30% while incurring a minimal performance loss of only 1%.\n  - **Orion-14B-Chat-Int4:**  A quantized chat model utilizing 4-bit integer weights.\n\n\n<a name=\"model-download\"></a><br>\n# 2. Model Download\n\nModel release and download links are provided in the table below:\n\n| Model Name              | HuggingFace Download Links                                                        | ModelScope Download Links                                                                       |\n|-------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|\n| ‚öæOrion-14B-Base        | [Orion-14B-Base](https://huggingface.co/OrionStarAI/Orion-14B-Base)               | [Orion-14B-Base](https://modelscope.cn/models/OrionStarAI/Orion-14B-Base/summary)               |\n| üòõOrion-14B-Chat        | [Orion-14B-Chat](https://huggingface.co/OrionStarAI/Orion-14B-Chat)               | [Orion-14B-Chat](https://modelscope.cn/models/OrionStarAI/Orion-14B-Chat/summary)               |\n| üìÉOrion-14B-LongChat    | [Orion-14B-LongChat](https://huggingface.co/OrionStarAI/Orion-14B-LongChat)       | [Orion-14B-LongChat](https://modelscope.cn/models/OrionStarAI/Orion-14B-LongChat/summary)       |\n| üîéOrion-14B-Chat-RAG    | [Orion-14B-Chat-RAG](https://huggingface.co/OrionStarAI/Orion-14B-Chat-RAG)       | [Orion-14B-Chat-RAG](https://modelscope.cn/models/OrionStarAI/Orion-14B-Chat-RAG/summary)       |\n| üîåOrion-14B-Chat-Plugin | [Orion-14B-Chat-Plugin](https://huggingface.co/OrionStarAI/Orion-14B-Chat-Plugin) | [Orion-14B-Chat-Plugin](https://modelscope.cn/models/OrionStarAI/Orion-14B-Chat-Plugin/summary) |\n| üíºOrion-14B-Base-Int4   | [Orion-14B-Base-Int4](https://huggingface.co/OrionStarAI/Orion-14B-Base-Int4)     | [Orion-14B-Base-Int4](https://modelscope.cn/models/OrionStarAI/Orion-14B-Base-Int4/summary)     |\n| üì¶Orion-14B-Chat-Int4   | [Orion-14B-Chat-Int4](https://huggingface.co/OrionStarAI/Orion-14B-Chat-Int4)     | [Orion-14B-Chat-Int4](https://modelscope.cn/models/OrionStarAI/Orion-14B-Chat-Int4/summary)     |\n\n<a name=\"model-benchmark\"></a><br>\n# 3. Model Benchmarks\n\n## 3.1. Base Model Orion-14B-Base Benchmarks\n### 3.1.1. LLM evaluation results on examination and professional knowledge\n| Model              | C-Eval   | CMMLU    | MMLU     | AGIEval  | Gaokao   | BBH      |\n|--------------------|----------|----------|----------|----------|----------|----------|\n| LLaMA2-13B         |   41.4   |   38.4   |   55.0   |   30.9   |   18.2   |   45.6   |\n| Skywork-13B        |   59.1   |   61.4   |   62.7   |   43.6   |   56.1   |   48.3   |\n| Baichuan2-13B      |   59.0   |   61.3   |   59.5   |   37.4   |   45.6   |   49.0   |\n| QWEN-14B           |   71.7   |   70.2   |   67.9   |   51.9   | **62.5** |   53.7   |\n| InternLM-20B       |   58.8   |   59.0   |   62.1   |   44.6   |   45.5   |   52.5   |\n| **Orion-14B-Base** | **72.9** | **70.6** | **69.9** | **54.7** |   62.1   | **56.5** |\n\n### 3.1.2. LLM evaluation results on language understanding and common knowledge\n| Model             |RACE-middle|RACE-high |HellaSwag | PIQA     | Lambada  | WSC      |\n|--------------------|----------|----------|----------|----------|----------|----------|\n| LLaMA 2-13B        |   63.0   |   58.9   |   77.5   |   79.8   |   76.5   |   66.3   |\n| Skywork-13B        |   87.6   |   84.1   |   73.7   |   78.3   |   71.8   |   66.3   |\n| Baichuan 2-13B     |   68.9   |   67.2   |   70.8   |   78.1   |   74.1   |   66.3   |\n| QWEN-14B           |   93.0   |   90.3   | **80.2** |   79.8   |   71.4   |   66.3   |\n| InternLM-20B       |   86.4   |   83.3   |   78.1   | **80.3** |   71.8   |   68.3   |\n| **Orion-14B-Base** | **93.2** | **91.3** |   78.5   |   79.5   | **78.8** | **70.2** |\n\n### 3.1.3. LLM evaluation results of OpenCompass testsets\n| Model | Average  | Examination | Language | Knowledge | Understanding | Reasoning |\n|------------------|----------|----------|----------|----------|----------|----------|\n| LLaMA 2-13B      |   47.3   |   45.2   |   47.0   |   58.3   |   50.9   |   43.6   |\n| Skywork-13B      |   53.6   |   61.1   |   51.3   |   52.7   |   64.5   |   45.2   |\n| Baichuan 2-13B   |   49.4   |   51.8   |   47.5   |   48.9   |   58.1   |   44.2   |\n| QWEN-14B         |   62.4   |   71.3   |   52.67  |   56.1   |   68.8   |   60.1   |\n| InternLM-20B     |   59.4   |   62.5   |   55.0   | **60.1** |   67.3   |   54.9   |\n|**Orion-14B-Base**| **64.3** | **71.4** | **55.0** |   60.0   | **71.9** | **61.6** |\n\n### 3.1.4. Comparison of LLM performances on Japanese testsets\n| Model             |**Average**|  JCQA    |  JNLI    |  MARC    |  JSQD    |  JQK     |  XLS     |  XWN     |  MGSM    |\n|--------------------|----------|----------|----------|----------|----------|----------|----------|----------|----------|\n| PLaMo-13B          |   52.3   |   56.7   |   42.8   |   95.8   |   70.6   |   71.0   |   8.70   |   70.5   |   2.40   |\n| WebLab-10B         |   50.7   |   66.6   |   53.7   |   82.1   |   62.9   |   56.2   |   10.0   |   72.0   |   2.40   |\n| ELYZA-jp-7B        |   48.8   |   71.7   |   25.3   |   86.6   |   70.8   |   64.1   |   2.50   |   62.1   |   7.20   |\n| StableLM-jp-7B     |   51.1   |   33.4   |   43.3   | **96.7** |   70.6   |   78.1   |   10.7   |   72.8   |   2.80   |\n| LLaMA 2-13B        |   46.3   |   75.0   |   47.6   |   38.8   |   76.1   |   67.7   |   18.1   |   63.2   |   10.4   |\n| Baichuan 2-13B     |   57.1   |   73.7   |   31.3   |   91.6   |   80.5   |   63.3   |   18.6   |   72.2   |   25.2   |\n| QWEN-14B           |   65.8   |   85.9   |   60.7   |   97.0   |   83.3   |   71.8   |   18.8   |   70.6   |   38.0   |\n| Yi-34B             |   67.1   |   83.8   |   61.2   |   95.2   | **86.1** |   78.5   | **27.2** |   69.2   |   35.2   |\n| **Orion-14B-Base** | **69.1** | **88.2** | **75.8** |   94.1   |   75.7   | **85.1** |   17.3   | **78.8** | **38.0** |\n\n### 3.1.5. Comparison of LLM performances on Korean testsets. n = 0 and n = 5 stand for n-shot prompts used in the evaluation\n|Model      | **Average**<br>n=0&nbsp;&nbsp;n=5 | HellaSwag<br>n=0&nbsp;&nbsp;n=5 | COPA<br> n=0&nbsp;&nbsp;n=5 | BooIQ<br>n=0&nbsp;&nbsp;n=5 | SentiNeg<br>n=0&nbsp;&nbsp;n=5|\n|------------------|------------------------------|------------------------------|------------------------------|------------------------------|------------------------------|\n| KoGPT            |  53.0   &nbsp;&nbsp;   70.1  |  55.9   &nbsp;&nbsp;   58.3  |  73.5   &nbsp;&nbsp;   72.9  |  45.1   &nbsp;&nbsp;   59.8  |  37.5   &nbsp;&nbsp;   89.4  |\n| Polyglot-ko-13B  |  69.6   &nbsp;&nbsp;   73.7  |**59.5** &nbsp;&nbsp; **63.1**|**79.4** &nbsp;&nbsp; **81.1**|  48.2   &nbsp;&nbsp;   60.4  |  91.2   &nbsp;&nbsp;   90.2  |\n| LLaMA 2-13B      |  46.7   &nbsp;&nbsp;   63.7  |  41.3   &nbsp;&nbsp;   44.0  |  59.3   &nbsp;&nbsp;   63.8  |  34.9   &nbsp;&nbsp;   73.8  |  51.5   &nbsp;&nbsp;   73.4  |\n| Baichuan 2-13B   |  52.1   &nbsp;&nbsp;   58.7  |  39.2   &nbsp;&nbsp;   39.6  |  60.6   &nbsp;&nbsp;   60.6  |  58.4   &nbsp;&nbsp;   61.5  |  50.3   &nbsp;&nbsp;   72.9  |\n| QWEN-14B         |  53.8   &nbsp;&nbsp;   73.7  |  45.3   &nbsp;&nbsp;   46.8  |  64.9   &nbsp;&nbsp;   68.9  |  33.4   &nbsp;&nbsp;   83.5  |  71.5   &nbsp;&nbsp;   95.7  |\n| Yi-34B           |  54.2   &nbsp;&nbsp;   72.1  |  44.6   &nbsp;&nbsp;   44.7  |  58.0   &nbsp;&nbsp;   60.6  |  65.9   &nbsp;&nbsp;   90.2  |  48.3   &nbsp;&nbsp;   92.9  |\n|**Orion-14B-Chat**|**74.5** &nbsp;&nbsp; **79.6**|  47.0   &nbsp;&nbsp;   49.6  |  77.7   &nbsp;&nbsp;   79.4  |**81.6** &nbsp;&nbsp; **90.7**|**92.4** &nbsp;&nbsp; **98.7**|\n\n### 3.1.6. Multilingual evaluation\n| Model              | Train Lang | Japanese | Korean   | Chinese  |  English |\n|--------------------|------------|----------|----------|----------|----------|\n| PLaMo-13B          |  En,Jp     |   52.3   |   *      |   *      |   *      |\n| Weblab-10B         |  En,Jp     |   50.7   |   *      |   *      |   *      |\n| ELYZA-jp-7B        |  En,Jp     |   48.8   |   *      |   *      |   *      |\n| StableLM-jp-7B     |  En,Jp     |   51.1   |   *      |   *      |   *      |\n| KoGPT-6B           |  En,Ko     |   *      |   70.1   |   *      |   *      |\n| Polyglot-ko-13B    |  En,Ko     |   *      |   70.7   |   *      |   *      |\n| Baichuan2-13B      |  Multi     |   57.1   |   58.7   |   50.8   |   57.1   |\n| Qwen-14B           |  Multi     |   65.8   |   73.7   |   64.5   |   65.4   |\n| Llama2-13B         |  Multi     |   46.3   |   63.7   |   41.4   |   55.3   |\n| Yi-34B             |  Multi     |   67.1   |   72.2   |   58.7   | **68.8** |\n| **Orion-14B-Chat** |  Multi     | **69.1** | **79.5** | **67.9** |   67.3   |\n\n\n## 3.2. Chat Model Orion-14B-Chat Benchmarks\n### 3.2.1. Chat model subjective evaluation of MTBench\n| Model        | First-Turn | Second-Turn | **Average** |\n|----------------------|----------|----------|----------|\n| Baichuan2-13B-Chat   |   7.05   |   6.47   |   6.76   |\n| Qwen-14B-Chat        |   7.30   |   6.62   |   6.96   |\n| Llama2-13B-Chat      |   7.10   |   6.20   |   6.65   |\n| InternLM-20B-Chat    |   7.03   |   5.93   |   6.48   |\n| **Orion-14B-Chat**   | **7.68** | **7.07** | **7.37** |\n\\* use vllm for inference\n\n### 3.2.2. Chat model subjective evaluation of AlignBench\n| Model              | Math.  |  Logi. | Basic. | Chi.   | Comp.  | Writ.  | Role.  | Prof.  |**Avg.**|\n|--------------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n| Baichuan2-13B-Chat |  3.76  |  4.07  |  6.22  |  6.05  |  7.11  |  6.97  |  6.75  |  6.43  |  5.25  |\n| Qwen-14B-Chat      |**4.91**|**4.71**|**6.90**|  6.36  |  6.74  |  6.64  |  6.59  |  6.56  |**5.72**|\n| Llama2-13B-Chat    |  3.05  |  3.79  |  5.43  |  4.40  |  6.76  |  6.63  |  6.99  |  5.65  |  4.70  |\n| InternLM-20B-Chat  |  3.39  |  3.92  |  5.96  |  5.50  |**7.18**|  6.19  |  6.49  |  6.22  |  4.96  |\n| **Orion-14B-Chat** |  4.00  |  4.24  |  6.18  |**6.57**|  7.16  |**7.36**|**7.16**|**6.99**|  5.51  |\n\\* use vllm for inference\n\n## 3.3. LongChat Model Orion-14B-LongChat Benchmarks\n### 3.3.1. LongChat evaluation of LongBench\n| Model           | NarrativeQA|MultiFieldQA-en|MultiFieldQA-zh| DuReader  | QMSum     | VCSUM     | TREC      | TriviaQA  | LSHT      |RepoBench-P|\n|--------------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n| GPT-3.5-Turbo-16k        | **23.60** | **52.30** | **61.20** |   28.70   |   23.40   | **16.00** |   68.00   | **91.40** |   29.20   |   53.60   |\n| LongChat-v1.5-7B-32k     |   16.90   |   41.40   |   29.10   |   19.50   |   22.70   |    9.90   |   63.50   |   82.30   |   23.20   |   55.30   |\n| Vicuna-v1.5-7B-16k       |   19.40   |   38.50   |   43.00   |   19.30   |   22.80   |   15.10   |   71.50   |   86.20   |   28.80   |   43.50   |\n| Yi-6B-200K               |   14.11   |   36.74   |   22.68   |   14.01   |   20.44   |    8.08   |   72.00   |   86.61   |   38.00   | **63.29** |\n| Orion-14B-LongChat       |   19.47   |   48.11   |   55.84   | **37.02** | **24.87** |   15.44   | **77.00** |   89.12   | **45.50** |   54.31   |\n\n\n## 3.4. Chat RAG Model Benchmarks\n### 3.4.1. LLM evaluation results of self-built RAG testsets\n|Model|Effectiveness of Response(Keyword)|*Effectiveness of ResponseÔºàsubjective evaluationÔºâ|Quoting Ability|Fallback Ability|*AutoQA|*Data Extraction|\n|---------------------|------|------|------|------|------|------|\n| Baichuan2-13B-Chat  |  85  |  76  |  1   |  0   |  69  |  51  |\n| Qwen-14B-Chat       |  79  |  77  |  75  |  47  |  68  |  72  |\n| Qwen-72B-Chat(Int4) |  87  |  89  |  90  |  32  |  67  |  76  |\n| GPT-4               |  91  |  94  |  96  |  95  |  75  |  86  |\n| Orion-14B-Chat-RAG  |  86  |  87  |  91  |  97  |  73  |  71  |\n \\* means manual assessment\n\n## 3.5. Chat Plugin Model Orion-14B-Chat-Plugin Benchmarks\n### 3.5.1. LLM evaluation results of self-built plugin testsets\n|Model |Intent Recognition with Full Params |Intent Recognition with Missing Params |Non-Plugin Invocation Recognition |\n|-----------------------|--------|-----------|--------|\n| Baichuan2-13B-Chat    |   25   |   0       |   0    |\n| Qwen-14B-Chat         |   55   |   0       |   50   |\n| GPT-4                 | **95** |   52.38   |   70   |\n| Orion-14B-Chat-Plugin |  92.5  | **60.32** | **90** |\n\n## 3.6. Quantized Model Orion-14B-Base-Int4 Benchmarks\n### 3.6.1. Comparison of before and after quantization\n|Model |Size(GB)|Inference Speed(tokens/s)|C-Eval|CMMLU|MMLU|RACE|HellaSwag|\n|-------------------------|-------|-----|------|------|------|------|------|\n| OrionStar-14B-Base      |  28.0 | 135 | 72.8 | 70.6 | 70.0 | 93.3 | 78.5 |\n| OrionStar-14B-Base-Int4 |  8.3  | 178 | 71.8 | 69.8 | 69.2 | 93.1 | 78.0 |\n\n\n<a name=\"model-inference\"></a><br>\n# 4. Model Inference\n\nModel weights, source code, and configuration needed for inference are published on Hugging Face, and the download link\nis available in the table at the beginning of this document. We demonstrate various inference methods here, and the\nprogram will automatically download the necessary resources from Hugging Face.\n\n## 4.1. Python Code\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers.generation.utils import GenerationConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\"OrionStarAI/Orion-14B\", use_fast=False, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"OrionStarAI/Orion-14B\", device_map=\"auto\",\n                                             torch_dtype=torch.bfloat16, trust_remote_code=True)\n\nmodel.generation_config = GenerationConfig.from_pretrained(\"OrionStarAI/Orion-14B\")\nmessages = [{\"role\": \"user\", \"content\": \"Hello, what is your name? \"}]\nresponse = model.chat(tokenizer, messages, streaming=False)\nprint(response)\n\n```\n\nIn the above Python code, the model is loaded with `device_map='auto'` to utilize all available GPUs. To specify the\ndevice, you can use something like `export CUDA_VISIBLE_DEVICES=0,1` (using GPUs 0 and 1).\n\n## 4.2. Command Line Tool\n\n```shell\nCUDA_VISIBLE_DEVICES=0 python cli_demo.py\n```\n\nThis command-line tool is designed for chat scenarios, and thus, it does not support calling the base model.\n\n## 4.3. Direct Script Inference\n\n```shell\n\n# base model\nCUDA_VISIBLE_DEVICES=0 python demo/text_generation_base.py --model OrionStarAI/Orion-14B --tokenizer OrionStarAI/Orion-14B --prompt hello\n\n# chat model\nCUDA_VISIBLE_DEVICES=0 python demo/text_generation.py --model OrionStarAI/Orion-14B-Chat --tokenizer OrionStarAI/Orion-14B-Chat --prompt hi\n\n```\n<a name=\"vllm\"></a><br>\n## 4.4. Inference by vllm\n\n- Project URL<br>\n  https://github.com/vllm-project/vllm\n\n- Pull Request<br>\n  https://github.com/vllm-project/vllm/pull/2539\n\n<a name=\"llama-cpp\"></a><br>\n## 4.5. Inference by llama.cpp\n\n- Project URL<br>\n  https://github.com/ggerganov/llama.cpp\n\n- Pull Request<br>\n  https://github.com/ggerganov/llama.cpp/pull/5118\n\n- How to convert to GGUF model\n\n  ```shell\n  python convert-hf-to-gguf.py path/to/Orion-14B-Chat --outfile chat.gguf\n  ```\n\n- How to run generation\n\n  ```shell\n  ./main --frequency-penalty 0.5 --frequency-penalty 0.5 --top-k 5 --top-p 0.9 -m chat.gguf -p \"Building a website can be done in 10 simple steps:\\nStep 1:\" -n 400 -e\n  ```\n\n## 4.6 Example Output\n\n### 4.6.1. Casual Chat\n\n`````\nUser: Hello\nOrion-14B: Hello! How can I help you today? If you have any questions or need assistance, feel free to ask.\nUser: What functions do you have?\nOrion-14B: As an AI language model, I have a wide range of functions and capabilities, including but not limited to:\n  Answering general knowledge questions: I can provide information on various topics such as history, science, geography, and more.\n  Providing definitions and explanations: I can explain complex concepts and provide definitions for words and phrases.\n  Assisting with tasks: I can help with simple tasks like setting reminders, converting units of measurement, and even ordering food from restaurants.\n  Generating text: I can write short stories, essays, articles, and other types of content based on prompts given to me.\n  Translating languages: I can translate text from one language to another.\n  Chatting: I can engage in conversation with users and respond to their queries in a conversational manner.\n  Summarizing long texts: I can summarize longer texts like articles, books, and research papers.\n  Generating random numbers and names: I can generate random numbers within a specified range and also suggest names based on certain criteria.\n  Playing games: I can play simple games like Hangman, Trivia, and more.\n  Providing recommendations: I can recommend movies, music, books, and other forms of entertainment based on user preferences.\n  These are just some of the many functions that I am capable of performing. If you have a specific task in mind, feel free to ask me about it.\nUser: Tell me a joke.\nOrion-14B: Sure, here's a classic one-liner: Why don't scientists trust atoms? Because they make up everything.\n`````\n\n### 4.6.2. Japanese & Korean Chat\n\n`````\nUserÔºöËá™Â∑±„ÇíÁ¥π‰ªã„Åó„Å¶„Åè„Å†„Åï„ÅÑ\nOrion-14BÔºö„Åì„Çì„Å´„Å°„ÅØ„ÄÅÁßÅ„ÅÆÂêçÂâç„ÅØChatMax„Åß„ÄÅOrionStar„Å´„Çà„Å£„Å¶ÈñãÁô∫„Åï„Çå„ÅüAI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇÁßÅ„ÅØ„É¶„Éº„Ç∂„Éº„Å´Ê≠£Á¢∫„Åß„ÄÅÂÆ¢Ë¶≥ÁöÑ„Åß„ÄÅÊúâÁî®„Å™ÂõûÁ≠î„ÇíÊèê‰æõ„Åó„ÄÅÂΩº„Çâ„ÅåÂïèÈ°å„ÇíËß£Ê±∫„Åó„ÄÅÊÉÖÂ†±„ÇíÂèñÂæó„Åô„Çã„ÅÆ„ÇíÂä©„Åë„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\nUserÔºöÏûêÍ∏∞ÏÜåÍ∞úÎ•º Ìï¥Ï£ºÏÑ∏Ïöî.\nOrion-14BÔºöÏïàÎÖïÌïòÏÑ∏Ïöî, Ï†ú Ïù¥Î¶ÑÏùÄ ChatMaxÏûÖÎãàÎã§. OrionStarÏóêÏÑú Í∞úÎ∞úÌïú AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. Ï†ÄÎäî ÏÇ¨Ïö©ÏûêÎì§ÏóêÍ≤å Ï†ïÌôïÌïòÍ≥† Í∞ùÍ¥ÄÏ†ÅÏù¥Î©∞ Ïú†Ïö©Ìïú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÏó¨ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ≥† Ï†ïÎ≥¥Î•º ÏñªÎäî Îç∞ ÎèÑÏõÄÏùÑ Ï§Ñ Ïàò ÏûàÏäµÎãàÎã§.\n`````\n\n<a name=\"declarations-license\"></a><br>\n# 5. Declarations, License\n\n## 5.1. Declarations\n\nWe strongly urge all users not to use the Orion-14B model for any activities that may harm national or social security or violate the law.\nAdditionally, we request users not to use the Orion-14B model for internet services without proper security review and filing.\nWe hope all users abide by this principle to ensure that technological development takes place in a regulated and legal environment.\nWe have done our best to ensure the compliance of the data used in the model training process. However, despite our\nsignificant efforts, unforeseen issues may still arise due to the complexity of the model and data. Therefore, if any\nproblems arise due to the use of the Orion-14B open-source model, including but not limited to data security\nissues, public opinion risks, or any risks and issues arising from the model being misled, abused, disseminated, or\nimproperly utilized, we will not assume any responsibility.\n\n## 5.2. License\n\nCommunity use of the Orion-14B series models\n- For code, please comply with  [Apache License Version 2.0](./LICENSE)<br>\n- For model, please comply with [„ÄêOrion-14B Series„Äë Models Community License Agreement](./ModelsCommunityLicenseAgreement)\n\n\n<a name=\"company-introduction\"></a><br>\n# 6. Company Introduction\n\nOrionStar is a leading global service robot solutions company, founded in September 2016. OrionStar is dedicated to\nusing artificial intelligence technology to create the next generation of revolutionary robots, allowing people to break\nfree from repetitive physical labor and making human work and life more intelligent and enjoyable. Through technology,\nOrionStar aims to make society and the world a better place.\n\nOrionStar possesses fully self-developed end-to-end artificial intelligence technologies, such as voice interaction and\nvisual navigation. It integrates product development capabilities and technological application capabilities. Based on\nthe Orion robotic arm platform, it has launched products such as OrionStar AI Robot Greeting, AI Robot Greeting Mini,\nLucki, Coffee Master, and established the open platform OrionOS for Orion robots. Following the philosophy of \"Born for\nTruly Useful Robots\", OrionStar empowers more people through AI technology.\n\n**The core strengths of OrionStar lies in possessing end-to-end AI application capabilities,** including big data preprocessing, large model pretraining, fine-tuning, prompt engineering, agent, etc.  With comprehensive end-to-end model training capabilities, including systematic data processing workflows and the parallel model training capability of hundreds of GPUs, it has been successfully applied in various industry scenarios such as government affairs, cloud services, international e-commerce, and fast-moving consumer goods.\n\nCompanies with demands for deploying large-scale model applications are welcome to contact us.<br>\n**Enquiry Hotline: 400-898-7779**<br>\n**E-mail: ai@orionstar.com**<br>\n**Discord Link: https://discord.gg/zumjDWgdAs**\n\n<div align=\"center\">\n  <img src=\"./assets/imgs/wechat_group.jpg\" alt=\"wechat\" width=\"40%\" />\n</div>\n\n\n\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat",
          "files": [],
          "modelId": "OrionStarAI/Orion-14B-Chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat",
          "files": [],
          "modelId": "OrionStarAI/Orion-14B-Chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat",
          "files": [],
          "modelId": "OrionStarAI/Orion-14B-Chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat",
          "files": [],
          "modelId": "OrionStarAI/Orion-14B-Chat"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/OrionStarAI/Orion-14B-Chat",
          "files": [],
          "modelId": "OrionStarAI/Orion-14B-Chat"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 17369
    },
    {
      "id": "github-crewAIInc-crewAI",
      "name": "crewAI",
      "author": "crewAIInc",
      "description": "Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "aiagentframework",
        "llms"
      ],
      "likes": 81234,
      "downloads": 81234,
      "lastModified": "2025-11-20T14:32:49Z",
      "lastModifiedTimestamp": 1763649169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/crewAIInc/crewAI",
          "homepage": "https://crewai.com",
          "language": "Python",
          "forks": 5422,
          "open_issues": 197,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/170677839?v=4",
      "velocity": 44678.7,
      "is_rising_star": true,
      "heatScore": 13406.83610297468,
      "popularityScore": 40617
    },
    {
      "id": "github-ray-project-ray",
      "name": "ray",
      "author": "ray-project",
      "description": "Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.",
      "task": "tool",
      "tags": [
        "data-science",
        "deep-learning",
        "deployment",
        "distributed",
        "hyperparameter-optimization",
        "hyperparameter-search",
        "large-language-models",
        "llm",
        "llm-inference",
        "llm-serving",
        "machine-learning",
        "optimization",
        "parallel",
        "python",
        "pytorch",
        "ray",
        "reinforcement-learning",
        "rllib",
        "serving",
        "tensorflow"
      ],
      "likes": 79862,
      "downloads": 79862,
      "lastModified": "2025-11-20T15:50:42Z",
      "lastModifiedTimestamp": 1763653842000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ray-project/ray",
          "homepage": "https://ray.io",
          "language": "Python",
          "forks": 6924,
          "open_issues": 3226,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/22125274?v=4",
      "velocity": 43923,
      "is_rising_star": true,
      "heatScore": 13180.120917130518,
      "popularityScore": 39930
    },
    {
      "id": "github-zhayujie-chatgpt-on-wechat",
      "name": "chatgpt-on-wechat",
      "author": "zhayujie",
      "description": "Âü∫‰∫éÂ§ßÊ®°ÂûãÊê≠Âª∫ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂêåÊó∂ÊîØÊåÅ ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ Á≠âÊé•ÂÖ•ÔºåÂèØÈÄâÊã©ChatGPT/Claude/DeepSeek/ÊñáÂøÉ‰∏ÄË®Ä/ËÆØÈ£ûÊòüÁÅ´/ÈÄö‰πâÂçÉÈóÆ/ Gemini/GLM-4/Kimi/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥ÂíåÂõæÁâáÔºåËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíå‰∫íËÅîÁΩëÔºåÊîØÊåÅÂü∫‰∫éËá™ÊúâÁü•ËØÜÂ∫ìËøõË°åÂÆöÂà∂‰ºÅ‰∏öÊô∫ËÉΩÂÆ¢Êúç„ÄÇ",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agent",
        "chatgpt",
        "claude-4",
        "deepseek",
        "dingtalk",
        "feishu-bot",
        "gemini",
        "gpt-4",
        "kimi",
        "linkai",
        "llm",
        "mcp",
        "multi-agent",
        "openai",
        "python3",
        "qwen",
        "rag",
        "wechat",
        "wechat-bot",
        "rag-knowledge-base-qa",
        "general-dialogue-qa"
      ],
      "likes": 79540,
      "downloads": 79540,
      "lastModified": "2025-11-20T15:05:28Z",
      "lastModifiedTimestamp": 1763651128000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/zhayujie/chatgpt-on-wechat",
          "homepage": "https://link-ai.tech",
          "language": "Python",
          "forks": 9502,
          "open_issues": 355,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/26161723?v=4",
      "velocity": 43747,
      "is_rising_star": true,
      "heatScore": 13127.3196965577,
      "popularityScore": 39770
    },
    {
      "id": "github-milvus-io-milvus",
      "name": "milvus",
      "author": "milvus-io",
      "description": "Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search",
      "task": "tool",
      "tags": [
        "anns",
        "cloud-native",
        "diskann",
        "distributed",
        "embedding-database",
        "embedding-similarity",
        "embedding-store",
        "faiss",
        "golang",
        "hnsw",
        "image-search",
        "llm",
        "nearest-neighbor-search",
        "rag",
        "vector-database",
        "vector-search",
        "vector-similarity",
        "vector-store",
        "rag-knowledge-base-qa"
      ],
      "likes": 79350,
      "downloads": 79350,
      "lastModified": "2025-11-20T15:45:07Z",
      "lastModifiedTimestamp": 1763653507000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/milvus-io/milvus",
          "homepage": "https://milvus.io",
          "language": "Go",
          "forks": 3586,
          "open_issues": 905,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/51735404?v=4",
      "velocity": 43642.5,
      "is_rising_star": true,
      "heatScore": 13095.968969517113,
      "popularityScore": 39675
    },
    {
      "id": "github-janhq-jan",
      "name": "jan",
      "author": "janhq",
      "description": "Jan is an open source alternative to ChatGPT that runs 100% offline on your computer.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "gpt",
        "llamacpp",
        "llm",
        "localai",
        "open-source",
        "self-hosted",
        "tauri",
        "general-dialogue-qa"
      ],
      "likes": 78750,
      "downloads": 78750,
      "lastModified": "2025-11-20T13:35:09Z",
      "lastModifiedTimestamp": 1763645709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/janhq/jan",
          "homepage": "https://jan.ai/",
          "language": "TypeScript",
          "forks": 2401,
          "open_issues": 191,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102363196?v=4",
      "velocity": 43312.5,
      "is_rising_star": true,
      "heatScore": 12996.966662117451,
      "popularityScore": 39375
    },
    {
      "id": "byroneverson/Mistral-Small-Instruct-2409-abliterated",
      "name": "Mistral-Small-Instruct-2409-abliterated",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "llm",
        "chat",
        "instruct",
        "it",
        "abliterated",
        "conversational",
        "en",
        "base_model:mistralai/Mistral-Small-Instruct-2409",
        "base_model:finetune:mistralai/Mistral-Small-Instruct-2409",
        "license:other",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us",
        "deploy:azure",
        "general-dialogue-qa"
      ],
      "likes": 140,
      "downloads": 78570,
      "lastModifiedTimestamp": null,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/byroneverson/Mistral-Small-Instruct-2409-abliterated",
          "files": [],
          "modelId": "byroneverson/Mistral-Small-Instruct-2409-abliterated"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/byroneverson/Mistral-Small-Instruct-2409-abliterated",
          "files": [],
          "modelId": "byroneverson/Mistral-Small-Instruct-2409-abliterated"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/byroneverson/Mistral-Small-Instruct-2409-abliterated",
          "files": [],
          "modelId": "byroneverson/Mistral-Small-Instruct-2409-abliterated"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/byroneverson/Mistral-Small-Instruct-2409-abliterated",
          "files": [],
          "modelId": "byroneverson/Mistral-Small-Instruct-2409-abliterated"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/byroneverson/Mistral-Small-Instruct-2409-abliterated",
          "files": [],
          "modelId": "byroneverson/Mistral-Small-Instruct-2409-abliterated"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 15756
    },
    {
      "id": "github-mudler-LocalAI",
      "name": "LocalAI",
      "author": "mudler",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "likes": 77768,
      "downloads": 77768,
      "lastModified": "2025-11-20T15:54:00Z",
      "lastModifiedTimestamp": 1763654040000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mudler/LocalAI",
          "homepage": "https://localai.io",
          "language": "Go",
          "forks": 3085,
          "open_issues": 244,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/2420543?v=4",
      "velocity": 42771.3,
      "is_rising_star": true,
      "heatScore": 12834.602839654122,
      "popularityScore": 38883
    },
    {
      "id": "github-QuivrHQ-quivr",
      "name": "quivr",
      "author": "QuivrHQ",
      "description": "Opiniated RAG for integrating GenAI in your apps üß†   Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want. ",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "chatbot",
        "chatgpt",
        "database",
        "docker",
        "framework",
        "frontend",
        "groq",
        "html",
        "javascript",
        "llm",
        "openai",
        "postgresql",
        "privacy",
        "rag",
        "react",
        "security",
        "typescript",
        "vector",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 77264,
      "downloads": 77264,
      "lastModified": "2025-11-20T12:53:10Z",
      "lastModifiedTimestamp": 1763643190000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/QuivrHQ/quivr",
          "homepage": "https://core.quivr.com",
          "language": "Python",
          "forks": 3689,
          "open_issues": 16,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/159330290?v=4",
      "velocity": 42495.2,
      "is_rising_star": true,
      "heatScore": 12751.770870903854,
      "popularityScore": 38632
    },
    {
      "id": "github-2noise-ChatTTS",
      "name": "ChatTTS",
      "author": "2noise",
      "description": "A generative speech model for daily dialogue.",
      "task": "tool",
      "tags": [
        "agent",
        "chat",
        "chatgpt",
        "chattts",
        "chinese",
        "chinese-language",
        "english",
        "english-language",
        "gpt",
        "llm",
        "llm-agent",
        "natural-language-inference",
        "python",
        "text-to-speech",
        "torch",
        "torchaudio",
        "tts",
        "general-dialogue-qa"
      ],
      "likes": 76366,
      "downloads": 76366,
      "lastModified": "2025-11-20T14:57:26Z",
      "lastModifiedTimestamp": 1763650646000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/2noise/ChatTTS",
          "homepage": "https://2noise.com",
          "language": "Python",
          "forks": 4148,
          "open_issues": 67,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/164844019?v=4",
      "velocity": 42001.3,
      "is_rising_star": true,
      "heatScore": 12603.597316994952,
      "popularityScore": 38183
    },
    {
      "id": "github-upstash-context7",
      "name": "context7",
      "author": "upstash",
      "description": "Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors",
      "task": "tool",
      "tags": [
        "llm",
        "mcp",
        "mcp-server",
        "vibe-coding",
        "code-generation-assistance"
      ],
      "likes": 75160,
      "downloads": 75160,
      "lastModified": "2025-11-20T15:36:23Z",
      "lastModifiedTimestamp": 1763652983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/upstash/context7",
          "homepage": "https://context7.com",
          "language": "JavaScript",
          "forks": 1863,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/74989412?v=4",
      "velocity": 41338,
      "is_rising_star": true,
      "heatScore": 12404.602477832499,
      "popularityScore": 37580
    },
    {
      "id": "github-chatboxai-chatbox",
      "name": "chatbox",
      "author": "chatboxai",
      "description": "User-friendly Desktop Client App for AI Models/LLMs (GPT, Claude, Gemini, Ollama...)",
      "task": "tool",
      "tags": [
        "assistant",
        "chatbot",
        "chatgpt",
        "claude",
        "copilot",
        "deepseek",
        "gemini",
        "gpt",
        "gpt-5",
        "ollama",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 74948,
      "downloads": 74948,
      "lastModified": "2025-11-20T14:27:41Z",
      "lastModifiedTimestamp": 1763648861000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatboxai/chatbox",
          "homepage": "https://chatboxai.app?utm_medium=github",
          "language": "TypeScript",
          "forks": 3786,
          "open_issues": 969,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/199570308?v=4",
      "velocity": 41221.4,
      "is_rising_star": true,
      "heatScore": 12369.621619149064,
      "popularityScore": 37474
    },
    {
      "id": "github-ToolJet-ToolJet",
      "name": "ToolJet",
      "author": "ToolJet",
      "description": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building internal tools, dashboard, business applications, workflows and AI agents üöÄ",
      "task": "tool",
      "tags": [
        "ai-app-builder",
        "docker",
        "hacktoberfest",
        "internal-applications",
        "internal-project",
        "internal-tool",
        "internal-tools",
        "javascript",
        "kubernetes",
        "low-code",
        "low-code-development-platform",
        "low-code-framework",
        "no-code",
        "nodejs",
        "reactjs",
        "self-hosted",
        "typescript",
        "web-development-tools",
        "workflow-automation"
      ],
      "likes": 73858,
      "downloads": 73858,
      "lastModified": "2025-11-20T10:01:22Z",
      "lastModifiedTimestamp": 1763632882000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ToolJet/ToolJet",
          "homepage": "https://tooljet.ai",
          "language": "JavaScript",
          "forks": 4877,
          "open_issues": 951,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/82193554?v=4",
      "velocity": 40621.9,
      "is_rising_star": true,
      "heatScore": 12189.767165515355,
      "popularityScore": 36929
    },
    {
      "id": "github-alibaba-arthas",
      "name": "arthas",
      "author": "alibaba",
      "description": "Alibaba Java Diagnostic Tool Arthas/Alibaba JavaËØäÊñ≠Âà©Âô®Arthas",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "arthas",
        "classloader",
        "diagnosis",
        "java",
        "jvm",
        "trace",
        "trouble-shooting"
      ],
      "likes": 73704,
      "downloads": 73704,
      "lastModified": "2025-11-20T11:33:25Z",
      "lastModifiedTimestamp": 1763638405000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/alibaba/arthas",
          "homepage": "https://arthas.aliyun.com/",
          "language": "Java",
          "forks": 7604,
          "open_issues": 455,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1961952?v=4",
      "velocity": 40537.2,
      "is_rising_star": true,
      "heatScore": 12164.356530993009,
      "popularityScore": 36852
    },
    {
      "id": "github-chatchat-space-Langchain-Chatchat",
      "name": "Langchain-Chatchat",
      "author": "chatchat-space",
      "description": "Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langchain ‰∏é ChatGLM, Qwen ‰∏é Llama Á≠âËØ≠Ë®ÄÊ®°ÂûãÁöÑ RAG ‰∏é Agent Â∫îÁî® | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain ",
      "task": "tool",
      "tags": [
        "chatbot",
        "chatchat",
        "chatglm",
        "chatgpt",
        "embedding",
        "faiss",
        "fastchat",
        "gpt",
        "knowledge-base",
        "langchain",
        "langchain-chatglm",
        "llama",
        "llm",
        "milvus",
        "ollama",
        "qwen",
        "rag",
        "retrieval-augmented-generation",
        "streamlit",
        "xinference",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 73208,
      "downloads": 73208,
      "lastModified": "2025-11-20T14:18:54Z",
      "lastModifiedTimestamp": 1763648334000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatchat-space/Langchain-Chatchat",
          "homepage": "",
          "language": "Python",
          "forks": 6070,
          "open_issues": 28,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/139558948?v=4",
      "velocity": 40264.4,
      "is_rising_star": true,
      "heatScore": 12082.514478287832,
      "popularityScore": 36604
    },
    {
      "id": "github-CherryHQ-cherry-studio",
      "name": "cherry-studio",
      "author": "CherryHQ",
      "description": "üçí Cherry Studio is a desktop client that supports for multiple LLM providers.",
      "task": "tool",
      "tags": [
        "agent",
        "anthropic",
        "assistant",
        "chatbot",
        "chatbotai",
        "electron",
        "llm",
        "mcp-client",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 71276,
      "downloads": 71276,
      "lastModified": "2025-11-20T13:54:08Z",
      "lastModifiedTimestamp": 1763646848000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CherryHQ/cherry-studio",
          "homepage": "https://cherry-ai.com",
          "language": "TypeScript",
          "forks": 3235,
          "open_issues": 542,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/187777663?v=4",
      "velocity": 39201.8,
      "is_rising_star": true,
      "heatScore": 11763.726347856722,
      "popularityScore": 35638
    },
    {
      "id": "github-karpathy-LLM101n",
      "name": "LLM101n",
      "author": "karpathy",
      "description": "LLM101n: Let's build a Storyteller",
      "task": "tool",
      "tags": [],
      "likes": 71188,
      "downloads": 71188,
      "lastModified": "2025-11-20T15:19:34Z",
      "lastModifiedTimestamp": 1763651974000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/LLM101n",
          "homepage": "",
          "language": null,
          "forks": 1937,
          "open_issues": 19,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 39153.4,
      "is_rising_star": true,
      "heatScore": 11749.205972298092,
      "popularityScore": 35594
    },
    {
      "id": "github-agno-agi-agno",
      "name": "agno",
      "author": "agno-agi",
      "description": "Multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "developer-tools",
        "python"
      ],
      "likes": 70800,
      "downloads": 70800,
      "lastModified": "2025-11-20T15:16:06Z",
      "lastModifiedTimestamp": 1763651766000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/agno-agi/agno",
          "homepage": "https://docs.agno.com",
          "language": "Python",
          "forks": 4648,
          "open_issues": 294,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/104874993?v=4",
      "velocity": 38940,
      "is_rising_star": true,
      "heatScore": 11685.18431087104,
      "popularityScore": 35400
    },
    {
      "id": "github-Alibaba-NLP-DeepResearch",
      "name": "DeepResearch",
      "author": "Alibaba-NLP",
      "description": "Tongyi Deep Research, the Leading Open-source Deep Research Agent",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "artificial-intelligence",
        "deep-research",
        "deepresearch",
        "information-seeking",
        "llm",
        "tongyi",
        "web-agent",
        "ai",
        "gpt",
        "o3-mini",
        "research"
      ],
      "likes": 70728,
      "downloads": 70728,
      "lastModified": "2025-11-20T14:51:54Z",
      "lastModifiedTimestamp": 1763650314000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Alibaba-NLP/DeepResearch",
          "homepage": "https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/",
          "language": "Python",
          "forks": 1314,
          "open_issues": 66,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/dzhng/deep-research",
          "homepage": "",
          "language": "TypeScript",
          "forks": 1867,
          "open_issues": 77,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/64211549?v=4",
      "velocity": 38900.4,
      "is_rising_star": true,
      "heatScore": 11673.304001563694,
      "popularityScore": 35364
    },
    {
      "id": "github-reworkd-AgentGPT",
      "name": "AgentGPT",
      "author": "reworkd",
      "description": "ü§ñ Assemble, configure, and deploy autonomous AI Agents in your browser.",
      "task": "tool",
      "tags": [
        "agent",
        "agentgpt",
        "agi",
        "autogpt",
        "baby-agi",
        "gpt",
        "langchain",
        "next",
        "openai",
        "t3",
        "t3-stack"
      ],
      "likes": 70512,
      "downloads": 70512,
      "lastModified": "2025-11-20T10:00:19Z",
      "lastModifiedTimestamp": 1763632819000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/reworkd/AgentGPT",
          "homepage": "https://agentgpt.reworkd.ai",
          "language": "TypeScript",
          "forks": 9487,
          "open_issues": 214,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/120154269?v=4",
      "velocity": 38781.6,
      "is_rising_star": true,
      "heatScore": 11637.663071748948,
      "popularityScore": 35256
    },
    {
      "id": "github-microsoft-qlib",
      "name": "qlib",
      "author": "microsoft",
      "description": "Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.",
      "task": "tool",
      "tags": [
        "algorithmic-trading",
        "auto-quant",
        "deep-learning",
        "finance",
        "fintech",
        "investment",
        "machine-learning",
        "paper",
        "platform",
        "python",
        "quant",
        "quant-dataset",
        "quant-models",
        "quantitative-finance",
        "quantitative-trading",
        "research",
        "research-paper",
        "stock-data"
      ],
      "likes": 67791,
      "downloads": 67791,
      "lastModified": "2025-11-20T15:50:29Z",
      "lastModifiedTimestamp": 1763653829000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/qlib",
          "homepage": "https://qlib.readthedocs.io/en/latest/",
          "language": "Python",
          "forks": 5248,
          "open_issues": 306,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 37284.5,
      "is_rising_star": true,
      "heatScore": 11188.521103915695,
      "popularityScore": 33895
    },
    {
      "id": "github-1Panel-dev-1Panel",
      "name": "1Panel",
      "author": "1Panel-dev",
      "description": "üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.",
      "task": "tool",
      "tags": [
        "1panel",
        "cockpit",
        "docker",
        "docker-ui",
        "lamp",
        "linux",
        "lnmp",
        "ollama",
        "webmin"
      ],
      "likes": 64204,
      "downloads": 64204,
      "lastModified": "2025-11-20T15:40:23Z",
      "lastModifiedTimestamp": 1763653223000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/1Panel-dev/1Panel",
          "homepage": "https://1panel.pro",
          "language": "Go",
          "forks": 2842,
          "open_issues": 302,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/109613420?v=4",
      "velocity": 35312.2,
      "is_rising_star": true,
      "heatScore": 10596.814581933142,
      "popularityScore": 32102
    },
    {
      "id": "github-danny-avila-LibreChat",
      "name": "LibreChat",
      "author": "danny-avila",
      "description": "Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "artifacts",
        "aws",
        "azure",
        "chatgpt",
        "chatgpt-clone",
        "claude",
        "clone",
        "deepseek",
        "gemini",
        "google",
        "gpt-5",
        "librechat",
        "mcp",
        "o1",
        "openai",
        "responses-api",
        "vision",
        "webui",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 63636,
      "downloads": 63636,
      "lastModified": "2025-11-20T15:49:34Z",
      "lastModifiedTimestamp": 1763653774000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/danny-avila/LibreChat",
          "homepage": "https://librechat.ai/",
          "language": "TypeScript",
          "forks": 6245,
          "open_issues": 354,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110412045?v=4",
      "velocity": 34999.8,
      "is_rising_star": true,
      "heatScore": 10503.091880568634,
      "popularityScore": 31818
    },
    {
      "id": "github-khoj-ai-khoj",
      "name": "khoj",
      "author": "khoj-ai",
      "description": "Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "assistant",
        "chat",
        "chatgpt",
        "emacs",
        "image-generation",
        "llama3",
        "llamacpp",
        "llm",
        "obsidian",
        "obsidian-md",
        "offline-llm",
        "productivity",
        "rag",
        "research",
        "self-hosted",
        "semantic-search",
        "stt",
        "whatsapp-ai",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 63230,
      "downloads": 63230,
      "lastModified": "2025-11-20T14:35:37Z",
      "lastModifiedTimestamp": 1763649337000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/khoj-ai/khoj",
          "homepage": "https://khoj.dev",
          "language": "Python",
          "forks": 1863,
          "open_issues": 85,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134046886?v=4",
      "velocity": 34776.5,
      "is_rising_star": true,
      "heatScore": 10436.099934846034,
      "popularityScore": 31615
    },
    {
      "id": "github-BerriAI-litellm",
      "name": "litellm",
      "author": "BerriAI",
      "description": "Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]",
      "task": "tool",
      "tags": [
        "ai-gateway",
        "anthropic",
        "azure-openai",
        "bedrock",
        "gateway",
        "langchain",
        "litellm",
        "llm",
        "llm-gateway",
        "llmops",
        "mcp-gateway",
        "openai",
        "openai-proxy",
        "vertex-ai"
      ],
      "likes": 62736,
      "downloads": 62736,
      "lastModified": "2025-11-20T14:16:45Z",
      "lastModifiedTimestamp": 1763648205000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/BerriAI/litellm",
          "homepage": "https://docs.litellm.ai/docs/",
          "language": "Python",
          "forks": 4769,
          "open_issues": 1382,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/121462774?v=4",
      "velocity": 34504.8,
      "is_rising_star": true,
      "heatScore": 10354.587550471952,
      "popularityScore": 31368
    },
    {
      "id": "github-continuedev-continue",
      "name": "continue",
      "author": "continuedev",
      "description": "‚è© Ship faster with Continuous AI. Open-source CLI that can be used in TUI mode as a coding agent or Headless mode to run background agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "background-agents",
        "claude",
        "cli",
        "continuous-ai",
        "developer-tools",
        "gemini",
        "gpt",
        "hacktoberfest",
        "jetbrains",
        "llm",
        "open-source",
        "qwen",
        "vscode",
        "workflows",
        "code-generation-assistance"
      ],
      "likes": 59846,
      "downloads": 59846,
      "lastModified": "2025-11-20T15:50:10Z",
      "lastModifiedTimestamp": 1763653810000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/continuedev/continue",
          "homepage": "https://docs.continue.dev/",
          "language": "TypeScript",
          "forks": 3805,
          "open_issues": 667,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127876214?v=4",
      "velocity": 32915.3,
      "is_rising_star": true,
      "heatScore": 9877.72321375225,
      "popularityScore": 29923
    },
    {
      "id": "github-JushBJJ-Mr.-Ranedeer-AI-Tutor",
      "name": "Mr.-Ranedeer-AI-Tutor",
      "author": "JushBJJ",
      "description": "A GPT-4 AI Tutor Prompt for customizable personalized learning experiences.",
      "task": "tool",
      "tags": [
        "ai",
        "education",
        "gpt-4",
        "llm"
      ],
      "likes": 59336,
      "downloads": 59336,
      "lastModified": "2025-11-20T02:26:40Z",
      "lastModifiedTimestamp": 1763605600000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor",
          "homepage": "https://Mr-Ranedeer.com",
          "language": null,
          "forks": 3373,
          "open_issues": 14,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/36951064?v=4",
      "velocity": 32634.8,
      "is_rising_star": true,
      "heatScore": 9793.570612036001,
      "popularityScore": 29668
    },
    {
      "id": "github-microsoft-graphrag",
      "name": "graphrag",
      "author": "microsoft",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "task": "tool",
      "tags": [
        "gpt",
        "gpt-4",
        "gpt4",
        "graphrag",
        "llm",
        "llms",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 58536,
      "downloads": 58536,
      "lastModified": "2025-11-20T15:31:55Z",
      "lastModifiedTimestamp": 1763652715000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/graphrag",
          "homepage": "https://microsoft.github.io/graphrag/",
          "language": "Python",
          "forks": 3081,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 32194.8,
      "is_rising_star": true,
      "heatScore": 9661.566485519254,
      "popularityScore": 29268
    },
    {
      "id": "github-feder-cr-Jobs_Applier_AI_Agent_AIHawk",
      "name": "Jobs_Applier_AI_Agent_AIHawk",
      "author": "feder-cr",
      "description": "AIHawk aims to easy job hunt process by automating the job application process. Utilizing artificial intelligence, it enables users to apply for multiple jobs in a tailored way.",
      "task": "tool",
      "tags": [
        "agent",
        "application-resume",
        "artificial-intelligence",
        "automate",
        "automation",
        "bot",
        "chatgpt",
        "chrome",
        "gpt",
        "human-resources",
        "job",
        "jobs",
        "jobsearch",
        "jobseeker",
        "opeai",
        "python",
        "resume",
        "scraper",
        "scraping",
        "selenium"
      ],
      "likes": 58162,
      "downloads": 58162,
      "lastModified": "2025-11-20T14:18:17Z",
      "lastModifiedTimestamp": 1763648297000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/feder-cr/Jobs_Applier_AI_Agent_AIHawk",
          "homepage": "",
          "language": "Python",
          "forks": 4424,
          "open_issues": 13,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85809106?v=4",
      "velocity": 31989.1,
      "is_rising_star": true,
      "heatScore": 9599.854536989074,
      "popularityScore": 29081
    },
    {
      "id": "github-666ghj-BettaFish",
      "name": "BettaFish",
      "author": "666ghj",
      "description": "ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ",
      "task": "tool",
      "tags": [
        "agent-framework",
        "data-analysis",
        "deep-research",
        "deep-search",
        "llms",
        "multi-agent-system",
        "nlp",
        "public-opinion-analysis",
        "python3",
        "sentiment-analysis",
        "data-analysis-insights"
      ],
      "likes": 57118,
      "downloads": 57118,
      "lastModified": "2025-11-20T15:53:38Z",
      "lastModifiedTimestamp": 1763654018000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/666ghj/BettaFish",
          "homepage": "",
          "language": "Python",
          "forks": 5502,
          "open_issues": 69,
          "license": "GNU General Public License v2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110395318?v=4",
      "velocity": 31413.8,
      "is_rising_star": true,
      "heatScore": 9427.259020097514,
      "popularityScore": 28558
    },
    {
      "id": "github-karpathy-llm.c",
      "name": "llm.c",
      "author": "karpathy",
      "description": "LLM training in simple, raw C/CUDA",
      "task": "tool",
      "tags": [],
      "likes": 56400,
      "downloads": 56400,
      "lastModified": "2025-11-20T14:42:34Z",
      "lastModifiedTimestamp": 1763649754000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/llm.c",
          "homepage": "",
          "language": "Cuda",
          "forks": 3291,
          "open_issues": 215,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 31020,
      "is_rising_star": true,
      "heatScore": 9309.115185155992,
      "popularityScore": 28200
    },
    {
      "id": "github-songquanpeng-one-api",
      "name": "one-api",
      "author": "songquanpeng",
      "description": "LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.",
      "task": "tool",
      "tags": [
        "api",
        "api-gateway",
        "azure-openai-api",
        "chatgpt",
        "claude",
        "ernie-bot",
        "gemini",
        "gpt",
        "openai",
        "openai-api",
        "proxy",
        "general-dialogue-qa"
      ],
      "likes": 56137,
      "downloads": 56137,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/songquanpeng/one-api",
          "homepage": "https://openai.justsong.cn/",
          "language": "JavaScript",
          "forks": 5528,
          "open_issues": 969,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/39998050?v=4",
      "velocity": 30874.8,
      "is_rising_star": true,
      "heatScore": 9265.553758858363,
      "popularityScore": 28068
    },
    {
      "id": "github-OpenBMB-ChatDev",
      "name": "ChatDev",
      "author": "OpenBMB",
      "description": "Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)",
      "task": "tool",
      "tags": [],
      "likes": 55500,
      "downloads": 55500,
      "lastModified": "2025-11-20T09:53:36Z",
      "lastModifiedTimestamp": 1763632416000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBMB/ChatDev",
          "homepage": "https://arxiv.org/abs/2307.07924",
          "language": "Python",
          "forks": 3489,
          "open_issues": 50,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/89920203?v=4",
      "velocity": 30525,
      "is_rising_star": true,
      "heatScore": 9160.6102950462,
      "popularityScore": 27750
    },
    {
      "id": "github-stanford-oval-storm",
      "name": "storm",
      "author": "stanford-oval",
      "description": "An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.",
      "task": "tool",
      "tags": [
        "agentic-rag",
        "deep-research",
        "emnlp2024",
        "knowledge-curation",
        "large-language-models",
        "naacl",
        "nlp",
        "report-generation",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 55244,
      "downloads": 55244,
      "lastModified": "2025-11-20T11:29:33Z",
      "lastModifiedTimestamp": 1763638173000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/stanford-oval/storm",
          "homepage": "http://storm.genie.stanford.edu",
          "language": "Python",
          "forks": 2505,
          "open_issues": 87,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13667124?v=4",
      "velocity": 30384.2,
      "is_rising_star": true,
      "heatScore": 9118.368889590394,
      "popularityScore": 27622
    },
    {
      "id": "github-voideditor-void",
      "name": "void",
      "author": "voideditor",
      "description": "An AI tool from GitHub.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "claude",
        "copilot",
        "cursor",
        "developer-tools",
        "editor",
        "llm",
        "open-source",
        "openai",
        "visual-studio-code",
        "vscode",
        "vscode-extension"
      ],
      "likes": 55124,
      "downloads": 55124,
      "lastModified": "2025-11-20T14:53:51Z",
      "lastModifiedTimestamp": 1763650431000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/voideditor/void",
          "homepage": "https://voideditor.com",
          "language": "TypeScript",
          "forks": 2149,
          "open_issues": 303,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/181171420?v=4",
      "velocity": 30318.2,
      "is_rising_star": true,
      "heatScore": 9098.568228539569,
      "popularityScore": 27562
    },
    {
      "id": "github-nrwl-nx",
      "name": "nx",
      "author": "nrwl",
      "description": "Get to green PRs in half the time. Nx optimizes your builds, scales your CI, and fixes failed PRs. Built for developers and AI agents.",
      "task": "tool",
      "tags": [
        "angular",
        "build",
        "build-system",
        "build-tool",
        "building-tool",
        "cli",
        "cypress",
        "hacktoberfest",
        "javascript",
        "monorepo",
        "nextjs",
        "nodejs",
        "nx",
        "nx-workspaces",
        "react",
        "storybook",
        "typescript"
      ],
      "likes": 55054,
      "downloads": 55054,
      "lastModified": "2025-11-20T15:43:56Z",
      "lastModifiedTimestamp": 1763653436000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nrwl/nx",
          "homepage": "https://nx.dev",
          "language": "TypeScript",
          "forks": 2623,
          "open_issues": 789,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23692104?v=4",
      "velocity": 30279.7,
      "is_rising_star": true,
      "heatScore": 9087.017842261728,
      "popularityScore": 27527
    },
    {
      "id": "github-microsoft-semantic-kernel",
      "name": "semantic-kernel",
      "author": "microsoft",
      "description": "Integrate cutting-edge LLM technology quickly and easily into your apps",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "llm",
        "openai",
        "sdk"
      ],
      "likes": 53406,
      "downloads": 53406,
      "lastModified": "2025-11-20T12:07:50Z",
      "lastModifiedTimestamp": 1763640470000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/semantic-kernel",
          "homepage": "https://aka.ms/semantic-kernel",
          "language": "C#",
          "forks": 4352,
          "open_issues": 570,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 29373.3,
      "is_rising_star": true,
      "heatScore": 8815.088603423534,
      "popularityScore": 26703
    },
    {
      "id": "github-labring-FastGPT",
      "name": "FastGPT",
      "author": "labring",
      "description": "FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.",
      "task": "tool",
      "tags": [
        "agent",
        "claude",
        "deepseek",
        "llm",
        "mcp",
        "nextjs",
        "openai",
        "qwen",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 52648,
      "downloads": 52648,
      "lastModified": "2025-11-20T15:45:26Z",
      "lastModifiedTimestamp": 1763653526000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/labring/FastGPT",
          "homepage": "https://fastgpt.io",
          "language": "TypeScript",
          "forks": 6777,
          "open_issues": 653,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102226726?v=4",
      "velocity": 28956.4,
      "is_rising_star": true,
      "heatScore": 8690.0142578659,
      "popularityScore": 26324
    },
    {
      "id": "github-ComposioHQ-composio",
      "name": "composio",
      "author": "ComposioHQ",
      "description": "Composio equips your AI agents & LLMs with 100+ high-quality integrations via function calling",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "aiagents",
        "developer-tools",
        "function-calling",
        "gpt-4",
        "javascript",
        "js",
        "llm",
        "llmops",
        "mcp",
        "python",
        "remote-mcp-server",
        "sse",
        "typescript"
      ],
      "likes": 52338,
      "downloads": 52338,
      "lastModified": "2025-11-20T13:33:16Z",
      "lastModifiedTimestamp": 1763645596000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ComposioHQ/composio",
          "homepage": "https://docs.composio.dev",
          "language": "TypeScript",
          "forks": 4399,
          "open_issues": 28,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128464815?v=4",
      "velocity": 28785.9,
      "is_rising_star": true,
      "heatScore": 8638.862462605848,
      "popularityScore": 26169
    },
    {
      "id": "github-datawhalechina-self-llm",
      "name": "self-llm",
      "author": "datawhalechina",
      "description": "„ÄäÂºÄÊ∫êÂ§ßÊ®°ÂûãÈ£üÁî®ÊåáÂçó„ÄãÈíàÂØπ‰∏≠ÂõΩÂÆùÂÆùÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫‰∫éLinuxÁéØÂ¢ÉÂø´ÈÄüÂæÆË∞ÉÔºàÂÖ®ÂèÇÊï∞/LoraÔºâ„ÄÅÈÉ®ÁΩ≤ÂõΩÂÜÖÂ§ñÂºÄÊ∫êÂ§ßÊ®°ÂûãÔºàLLMÔºâ/Â§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÔºàMLLMÔºâÊïôÁ®ã",
      "task": "tool",
      "tags": [
        "chatglm",
        "chatglm3",
        "gemma-2b-it",
        "glm-4",
        "internlm2",
        "llama3",
        "llm",
        "lora",
        "minicpm",
        "q-wen",
        "qwen",
        "qwen1-5",
        "qwen2"
      ],
      "likes": 52152,
      "downloads": 52152,
      "lastModified": "2025-11-20T15:48:41Z",
      "lastModifiedTimestamp": 1763653721000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/datawhalechina/self-llm",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2629,
          "open_issues": 147,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/46047812?v=4",
      "velocity": 28683.6,
      "is_rising_star": true,
      "heatScore": 8608.1713803389,
      "popularityScore": 26076
    },
    {
      "id": "github-Hannibal046-Awesome-LLM",
      "name": "Awesome-LLM",
      "author": "Hannibal046",
      "description": "Awesome-LLM: a curated list of Large Language Model",
      "task": "tool",
      "tags": [],
      "likes": 51190,
      "downloads": 51190,
      "lastModified": "2025-11-20T15:23:28Z",
      "lastModifiedTimestamp": 1763652208000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Hannibal046/Awesome-LLM",
          "homepage": "",
          "language": null,
          "forks": 2192,
          "open_issues": 51,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/38466901?v=4",
      "velocity": 28154.5,
      "is_rising_star": true,
      "heatScore": 8449.435720471049,
      "popularityScore": 25595
    },
    {
      "id": "github-warpdotdev-Warp",
      "name": "Warp",
      "author": "warpdotdev",
      "description": "Warp is the agentic development environment, built for coding with multiple AI agents.",
      "task": "tool",
      "tags": [
        "bash",
        "linux",
        "macos",
        "rust",
        "shell",
        "terminal",
        "wasm",
        "zsh",
        "code-generation-assistance"
      ],
      "likes": 50620,
      "downloads": 50620,
      "lastModified": "2025-11-20T15:49:51Z",
      "lastModifiedTimestamp": 1763653791000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/warpdotdev/Warp",
          "homepage": "https://warp.dev",
          "language": null,
          "forks": 581,
          "open_issues": 3958,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/71840468?v=4",
      "velocity": 27841,
      "is_rising_star": true,
      "heatScore": 8355.382316512678,
      "popularityScore": 25310
    },
    {
      "id": "github-TauricResearch-TradingAgents",
      "name": "TradingAgents",
      "author": "TauricResearch",
      "description": "TradingAgents: Multi-Agents LLM Financial Trading Framework",
      "task": "tool",
      "tags": [
        "agent",
        "finance",
        "llm",
        "multiagent",
        "trading"
      ],
      "likes": 50536,
      "downloads": 50536,
      "lastModified": "2025-11-20T15:34:43Z",
      "lastModifiedTimestamp": 1763652883000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/TauricResearch/TradingAgents",
          "homepage": "https://arxiv.org/pdf/2412.20138",
          "language": "Python",
          "forks": 4718,
          "open_issues": 200,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192884433?v=4",
      "velocity": 27794.8,
      "is_rising_star": true,
      "heatScore": 8341.521811638786,
      "popularityScore": 25268
    },
    {
      "id": "github-CopilotKit-CopilotKit",
      "name": "CopilotKit",
      "author": "CopilotKit",
      "description": "React UI + elegant infrastructure for AI Copilots, AI chatbots, and in-app AI agents. The Agentic last-mile ü™Å",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai",
        "ai-agent",
        "ai-assistant",
        "assistant",
        "copilot",
        "copilot-chat",
        "hacktoberfest",
        "langchain",
        "langgraph",
        "llm",
        "nextjs",
        "open-source",
        "react",
        "reactjs",
        "ts",
        "typescript",
        "general-dialogue-qa"
      ],
      "likes": 50076,
      "downloads": 50076,
      "lastModified": "2025-11-20T14:45:22Z",
      "lastModifiedTimestamp": 1763649922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CopilotKit/CopilotKit",
          "homepage": "https://docs.copilotkit.ai",
          "language": "TypeScript",
          "forks": 3341,
          "open_issues": 435,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131273140?v=4",
      "velocity": 27541.8,
      "is_rising_star": true,
      "heatScore": 8265.619031886114,
      "popularityScore": 25038
    },
    {
      "id": "h2oai/h2ovl-mississippi-800m",
      "name": "h2ovl-mississippi-800m",
      "description": "A model for text-generation.",
      "task": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "h2ovl_chat",
        "feature-extraction",
        "gpt",
        "llm",
        "multimodal large language model",
        "ocr",
        "text-generation",
        "conversational",
        "custom_code",
        "en",
        "arxiv:2410.13611",
        "license:apache-2.0",
        "region:us",
        "general-dialogue-qa"
      ],
      "likes": 390,
      "downloads": 49900,
      "lastModifiedTimestamp": null,
      "readme": "---\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- gpt\n- llm\n- multimodal large language model\n- ocr\nthumbnail: >-\n  https://h2o.ai/etc.clientlibs/h2o/clientlibs/clientlib-site/resources/images/favicon.ico\npipeline_tag: text-generation\n---\n# Model Card\n[\\[üìú H2OVL-Mississippi Paper\\]](https://arxiv.org/abs/2410.13611)\n[\\[ü§ó HF Demo\\]](https://huggingface.co/spaces/h2oai/h2ovl-mississippi)\n[\\[üöÄ Quick Start\\]](#quick-start)\n\nThe H2OVL-Mississippi-800M is a compact yet powerful vision-language model from H2O.ai, featuring 0.8 billion parameters. Despite its small size, it delivers state-of-the-art performance in text recognition, excelling in the Text Recognition segment of OCRBench and outperforming much larger models in this domain. Built upon the robust architecture of our H2O-Danube language models, the Mississippi-800M extends their capabilities by seamlessly integrating vision and language tasks.\n\n<div align=\"center\">\n  <img src=\"./assets/text_recognition.png\" alt=\"Mississippi-2B Benchmarks\" width=\"600\"/>\n</div>\n\n## Key Features:\n\n- 0.8 Billion Parameters: Balance between performance and efficiency, making it suitable for OCR and document processing.\n- Trained on 19 million image-text pairs, with a focus on OCR, document comprehension, and chart, figure, and table interpretation, the model is optimized for superior OCR performance.\n\n\n<div align=\"center\">\n  <img src=\"./assets/perf_size.png\" alt=\"Mississippi-2B Benchmarks\" width=\"600\"/>\n</div>\n\n\n## Benchmarks\n\n### Performance Comparison of Similar Sized Models Across Multiple Benchmarks - OpenVLM Leaderboard\n\n| **Models**                 | **Params (B)** | **Avg. Score** | **MMBench** | **MMStar** | **MMMU<sub>VAL</sub>** | **Math Vista** | **Hallusion** | **AI2D<sub>TEST</sub>** | **OCRBench** | **MMVet** |\n|----------------------------|----------------|----------------|-------------|------------|-----------------------|----------------|---------------|-------------------------|--------------|-----------|\n| Qwen2-VL-2B                | 2.1            | **57.2**       | **72.2**    | 47.5       | 42.2                  | 47.8           | **42.4**      | 74.7                    | **797**      | **51.5**  |\n| **H2OVL-Mississippi-2B**    | 2.1            | 54.4           | 64.8        | 49.6       | 35.2                  | **56.8**       | 36.4          | 69.9                    | 782          | 44.7      |\n| InternVL2-2B               | 2.1            | 53.9           | 69.6        | **49.8**   | 36.3                  | 46.0           | 38.0          | 74.1                    | 781          | 39.7      |\n| Phi-3-Vision               | 4.2            | 53.6           | 65.2        | 47.7       | **46.1**              | 44.6           | 39.0          | **78.4**                 | 637          | 44.1      |\n| MiniMonkey                 | 2.2            | 52.7           | 68.9        | 48.1       | 35.7                  | 45.3           | 30.9          | 73.7                    | **794**      | 39.8      |\n| MiniCPM-V-2                | 2.8            | 47.9           | 65.8        | 39.1       | 38.2                  | 39.8           | 36.1          | 62.9                    | 605          | 41.0      |\n| InternVL2-1B               | 0.8            | 48.3           | 59.7        | 45.6       | 36.7                  | 39.4           | 34.3          | 63.8                    | 755          | 31.5      |\n| PaliGemma-3B-mix-448       | 2.9            | 46.5           | 65.6        | 48.3       | 34.9                  | 28.7           | 32.2          | 68.3                    | 614          | 33.1      |\n| **H2OVL-Mississippi-0.8B** | 0.8            | 43.5           | 47.7        | 39.1       | 34.0                  | 39.0           | 29.6          | 53.6                    | 751          | 30.0      |\n| DeepSeek-VL-1.3B           | 2.0            | 39.6           | 63.8        | 39.9       | 33.8                  | 29.8           | 27.6          | 51.5                    | 413          | 29.2      |\n\n\n\n## Quick Start\n\n### Install dependencies:\n```bash\npip install transformers torch torchvision einops timm peft sentencepiece flash_attn\n```\n\n### Sample demo:\n\n```python\nimport torch\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n\n# Set up the model and tokenizer\nmodel_path = 'h2oai/h2ovl-mississippi-800m'\nconfig = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\nconfig.llm_config._attn_implementation = 'flash_attention_2'\nmodel = AutoModel.from_pretrained(\n    model_path,\n    torch_dtype=torch.bfloat16,\n    config=config,\n    low_cpu_mem_usage=True,\n    trust_remote_code=True).eval().cuda()\ntokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False)\ngeneration_config = dict(max_new_tokens=2048, do_sample=True)\n\n# pure-text conversation\nquestion = 'Hello, how are you?'\nresponse, history = model.chat(tokenizer, None, question, generation_config, history=None, return_history=True)\nprint(f'User: {question}\\nAssistant: {response}')\n\n\n# Example for single image\nimage_file = './examples/image.jpg'\nquestion = '<image>\\nRead the text in the image.'\nresponse, history = model.chat(tokenizer, image_file, question, generation_config, history=None, return_history=True)\nprint(f'User: {question}\\nAssistant: {response}')\n\n\n```\n\n\n## Prompt Engineering for JSON Extraction\n\n### Overview\n\nThis guide demonstrates how to create prompts for extracting information and converting it into structured JSON outputs. It starts with basic examples and progresses to more complex JSON structures, including handling data from images of tables and charts. The objective is to help users design effective prompts that can be used in various applications, such as natural language processing, chatbots, or data extraction from visual inputs.\n\n### Table of Contents\n\n1. [Getting Started](#getting-started)\n2. [Extracting Simple Information](#example-1-extracting-simple-information-from-an-image)\n3. [Extracting Nested Information](#example-2-extracting-nested-information-from-an-image)\n4. [Extracting Lists and Arrays](#example-3-extracting-lists-and-arrays-from-an-image)\n5. [Extracting Tables](#example-4-extracting-table-data-from-an-image)\n6. [Extracting Charts](#example-5-extracting-chart-data-from-an-image)\n7. [Best Practices](#best-practices)\n\n---\n\n### Getting Started\n\nTo get started with JSON extraction from images, it's essential to have a clear understanding of the visual content you want to extract and the structure of the desired JSON output. The following examples will guide you through crafting prompts to achieve this.\n\n\n#### Example 1: Extracting Simple Information from an Image\n\n**Hypothetical Scenario:**\nYou have an image of a form that contains basic details like \"Name,\" \"Date of Birth,\" and \"Address.\"\n\n**Prompt:**\n```\nExtract the details from the form image and structure them into JSON format:\n{\n    \"name\": \"\",\n    \"date_of_birth\": \"\",\n    \"address\": \"\"\n}\n```\n\n**Expected Output:**\n```json\n{\n  \"name\": \"John Doe\",\n  \"date_of_birth\": \"1990-01-01\",\n  \"address\": \"1234 Elm Street, Springfield\"\n}\n```\n\n#### Example 2: Extracting Nested Information from an Image\n\n**Hypothetical Scenario:**\nYou have an image of a form that contains detailed personal information, including contact details and emergency contacts.\n\n**Prompt:**\n```\nExtract the information from the form and format it as follows:\n{\n    \"personal_details\": {\n        \"name\": \"\",\n        \"age\": 0,\n        \"gender\": \"\"\n    },\n    \"contact\": {\n        \"phone\": \"\",\n        \"email\": \"\"\n    },\n    \"emergency_contact\": {\n        \"name\": \"\",\n        \"relation\": \"\",\n        \"phone\": \"\"\n    }\n}\n```\n\n**Expected Output:**\n```json\n{\n  \"personal_details\": {\n    \"name\": \"Sarah Connor\",\n    \"age\": 35,\n    \"gender\": \"Female\"\n  },\n  \"contact\": {\n    \"phone\": \"555-1234\",\n    \"email\": \"sarah.connor@example.com\"\n  },\n  \"emergency_contact\": {\n    \"name\": \"Kyle Reese\",\n    \"relation\": \"Friend\",\n    \"phone\": \"555-5678\"\n  }\n}\n```\n\n\n#### Example 3: Extracting Lists and Arrays from an Image\n\n**Hypothetical Scenario:**\nYou have an image of a schedule that lists several events, their times, and locations.\n\n**Prompt:**\n```\nExtract the event details from the schedule image and structure them into JSON:\n{\n    \"events\": [\n        {\n            \"name\": \"\",\n            \"time\": \"\",\n            \"location\": \"\"\n        }\n    ]\n}\n```\n\n**Expected Output:**\n```json\n{\n  \"events\": [\n    {\n      \"name\": \"Morning Meeting\",\n      \"time\": \"09:00 AM\",\n      \"location\": \"Conference Room 1\"\n    },\n    {\n      \"name\": \"Lunch Break\",\n      \"time\": \"12:00 PM\",\n      \"location\": \"Cafeteria\"\n    },\n    {\n      \"name\": \"Project Update\",\n      \"time\": \"02:00 PM\",\n      \"location\": \"Conference Room 2\"\n    }\n  ]\n}\n```\n\n\n#### Example 4: Extracting Table Data from an Image\n\nImages of tables often contain structured data that needs to be parsed and converted to JSON. The following example demonstrates how to handle tabular data extraction.\n\n**Hypothetical Scenario:**\nYou have an image of a table listing product names, prices, and quantities.\n\n**Prompt:**\n```\nExtract the data from the table image and format it as JSON:\n{\n    \"products\": [\n        {\n            \"product_name\": \"\",\n            \"price\": \"\",\n            \"quantity\": 0\n        }\n    ]\n}\n```\n\n**Expected Output:**\n```json\n{\n  \"products\": [\n    {\n      \"product_name\": \"Apples\",\n      \"price\": \"$2\",\n      \"quantity\": 10\n    },\n    {\n      \"product_name\": \"Bananas\",\n      \"price\": \"$1\",\n      \"quantity\": 20\n    },\n    {\n      \"product_name\": \"Oranges\",\n      \"price\": \"$3\",\n      \"quantity\": 15\n    }\n  ]\n}\n```\n\n\n#### Example 5: Extracting Chart Data from an Image\n\nCharts include metadata and data points that need to be accurately extracted. Here's how to structure prompts to extract chart data from images.\n\n**Hypothetical Scenario:**\nYou have an image of a bar chart that shows monthly sales figures.\n\n**Prompt:**\n```\nExtract the details of the bar chart from the image, including the title, axis labels, and data points and format it as JSON:\n{\n    \"chart\": {\n        \"title\": \"\",\n        \"x_axis\": \"\",\n        \"y_axis\": \"\",\n        \"data_points\": [\n            {\n                \"label\": \"\",\n                \"value\": 0\n            }\n        ]\n    }\n}\n```\n\n**Expected Output:**\n```json\n{\n  \"chart\": {\n    \"title\": \"Monthly Sales Report\",\n    \"x_axis\": \"Months\",\n    \"y_axis\": \"Sales (in $)\",\n    \"data_points\": [\n      {\n        \"label\": \"January\",\n        \"value\": 500\n      },\n      {\n        \"label\": \"February\",\n        \"value\": 600\n      },\n      {\n        \"label\": \"March\",\n        \"value\": 700\n      }\n    ]\n  }\n}\n```\n\n## Best Practices\n\n1. **Be Explicit**: Clearly define the desired keys and structure in your prompt to avoid ambiguity.\n2. **Use Examples**: Provide sample outputs so that the system can understand the expected format.\n3. **Anticipate Variations**: Consider possible variations in the visual data and ensure the prompt can accommodate them.\n4. **Start Simple**: Begin with simple structures, and progressively increase complexity as needed.\n5. **Test and Iterate**: Refine your prompts through testing to ensure accuracy and consistency in outputs.\n\n## Acknowledgments\n\nWe would like to express our gratitude to the [InternVL team at OpenGVLab](https://github.com/OpenGVLab/InternVL) for their research and codebases, upon which we have built and expanded. We also acknowledge the work of the [LLaVA team](https://github.com/haotian-liu/LLaVA) and the [Monkey team](https://github.com/Yuliang-Liu/Monkey/tree/main/project/mini_monkey) for their insights and techniques used in improving multimodal models.\n\n## Disclaimer\n\nPlease read this disclaimer carefully before using the large language model provided in this repository. Your use of the model signifies your agreement to the following terms and conditions.\n\n- Biases and Offensiveness: The large language model is trained on a diverse range of internet text data, which may contain biased, racist, offensive, or otherwise inappropriate content. By using this model, you acknowledge and accept that the generated content may sometimes exhibit biases or produce content that is offensive or inappropriate. The developers of this repository do not endorse, support, or promote any such content or viewpoints.\n- Limitations: The large language model is an AI-based tool and not a human. It may produce incorrect, nonsensical, or irrelevant responses. It is the user's responsibility to critically evaluate the generated content and use it at their discretion.\n- Use at Your Own Risk: Users of this large language model must assume full responsibility for any consequences that may arise from their use of the tool. The developers and contributors of this repository shall not be held liable for any damages, losses, or harm resulting from the use or misuse of the provided model.\n- Ethical Considerations: Users are encouraged to use the large language model responsibly and ethically. By using this model, you agree not to use it for purposes that promote hate speech, discrimination, harassment, or any form of illegal or harmful activities.\n- Reporting Issues: If you encounter any biased, offensive, or otherwise inappropriate content generated by the large language model, please report it to the repository maintainers through the provided channels. Your feedback will help improve the model and mitigate potential issues.\n- Changes to this Disclaimer: The developers of this repository reserve the right to modify or update this disclaimer at any time without prior notice. It is the user's responsibility to periodically review the disclaimer to stay informed about any changes.\n\nBy using the large language model provided in this repository, you agree to accept and comply with the terms and conditions outlined in this disclaimer. If you do not agree with any part of this disclaimer, you should refrain from using the model and any content generated by it.",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2ovl-mississippi-800m",
          "files": [],
          "modelId": "h2oai/h2ovl-mississippi-800m"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2ovl-mississippi-800m",
          "files": [],
          "modelId": "h2oai/h2ovl-mississippi-800m"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2ovl-mississippi-800m",
          "files": [],
          "modelId": "h2oai/h2ovl-mississippi-800m"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2ovl-mississippi-800m",
          "files": [],
          "modelId": "h2oai/h2ovl-mississippi-800m"
        },
        {
          "platform": "Hugging Face",
          "url": "https://huggingface.co/h2oai/h2ovl-mississippi-800m",
          "files": [],
          "modelId": "h2oai/h2ovl-mississippi-800m"
        }
      ],
      "thumbnail": null,
      "velocity": null,
      "is_rising_star": false,
      "heatScore": null,
      "popularityScore": 10097
    },
    {
      "id": "github-chroma-core-chroma",
      "name": "chroma",
      "author": "chroma-core",
      "description": "Open-source search and retrieval database for AI applications.",
      "task": "tool",
      "tags": [
        "ai",
        "database",
        "document-retrieval",
        "embeddings",
        "llm",
        "llms",
        "rag",
        "rust",
        "rust-lang",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 49026,
      "downloads": 49026,
      "lastModified": "2025-11-20T14:11:20Z",
      "lastModifiedTimestamp": 1763647880000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chroma-core/chroma",
          "homepage": "https://www.trychroma.com/",
          "language": "Rust",
          "forks": 1926,
          "open_issues": 491,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/105881770?v=4",
      "velocity": 26964.3,
      "is_rising_star": true,
      "heatScore": 8092.362589927232,
      "popularityScore": 24513
    },
    {
      "id": "github-microsoft-JARVIS",
      "name": "JARVIS",
      "author": "microsoft",
      "description": "JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf",
      "task": "tool",
      "tags": [
        "deep-learning",
        "platform",
        "pytorch"
      ],
      "likes": 48902,
      "downloads": 48902,
      "lastModified": "2025-11-20T11:10:51Z",
      "lastModifiedTimestamp": 1763637051000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/JARVIS",
          "homepage": "",
          "language": "Python",
          "forks": 2052,
          "open_issues": 344,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26896.1,
      "is_rising_star": true,
      "heatScore": 8071.901820070982,
      "popularityScore": 24451
    },
    {
      "id": "github-microsoft-BitNet",
      "name": "BitNet",
      "author": "microsoft",
      "description": "Official inference framework for 1-bit LLMs",
      "task": "tool",
      "tags": [],
      "likes": 48820,
      "downloads": 48820,
      "lastModified": "2025-11-20T12:29:27Z",
      "lastModifiedTimestamp": 1763641767000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/BitNet",
          "homepage": "",
          "language": "Python",
          "forks": 1895,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26851,
      "is_rising_star": true,
      "heatScore": 8058.3713098995,
      "popularityScore": 24410
    },
    {
      "id": "github-assafelovic-gpt-researcher",
      "name": "gpt-researcher",
      "author": "assafelovic",
      "description": "An LLM agent that conducts deep research (local and web) on any given topic and generates a long report with citations.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "automation",
        "deepresearch",
        "llms",
        "mcp",
        "mcp-server",
        "python",
        "research",
        "search",
        "webscraping"
      ],
      "likes": 48440,
      "downloads": 48440,
      "lastModified": "2025-11-20T15:20:31Z",
      "lastModifiedTimestamp": 1763652031000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/assafelovic/gpt-researcher",
          "homepage": "https://gptr.dev",
          "language": "Python",
          "forks": 3202,
          "open_issues": 149,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13554167?v=4",
      "velocity": 26642,
      "is_rising_star": true,
      "heatScore": 7995.668934448769,
      "popularityScore": 24220
    },
    {
      "id": "github-e2b-dev-awesome-ai-agents",
      "name": "awesome-ai-agents",
      "author": "e2b-dev",
      "description": "A list of AI autonomous agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artificial-intelligence",
        "autogpt",
        "autonomous-agents",
        "awesome",
        "babyagi",
        "copilot",
        "gpt",
        "gpt-4",
        "gpt-engineer",
        "openai",
        "python"
      ],
      "likes": 48438,
      "downloads": 48438,
      "lastModified": "2025-11-20T14:47:26Z",
      "lastModifiedTimestamp": 1763650046000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/e2b-dev/awesome-ai-agents",
          "homepage": "https://e2b.dev/docs",
          "language": null,
          "forks": 2026,
          "open_issues": 78,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/129434473?v=4",
      "velocity": 26640.9,
      "is_rising_star": true,
      "heatScore": 7995.338921897165,
      "popularityScore": 24219
    }
  ],
  "newest": [
    {
      "id": "github-keploy-keploy",
      "name": "keploy",
      "author": "keploy",
      "description": "API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "ai-testing-tool",
        "api-testing",
        "code-quality",
        "mock",
        "mock-data-generator",
        "mock-framework",
        "test-automation",
        "test-automation-framework",
        "test-generation",
        "testing",
        "testing-library",
        "testing-tool",
        "testing-tools"
      ],
      "likes": 25599,
      "downloads": 25599,
      "lastModified": "2025-11-20T15:55:03Z",
      "lastModifiedTimestamp": 1763654103000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/keploy/keploy",
          "homepage": "https://keploy.io",
          "language": "Go",
          "forks": 1795,
          "open_issues": 345,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/92252339?v=4",
      "velocity": 14078.9,
      "is_rising_star": true,
      "heatScore": 4226.545046978754,
      "popularityScore": 12799
    },
    {
      "id": "github-sst-opencode",
      "name": "opencode",
      "author": "sst",
      "description": "The AI coding agent built for the terminal.",
      "task": "tool",
      "tags": [
        "ai",
        "claude",
        "code",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 85846,
      "downloads": 85846,
      "lastModified": "2025-11-20T15:54:52Z",
      "lastModifiedTimestamp": 1763654092000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sst/opencode",
          "homepage": "https://opencode.ai",
          "language": "TypeScript",
          "forks": 2685,
          "open_issues": 1494,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/opencode-ai/opencode",
          "homepage": "",
          "language": "Go",
          "forks": 807,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/66570915?v=4",
      "velocity": 47215.3,
      "is_rising_star": true,
      "heatScore": 14167.832890130338,
      "popularityScore": 42923
    },
    {
      "id": "github-GibsonAI-Memori",
      "name": "Memori",
      "author": "GibsonAI",
      "description": "Open-Source Memory Engine for LLMs, AI Agents & Multi-Agent Systems",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "aiagent",
        "awesome",
        "chatgpt",
        "hacktoberfest",
        "hacktoberfest2025",
        "llm",
        "long-short-term-memory",
        "memori-ai",
        "memory",
        "memory-management",
        "python",
        "rag",
        "state-management",
        "rag-knowledge-base-qa"
      ],
      "likes": 11066,
      "downloads": 11066,
      "lastModified": "2025-11-20T15:54:26Z",
      "lastModifiedTimestamp": 1763654066000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/GibsonAI/Memori",
          "homepage": "https://memorilabs.ai",
          "language": "Python",
          "forks": 402,
          "open_issues": 41,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/158103259?v=4",
      "velocity": 6085.2,
      "is_rising_star": true,
      "heatScore": 1828.1800724691498,
      "popularityScore": 5532
    },
    {
      "id": "github-browser-use-browser-use",
      "name": "browser-use",
      "author": "browser-use",
      "description": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "ai-tools",
        "browser-automation",
        "browser-use",
        "llm",
        "playwright",
        "python"
      ],
      "likes": 145557,
      "downloads": 145557,
      "lastModified": "2025-11-20T15:54:22Z",
      "lastModifiedTimestamp": 1763654062000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/browser-use/browser-use",
          "homepage": "https://browser-use.com",
          "language": "Python",
          "forks": 8663,
          "open_issues": 232,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192012301?v=4",
      "velocity": 80055.8,
      "is_rising_star": true,
      "heatScore": 24020.143404258793,
      "popularityScore": 72778
    },
    {
      "id": "github-apify-crawlee",
      "name": "crawlee",
      "author": "apify",
      "description": "Crawlee‚ÄîA web scraping and browser automation library for Node.js to build reliable crawlers. In JavaScript and TypeScript. Extract data for AI, LLMs, RAG, or GPTs. Download HTML, PDF, JPG, PNG, and other files from websites. Works with Puppeteer, Playwright, Cheerio, JSDOM, and raw HTTP. Both headful and headless mode. With proxy rotation.",
      "task": "tool",
      "tags": [
        "apify",
        "automation",
        "crawler",
        "crawling",
        "headless",
        "headless-chrome",
        "javascript",
        "nodejs",
        "npm",
        "playwright",
        "puppeteer",
        "scraper",
        "scraping",
        "typescript",
        "web-crawler",
        "web-crawling",
        "web-scraping",
        "rag-knowledge-base-qa"
      ],
      "likes": 41183,
      "downloads": 41183,
      "lastModified": "2025-11-20T15:54:21Z",
      "lastModifiedTimestamp": 1763654061000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/apify/crawlee",
          "homepage": "https://crawlee.dev",
          "language": "TypeScript",
          "forks": 1100,
          "open_issues": 199,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/24586296?v=4",
      "velocity": 22650.1,
      "is_rising_star": true,
      "heatScore": 6798.049588970692,
      "popularityScore": 20591
    },
    {
      "id": "github-langchain-ai-langgraph",
      "name": "langgraph",
      "author": "langchain-ai",
      "description": "Build resilient language agents as graphs.",
      "task": "tool",
      "tags": [],
      "likes": 42463,
      "downloads": 42463,
      "lastModified": "2025-11-20T15:54:17Z",
      "lastModifiedTimestamp": 1763654057000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain-ai/langgraph",
          "homepage": "https://docs.langchain.com/oss/python/langgraph/",
          "language": "Python",
          "forks": 3741,
          "open_issues": 195,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
      "velocity": 23354.1,
      "is_rising_star": true,
      "heatScore": 7009.258893633863,
      "popularityScore": 21231
    },
    {
      "id": "github-ashishpatel26-500-AI-Agents-Projects",
      "name": "500-AI-Agents-Projects",
      "author": "ashishpatel26",
      "description": "The 500 AI Agents Projects is a curated collection of AI agent use cases across various industries. It showcases practical applications and provides links to open-source projects for implementation, illustrating how AI agents are transforming sectors such as healthcare, finance, education, retail, and more.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "genai"
      ],
      "likes": 32808,
      "downloads": 32808,
      "lastModified": "2025-11-20T15:54:02Z",
      "lastModifiedTimestamp": 1763654042000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ashishpatel26/500-AI-Agents-Projects",
          "homepage": "https://github.com/ashishpatel26/500-AI-Agents-Projects",
          "language": null,
          "forks": 3001,
          "open_issues": 19,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/3095771?v=4",
      "velocity": 18043.3,
      "is_rising_star": true,
      "heatScore": 5415.940464832431,
      "popularityScore": 16403
    },
    {
      "id": "github-mudler-LocalAI",
      "name": "LocalAI",
      "author": "mudler",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "likes": 77768,
      "downloads": 77768,
      "lastModified": "2025-11-20T15:54:00Z",
      "lastModifiedTimestamp": 1763654040000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mudler/LocalAI",
          "homepage": "https://localai.io",
          "language": "Go",
          "forks": 3085,
          "open_issues": 244,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/2420543?v=4",
      "velocity": 42771.3,
      "is_rising_star": true,
      "heatScore": 12834.602839654122,
      "popularityScore": 38883
    },
    {
      "id": "github-ggml-org-llama.cpp",
      "name": "llama.cpp",
      "author": "ggml-org",
      "description": "LLM inference in C/C++",
      "task": "tool",
      "tags": [
        "ggml"
      ],
      "likes": 180265,
      "downloads": 180265,
      "lastModified": "2025-11-20T15:53:48Z",
      "lastModifiedTimestamp": 1763654028000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ggml-org/llama.cpp",
          "homepage": "",
          "language": "C++",
          "forks": 13769,
          "open_issues": 893,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134263123?v=4",
      "velocity": 99145.2,
      "is_rising_star": true,
      "heatScore": 29747.0284186785,
      "popularityScore": 90132
    },
    {
      "id": "github-lobehub-lobe-chat",
      "name": "lobe-chat",
      "author": "lobehub",
      "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artifacts",
        "chat",
        "chatgpt",
        "claude",
        "deepseek",
        "deepseek-r1",
        "function-calling",
        "gemini",
        "gpt",
        "knowledge-base",
        "mcp",
        "nextjs",
        "ollama",
        "openai",
        "rag",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 135771,
      "downloads": 135771,
      "lastModified": "2025-11-20T15:53:45Z",
      "lastModifiedTimestamp": 1763654025000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/lobehub/lobe-chat",
          "homepage": "https://lobechat.com",
          "language": "TypeScript",
          "forks": 13999,
          "open_issues": 993,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
      "velocity": 74673.5,
      "is_rising_star": true,
      "heatScore": 22405.432246153854,
      "popularityScore": 67885
    },
    {
      "id": "github-bytedance-UI-TARS-desktop",
      "name": "UI-TARS-desktop",
      "author": "bytedance",
      "description": "The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra",
      "task": "tool",
      "tags": [
        "agent",
        "agent-tars",
        "browser-use",
        "computer-use",
        "gui-agent",
        "gui-operator",
        "mcp",
        "mcp-server",
        "multimodal",
        "tars",
        "ui-tars",
        "vision",
        "vlm"
      ],
      "likes": 39089,
      "downloads": 39089,
      "lastModified": "2025-11-20T15:53:40Z",
      "lastModifiedTimestamp": 1763654020000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/bytedance/UI-TARS-desktop",
          "homepage": "https://agent-tars.com",
          "language": "TypeScript",
          "forks": 1858,
          "open_issues": 304,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4158466?v=4",
      "velocity": 21498.4,
      "is_rising_star": true,
      "heatScore": 6452.523724972339,
      "popularityScore": 19544
    },
    {
      "id": "github-BloopAI-vibe-kanban",
      "name": "vibe-kanban",
      "author": "BloopAI",
      "description": "Kanban board to manage your AI coding agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai-agents",
        "kanban",
        "management",
        "task-manager",
        "code-generation-assistance"
      ],
      "likes": 11958,
      "downloads": 11958,
      "lastModified": "2025-11-20T15:53:40Z",
      "lastModifiedTimestamp": 1763654020000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/BloopAI/vibe-kanban",
          "homepage": "https://www.vibekanban.com/",
          "language": "Rust",
          "forks": 599,
          "open_issues": 98,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/75376775?v=4",
      "velocity": 6576.9,
      "is_rising_star": true,
      "heatScore": 1975.7136908287916,
      "popularityScore": 5979
    },
    {
      "id": "github-666ghj-BettaFish",
      "name": "BettaFish",
      "author": "666ghj",
      "description": "ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ",
      "task": "tool",
      "tags": [
        "agent-framework",
        "data-analysis",
        "deep-research",
        "deep-search",
        "llms",
        "multi-agent-system",
        "nlp",
        "public-opinion-analysis",
        "python3",
        "sentiment-analysis",
        "data-analysis-insights"
      ],
      "likes": 57118,
      "downloads": 57118,
      "lastModified": "2025-11-20T15:53:38Z",
      "lastModifiedTimestamp": 1763654018000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/666ghj/BettaFish",
          "homepage": "",
          "language": "Python",
          "forks": 5502,
          "open_issues": 69,
          "license": "GNU General Public License v2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110395318?v=4",
      "velocity": 31413.8,
      "is_rising_star": true,
      "heatScore": 9427.259020097514,
      "popularityScore": 28558
    },
    {
      "id": "github-bytedance-deer-flow",
      "name": "deer-flow",
      "author": "bytedance",
      "description": "DeerFlow is a community-driven Deep Research framework, combining language models with tools like web search, crawling, and Python execution, while contributing back to the open-source community.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "ai-agents",
        "bytedance",
        "deep-research",
        "langchain",
        "langgraph",
        "langmanus",
        "llm",
        "multi-agent",
        "nodejs",
        "podcast",
        "python",
        "typescript"
      ],
      "likes": 36383,
      "downloads": 36383,
      "lastModified": "2025-11-20T15:53:32Z",
      "lastModifiedTimestamp": 1763654012000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/bytedance/deer-flow",
          "homepage": "https://deerflow.tech",
          "language": "Python",
          "forks": 2270,
          "open_issues": 222,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4158466?v=4",
      "velocity": 20010.1,
      "is_rising_star": true,
      "heatScore": 6006.01191631314,
      "popularityScore": 18191
    },
    {
      "id": "github-GoogleCloudPlatform-generative-ai",
      "name": "generative-ai",
      "author": "GoogleCloudPlatform",
      "description": "Sample code and notebooks for Generative AI on Google Cloud, with Gemini on Vertex AI",
      "task": "tool",
      "tags": [
        "agents",
        "gcp",
        "gemini",
        "gemini-api",
        "gen-ai",
        "generative-ai",
        "google",
        "google-cloud",
        "google-gemini",
        "langchain",
        "large-language-models",
        "llm",
        "vertex-ai",
        "vertex-ai-gemini-api",
        "vertexai",
        "code-generation-assistance"
      ],
      "likes": 24156,
      "downloads": 24156,
      "lastModified": "2025-11-20T15:53:31Z",
      "lastModifiedTimestamp": 1763654011000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/GoogleCloudPlatform/generative-ai",
          "homepage": "https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview",
          "language": "Jupyter Notebook",
          "forks": 3527,
          "open_issues": 57,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/2810941?v=4",
      "velocity": 13285.8,
      "is_rising_star": true,
      "heatScore": 3988.5974216868867,
      "popularityScore": 12078
    },
    {
      "id": "github-ansible-ansible",
      "name": "ansible",
      "author": "ansible",
      "description": "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",
      "task": "tool",
      "tags": [
        "ansible",
        "python",
        "code-generation-assistance"
      ],
      "likes": 134117,
      "downloads": 134117,
      "lastModified": "2025-11-20T15:53:03Z",
      "lastModifiedTimestamp": 1763653983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ansible/ansible",
          "homepage": "https://www.ansible.com/",
          "language": "Python",
          "forks": 24129,
          "open_issues": 878,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1507452?v=4",
      "velocity": 73763.8,
      "is_rising_star": true,
      "heatScore": 22132.518519950987,
      "popularityScore": 67058
    },
    {
      "id": "github-mlabonne-llm-course",
      "name": "llm-course",
      "author": "mlabonne",
      "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
      "task": "tool",
      "tags": [
        "course",
        "large-language-models",
        "llm",
        "machine-learning",
        "roadmap"
      ],
      "likes": 135657,
      "downloads": 135657,
      "lastModified": "2025-11-20T15:52:59Z",
      "lastModifiedTimestamp": 1763653979000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mlabonne/llm-course",
          "homepage": "https://mlabonne.github.io/blog/",
          "language": null,
          "forks": 7688,
          "open_issues": 76,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/81252890?v=4",
      "velocity": 74610.8,
      "is_rising_star": true,
      "heatScore": 22386.62199079003,
      "popularityScore": 67828
    },
    {
      "id": "github-usestrix-strix",
      "name": "strix",
      "author": "usestrix",
      "description": "Open-source AI agents for penetration testing",
      "task": "tool",
      "tags": [
        "agents",
        "artificial-intelligence",
        "cybersecurity",
        "generative-ai",
        "llm",
        "penetration-testing"
      ],
      "likes": 25533,
      "downloads": 25533,
      "lastModified": "2025-11-20T15:52:58Z",
      "lastModifiedTimestamp": 1763653978000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/usestrix/strix",
          "homepage": "https://usestrix.com/",
          "language": "Python",
          "forks": 1188,
          "open_issues": 29,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/187630752?v=4",
      "velocity": 14042.6,
      "is_rising_star": true,
      "heatScore": 4215.654262200867,
      "popularityScore": 12766
    },
    {
      "id": "github-firecrawl-firecrawl",
      "name": "firecrawl",
      "author": "firecrawl",
      "description": "üî• The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-crawler",
        "ai-scraping",
        "ai-search",
        "crawler",
        "data-extraction",
        "html-to-markdown",
        "llm",
        "markdown",
        "scraper",
        "scraping",
        "web-crawler",
        "web-data",
        "web-data-extraction",
        "web-scraper",
        "web-scraping",
        "web-search",
        "webscraping"
      ],
      "likes": 136343,
      "downloads": 136343,
      "lastModified": "2025-11-20T15:52:57Z",
      "lastModifiedTimestamp": 1763653977000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/firecrawl/firecrawl",
          "homepage": "https://firecrawl.dev",
          "language": "TypeScript",
          "forks": 5309,
          "open_issues": 134,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/135057108?v=4",
      "velocity": 74988.1,
      "is_rising_star": true,
      "heatScore": 22499.813524224726,
      "popularityScore": 68171
    },
    {
      "id": "github-Fosowl-agenticSeek",
      "name": "agenticSeek",
      "author": "Fosowl",
      "description": "Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "autonomous-agents",
        "deepseek-r1",
        "llm",
        "llm-agents",
        "voice-assistant",
        "code-generation-assistance"
      ],
      "likes": 47425,
      "downloads": 47425,
      "lastModified": "2025-11-20T15:52:39Z",
      "lastModifiedTimestamp": 1763653959000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Fosowl/agenticSeek",
          "homepage": "http://agenticseek.tech",
          "language": "Python",
          "forks": 2570,
          "open_issues": 36,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/49105846?v=4",
      "velocity": 26083.2,
      "is_rising_star": true,
      "heatScore": 7828.022490550911,
      "popularityScore": 23712
    },
    {
      "id": "github-block-goose",
      "name": "goose",
      "author": "block",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "task": "tool",
      "tags": [
        "hacktoberfest",
        "mcp",
        "code-generation-assistance"
      ],
      "likes": 44545,
      "downloads": 44545,
      "lastModified": "2025-11-20T15:52:39Z",
      "lastModifiedTimestamp": 1763653959000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/block/goose",
          "homepage": "https://block.github.io/goose/",
          "language": "Rust",
          "forks": 2022,
          "open_issues": 181,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/185116535?v=4",
      "velocity": 24499.2,
      "is_rising_star": true,
      "heatScore": 7352.803445101946,
      "popularityScore": 22272
    },
    {
      "id": "github-x1xhlol-system-prompts-and-models-of-ai-tools",
      "name": "system-prompts-and-models-of-ai-tools",
      "author": "x1xhlol",
      "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
      "task": "tool",
      "tags": [
        "ai",
        "bolt",
        "cluely",
        "copilot",
        "cursor",
        "cursorai",
        "devin",
        "github-copilot",
        "lovable",
        "open-source",
        "perplexity",
        "replit",
        "system-prompts",
        "trae",
        "trae-ai",
        "trae-ide",
        "v0",
        "vscode",
        "windsurf",
        "windsurf-ai",
        "code-generation-assistance"
      ],
      "likes": 193011,
      "downloads": 193011,
      "lastModified": "2025-11-20T15:52:37Z",
      "lastModifiedTimestamp": 1763653957000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
          "homepage": "",
          "language": null,
          "forks": 25948,
          "open_issues": 94,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/185671340?v=4",
      "velocity": 106155.5,
      "is_rising_star": true,
      "heatScore": 31850.139188020687,
      "popularityScore": 96505
    },
    {
      "id": "github-langfuse-langfuse",
      "name": "langfuse",
      "author": "langfuse",
      "description": "ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ",
      "task": "tool",
      "tags": [
        "analytics",
        "autogen",
        "evaluation",
        "langchain",
        "large-language-models",
        "llama-index",
        "llm",
        "llm-evaluation",
        "llm-observability",
        "llmops",
        "monitoring",
        "observability",
        "open-source",
        "openai",
        "playground",
        "prompt-engineering",
        "prompt-management",
        "self-hosted",
        "ycombinator",
        "data-analysis-insights"
      ],
      "likes": 36954,
      "downloads": 36954,
      "lastModified": "2025-11-20T15:52:33Z",
      "lastModifiedTimestamp": 1763653953000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langfuse/langfuse",
          "homepage": "https://langfuse.com/docs",
          "language": "TypeScript",
          "forks": 1788,
          "open_issues": 432,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134601687?v=4",
      "velocity": 20324.7,
      "is_rising_star": true,
      "heatScore": 6100.396658473941,
      "popularityScore": 18477
    },
    {
      "id": "github-google-gemini-gemini-cli",
      "name": "gemini-cli",
      "author": "google-gemini",
      "description": "An open-source AI agent that brings the power of Gemini directly into your terminal.",
      "task": "tool",
      "tags": [
        "gemini",
        "gemini-api"
      ],
      "likes": 167383,
      "downloads": 167383,
      "lastModified": "2025-11-20T15:52:04Z",
      "lastModifiedTimestamp": 1763653924000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/google-gemini/gemini-cli",
          "homepage": "https://geminicli.com",
          "language": "TypeScript",
          "forks": 9443,
          "open_issues": 3033,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/161781182?v=4",
      "velocity": 92060.1,
      "is_rising_star": true,
      "heatScore": 27621.47587876247,
      "popularityScore": 83691
    },
    {
      "id": "github-anthropics-claude-code",
      "name": "claude-code",
      "author": "anthropics",
      "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 85919,
      "downloads": 85919,
      "lastModified": "2025-11-20T15:52:02Z",
      "lastModifiedTimestamp": 1763653922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/anthropics/claude-code",
          "homepage": "https://code.claude.com/docs/en/overview",
          "language": "Shell",
          "forks": 2910,
          "open_issues": 5342,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/76263028?v=4",
      "velocity": 47254.9,
      "is_rising_star": true,
      "heatScore": 14179.713144990883,
      "popularityScore": 42959
    },
    {
      "id": "github-hsliuping-TradingAgents-CN",
      "name": "TradingAgents-CN",
      "author": "hsliuping",
      "description": "Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìLLMÁöÑ‰∏≠ÊñáÈáëËûç‰∫§ÊòìÊ°ÜÊû∂ - TradingAgents‰∏≠ÊñáÂ¢ûÂº∫Áâà",
      "task": "tool",
      "tags": [],
      "likes": 26107,
      "downloads": 26107,
      "lastModified": "2025-11-20T15:51:56Z",
      "lastModifiedTimestamp": 1763653916000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/hsliuping/TradingAgents-CN",
          "homepage": null,
          "language": "Python",
          "forks": 2818,
          "open_issues": 55,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128790537?v=4",
      "velocity": 14358.3,
      "is_rising_star": true,
      "heatScore": 4310.371020525852,
      "popularityScore": 13053
    },
    {
      "id": "github-poloclub-transformer-explainer",
      "name": "transformer-explainer",
      "author": "poloclub",
      "description": "Transformer Explained Visually: Learn How LLM Transformer Models Work with Interactive Visualization",
      "task": "tool",
      "tags": [
        "deep-learning",
        "generative-ai",
        "gpt",
        "langauge-model",
        "llm",
        "visualization",
        "data-analysis-insights"
      ],
      "likes": 11961,
      "downloads": 11961,
      "lastModified": "2025-11-20T15:51:53Z",
      "lastModifiedTimestamp": 1763653913000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/poloclub/transformer-explainer",
          "homepage": "https://poloclub.github.io/transformer-explainer/",
          "language": "JavaScript",
          "forks": 632,
          "open_issues": 20,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/19315506?v=4",
      "velocity": 6578,
      "is_rising_star": true,
      "heatScore": 1976.0437416616883,
      "popularityScore": 5980
    },
    {
      "id": "github-Shubhamsaboo-awesome-llm-apps",
      "name": "awesome-llm-apps",
      "author": "Shubhamsaboo",
      "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
      "task": "tool",
      "tags": [
        "llms",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 158413,
      "downloads": 158413,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
          "homepage": "https://www.theunwindai.com",
          "language": "Python",
          "forks": 10579,
          "open_issues": 3,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/31396011?v=4",
      "velocity": 87126.6,
      "is_rising_star": true,
      "heatScore": 26141.409134495156,
      "popularityScore": 79206
    },
    {
      "id": "github-songquanpeng-one-api",
      "name": "one-api",
      "author": "songquanpeng",
      "description": "LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.",
      "task": "tool",
      "tags": [
        "api",
        "api-gateway",
        "azure-openai-api",
        "chatgpt",
        "claude",
        "ernie-bot",
        "gemini",
        "gpt",
        "openai",
        "openai-api",
        "proxy",
        "general-dialogue-qa"
      ],
      "likes": 56137,
      "downloads": 56137,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/songquanpeng/one-api",
          "homepage": "https://openai.justsong.cn/",
          "language": "JavaScript",
          "forks": 5528,
          "open_issues": 969,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/39998050?v=4",
      "velocity": 30874.8,
      "is_rising_star": true,
      "heatScore": 9265.553758858363,
      "popularityScore": 28068
    },
    {
      "id": "github-ollama-ollama",
      "name": "ollama",
      "author": "ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "task": "tool",
      "tags": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "likes": 312577,
      "downloads": 312577,
      "lastModified": "2025-11-20T15:51:00Z",
      "lastModifiedTimestamp": 1763653860000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ollama/ollama",
          "homepage": "https://ollama.com",
          "language": "Go",
          "forks": 13697,
          "open_issues": 2258,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/151674099?v=4",
      "velocity": 171916.8,
      "is_rising_star": true,
      "heatScore": 51578.675749888665,
      "popularityScore": 156288
    },
    {
      "id": "github-langchain4j-langchain4j",
      "name": "langchain4j",
      "author": "langchain4j",
      "description": "LangChain4j is an open-source Java library that simplifies the integration of LLMs into Java applications through a unified API, providing access to popular LLMs and vector databases. It makes implementing RAG, tool calling (including support for MCP), and agents easy. LangChain4j integrates seamlessly with various enterprise Java frameworks.",
      "task": "tool",
      "tags": [
        "anthropic",
        "chatgpt",
        "chroma",
        "embeddings",
        "gemini",
        "gpt",
        "huggingface",
        "java",
        "langchain",
        "llama",
        "llm",
        "llms",
        "milvus",
        "ollama",
        "onnx",
        "openai",
        "openai-api",
        "pgvector",
        "pinecone",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 19364,
      "downloads": 19364,
      "lastModified": "2025-11-20T15:51:00Z",
      "lastModifiedTimestamp": 1763653860000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain4j/langchain4j",
          "homepage": "https://docs.langchain4j.dev",
          "language": "Java",
          "forks": 1764,
          "open_issues": 631,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/132277850?v=4",
      "velocity": 10650.2,
      "is_rising_star": true,
      "heatScore": 3197.8502069522974,
      "popularityScore": 9682
    },
    {
      "id": "github-ValueCell-ai-valuecell",
      "name": "valuecell",
      "author": "ValueCell-ai",
      "description": "ValueCell is a community-driven, multi-agent platform for financial applications.",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "assitant",
        "crypto",
        "equity",
        "finance",
        "investment",
        "mcp",
        "python",
        "react",
        "stock-market"
      ],
      "likes": 12881,
      "downloads": 12881,
      "lastModified": "2025-11-20T15:50:46Z",
      "lastModifiedTimestamp": 1763653846000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ValueCell-ai/valuecell",
          "homepage": "https://valuecell.ai",
          "language": "Python",
          "forks": 1099,
          "open_issues": 22,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/234340495?v=4",
      "velocity": 7084,
      "is_rising_star": true,
      "heatScore": 2127.866267309409,
      "popularityScore": 6440
    },
    {
      "id": "github-ray-project-ray",
      "name": "ray",
      "author": "ray-project",
      "description": "Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.",
      "task": "tool",
      "tags": [
        "data-science",
        "deep-learning",
        "deployment",
        "distributed",
        "hyperparameter-optimization",
        "hyperparameter-search",
        "large-language-models",
        "llm",
        "llm-inference",
        "llm-serving",
        "machine-learning",
        "optimization",
        "parallel",
        "python",
        "pytorch",
        "ray",
        "reinforcement-learning",
        "rllib",
        "serving",
        "tensorflow"
      ],
      "likes": 79862,
      "downloads": 79862,
      "lastModified": "2025-11-20T15:50:42Z",
      "lastModifiedTimestamp": 1763653842000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ray-project/ray",
          "homepage": "https://ray.io",
          "language": "Python",
          "forks": 6924,
          "open_issues": 3226,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/22125274?v=4",
      "velocity": 43923,
      "is_rising_star": true,
      "heatScore": 13180.120917130518,
      "popularityScore": 39930
    },
    {
      "id": "github-microsoft-qlib",
      "name": "qlib",
      "author": "microsoft",
      "description": "Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.",
      "task": "tool",
      "tags": [
        "algorithmic-trading",
        "auto-quant",
        "deep-learning",
        "finance",
        "fintech",
        "investment",
        "machine-learning",
        "paper",
        "platform",
        "python",
        "quant",
        "quant-dataset",
        "quant-models",
        "quantitative-finance",
        "quantitative-trading",
        "research",
        "research-paper",
        "stock-data"
      ],
      "likes": 67791,
      "downloads": 67791,
      "lastModified": "2025-11-20T15:50:29Z",
      "lastModifiedTimestamp": 1763653829000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/qlib",
          "homepage": "https://qlib.readthedocs.io/en/latest/",
          "language": "Python",
          "forks": 5248,
          "open_issues": 306,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 37284.5,
      "is_rising_star": true,
      "heatScore": 11188.521103915695,
      "popularityScore": 33895
    },
    {
      "id": "github-prowler-cloud-prowler",
      "name": "prowler",
      "author": "prowler-cloud",
      "description": "Prowler is the Open Cloud Security for AWS, Azure, GCP, Kubernetes, M365 and more. As agent-less, it helps for continuous monitoring, security assessments & audits, incident response, compliance, hardening and forensics readiness. Includes CIS, NIST 800, NIST CSF, CISA, FedRAMP, PCI-DSS, GDPR, HIPAA, FFIEC, SOC2, ENS and more",
      "task": "tool",
      "tags": [
        "aws",
        "azure",
        "cis-benchmark",
        "cloud",
        "cloudsecurity",
        "compliance",
        "cspm",
        "devsecops",
        "forensics",
        "gcp",
        "gdpr",
        "hacktoberfest",
        "hardening",
        "iam",
        "multi-cloud",
        "python",
        "security",
        "security-audit",
        "security-hardening",
        "security-tools"
      ],
      "likes": 24666,
      "downloads": 24666,
      "lastModified": "2025-11-20T15:50:22Z",
      "lastModifiedTimestamp": 1763653822000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/prowler-cloud/prowler",
          "homepage": "https://prowler.com",
          "language": "Python",
          "forks": 1853,
          "open_issues": 160,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/97106991?v=4",
      "velocity": 13566.3,
      "is_rising_star": true,
      "heatScore": 4072.753772760863,
      "popularityScore": 12333
    },
    {
      "id": "github-comet-ml-opik",
      "name": "opik",
      "author": "comet-ml",
      "description": "Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.",
      "task": "tool",
      "tags": [
        "evaluation",
        "hacktoberfest",
        "hacktoberfest2025",
        "langchain",
        "llama-index",
        "llm",
        "llm-evaluation",
        "llm-observability",
        "llmops",
        "open-source",
        "openai",
        "playground",
        "prompt-engineering",
        "rag-knowledge-base-qa"
      ],
      "likes": 31746,
      "downloads": 31746,
      "lastModified": "2025-11-20T15:50:16Z",
      "lastModifiedTimestamp": 1763653816000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/comet-ml/opik",
          "homepage": "https://www.comet.com/docs/opik/",
          "language": "Python",
          "forks": 1182,
          "open_issues": 138,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/31487821?v=4",
      "velocity": 17460.3,
      "is_rising_star": true,
      "heatScore": 5241.030480463178,
      "popularityScore": 15873
    },
    {
      "id": "github-airweave-ai-airweave",
      "name": "airweave",
      "author": "airweave-ai",
      "description": "Context retrieval for AI agents across apps and databases",
      "task": "tool",
      "tags": [
        "agents",
        "knowledge-graph",
        "llm",
        "llm-agent",
        "rag",
        "search",
        "search-agent",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 10470,
      "downloads": 10470,
      "lastModified": "2025-11-20T15:50:14Z",
      "lastModifiedTimestamp": 1763653814000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/airweave-ai/airweave",
          "homepage": "https://airweave.ai",
          "language": "Python",
          "forks": 622,
          "open_issues": 46,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192721200?v=4",
      "velocity": 5758.5,
      "is_rising_star": true,
      "heatScore": 1730.1532997465151,
      "popularityScore": 5235
    },
    {
      "id": "github-continuedev-continue",
      "name": "continue",
      "author": "continuedev",
      "description": "‚è© Ship faster with Continuous AI. Open-source CLI that can be used in TUI mode as a coding agent or Headless mode to run background agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "background-agents",
        "claude",
        "cli",
        "continuous-ai",
        "developer-tools",
        "gemini",
        "gpt",
        "hacktoberfest",
        "jetbrains",
        "llm",
        "open-source",
        "qwen",
        "vscode",
        "workflows",
        "code-generation-assistance"
      ],
      "likes": 59846,
      "downloads": 59846,
      "lastModified": "2025-11-20T15:50:10Z",
      "lastModifiedTimestamp": 1763653810000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/continuedev/continue",
          "homepage": "https://docs.continue.dev/",
          "language": "TypeScript",
          "forks": 3805,
          "open_issues": 667,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127876214?v=4",
      "velocity": 32915.3,
      "is_rising_star": true,
      "heatScore": 9877.72321375225,
      "popularityScore": 29923
    },
    {
      "id": "github-langchain-ai-langchain",
      "name": "langchain",
      "author": "langchain-ai",
      "description": "ü¶úüîó The platform for reliable agents.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "aiagentframework",
        "anthropic",
        "chatgpt",
        "enterprise",
        "framework",
        "gemini",
        "generative-ai",
        "langchain",
        "llm",
        "multiagent",
        "open-source",
        "openai",
        "pydantic",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 240248,
      "downloads": 240248,
      "lastModified": "2025-11-20T15:50:06Z",
      "lastModifiedTimestamp": 1763653806000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain-ai/langchain",
          "homepage": "https://docs.langchain.com/oss/python/langchain/",
          "language": "Python",
          "forks": 19786,
          "open_issues": 241,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
      "velocity": 132136.4,
      "is_rising_star": true,
      "heatScore": 39644.47574338047,
      "popularityScore": 120124
    },
    {
      "id": "github-langgenius-dify",
      "name": "dify",
      "author": "langgenius",
      "description": "Production-ready platform for agentic workflow development.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-ai",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "automation",
        "gemini",
        "genai",
        "gpt",
        "gpt-4",
        "llm",
        "low-code",
        "mcp",
        "nextjs",
        "no-code",
        "openai",
        "orchestration",
        "python",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 238804,
      "downloads": 238804,
      "lastModified": "2025-11-20T15:50:01Z",
      "lastModifiedTimestamp": 1763653801000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langgenius/dify",
          "homepage": "https://dify.ai",
          "language": "TypeScript",
          "forks": 18511,
          "open_issues": 682,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127165244?v=4",
      "velocity": 131342.2,
      "is_rising_star": true,
      "heatScore": 39406.21391066701,
      "popularityScore": 119402
    },
    {
      "id": "github-harry0703-MoneyPrinterTurbo",
      "name": "MoneyPrinterTurbo",
      "author": "harry0703",
      "description": "Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.",
      "task": "tool",
      "tags": [
        "ai",
        "automation",
        "chatgpt",
        "moviepy",
        "python",
        "shortvideo",
        "tiktok"
      ],
      "likes": 95706,
      "downloads": 95706,
      "lastModified": "2025-11-20T15:49:59Z",
      "lastModifiedTimestamp": 1763653799000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/harry0703/MoneyPrinterTurbo",
          "homepage": "",
          "language": "Python",
          "forks": 6701,
          "open_issues": 218,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4928832?v=4",
      "velocity": 52638.3,
      "is_rising_star": true,
      "heatScore": 15794.765942771677,
      "popularityScore": 47853
    },
    {
      "id": "github-QuantumNous-new-api",
      "name": "new-api",
      "author": "QuantumNous",
      "description": "AIÊ®°ÂûãËÅöÂêàÁÆ°ÁêÜ‰∏≠ËΩ¨ÂàÜÂèëÁ≥ªÁªüÔºå‰∏Ä‰∏™Â∫îÁî®ÁÆ°ÁêÜÊÇ®ÁöÑÊâÄÊúâAIÊ®°ÂûãÔºåÊîØÊåÅÂ∞ÜÂ§öÁßçÂ§ßÊ®°ÂûãËΩ¨‰∏∫Áªü‰∏ÄÊ†ºÂºèË∞ÉÁî®ÔºåÊîØÊåÅOpenAI„ÄÅClaude„ÄÅGeminiÁ≠âÊ†ºÂºèÔºåÂèØ‰æõ‰∏™‰∫∫ÊàñËÄÖ‰ºÅ‰∏öÂÜÖÈÉ®ÁÆ°ÁêÜ‰∏éÂàÜÂèëÊ∏†ÈÅì‰ΩøÁî®„ÄÇüç• The next-generation LLM gateway and AI asset management system supports multiple languages.",
      "task": "tool",
      "tags": [
        "ai-gateway",
        "claude",
        "deepseek",
        "gemini",
        "openai",
        "rerank"
      ],
      "likes": 25140,
      "downloads": 25140,
      "lastModified": "2025-11-20T15:49:52Z",
      "lastModifiedTimestamp": 1763653792000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/QuantumNous/new-api",
          "homepage": "https://www.newapi.ai",
          "language": "JavaScript",
          "forks": 2425,
          "open_issues": 464,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/205075698?v=4",
      "velocity": 13827,
      "is_rising_star": true,
      "heatScore": 4150.9695588784725,
      "popularityScore": 12570
    },
    {
      "id": "github-warpdotdev-Warp",
      "name": "Warp",
      "author": "warpdotdev",
      "description": "Warp is the agentic development environment, built for coding with multiple AI agents.",
      "task": "tool",
      "tags": [
        "bash",
        "linux",
        "macos",
        "rust",
        "shell",
        "terminal",
        "wasm",
        "zsh",
        "code-generation-assistance"
      ],
      "likes": 50620,
      "downloads": 50620,
      "lastModified": "2025-11-20T15:49:51Z",
      "lastModifiedTimestamp": 1763653791000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/warpdotdev/Warp",
          "homepage": "https://warp.dev",
          "language": null,
          "forks": 581,
          "open_issues": 3958,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/71840468?v=4",
      "velocity": 27841,
      "is_rising_star": true,
      "heatScore": 8355.382316512678,
      "popularityScore": 25310
    },
    {
      "id": "github-lyogavin-airllm",
      "name": "airllm",
      "author": "lyogavin",
      "description": "AirLLM 70B inference with single 4GB GPU",
      "task": "tool",
      "tags": [
        "chinese-llm",
        "chinese-nlp",
        "finetune",
        "generative-ai",
        "instruct-gpt",
        "instruction-set",
        "llama",
        "llm",
        "lora",
        "open-models",
        "open-source",
        "open-source-models",
        "qlora"
      ],
      "likes": 12758,
      "downloads": 12758,
      "lastModified": "2025-11-20T15:49:46Z",
      "lastModifiedTimestamp": 1763653786000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/lyogavin/airllm",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 503,
          "open_issues": 115,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1113905?v=4",
      "velocity": 7016.9,
      "is_rising_star": true,
      "heatScore": 2107.7333744751045,
      "popularityScore": 6379
    },
    {
      "id": "github-RooCodeInc-Roo-Code",
      "name": "Roo-Code",
      "author": "RooCodeInc",
      "description": "Roo Code gives you a whole dev team of AI agents in your code editor.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 41768,
      "downloads": 41768,
      "lastModified": "2025-11-20T15:49:45Z",
      "lastModifiedTimestamp": 1763653785000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/RooCodeInc/Roo-Code",
          "homepage": "https://roocode.com",
          "language": "TypeScript",
          "forks": 2534,
          "open_issues": 377,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/211522643?v=4",
      "velocity": 22972.4,
      "is_rising_star": true,
      "heatScore": 6894.743884135721,
      "popularityScore": 20884
    },
    {
      "id": "github-OpenCSGs-csghub",
      "name": "csghub",
      "author": "OpenCSGs",
      "description": "CSGHub is a brand-new open-source platform for managing LLMs, developed by the OpenCSG team. It offers both open-source and on-premise/SaaS solutions, with features comparable to Hugging Face. Gain full control over the lifecycle of LLMs, datasets, and agents, with Python SDK compatibility with Hugging Face. Join us! ‚≠êÔ∏è",
      "task": "tool",
      "tags": [
        "ai",
        "asset-management",
        "dataset",
        "deepseek",
        "deploy",
        "finetune",
        "git",
        "huggingface",
        "inference",
        "llm",
        "management-system",
        "model",
        "platform",
        "prompt",
        "ray",
        "space"
      ],
      "likes": 11490,
      "downloads": 11490,
      "lastModified": "2025-11-20T15:49:39Z",
      "lastModifiedTimestamp": 1763653779000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenCSGs/csghub",
          "homepage": "https://opencsg.com",
          "language": "Vue",
          "forks": 708,
          "open_issues": 75,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/153507210?v=4",
      "velocity": 6319.5,
      "is_rising_star": true,
      "heatScore": 1898.4815559351591,
      "popularityScore": 5745
    },
    {
      "id": "github-danny-avila-LibreChat",
      "name": "LibreChat",
      "author": "danny-avila",
      "description": "Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "artifacts",
        "aws",
        "azure",
        "chatgpt",
        "chatgpt-clone",
        "claude",
        "clone",
        "deepseek",
        "gemini",
        "google",
        "gpt-5",
        "librechat",
        "mcp",
        "o1",
        "openai",
        "responses-api",
        "vision",
        "webui",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 63636,
      "downloads": 63636,
      "lastModified": "2025-11-20T15:49:34Z",
      "lastModifiedTimestamp": 1763653774000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/danny-avila/LibreChat",
          "homepage": "https://librechat.ai/",
          "language": "TypeScript",
          "forks": 6245,
          "open_issues": 354,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110412045?v=4",
      "velocity": 34999.8,
      "is_rising_star": true,
      "heatScore": 10503.091880568634,
      "popularityScore": 31818
    },
    {
      "id": "github-confident-ai-deepeval",
      "name": "deepeval",
      "author": "confident-ai",
      "description": "The LLM Evaluation Framework",
      "task": "tool",
      "tags": [
        "evaluation-framework",
        "evaluation-metrics",
        "hacktoberfest",
        "llm-evaluation",
        "llm-evaluation-framework",
        "llm-evaluation-metrics",
        "python"
      ],
      "likes": 24514,
      "downloads": 24514,
      "lastModified": "2025-11-20T15:49:27Z",
      "lastModifiedTimestamp": 1763653767000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/confident-ai/deepeval",
          "homepage": "https://deepeval.com",
          "language": "Python",
          "forks": 1079,
          "open_issues": 223,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/130858411?v=4",
      "velocity": 13482.7,
      "is_rising_star": true,
      "heatScore": 4047.671893731911,
      "popularityScore": 12257
    },
    {
      "id": "github-sigoden-aichat",
      "name": "aichat",
      "author": "sigoden",
      "description": "All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI Tools & Agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "chatbot",
        "claude",
        "cli",
        "function-calling",
        "gemini",
        "llm",
        "ollama",
        "openai",
        "rag",
        "rust",
        "shell",
        "webui",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 17280,
      "downloads": 17280,
      "lastModified": "2025-11-20T15:49:04Z",
      "lastModifiedTimestamp": 1763653744000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sigoden/aichat",
          "homepage": "",
          "language": "Rust",
          "forks": 563,
          "open_issues": 19,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4012553?v=4",
      "velocity": 9504,
      "is_rising_star": true,
      "heatScore": 2853.9555948035945,
      "popularityScore": 8640
    },
    {
      "id": "github-influxdata-telegraf",
      "name": "telegraf",
      "author": "influxdata",
      "description": "Agent for collecting, processing, aggregating, and writing metrics, logs, and other arbitrary data.",
      "task": "tool",
      "tags": [
        "gnmi",
        "golang",
        "hacktoberfest",
        "influxdb",
        "json",
        "kafka",
        "logs",
        "metrics",
        "modbus",
        "monitoring",
        "mqtt",
        "opcua",
        "telegraf",
        "time-series",
        "windows-eventlog",
        "windows-management-instrumentation",
        "xpath"
      ],
      "likes": 32998,
      "downloads": 32998,
      "lastModified": "2025-11-20T15:48:52Z",
      "lastModifiedTimestamp": 1763653732000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/influxdata/telegraf",
          "homepage": "https://influxdata.com/telegraf",
          "language": "Go",
          "forks": 5744,
          "open_issues": 416,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/5713248?v=4",
      "velocity": 18148.9,
      "is_rising_star": true,
      "heatScore": 5447.62223876095,
      "popularityScore": 16499
    },
    {
      "id": "github-datawhalechina-self-llm",
      "name": "self-llm",
      "author": "datawhalechina",
      "description": "„ÄäÂºÄÊ∫êÂ§ßÊ®°ÂûãÈ£üÁî®ÊåáÂçó„ÄãÈíàÂØπ‰∏≠ÂõΩÂÆùÂÆùÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫‰∫éLinuxÁéØÂ¢ÉÂø´ÈÄüÂæÆË∞ÉÔºàÂÖ®ÂèÇÊï∞/LoraÔºâ„ÄÅÈÉ®ÁΩ≤ÂõΩÂÜÖÂ§ñÂºÄÊ∫êÂ§ßÊ®°ÂûãÔºàLLMÔºâ/Â§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÔºàMLLMÔºâÊïôÁ®ã",
      "task": "tool",
      "tags": [
        "chatglm",
        "chatglm3",
        "gemma-2b-it",
        "glm-4",
        "internlm2",
        "llama3",
        "llm",
        "lora",
        "minicpm",
        "q-wen",
        "qwen",
        "qwen1-5",
        "qwen2"
      ],
      "likes": 52152,
      "downloads": 52152,
      "lastModified": "2025-11-20T15:48:41Z",
      "lastModifiedTimestamp": 1763653721000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/datawhalechina/self-llm",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2629,
          "open_issues": 147,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/46047812?v=4",
      "velocity": 28683.6,
      "is_rising_star": true,
      "heatScore": 8608.1713803389,
      "popularityScore": 26076
    },
    {
      "id": "github-pydantic-pydantic-ai",
      "name": "pydantic-ai",
      "author": "pydantic",
      "description": "GenAI Agent Framework, the Pydantic way",
      "task": "tool",
      "tags": [
        "agent-framework",
        "genai",
        "llm",
        "pydantic",
        "python"
      ],
      "likes": 26910,
      "downloads": 26910,
      "lastModified": "2025-11-20T15:48:37Z",
      "lastModifiedTimestamp": 1763653717000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pydantic/pydantic-ai",
          "homepage": "https://ai.pydantic.dev",
          "language": "Python",
          "forks": 1412,
          "open_issues": 365,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110818415?v=4",
      "velocity": 14800.5,
      "is_rising_star": true,
      "heatScore": 4443.040241184917,
      "popularityScore": 13455
    },
    {
      "id": "github-github-copilot-cli",
      "name": "copilot-cli",
      "author": "github",
      "description": "GitHub Copilot CLI brings the power of Copilot coding agent directly to your terminal. ",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 10692,
      "downloads": 10692,
      "lastModified": "2025-11-20T15:48:27Z",
      "lastModifiedTimestamp": 1763653707000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/github/copilot-cli",
          "homepage": "",
          "language": null,
          "forks": 494,
          "open_issues": 317,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/9919?v=4",
      "velocity": 5880.6,
      "is_rising_star": true,
      "heatScore": 1766.7896771288704,
      "popularityScore": 5346
    },
    {
      "id": "github-run-llama-llama_index",
      "name": "llama_index",
      "author": "run-llama",
      "description": "LlamaIndex is the leading framework for building LLM-powered agents over your data.",
      "task": "tool",
      "tags": [
        "agents",
        "application",
        "data",
        "fine-tuning",
        "framework",
        "llamaindex",
        "llm",
        "multi-agents",
        "rag",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 90664,
      "downloads": 90664,
      "lastModified": "2025-11-20T15:48:18Z",
      "lastModifiedTimestamp": 1763653698000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/run-llama/llama_index",
          "homepage": "https://developers.llamaindex.ai",
          "language": "Python",
          "forks": 6534,
          "open_issues": 268,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/130722866?v=4",
      "velocity": 49865.2,
      "is_rising_star": true,
      "heatScore": 14962.819490122205,
      "popularityScore": 45332
    },
    {
      "id": "github-ChromeDevTools-chrome-devtools-mcp",
      "name": "chrome-devtools-mcp",
      "author": "ChromeDevTools",
      "description": "Chrome DevTools for coding agents",
      "task": "tool",
      "tags": [
        "browser",
        "chrome",
        "chrome-devtools",
        "debugging",
        "devtools",
        "mcp",
        "mcp-server",
        "puppeteer",
        "code-generation-assistance"
      ],
      "likes": 29996,
      "downloads": 29996,
      "lastModified": "2025-11-20T15:48:18Z",
      "lastModifiedTimestamp": 1763653698000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ChromeDevTools/chrome-devtools-mcp",
          "homepage": "https://npmjs.org/package/chrome-devtools-mcp",
          "language": "TypeScript",
          "forks": 921,
          "open_issues": 60,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/11260967?v=4",
      "velocity": 16497.8,
      "is_rising_star": true,
      "heatScore": 4952.263243613586,
      "popularityScore": 14998
    },
    {
      "id": "github-huggingface-datasets",
      "name": "datasets",
      "author": "huggingface",
      "description": "ü§ó The largest hub of ready-to-use datasets for AI models with fast, easy-to-use and efficient data manipulation tools",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "computer-vision",
        "dataset-hub",
        "datasets",
        "deep-learning",
        "huggingface",
        "llm",
        "machine-learning",
        "natural-language-processing",
        "nlp",
        "numpy",
        "pandas",
        "pytorch",
        "speech",
        "tensorflow",
        "data-analysis-insights"
      ],
      "likes": 41758,
      "downloads": 41758,
      "lastModified": "2025-11-20T15:47:47Z",
      "lastModifiedTimestamp": 1763653667000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/datasets",
          "homepage": "https://huggingface.co/docs/datasets",
          "language": "Python",
          "forks": 3014,
          "open_issues": 994,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 22966.9,
      "is_rising_star": true,
      "heatScore": 6893.0938113460315,
      "popularityScore": 20879
    },
    {
      "id": "github-kyegomez-swarms",
      "name": "swarms",
      "author": "kyegomez",
      "description": "The Enterprise-Grade Production-Ready Multi-Agent Orchestration Framework. Website: https://swarms.ai",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-workflow",
        "agents",
        "ai",
        "artificial-intelligence",
        "chatgpt",
        "gpt4",
        "gpt4all",
        "huggingface",
        "langchain",
        "langchain-python",
        "machine-learning",
        "multi-agent-systems",
        "prompt-engineering",
        "prompt-toolkit",
        "prompting",
        "swarms",
        "tree-of-thoughts"
      ],
      "likes": 10850,
      "downloads": 10850,
      "lastModified": "2025-11-20T15:47:39Z",
      "lastModifiedTimestamp": 1763653659000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/kyegomez/swarms",
          "homepage": "https://docs.swarms.world",
          "language": "Python",
          "forks": 681,
          "open_issues": 62,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/98760976?v=4",
      "velocity": 5967.5,
      "is_rising_star": true,
      "heatScore": 1792.8641358525979,
      "popularityScore": 5425
    },
    {
      "id": "github-FunAudioLLM-SenseVoice",
      "name": "SenseVoice",
      "author": "FunAudioLLM",
      "description": "Multilingual Voice Understanding Model",
      "task": "tool",
      "tags": [
        "ai",
        "aigc",
        "asr",
        "audio-event-classification",
        "cross-lingual",
        "gpt-4o",
        "llm",
        "multilingual",
        "python",
        "pytorch",
        "speech-emotion-recognition",
        "speech-recognition",
        "speech-to-text"
      ],
      "likes": 13972,
      "downloads": 13972,
      "lastModified": "2025-11-20T15:47:35Z",
      "lastModifiedTimestamp": 1763653655000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FunAudioLLM/SenseVoice",
          "homepage": "https://funaudiollm.github.io/",
          "language": "Python",
          "forks": 649,
          "open_issues": 162,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/167062371?v=4",
      "velocity": 7684.6,
      "is_rising_star": true,
      "heatScore": 2308.0710035202783,
      "popularityScore": 6986
    },
    {
      "id": "github-oraios-serena",
      "name": "serena",
      "author": "oraios",
      "description": "A powerful coding agent toolkit providing semantic retrieval and editing capabilities (MCP server & other integrations)",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "ai-coding",
        "claude",
        "claude-code",
        "language-server",
        "llms",
        "mcp-server",
        "programming",
        "vibe-coding",
        "code-generation-assistance"
      ],
      "likes": 32474,
      "downloads": 32474,
      "lastModified": "2025-11-20T15:47:32Z",
      "lastModifiedTimestamp": 1763653652000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/oraios/serena",
          "homepage": "https://oraios.github.io/serena",
          "language": "Python",
          "forks": 1105,
          "open_issues": 77,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/181485370?v=4",
      "velocity": 17860.7,
      "is_rising_star": true,
      "heatScore": 5361.157372775949,
      "popularityScore": 16237
    },
    {
      "id": "github-HKUDS-LightRAG",
      "name": "LightRAG",
      "author": "HKUDS",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "task": "tool",
      "tags": [
        "genai",
        "gpt",
        "gpt-4",
        "graphrag",
        "knowledge-graph",
        "large-language-models",
        "llm",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 47760,
      "downloads": 47760,
      "lastModified": "2025-11-20T15:47:31Z",
      "lastModifiedTimestamp": 1763653651000,
      "readme": "<div align=\"center\">\n\n<div style=\"margin: 20px 0;\">\n  <img src=\"./assets/logo.png\" width=\"120\" height=\"120\" alt=\"LightRAG Logo\" style=\"border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);\">\n</div>\n\n# üöÄ LightRAG: Simple and Fast Retrieval-Augmented Generation\n\n<div align=\"center\">\n    <a href=\"https://trendshift.io/repositories/13043\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13043\" alt=\"HKUDS%2FLightRAG | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);\"></div>\n</div>\n\n<div align=\"center\">\n  <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;\">\n    <p>\n      <a href='https://github.com/HKUDS/LightRAG'><img src='https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&logo=github&logoColor=white&labelColor=1a1a2e'></a>\n      <a href='https://arxiv.org/abs/2410.05779'><img src='https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&logo=arxiv&logoColor=white&labelColor=1a1a2e'></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/stargazers\"><img src='https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&style=for-the-badge&logo=star&logoColor=white&labelColor=1a1a2e' /></a>\n    </p>\n    <p>\n      <img src=\"https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&logo=python&logoColor=white&labelColor=1a1a2e\">\n      <a href=\"https://pypi.org/project/lightrag-hku/\"><img src=\"https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&logo=pypi&logoColor=white&labelColor=1a1a2e&color=ff6b6b\"></a>\n    </p>\n    <p>\n      <a href=\"https://discord.gg/yF2MmDJyGJ\"><img src=\"https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&logo=discord&logoColor=white&labelColor=1a1a2e\"></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/issues/285\"><img src=\"https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&logo=wechat&logoColor=white&labelColor=1a1a2e\"></a>\n    </p>\n    <p>\n      <a href=\"README-zh.md\"><img src=\"https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge\"></a>\n      <a href=\"README.md\"><img src=\"https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge\"></a>\n    </p>\n    <p>\n      <a href=\"https://pepy.tech/projects/lightrag-hku\"><img src=\"https://static.pepy.tech/personalized-badge/lightrag-hku?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=GREEN&left_text=downloads\"></a>\n    </p>\n  </div>\n</div>\n\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n  <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"800\">\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n    <img src=\"./README.assets/b2aaf634151b4706892693ffb43d9093.png\" width=\"800\" alt=\"LightRAG Diagram\">\n</div>\n\n---\n## üéâ News\n- [2025.11.05]üéØAdd **RAGAS-based** Evaluation Framework and **Langfuse** observability for LightRAG (API can return retrieved contexts with query results).\n- [2025.10.22]üéØEliminate bottlenecks in processing **large-scale datasets**.\n- [2025.09.15]üéØSignificantly enhances KG extraction accuracy for **small LLMs** like Qwen3-30B-A3B.\n- [2025.08.29]üéØ**Reranker** is supported now , significantly boosting performance for mixed queries(Set as default query mode now).\n- [2025.08.04]üéØ**Document deletion** with KG regeneration to ensure query performance.\n- [2025.06.16]üéØOur team has released [RAG-Anything](https://github.com/HKUDS/RAG-Anything) an All-in-One Multimodal RAG System for seamless text, image, table, and equation processing.\n- [2025.06.05]üéØLightRAG now supports comprehensive multimodal data handling through [RAG-Anything](https://github.com/HKUDS/RAG-Anything) integration, enabling seamless document parsing and RAG capabilities across diverse formats including PDFs, images, Office documents, tables, and formulas. Please refer to the new [multimodal section](https://github.com/HKUDS/LightRAG/?tab=readme-ov-file#multimodal-document-processing-rag-anything-integration) for details.\n- [2025.03.18]üéØLightRAG now supports citation functionality, enabling proper source attribution.\n- [2025.02.12]üéØYou can now use MongoDB as all in-one Storage.\n- [2025.02.05]üéØOur team has released [VideoRAG](https://github.com/HKUDS/VideoRAG) understanding extremely long-context videos.\n- [2025.01.13]üéØOur team has released [MiniRAG](https://github.com/HKUDS/MiniRAG) making RAG simpler with small models.\n- [2025.01.06]üéØYou can now use PostgreSQL as all in-one Storage.\n- [2024.11.19]üéØA comprehensive guide to LightRAG is now available on [LearnOpenCV](https://learnopencv.com/lightrag). Many thanks to the blog author.\n- [2024.11.09]üéØIntroducing the LightRAG Webui, which allows you to insert, query, visualize LightRAG knowledge.\n- [2024.11.04]üéØYou can now [use Neo4J for Storage](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage).\n- [2024.10.18]üéØWe've added a link to a [LightRAG Introduction Video](https://youtu.be/oageL-1I0GE). Thanks to the author!\n- [2024.10.17]üéØWe have created a [Discord channel](https://discord.gg/yF2MmDJyGJ)! Welcome to join for sharing and discussions! üéâüéâ\n- [2024.10.16]üéØLightRAG now supports [Ollama models](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start)!\n\n<details>\n  <summary style=\"font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;\">\n    Algorithm Flowchart\n  </summary>\n\n![LightRAG Indexing Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg)\n*Figure 1: LightRAG Indexing Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n![LightRAG Retrieval and Querying Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg)\n*Figure 2: LightRAG Retrieval and Querying Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n\n</details>\n\n## Installation\n\n> **üí° Using uv for Package Management**: This project uses [uv](https://docs.astral.sh/uv/) for fast and reliable Python package management.\n> Install uv first: `curl -LsSf https://astral.sh/uv/install.sh | sh` (Unix/macOS) or `powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"` (Windows)\n>\n> **Note**: You can also use pip if you prefer, but uv is recommended for better performance and more reliable dependency management.\n>\n> **üì¶ Offline Deployment**: For offline or air-gapped environments, see the [Offline Deployment Guide](./docs/OfflineDeployment.md) for instructions on pre-installing all dependencies and cache files.\n\n### Install LightRAG Server\n\nThe LightRAG Server is designed to provide Web UI and API support. The Web UI facilitates document indexing, knowledge graph exploration, and a simple RAG query interface. LightRAG Server also provide an Ollama compatible interfaces, aiming to emulate LightRAG as an Ollama chat model. This allows AI chat bot, such as Open WebUI, to access LightRAG easily.\n\n* Install from PyPI\n\n```bash\n# Using uv (recommended)\nuv pip install \"lightrag-hku[api]\"\n# Or using pip\n# pip install \"lightrag-hku[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\nlightrag-server\n```\n\n* Installation from Source\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\n\n# Using uv (recommended)\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync --extra api\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or using pip with virtual environment\n# python -m venv .venv\n# source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n# pip install -e \".[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\n# Build front-end artifacts\ncd lightrag_webui\nbun install --frozen-lockfile\nbun run build\ncd ..\n\nlightrag-server\n```\n\n* Launching the LightRAG Server with Docker Compose\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n# modify LLM and Embedding settings in .env\ndocker compose up\n```\n\n> Historical versions of LightRAG docker images can be found here: [LightRAG Docker Images]( https://github.com/HKUDS/LightRAG/pkgs/container/lightrag)\n\n### Install  LightRAG Core\n\n* Install from source (Recommended)\n\n```bash\ncd LightRAG\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or: pip install -e .\n```\n\n* Install from PyPI\n\n```bash\nuv pip install lightrag-hku\n# Or: pip install lightrag-hku\n```\n\n## Quick Start\n\n### LLM and Technology Stack Requirements for LightRAG\n\nLightRAG's demands on the capabilities of Large Language Models (LLMs) are significantly higher than those of traditional RAG, as it requires the LLM to perform entity-relationship extraction tasks from documents. Configuring appropriate Embedding and Reranker models is also crucial for improving query performance.\n\n- **LLM Selection**:\n  - It is recommended to use an LLM with at least 32 billion parameters.\n  - The context length should be at least 32KB, with 64KB being recommended.\n  - It is not recommended to choose reasoning models during the document indexing stage.\n  - During the query stage, it is recommended to choose models with stronger capabilities than those used in the indexing stage to achieve better query results.\n- **Embedding Model**:\n  - A high-performance Embedding model is essential for RAG.\n  - We recommend using mainstream multilingual Embedding models, such as: `BAAI/bge-m3` and `text-embedding-3-large`.\n  - **Important Note**: The Embedding model must be determined before document indexing, and the same model must be used during the document query phase. For certain storage solutions (e.g., PostgreSQL), the vector dimension must be defined upon initial table creation. Therefore, when changing embedding models, it is necessary to delete the existing vector-related tables and allow LightRAG to recreate them with the new dimensions.\n- **Reranker Model Configuration**:\n  - Configuring a Reranker model can significantly enhance LightRAG's retrieval performance.\n  - When a Reranker model is enabled, it is recommended to set the \"mix mode\" as the default query mode.\n  - We recommend using mainstream Reranker models, such as: `BAAI/bge-reranker-v2-m3` or models provided by services like Jina.\n\n### Quick Start for LightRAG Server\n\n* For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).\n\n### Quick Start for LightRAG core\n\nTo get started with LightRAG core, refer to the sample codes available in the `examples` folder. Additionally, a [video demo](https://www.youtube.com/watch?v=g21royNJ4fw) demonstration is provided to guide you through the local setup process. If you already possess an OpenAI API key, you can run the demo right away:\n\n```bash\n### you should run the demo code with project folder\ncd LightRAG\n### provide your API-KEY for OpenAI\nexport OPENAI_API_KEY=\"sk-...your_opeai_key...\"\n### download the demo document of \"A Christmas Carol\" by Charles Dickens\ncurl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt > ./book.txt\n### run the demo code\npython examples/lightrag_openai_demo.py\n```\n\nFor a streaming response implementation example, please see `examples/lightrag_openai_compatible_demo.py`. Prior to execution, ensure you modify the sample code's LLM and embedding configurations accordingly.\n\n**Note 1**: When running the demo program, please be aware that different test scripts may use different embedding models. If you switch to a different embedding model, you must clear the data directory (`./dickens`); otherwise, the program may encounter errors. If you wish to retain the LLM cache, you can preserve the `kv_store_llm_response_cache.json` file while clearing the data directory.\n\n**Note 2**: Only `lightrag_openai_demo.py` and `lightrag_openai_compatible_demo.py` are officially supported sample codes. Other sample files are community contributions that haven't undergone full testing and optimization.\n\n## Programing with LightRAG Core\n\n> ‚ö†Ô∏è **If you would like to integrate LightRAG into your project, we recommend utilizing the REST API provided by the LightRAG Server**. LightRAG Core is typically intended for embedded applications or for researchers who wish to conduct studies and evaluations.\n\n### ‚ö†Ô∏è Important: Initialization Requirements\n\n**LightRAG requires explicit initialization before use.** You must call `await rag.initialize_storages()` after creating a LightRAG instance, otherwise you will encounter errors.\n\n### A Simple Program\n\nUse the below Python snippet to initialize LightRAG, insert text to it, and perform queries:\n\n```python\nimport os\nimport asyncio\nfrom lightrag import LightRAG, QueryParam\nfrom lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed\nfrom lightrag.utils import setup_logger\n\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nWORKING_DIR = \"./rag_storage\"\nif not os.path.exists(WORKING_DIR):\n    os.mkdir(WORKING_DIR)\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        embedding_func=openai_embed,\n        llm_model_func=gpt_4o_mini_complete,\n    )\n    # IMPORTANT: Both initialization calls are required!\n    await rag.initialize_storages()  # Initialize storage backends    return rag\n\nasync def main():\n    try:\n        # Initialize RAG instance\n        rag = await initialize_rag()\n        await rag.ainsert(\"Your text\")\n\n        # Perform hybrid search\n        mode = \"hybrid\"\n        print(\n          await rag.aquery(\n              \"What are the top themes in this story?\",\n              param=QueryParam(mode=mode)\n          )\n        )\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        if rag:\n            await rag.finalize_storages()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nImportant notes for the above snippet:\n\n- Export your OPENAI_API_KEY environment variable before running the script.\n- This program uses the default storage settings for LightRAG, so all data will be persisted to WORKING_DIR/rag_storage.\n- This program demonstrates only the simplest way to initialize a LightRAG object: Injecting the embedding and LLM functions, and initializing storage and pipeline status after creating the LightRAG object.\n\n### LightRAG init parameters\n\nA full list of LightRAG init parameters:\n\n<details>\n<summary> Parameters </summary>\n\n| **Parameter** | **Type** | **Explanation** | **Default** |\n|--------------|----------|-----------------|-------------|\n| **working_dir** | `str` | Directory where the cache will be stored | `lightrag_cache+timestamp` |\n| **workspace** | str | Workspace name for data isolation between different LightRAG Instances |  |\n| **kv_storage** | `str` | Storage type for documents and text chunks. Supported types: `JsonKVStorage`,`PGKVStorage`,`RedisKVStorage`,`MongoKVStorage` | `JsonKVStorage` |\n| **vector_storage** | `str` | Storage type for embedding vectors. Supported types: `NanoVectorDBStorage`,`PGVectorStorage`,`MilvusVectorDBStorage`,`ChromaVectorDBStorage`,`FaissVectorDBStorage`,`MongoVectorDBStorage`,`QdrantVectorDBStorage` | `NanoVectorDBStorage` |\n| **graph_storage** | `str` | Storage type for graph edges and nodes. Supported types: `NetworkXStorage`,`Neo4JStorage`,`PGGraphStorage`,`AGEStorage` | `NetworkXStorage` |\n| **doc_status_storage** | `str` | Storage type for documents process status. Supported types: `JsonDocStatusStorage`,`PGDocStatusStorage`,`MongoDocStatusStorage` | `JsonDocStatusStorage` |\n| **chunk_token_size** | `int` | Maximum token size per chunk when splitting documents | `1200` |\n| **chunk_overlap_token_size** | `int` | Overlap token size between two chunks when splitting documents | `100` |\n| **tokenizer** | `Tokenizer` | The function used to convert text into tokens (numbers) and back using .encode() and .decode() functions following `TokenizerInterface` protocol. If you don't specify one, it will use the default Tiktoken tokenizer. | `TiktokenTokenizer` |\n| **tiktoken_model_name** | `str` | If you're using the default Tiktoken tokenizer, this is the name of the specific Tiktoken model to use. This setting is ignored if you provide your own tokenizer. | `gpt-4o-mini` |\n| **entity_extract_max_gleaning** | `int` | Number of loops in the entity extraction process, appending history messages | `1` |\n| **node_embedding_algorithm** | `str` | Algorithm for node embedding (currently not used) | `node2vec` |\n| **node2vec_params** | `dict` | Parameters for node embedding | `{\"dimensions\": 1536,\"num_walks\": 10,\"walk_length\": 40,\"window_size\": 2,\"iterations\": 3,\"random_seed\": 3,}` |\n| **embedding_func** | `EmbeddingFunc` | Function to generate embedding vectors from text | `openai_embed` |\n| **embedding_batch_num** | `int` | Maximum batch size for embedding processes (multiple texts sent per batch) | `32` |\n| **embedding_func_max_async** | `int` | Maximum number of concurrent asynchronous embedding processes | `16` |\n| **llm_model_func** | `callable` | Function for LLM generation | `gpt_4o_mini_complete` |\n| **llm_model_name** | `str` | LLM model name for generation | `meta-llama/Llama-3.2-1B-Instruct` |\n| **summary_context_size** | `int` | Maximum tokens send to LLM to generate summaries for entity relation merging | `10000`Ôºàconfigured by env var SUMMARY_CONTEXT_SIZE) |\n| **summary_max_tokens** | `int` | Maximum token size for entity/relation description | `500`Ôºàconfigured by env var SUMMARY_MAX_TOKENS) |\n| **llm_model_max_async** | `int` | Maximum number of concurrent asynchronous LLM processes | `4`Ôºàdefault value changed by env var MAX_ASYNC) |\n| **llm_model_kwargs** | `dict` | Additional parameters for LLM generation | |\n| **vector_db_storage_cls_kwargs** | `dict` | Additional parameters for vector database, like setting the threshold for nodes and relations retrieval | cosine_better_than_threshold: 0.2Ôºàdefault value changed by env var COSINE_THRESHOLD) |\n| **enable_llm_cache** | `bool` | If `TRUE`, stores LLM results in cache; repeated prompts return cached responses | `TRUE` |\n| **enable_llm_cache_for_entity_extract** | `bool` | If `TRUE`, stores LLM results in cache for entity extraction; Good for beginners to debug your application | `TRUE` |\n| **addon_params** | `dict` | Additional parameters, e.g., `{\"language\": \"Simplified Chinese\", \"entity_types\": [\"organization\", \"person\", \"location\", \"event\"]}`: sets example limit, entiy/relation extraction output language | language: English` |\n| **embedding_cache_config** | `dict` | Configuration for question-answer caching. Contains three parameters: `enabled`: Boolean value to enable/disable cache lookup functionality. When enabled, the system will check cached responses before generating new answers. `similarity_threshold`: Float value (0-1), similarity threshold. When a new question's similarity with a cached question exceeds this threshold, the cached answer will be returned directly without calling the LLM. `use_llm_check`: Boolean value to enable/disable LLM similarity verification. When enabled, LLM will be used as a secondary check to verify the similarity between questions before returning cached answers. | Default: `{\"enabled\": False, \"similarity_threshold\": 0.95, \"use_llm_check\": False}` |\n\n</details>\n\n### Query Param\n\nUse QueryParam to control the behavior your query:\n\n```python\nclass QueryParam:\n    \"\"\"Configuration parameters for query execution in LightRAG.\"\"\"\n\n    mode: Literal[\"local\", \"global\", \"hybrid\", \"naive\", \"mix\", \"bypass\"] = \"global\"\n    \"\"\"Specifies the retrieval mode:\n    - \"local\": Focuses on context-dependent information.\n    - \"global\": Utilizes global knowledge.\n    - \"hybrid\": Combines local and global retrieval methods.\n    - \"naive\": Performs a basic search without advanced techniques.\n    - \"mix\": Integrates knowledge graph and vector retrieval.\n    \"\"\"\n\n    only_need_context: bool = False\n    \"\"\"If True, only returns the retrieved context without generating a response.\"\"\"\n\n    only_need_prompt: bool = False\n    \"\"\"If True, only returns the generated prompt without producing a response.\"\"\"\n\n    response_type: str = \"Multiple Paragraphs\"\n    \"\"\"Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'.\"\"\"\n\n    stream: bool = False\n    \"\"\"If True, enables streaming output for real-time responses.\"\"\"\n\n    top_k: int = int(os.getenv(\"TOP_K\", \"60\"))\n    \"\"\"Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode.\"\"\"\n\n    chunk_top_k: int = int(os.getenv(\"CHUNK_TOP_K\", \"20\"))\n    \"\"\"Number of text chunks to retrieve initially from vector search and keep after reranking.\n    If None, defaults to top_k value.\n    \"\"\"\n\n    max_entity_tokens: int = int(os.getenv(\"MAX_ENTITY_TOKENS\", \"6000\"))\n    \"\"\"Maximum number of tokens allocated for entity context in unified token control system.\"\"\"\n\n    max_relation_tokens: int = int(os.getenv(\"MAX_RELATION_TOKENS\", \"8000\"))\n    \"\"\"Maximum number of tokens allocated for relationship context in unified token control system.\"\"\"\n\n    max_total_tokens: int = int(os.getenv(\"MAX_TOTAL_TOKENS\", \"30000\"))\n    \"\"\"Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt).\"\"\"\n\n    # History mesages is only send to LLM for context, not used for retrieval\n    conversation_history: list[dict[str, str]] = field(default_factory=list)\n    \"\"\"Stores past conversation history to maintain context.\n    Format: [{\"role\": \"user/assistant\", \"content\": \"message\"}].\n    \"\"\"\n\n    ids: list[str] | None = None\n    \"\"\"List of ids to filter the results.\"\"\"\n\n    model_func: Callable[..., object] | None = None\n    \"\"\"Optional override for the LLM model function to use for this specific query.\n    If provided, this will be used instead of the global model function.\n    This allows using different models for different query modes.\n    \"\"\"\n\n    user_prompt: str | None = None\n    \"\"\"User-provided prompt for the query.\n    Addition instructions for LLM. If provided, this will be inject into the prompt template.\n    It's purpose is the let user customize the way LLM generate the response.\n    \"\"\"\n\n    enable_rerank: bool = True\n    \"\"\"Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.\n    Default is True to enable reranking when rerank model is available.\n    \"\"\"\n```\n\n> default value of Top_k can be change by environment  variables  TOP_K.\n\n### LLM and Embedding Injection\n\nLightRAG requires the utilization of LLM and Embedding models to accomplish document indexing and querying tasks. During the initialization phase, it is necessary to inject the invocation methods of the relevant models into LightRAGÔºö\n\n<details>\n<summary> <b>Using Open AI-like APIs</b> </summary>\n\n* LightRAG also supports Open AI-like chat/embeddings APIs:\n\n```python\nasync def llm_model_func(\n    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n) -> str:\n    return await openai_complete_if_cache(\n        \"solar-mini\",\n        prompt,\n        system_prompt=system_prompt,\n        history_messages=history_messages,\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\",\n        **kwargs\n    )\n\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    return await openai_embed(\n        texts,\n        model=\"solar-embedding-1-large-query\",\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\"\n    )\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=llm_model_func,\n        embedding_func=EmbeddingFunc(\n            embedding_dim=4096,\n            func=embedding_func\n        )\n    )\n\n    await rag.initialize_storages()\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using Hugging Face Models</b> </summary>\n\n* If you want to use Hugging Face models, you only need to set LightRAG as follows:\n\nSee `lightrag_hf_demo.py`\n\n```python\n# Initialize LightRAG with Hugging Face model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=hf_model_complete,  # Use Hugging Face model for text generation\n    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face\n    # Use Hugging Face embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=lambda texts: hf_embed(\n            texts,\n            tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n            embed_model=AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n        )\n    ),\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Ollama Models</b> </summary>\n**Overview**\n\nIf you want to use Ollama models, you need to pull model you plan to use and embedding model, for example `nomic-embed-text`.\n\nThen you only need to set LightRAG as follows:\n\n```python\n# Initialize LightRAG with Ollama model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Increasing context size**\n\nIn order for LightRAG to work context should be at least 32k tokens. By default Ollama models have context size of 8k. You can achieve this using one of two ways:\n\n* **Increasing the `num_ctx` parameter in Modelfile**\n\n1. Pull the model:\n\n```bash\nollama pull qwen2\n```\n\n2. Display the model file:\n\n```bash\nollama show --modelfile qwen2 > Modelfile\n```\n\n3. Edit the Modelfile by adding the following line:\n\n```bash\nPARAMETER num_ctx 32768\n```\n\n4. Create the modified model:\n\n```bash\nollama create -f Modelfile qwen2m\n```\n\n* **Setup `num_ctx` via Ollama API**\n\nTiy can use `llm_model_kwargs` param to configure ollama:\n\n```python\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    llm_model_kwargs={\"options\": {\"num_ctx\": 32768}},\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Low RAM GPUs**\n\nIn order to run this experiment on low RAM GPU you should select small model and tune context window (increasing context increase memory consumption). For example, running this ollama example on repurposed mining GPU with 6Gb of RAM required to set context size to 26k while using `gemma2:2b`. It was able to find 197 entities and 19 relations on `book.txt`.\n\n</details>\n<details>\n<summary> <b>LlamaIndex</b> </summary>\n\nLightRAG supports integration with LlamaIndex (`llm/llama_index_impl.py`):\n\n- Integrates with OpenAI and other providers through LlamaIndex\n- See [LlamaIndex Documentation](lightrag/llm/Readme.md) for detailed setup and examples\n\n**Example Usage**\n\n```python\n# Using LlamaIndex with direct OpenAI access\nimport asyncio\nfrom lightrag import LightRAG\nfrom lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom lightrag.utils import setup_logger\n\n# Setup log handler for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=\"your/path\",\n        llm_model_func=llama_index_complete_if_cache,  # LlamaIndex-compatible completion function\n        embedding_func=EmbeddingFunc(    # LlamaIndex-compatible embedding function\n            embedding_dim=1536,\n            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)\n        ),\n    )\n\n    await rag.initialize_storages()\n    return rag\n\ndef main():\n    # Initialize RAG instance\n    rag = asyncio.run(initialize_rag())\n\n    with open(\"./book.txt\", \"r\", encoding=\"utf-8\") as f:\n        rag.insert(f.read())\n\n    # Perform naive search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\n    )\n\n    # Perform local search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\n    )\n\n    # Perform global search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\n    )\n\n    # Perform hybrid search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**For detailed documentation and examples, see:**\n\n- [LlamaIndex Documentation](lightrag/llm/Readme.md)\n- [Direct OpenAI Example](examples/lightrag_llamaindex_direct_demo.py)\n- [LiteLLM Proxy Example](examples/lightrag_llamaindex_litellm_demo.py)\n\n</details>\n\n### Rerank Function Injection\n\nTo enhance retrieval quality, documents can be re-ranked based on a more effective relevance scoring model. The `rerank.py` file provides three Reranker provider driver functions:\n\n* **Cohere / vLLM**: `cohere_rerank`\n* **Jina AI**: `jina_rerank`\n* **Aliyun**: `ali_rerank`\n\nYou can inject one of these functions into the `rerank_model_func` attribute of the LightRAG object. This will enable LightRAG's query function to re-order retrieved text blocks using the injected function. For detailed usage, please refer to the `examples/rerank_example.py` file.\n\n### User Prompt vs. Query\n\nWhen using LightRAG for content queries, avoid combining the search process with unrelated output processing, as this significantly impacts query effectiveness. The `user_prompt` parameter in Query Param is specifically designed to address this issue ‚Äî it does not participate in the RAG retrieval phase, but rather guides the LLM on how to process the retrieved results after the query is completed. Here's how to use it:\n\n```python\n# Create query parameters\nquery_param = QueryParam(\n    mode = \"hybrid\",  # Other modesÔºölocal, global, hybrid, mix, naive\n    user_prompt = \"For diagrams, use mermaid format with English/Pinyin node names and Chinese display labels\",\n)\n\n# Query and process\nresponse_default = rag.query(\n    \"Please draw a character relationship diagram for Scrooge\",\n    param=query_param\n)\nprint(response_default)\n```\n\n### Insert\n\n<details>\n  <summary> <b> Basic Insert </b></summary>\n\n```python\n# Basic Insert\nrag.insert(\"Text\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Batch Insert </b></summary>\n\n```python\n# Basic Batch Insert: Insert multiple texts at once\nrag.insert([\"TEXT1\", \"TEXT2\",...])\n\n# Batch Insert with custom batch size configuration\nrag = LightRAG(\n    ...\n    working_dir=WORKING_DIR,\n    max_parallel_insert = 4\n)\n\nrag.insert([\"TEXT1\", \"TEXT2\", \"TEXT3\", ...])  # Documents will be processed in batches of 4\n```\n\nThe `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.The `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.\n\n</details>\n\n<details>\n  <summary> <b> Insert with ID </b></summary>\n\nIf you want to provide your own IDs for your documents, number of documents and number of IDs must be the same.\n\n```python\n# Insert single text, and provide ID for it\nrag.insert(\"TEXT1\", ids=[\"ID_FOR_TEXT1\"])\n\n# Insert multiple texts, and provide IDs for them\nrag.insert([\"TEXT1\", \"TEXT2\",...], ids=[\"ID_FOR_TEXT1\", \"ID_FOR_TEXT2\"])\n```\n\n</details>\n\n<details>\n  <summary><b>Insert using Pipeline</b></summary>\n\nThe `apipeline_enqueue_documents` and `apipeline_process_enqueue_documents` functions allow you to perform incremental insertion of documents into the graph.\n\nThis is useful for scenarios where you want to process documents in the background while still allowing the main thread to continue executing.\n\nAnd using a routine to process new documents.\n\n```python\nrag = LightRAG(..)\n\nawait rag.apipeline_enqueue_documents(input)\n# Your routine in loop\nawait rag.apipeline_process_enqueue_documents(input)\n```\n\n</details>\n\n<details>\n  <summary><b>Insert Multi-file Type Support</b></summary>\n\nThe `textract` supports reading file types such as TXT, DOCX, PPTX, CSV, and PDF.\n\n```python\nimport textract\n\nfile_path = 'TEXT.pdf'\ntext_content = textract.process(file_path)\n\nrag.insert(text_content.decode('utf-8'))\n```\n\n</details>\n\n<details>\n  <summary><b>Citation Functionality</b></summary>\n\nBy providing file paths, the system ensures that sources can be traced back to their original documents.\n\n```python\n# Define documents and their file paths\ndocuments = [\"Document content 1\", \"Document content 2\"]\nfile_paths = [\"path/to/doc1.txt\", \"path/to/doc2.txt\"]\n\n# Insert documents with file paths\nrag.insert(documents, file_paths=file_paths)\n```\n\n</details>\n\n### Storage\n\nLightRAG uses 4 types of storage for different purposes:\n\n* KV_STORAGE: llm response cache, text chunks, document information\n* VECTOR_STORAGE: entities vectors, relation vectors, chunks vectors\n* GRAPH_STORAGE: entity relation graph\n* DOC_STATUS_STORAGE: document indexing status\n\nEach storage type has several implementations:\n\n* KV_STORAGE supported implementations:\n\n```\nJsonKVStorage    JsonFile (default)\nPGKVStorage      Postgres\nRedisKVStorage   Redis\nMongoKVStorage   MongoDB\n```\n\n* GRAPH_STORAGE supported implementations:\n\n```\nNetworkXStorage      NetworkX (default)\nNeo4JStorage         Neo4J\nPGGraphStorage       PostgreSQL with AGE plugin\nMemgraphStorage.     Memgraph\n```\n\n> Testing has shown that Neo4J delivers superior performance in production environments compared to PostgreSQL with AGE plugin.\n\n* VECTOR_STORAGE supported implementations:\n\n```\nNanoVectorDBStorage         NanoVector (default)\nPGVectorStorage             Postgres\nMilvusVectorDBStorage       Milvus\nFaissVectorDBStorage        Faiss\nQdrantVectorDBStorage       Qdrant\nMongoVectorDBStorage        MongoDB\n```\n\n* DOC_STATUS_STORAGE: supported implementations:\n\n```\nJsonDocStatusStorage        JsonFile (default)\nPGDocStatusStorage          Postgres\nMongoDocStatusStorage       MongoDB\n```\n\nExample connection configurations for each storage type can be found in the `env.example` file. The database instance in the connection string needs to be created by you on the database server beforehand. LightRAG is only responsible for creating tables within the database instance, not for creating the database instance itself. If using Redis as storage, remember to configure automatic data persistence rules for Redis, otherwise data will be lost after the Redis service restarts. If using PostgreSQL, it is recommended to use version 16.6 or above.\n\n<details>\n<summary> <b>Using Neo4J Storage</b> </summary>\n\n* For production level scenarios you will most likely want to leverage an enterprise solution\n* for KG storage. Running Neo4J in Docker is recommended for seamless local testing.\n* See: https://hub.docker.com/_/neo4j\n\n```python\nexport NEO4J_URI=\"neo4j://localhost:7687\"\nexport NEO4J_USERNAME=\"neo4j\"\nexport NEO4J_PASSWORD=\"password\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project be sure to override the default KG: NetworkX\n# by specifying kg=\"Neo4JStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Neo4J implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"Neo4JStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\nsee test_neo4j.py for a working example.\n\n</details>\n\n<details>\n<summary> <b>Using PostgreSQL Storage</b> </summary>\n\nFor production level scenarios you will most likely want to leverage an enterprise solution. PostgreSQL can provide a one-stop solution for you as KV store, VectorDB (pgvector) and GraphDB (apache AGE). PostgreSQL version 16.6 or higher is supported.\n\n* PostgreSQL is lightweight,the whole binary distribution including all necessary plugins can be zipped to 40MB: Ref to [Windows Release](https://github.com/ShanGor/apache-age-windows/releases/tag/PG17%2Fv1.5.0-rc0) as it is easy to install for Linux/Mac.\n* If you prefer docker, please start with this image if you are a beginner to avoid hiccups (Default user password:rag/rag): https://hub.docker.com/r/gzdaniel/postgres-for-rag\n* How to start? Ref to: [examples/lightrag_zhipu_postgres_demo.py](https://github.com/HKUDS/LightRAG/blob/main/examples/lightrag_zhipu_postgres_demo.py)\n* For high-performance graph database requirements, Neo4j is recommended as Apache AGE's performance is not as competitive.\n\n</details>\n\n<details>\n<summary> <b>Using Faiss Storage</b> </summary>\nBefore using Faiss vector database, you must manually install `faiss-cpu` or `faiss-gpu`.\n\n- Install the required dependencies:\n\n```\npip install faiss-cpu\n```\n\nYou can also install `faiss-gpu` if you have GPU support.\n\n- Here we are using `sentence-transformers` but you can also use `OpenAIEmbedding` model with `3072` dimensions.\n\n```python\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    embeddings = model.encode(texts, convert_to_numpy=True)\n    return embeddings\n\n# Initialize LightRAG with the LLM model function and embedding function\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=llm_model_func,\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=embedding_func,\n    ),\n    vector_storage=\"FaissVectorDBStorage\",\n    vector_db_storage_cls_kwargs={\n        \"cosine_better_than_threshold\": 0.3  # Your desired threshold\n    }\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Memgraph for Storage</b> </summary>\n\n* Memgraph is a high-performance, in-memory graph database compatible with the Neo4j Bolt protocol.\n* You can run Memgraph locally using Docker for easy testing:\n* See: https://memgraph.com/download\n\n```python\nexport MEMGRAPH_URI=\"bolt://localhost:7687\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project, override the default KG: NetworkX\n# by specifying kg=\"MemgraphStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Memgraph implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"MemgraphStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using MongoDB Storage</b> </summary>\n\nMongoDB provides a one-stop storage solution for LightRAG. MongoDB offers native KV storage and vector storage. LightRAG uses MongoDB collections to implement a simple graph storage. MongoDB's official vector search functionality (`$vectorSearch`) currently requires their official cloud service MongoDB Atlas. This functionality cannot be used on self-hosted MongoDB Community/Enterprise versions.\n\n</details>\n\n<details>\n<summary> <b>Using Redis Storage</b> </summary>\n\nLightRAG supports using Redis as KV storage. When using Redis storage, attention should be paid to persistence configuration and memory usage configuration. The following is the recommended Redis configuration:\n\n```\nsave 900 1\nsave 300 10\nsave 60 1000\nstop-writes-on-bgsave-error yes\nmaxmemory 4gb\nmaxmemory-policy noeviction\nmaxclients 500\n```\n\n</details>\n\n### Data Isolation Between LightRAG Instances\n\nThe `workspace` parameter ensures data isolation between different LightRAG instances. Once initialized, the `workspace` is immutable and cannot be changed.Here is how workspaces are implemented for different types of storage:\n\n- **For local file-based databases, data isolation is achieved through workspace subdirectories:** `JsonKVStorage`, `JsonDocStatusStorage`, `NetworkXStorage`, `NanoVectorDBStorage`, `FaissVectorDBStorage`.\n- **For databases that store data in collections, it's done by adding a workspace prefix to the collection name:** `RedisKVStorage`, `RedisDocStatusStorage`, `MilvusVectorDBStorage`, `MongoKVStorage`, `MongoDocStatusStorage`, `MongoVectorDBStorage`, `MongoGraphStorage`, `PGGraphStorage`.\n- **For Qdrant vector database, data isolation is achieved through payload-based partitioning (Qdrant's recommended multitenancy approach):** `QdrantVectorDBStorage` uses shared collections with payload filtering for unlimited workspace scalability.\n- **For relational databases, data isolation is achieved by adding a `workspace` field to the tables for logical data separation:** `PGKVStorage`, `PGVectorStorage`, `PGDocStatusStorage`.\n- **For the Neo4j graph database, logical data isolation is achieved through labels:** `Neo4JStorage`\n\nTo maintain compatibility with legacy data, the default workspace for PostgreSQL non-graph storage is `default` and, for PostgreSQL AGE graph storage is null, for Neo4j graph storage is `base` when no workspace is configured. For all external storages, the system provides dedicated workspace environment variables to override the common `WORKSPACE` environment variable configuration. These storage-specific workspace environment variables are: `REDIS_WORKSPACE`, `MILVUS_WORKSPACE`, `QDRANT_WORKSPACE`, `MONGODB_WORKSPACE`, `POSTGRES_WORKSPACE`, `NEO4J_WORKSPACE`.\n\n### AGENTS.md -- Guiding Coding Agents\n\nAGENTS.md is a simple, open format for guiding coding agents (https://agents.md/). It is a dedicated, predictable place to provide the context and instructions to help AI coding agents work on LightRAG project. Different AI coders should not maintain separate guidance files individually. If any AI coder cannot automatically recognize AGENTS.md, symbolic links can be used as a solution. After establishing symbolic links, you can prevent them from being committed to the Git repository by configuring your local `.gitignore_global`.\n\n## Edit Entities and Relations\n\nLightRAG now supports comprehensive knowledge graph management capabilities, allowing you to create, edit, and delete entities and relationships within your knowledge graph.\n\n<details>\n  <summary> <b> Create Entities and Relations </b></summary>\n\n```python\n# Create new entity\nentity = rag.create_entity(\"Google\", {\n    \"description\": \"Google is a multinational technology company specializing in internet-related services and products.\",\n    \"entity_type\": \"company\"\n})\n\n# Create another entity\nproduct = rag.create_entity(\"Gmail\", {\n    \"description\": \"Gmail is an email service developed by Google.\",\n    \"entity_type\": \"product\"\n})\n\n# Create relation between entities\nrelation = rag.create_relation(\"Google\", \"Gmail\", {\n    \"description\": \"Google develops and operates Gmail.\",\n    \"keywords\": \"develops operates service\",\n    \"weight\": 2.0\n})\n```\n\n</details>\n\n<details>\n  <summary> <b> Edit Entities and Relations </b></summary>\n\n```python\n# Edit an existing entity\nupdated_entity = rag.edit_entity(\"Google\", {\n    \"description\": \"Google is a subsidiary of Alphabet Inc., founded in 1998.\",\n    \"entity_type\": \"tech_company\"\n})\n\n# Rename an entity (with all its relationships properly migrated)\nrenamed_entity = rag.edit_entity(\"Gmail\", {\n    \"entity_name\": \"Google Mail\",\n    \"description\": \"Google Mail (formerly Gmail) is an email service.\"\n})\n\n# Edit a relation between entities\nupdated_relation = rag.edit_relation(\"Google\", \"Google Mail\", {\n    \"description\": \"Google created and maintains Google Mail service.\",\n    \"keywords\": \"creates maintains email service\",\n    \"weight\": 3.0\n})\n```\n\nAll operations are available in both synchronous and asynchronous versions. The asynchronous versions have the prefix \"a\" (e.g., `acreate_entity`, `aedit_relation`).\n\n</details>\n\n<details>\n  <summary> <b> Insert Custom KG </b></summary>\n\n```python\ncustom_kg = {\n        \"chunks\": [\n            {\n                \"content\": \"Alice and Bob are collaborating on quantum computing research.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\",\n            }\n        ],\n        \"entities\": [\n            {\n                \"entity_name\": \"Alice\",\n                \"entity_type\": \"person\",\n                \"description\": \"Alice is a researcher specializing in quantum physics.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Bob\",\n                \"entity_type\": \"person\",\n                \"description\": \"Bob is a mathematician.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Quantum Computing\",\n                \"entity_type\": \"technology\",\n                \"description\": \"Quantum computing utilizes quantum mechanical phenomena for computation.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ],\n        \"relationships\": [\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Bob\",\n                \"description\": \"Alice and Bob are research partners.\",\n                \"keywords\": \"collaboration research\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Alice conducts research on quantum computing.\",\n                \"keywords\": \"research expertise\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Bob\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Bob researches quantum computing.\",\n                \"keywords\": \"research application\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ]\n    }\n\nrag.insert_custom_kg(custom_kg)\n```\n\n</details>\n\n<details>\n  <summary> <b>Other Entity and Relation Operations</b></summary>\n\n- **create_entity**: Creates a new entity with specified attributes\n- **edit_entity**: Updates an existing entity's attributes or renames it\n\n\n- **create_relation**: Creates a new relation between existing entities\n- **edit_relation**: Updates an existing relation's attributes\n\nThese operations maintain data consistency across both the graph database and vector database components, ensuring your knowledge graph remains coherent.\n\n</details>\n\n## Delete Functions\n\nLightRAG provides comprehensive deletion capabilities, allowing you to delete documents, entities, and relationships.\n\n<details>\n<summary> <b>Delete Entities</b> </summary>\n\nYou can delete entities by their name along with all associated relationships:\n\n```python\n# Delete entity and all its relationships (synchronous version)\nrag.delete_by_entity(\"Google\")\n\n# Asynchronous version\nawait rag.adelete_by_entity(\"Google\")\n```\n\nWhen deleting an entity:\n- Removes the entity node from the knowledge graph\n- Deletes all associated relationships\n- Removes related embedding vectors from the vector database\n- Maintains knowledge graph integrity\n\n</details>\n\n<details>\n<summary> <b>Delete Relations</b> </summary>\n\nYou can delete relationships between two specific entities:\n\n```python\n# Delete relationship between two entities (synchronous version)\nrag.delete_by_relation(\"Google\", \"Gmail\")\n\n# Asynchronous version\nawait rag.adelete_by_relation(\"Google\", \"Gmail\")\n```\n\nWhen deleting a relationship:\n- Removes the specified relationship edge\n- Deletes the relationship's embedding vector from the vector database\n- Preserves both entity nodes and their other relationships\n\n</details>\n\n<details>\n<summary> <b>Delete by Document ID</b> </summary>\n\nYou can delete an entire document and all its related knowledge through document ID:\n\n```python\n# Delete by document ID (asynchronous version)\nawait rag.adelete_by_doc_id(\"doc-12345\")\n```\n\nOptimized processing when deleting by document ID:\n- **Smart Cleanup**: Automatically identifies and removes entities and relationships that belong only to this document\n- **Preserve Shared Knowledge**: If entities or relationships exist in other documents, they are preserved and their descriptions are rebuilt\n- **Cache Optimization**: Clears related LLM cache to reduce storage overhead\n- **Incremental Rebuilding**: Reconstructs affected entity and relationship descriptions from remaining documents\n\nThe deletion process includes:\n1. Delete all text chunks related to the document\n2. Identify and delete entities and relationships that belong only to this document\n3. Rebuild entities and relationships that still exist in other documents\n4. Update all related vector indexes\n5. Clean up document status records\n\nNote: Deletion by document ID is an asynchronous operation as it involves complex knowledge graph reconstruction processes.\n\n</details>\n\n**Important Reminders:**\n\n1. **Irreversible Operations**: All deletion operations are irreversible, please use with caution\n2. **Performance Considerations**: Deleting large amounts of data may take some time, especially deletion by document ID\n3. **Data Consistency**: Deletion operations automatically maintain consistency between the knowledge graph and vector database\n4. **Backup Recommendations**: Consider backing up data before performing important deletion operations\n\n**Batch Deletion Recommendations:**\n- For batch deletion operations, consider using asynchronous methods for better performance\n- For large-scale deletions, consider processing in batches to avoid excessive system load\n\n## Entity Merging\n\n<details>\n<summary> <b>Merge Entities and Their Relationships</b> </summary>\n\nLightRAG now supports merging multiple entities into a single entity, automatically handling all relationships:\n\n```python\n# Basic entity merging\nrag.merge_entities(\n    source_entities=[\"Artificial Intelligence\", \"AI\", \"Machine Intelligence\"],\n    target_entity=\"AI Technology\"\n)\n```\n\nWith custom merge strategy:\n\n```python\n# Define custom merge strategy for different fields\nrag.merge_entities(\n    source_entities=[\"John Smith\", \"Dr. Smith\", \"J. Smith\"],\n    target_entity=\"John Smith\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"entity_type\": \"keep_first\",   # Keep the entity type from the first entity\n        \"source_id\": \"join_unique\"     # Combine all unique source IDs\n    }\n)\n```\n\nWith custom target entity data:\n\n```python\n# Specify exact values for the merged entity\nrag.merge_entities(\n    source_entities=[\"New York\", \"NYC\", \"Big Apple\"],\n    target_entity=\"New York City\",\n    target_entity_data={\n        \"entity_type\": \"LOCATION\",\n        \"description\": \"New York City is the most populous city in the United States.\",\n    }\n)\n```\n\nAdvanced usage combining both approaches:\n\n```python\n# Merge company entities with both strategy and custom data\nrag.merge_entities(\n    source_entities=[\"Microsoft Corp\", \"Microsoft Corporation\", \"MSFT\"],\n    target_entity=\"Microsoft\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"source_id\": \"join_unique\"     # Combine source IDs\n    },\n    target_entity_data={\n        \"entity_type\": \"ORGANIZATION\",\n    }\n)\n```\n\nWhen merging entities:\n\n* All relationships from source entities are redirected to the target entity\n* Duplicate relationships are intelligently merged\n* Self-relationships (loops) are prevented\n* Source entities are removed after merging\n* Relationship weights and attributes are preserved\n\n</details>\n\n## Multimodal Document Processing (RAG-Anything Integration)\n\nLightRAG now seamlessly integrates with [RAG-Anything](https://github.com/HKUDS/RAG-Anything), a comprehensive **All-in-One Multimodal Document Processing RAG system** built specifically for LightRAG. RAG-Anything enables advanced parsing and retrieval-augmented generation (RAG) capabilities, allowing you to handle multimodal documents seamlessly and extract structured content‚Äîincluding text, images, tables, and formulas‚Äîfrom various document formats for integration into your RAG pipeline.\n\n**Key Features:**\n- **End-to-End Multimodal Pipeline**: Complete workflow from document ingestion and parsing to intelligent multimodal query answering\n- **Universal Document Support**: Seamless processing of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse file formats\n- **Specialized Content Analysis**: Dedicated processors for images, tables, mathematical equations, and heterogeneous content types\n- **Multimodal Knowledge Graph**: Automatic entity extraction and cross-modal relationship discovery for enhanced understanding\n- **Hybrid Intelligent Retrieval**: Advanced search capabilities spanning textual and multimodal content with contextual understanding\n\n**Quick Start:**\n1. Install RAG-Anything:\n   ```bash\n   pip install raganything\n   ```\n2. Process multimodal documents:\n    <details>\n    <summary> <b> RAGAnything Usage Example </b></summary>\n\n    ```python\n        import asyncio\n        from raganything import RAGAnything\n        from lightrag import LightRAG\n        from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n        from lightrag.utils import EmbeddingFunc\n        import os\n\n        async def load_existing_lightrag():\n            # First, create or load an existing LightRAG instance\n            lightrag_working_dir = \"./existing_lightrag_storage\"\n\n            # Check if previous LightRAG instance exists\n            if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):\n                print(\"‚úÖ Found existing LightRAG instance, loading...\")\n            else:\n                print(\"‚ùå No existing LightRAG instance found, will create new one\")\n\n            # Create/Load LightRAG instance with your configurations\n            lightrag_instance = LightRAG(\n                working_dir=lightrag_working_dir,\n                llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ),\n                embedding_func=EmbeddingFunc(\n                    embedding_dim=3072,\n                    func=lambda texts: openai_embed(\n                        texts,\n                        model=\"text-embedding-3-large\",\n                        api_key=api_key,\n                        base_url=base_url,\n                    ),\n                )\n            )\n\n            # Initialize storage (this will load existing data if available)\n            await lightrag_instance.initialize_storages()\n\n            # Now initialize RAGAnything with the existing LightRAG instance\n            rag = RAGAnything(\n                lightrag=lightrag_instance,  # Pass the existing LightRAG instance\n                # Only need vision model for multimodal processing\n                vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(\n                    \"gpt-4o\",\n                    \"\",\n                    system_prompt=None,\n                    history_messages=[],\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_prompt} if system_prompt else None,\n                        {\"role\": \"user\", \"content\": [\n                            {\"type\": \"text\", \"text\": prompt},\n                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n                        ]} if image_data else {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ) if image_data else openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                )\n                # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance\n            )\n\n            # Query the existing knowledge base\n            result = await rag.query_with_multimodal(\n                \"What data has been processed in this LightRAG instance?\",\n                mode=\"hybrid\"\n            )\n            print(\"Query result:\", result)\n\n            # Add new multimodal documents to the existing LightRAG instance\n            await rag.process_document_complete(\n                file_path=\"path/to/new/multimodal_document.pdf\",\n                output_dir=\"./output\"\n            )\n\n        if __name__ == \"__main__\":\n            asyncio.run(load_existing_lightrag())\n    ```\n    </details>\n\nFor detailed documentation and advanced usage, please refer to the [RAG-Anything repository](https://github.com/HKUDS/RAG-Anything).\n\n## Token Usage Tracking\n\n<details>\n<summary> <b>Overview and Usage</b> </summary>\n\nLightRAG provides a TokenTracker tool to monitor and manage token consumption by large language models. This feature is particularly useful for controlling API costs and optimizing performance.\n\n### Usage\n\n```python\nfrom lightrag.utils import TokenTracker\n\n# Create TokenTracker instance\ntoken_tracker = TokenTracker()\n\n# Method 1: Using context manager (Recommended)\n# Suitable for scenarios requiring automatic token usage tracking\nwith token_tracker:\n    result1 = await llm_model_func(\"your question 1\")\n    result2 = await llm_model_func(\"your question 2\")\n\n# Method 2: Manually adding token usage records\n# Suitable for scenarios requiring more granular control over token statistics\ntoken_tracker.reset()\n\nrag.insert()\n\nrag.query(\"your question 1\", param=QueryParam(mode=\"naive\"))\nrag.query(\"your question 2\", param=QueryParam(mode=\"mix\"))\n\n# Display total token usage (including insert and query operations)\nprint(\"Token usage:\", token_tracker.get_usage())\n```\n\n### Usage Tips\n- Use context managers for long sessions or batch operations to automatically track all token consumption\n- For scenarios requiring segmented statistics, use manual mode and call reset() when appropriate\n- Regular checking of token usage helps detect abnormal consumption early\n- Actively use this feature during development and testing to optimize production costs\n\n### Practical Examples\nYou can refer to these examples for implementing token tracking:\n- `examples/lightrag_gemini_track_token_demo.py`: Token tracking example using Google Gemini model\n- `examples/lightrag_siliconcloud_track_token_demo.py`: Token tracking example using SiliconCloud model\n\nThese examples demonstrate how to effectively use the TokenTracker feature with different models and scenarios.\n\n</details>\n\n## Data Export Functions\n\n### Overview\n\nLightRAG allows you to export your knowledge graph data in various formats for analysis, sharing, and backup purposes. The system supports exporting entities, relations, and relationship data.\n\n### Export Functions\n\n<details>\n  <summary> <b> Basic Usage </b></summary>\n\n```python\n# Basic CSV export (default format)\nrag.export_data(\"knowledge_graph.csv\")\n\n# Specify any format\nrag.export_data(\"output.xlsx\", file_format=\"excel\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Different File Formats supported </b></summary>\n\n```python\n#Export data in CSV format\nrag.export_data(\"graph_data.csv\", file_format=\"csv\")\n\n# Export data in Excel sheet\nrag.export_data(\"graph_data.xlsx\", file_format=\"excel\")\n\n# Export data in markdown format\nrag.export_data(\"graph_data.md\", file_format=\"md\")\n\n# Export data in Text\nrag.export_data(\"graph_data.txt\", file_format=\"txt\")\n```\n</details>\n\n<details>\n  <summary> <b> Additional Options </b></summary>\n\nInclude vector embeddings in the export (optional):\n\n```python\nrag.export_data(\"complete_data.csv\", include_vector_data=True)\n```\n</details>\n\n### Data Included in Export\n\nAll exports include:\n\n* Entity information (names, IDs, metadata)\n* Relation data (connections between entities)\n* Relationship information from vector database\n\n## Cache\n\n<details>\n  <summary> <b>Clear Cache</b> </summary>\n\nYou can clear the LLM response cache with different modes:\n\n```python\n# Clear all cache\nawait rag.aclear_cache()\n\n# Clear local mode cache\nawait rag.aclear_cache(modes=[\"local\"])\n\n# Clear extraction cache\nawait rag.aclear_cache(modes=[\"default\"])\n\n# Clear multiple modes\nawait rag.aclear_cache(modes=[\"local\", \"global\", \"hybrid\"])\n\n# Synchronous version\nrag.clear_cache(modes=[\"local\"])\n```\n\nValid modes are:\n\n- `\"default\"`: Extraction cache\n- `\"naive\"`: Naive search cache\n- `\"local\"`: Local search cache\n- `\"global\"`: Global search cache\n- `\"hybrid\"`: Hybrid search cache\n- `\"mix\"`: Mix search cache\n\n</details>\n\n## Troubleshooting\n\n### Common Initialization Errors\n\nIf you encounter these errors when using LightRAG:\n\n1. **`AttributeError: __aenter__`**\n   - **Cause**: Storage backends not initialized\n   - **Solution**: Call `await rag.initialize_storages()` after creating the LightRAG instance\n\n2. **`KeyError: 'history_messages'`**\n   - **Cause**: Pipeline status not initialized\n   - **Solution**: Call `\n3. **Both errors in sequence**\n   - **Cause**: Neither initialization method was called\n   - **Solution**: Always follow this pattern:\n   ```python\n   rag = LightRAG(...)\n   await rag.initialize_storages()   ```\n\n### Model Switching Issues\n\nWhen switching between different embedding models, you must clear the data directory to avoid errors. The only file you may want to preserve is `kv_store_llm_response_cache.json` if you wish to retain the LLM cache.\n\n## LightRAG API\n\nThe LightRAG Server is designed to provide Web UI and API support.  **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n## Graph Visualization\n\nThe LightRAG Server offers a comprehensive knowledge graph visualization feature. It supports various gravity layouts, node queries, subgraph filtering, and more. **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n![iShot_2025-03-23_12.40.08](./README.assets/iShot_2025-03-23_12.40.08.png)\n\n## Langfuse observability integration\n\nLangfuse provides a drop-in replacement for the OpenAI client that automatically tracks all LLM interactions, enabling developers to monitor, debug, and optimize their RAG systems without code changes.\n\n### Installation with Langfuse option\n\n```\npip install lightrag-hku\npip install lightrag-hku[observability]\n\n# Or install from souce code with debug mode enabled\npip install -e .\npip install -e \".[observability]\"\n```\n\n### Config Langfuse env vars\n\nmodify .env file:\n\n```\n## Langfuse Observability (Optional)\n# LLM observability and tracing platform\n# Install with: pip install lightrag-hku[observability]\n# Sign up at: https://cloud.langfuse.com or self-host\nLANGFUSE_SECRET_KEY=\"\"\nLANGFUSE_PUBLIC_KEY=\"\"\nLANGFUSE_HOST=\"https://cloud.langfuse.com\"  # or your self-hosted instance\nLANGFUSE_ENABLE_TRACE=true\n```\n\n### Langfuse Usage\n\nOnce installed and configured, Langfuse automatically traces all OpenAI LLM calls. Langfuse dashboard features include:\n\n- **Tracing**: View complete LLM call chains\n- **Analytics**: Token usage, latency, cost metrics\n- **Debugging**: Inspect prompts and responses\n- **Evaluation**: Compare model outputs\n- **Monitoring**: Real-time alerting\n\n### Important Notice\n\n**Note**: LightRAG currently only integrates OpenAI-compatible API calls with Langfuse. APIs such as Ollama, Azure, and AWS Bedrock are not yet supported for Langfuse observability.\n\n## RAGAS-based Evaluation\n\n**RAGAS** (Retrieval Augmented Generation Assessment) is a framework for reference-free evaluation of RAG systems using LLMs. There is an evaluation script based on RAGAS. For detailed information, please refer to [RAGAS-based Evaluation Framework](lightrag/evaluation/README.md).\n\n## Evaluation\n\n### Dataset\n\nThe dataset used in LightRAG can be downloaded from [TommyChien/UltraDomain](https://huggingface.co/datasets/TommyChien/UltraDomain).\n\n### Generate Query\n\nLightRAG uses the following prompt to generate high-level queries, with the corresponding code in `examples/generate_query.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\nGiven the following description of a dataset:\n\n{description}\n\nPlease identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.\n\nOutput the results in the following structure:\n- User 1: [user description]\n    - Task 1: [task description]\n        - Question 1:\n        - Question 2:\n        - Question 3:\n        - Question 4:\n        - Question 5:\n    - Task 2: [task description]\n        ...\n    - Task 5: [task description]\n- User 2: [user description]\n    ...\n- User 5: [user description]\n    ...\n```\n\n</details>\n\n### Batch Eval\n\nTo evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt, with the specific code available in `reproduce/batch_eval.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\n---Role---\nYou are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n---Goal---\nYou will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n\n- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?\n- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?\n- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?\n\nFor each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.\n\nHere is the question:\n{query}\n\nHere are the two answers:\n\n**Answer 1:**\n{answer1}\n\n**Answer 2:**\n{answer2}\n\nEvaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.\n\nOutput your evaluation in the following JSON format:\n\n{{\n    \"Comprehensiveness\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Empowerment\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Overall Winner\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Summarize why this answer is the overall winner based on the three criteria]\"\n    }}\n}}\n```\n\n</details>\n\n### Overall Performance Table\n\n|                      |**Agriculture**|            |**CS**|            |**Legal**|            |**Mix**|            |\n|----------------------|---------------|------------|------|------------|---------|------------|-------|------------|\n|                      |NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|\n|**Comprehensiveness**|32.4%|**67.6%**|38.4%|**61.6%**|16.4%|**83.6%**|38.8%|**61.2%**|\n|**Diversity**|23.6%|**76.4%**|38.0%|**62.0%**|13.6%|**86.4%**|32.4%|**67.6%**|\n|**Empowerment**|32.4%|**67.6%**|38.8%|**61.2%**|16.4%|**83.6%**|42.8%|**57.2%**|\n|**Overall**|32.4%|**67.6%**|38.8%|**61.2%**|15.2%|**84.8%**|40.0%|**60.0%**|\n|                      |RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|\n|**Comprehensiveness**|31.6%|**68.4%**|38.8%|**61.2%**|15.2%|**84.8%**|39.2%|**60.8%**|\n|**Diversity**|29.2%|**70.8%**|39.2%|**60.8%**|11.6%|**88.4%**|30.8%|**69.2%**|\n|**Empowerment**|31.6%|**68.4%**|36.4%|**63.6%**|15.2%|**84.8%**|42.4%|**57.6%**|\n|**Overall**|32.4%|**67.6%**|38.0%|**62.0%**|14.4%|**85.6%**|40.0%|**60.0%**|\n|                      |HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|\n|**Comprehensiveness**|26.0%|**74.0%**|41.6%|**58.4%**|26.8%|**73.2%**|40.4%|**59.6%**|\n|**Diversity**|24.0%|**76.0%**|38.8%|**61.2%**|20.0%|**80.0%**|32.4%|**67.6%**|\n|**Empowerment**|25.2%|**74.8%**|40.8%|**59.2%**|26.0%|**74.0%**|46.0%|**54.0%**|\n|**Overall**|24.8%|**75.2%**|41.6%|**58.4%**|26.4%|**73.6%**|42.4%|**57.6%**|\n|                      |GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|\n|**Comprehensiveness**|45.6%|**54.4%**|48.4%|**51.6%**|48.4%|**51.6%**|**50.4%**|49.6%|\n|**Diversity**|22.8%|**77.2%**|40.8%|**59.2%**|26.4%|**73.6%**|36.0%|**64.0%**|\n|**Empowerment**|41.2%|**58.8%**|45.2%|**54.8%**|43.6%|**56.4%**|**50.8%**|49.2%|\n|**Overall**|45.2%|**54.8%**|48.0%|**52.0%**|47.2%|**52.8%**|**50.4%**|49.6%|\n\n## Reproduce\n\nAll the code can be found in the `./reproduce` directory.\n\n### Step-0 Extract Unique Contexts\n\nFirst, we need to extract unique contexts in the datasets.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_unique_contexts(input_directory, output_directory):\n\n    os.makedirs(output_directory, exist_ok=True)\n\n    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))\n    print(f\"Found {len(jsonl_files)} JSONL files.\")\n\n    for file_path in jsonl_files:\n        filename = os.path.basename(file_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_unique_contexts.json\"\n        output_path = os.path.join(output_directory, output_filename)\n\n        unique_contexts_dict = {}\n\n        print(f\"Processing file: {filename}\")\n\n        try:\n            with open(file_path, 'r', encoding='utf-8') as infile:\n                for line_number, line in enumerate(infile, start=1):\n                    line = line.strip()\n                    if not line:\n                        continue\n                    try:\n                        json_obj = json.loads(line)\n                        context = json_obj.get('context')\n                        if context and context not in unique_contexts_dict:\n                            unique_contexts_dict[context] = None\n                    except json.JSONDecodeError as e:\n                        print(f\"JSON decoding error in file {filename} at line {line_number}: {e}\")\n        except FileNotFoundError:\n            print(f\"File not found: {filename}\")\n            continue\n        except Exception as e:\n            print(f\"An error occurred while processing file {filename}: {e}\")\n            continue\n\n        unique_contexts_list = list(unique_contexts_dict.keys())\n        print(f\"There are {len(unique_contexts_list)} unique `context` entries in the file {filename}.\")\n\n        try:\n            with open(output_path, 'w', encoding='utf-8') as outfile:\n                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)\n            print(f\"Unique `context` entries have been saved to: {output_filename}\")\n        except Exception as e:\n            print(f\"An error occurred while saving to the file {output_filename}: {e}\")\n\n    print(\"All files have been processed.\")\n\n```\n\n</details>\n\n### Step-1 Insert Contexts\n\nFor the extracted contexts, we insert them into the LightRAG system.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef insert_text(rag, file_path):\n    with open(file_path, mode='r') as f:\n        unique_contexts = json.load(f)\n\n    retries = 0\n    max_retries = 3\n    while retries < max_retries:\n        try:\n            rag.insert(unique_contexts)\n            break\n        except Exception as e:\n            retries += 1\n            print(f\"Insertion failed, retrying ({retries}/{max_retries}), error: {e}\")\n            time.sleep(10)\n    if retries == max_retries:\n        print(\"Insertion failed after exceeding the maximum number of retries\")\n```\n\n</details>\n\n### Step-2 Generate Queries\n\nWe extract tokens from the first and the second half of each context in the dataset, then combine them as dataset descriptions to generate queries.\n\n<details>\n<summary> Code </summary>\n\n```python\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\ndef get_summary(context, tot_tokens=2000):\n    tokens = tokenizer.tokenize(context)\n    half_tokens = tot_tokens // 2\n\n    start_tokens = tokens[1000:1000 + half_tokens]\n    end_tokens = tokens[-(1000 + half_tokens):1000]\n\n    summary_tokens = start_tokens + end_tokens\n    summary = tokenizer.convert_tokens_to_string(summary_tokens)\n\n    return summary\n```\n\n</details>\n\n### Step-3 Query\n\nFor the queries generated in Step-2, we will extract them and query LightRAG.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_queries(file_path):\n    with open(file_path, 'r') as f:\n        data = f.read()\n\n    data = data.replace('**', '')\n\n    queries = re.findall(r'- Question \\d+: (.+)', data)\n\n    return queries\n```\n\n</details>\n\n## üîó Related Projects\n\n*Ecosystem & Extensions*\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/RAG-Anything\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üì∏</span>\n          </div>\n          <b>RAG-Anything</b><br>\n          <sub>Multimodal RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/VideoRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üé•</span>\n          </div>\n          <b>VideoRAG</b><br>\n          <sub>Extreme Long-Context Video RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/MiniRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">‚ú®</span>\n          </div>\n          <b>MiniRAG</b><br>\n          <sub>Extremely Simple RAG</sub>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## ‚≠ê Star History\n\n<a href=\"https://star-history.com/#HKUDS/LightRAG&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n </picture>\n</a>\n\n## ü§ù Contribution\n\n<div align=\"center\">\n  We thank all our contributors for their valuable contributions.\n</div>\n\n<div align=\"center\">\n  <a href=\"https://github.com/HKUDS/LightRAG/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=HKUDS/LightRAG\" style=\"border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);\" />\n  </a>\n</div>\n\n---\n\n\n## üìñ Citation\n\n```python\n@article{guo2024lightrag,\ntitle={LightRAG: Simple and Fast Retrieval-Augmented Generation},\nauthor={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},\nyear={2024},\neprint={2410.05779},\narchivePrefix={arXiv},\nprimaryClass={cs.IR}\n}\n```\n\n---\n\n<div align=\"center\" style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;\">\n  <div>\n    <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"500\">\n  </div>\n  <div style=\"margin-top: 20px;\">\n    <a href=\"https://github.com/HKUDS/LightRAG\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/issues\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/discussions\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n  </div>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);\">\n    <div style=\"display: flex; justify-content: center; align-items: center; gap: 15px;\">\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n      <span style=\"color: #00d9ff; font-size: 18px;\">Thank you for visiting LightRAG!</span>\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n    </div>\n  </div>\n</div>\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/HKUDS/LightRAG",
          "homepage": "https://arxiv.org/abs/2410.05779",
          "language": "Python",
          "forks": 3507,
          "open_issues": 170,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/118165258?v=4",
      "velocity": 26268,
      "is_rising_star": true,
      "heatScore": 7883.464636756028,
      "popularityScore": 23880
    },
    {
      "id": "github-pathwaycom-pathway",
      "name": "pathway",
      "author": "pathwaycom",
      "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
      "task": "tool",
      "tags": [
        "batch-processing",
        "data-analytics",
        "data-pipelines",
        "data-processing",
        "dataflow",
        "etl",
        "etl-framework",
        "iot-analytics",
        "kafka",
        "machine-learning-algorithms",
        "pathway",
        "python",
        "real-time",
        "rust",
        "stream-processing",
        "streaming",
        "time-series-analysis",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 100330,
      "downloads": 100330,
      "lastModified": "2025-11-20T15:47:22Z",
      "lastModifiedTimestamp": 1763653642000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/pathway",
          "homepage": "https://pathway.com",
          "language": "Python",
          "forks": 1454,
          "open_issues": 39,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 55181.5,
      "is_rising_star": true,
      "heatScore": 16557.740286631673,
      "popularityScore": 50165
    },
    {
      "id": "github-toon-format-toon",
      "name": "toon",
      "author": "toon-format",
      "description": "üéí Token-Oriented Object Notation (TOON) ‚Äì Compact, human-readable, schema-aware JSON for LLM prompts. Spec, benchmarks, TypeScript SDK.",
      "task": "tool",
      "tags": [
        "data-format",
        "llm",
        "serialization",
        "tokenization"
      ],
      "likes": 37198,
      "downloads": 37198,
      "lastModified": "2025-11-20T15:47:06Z",
      "lastModifiedTimestamp": 1763653626000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/toon-format/toon",
          "homepage": "https://toonformat.dev",
          "language": "TypeScript",
          "forks": 791,
          "open_issues": 23,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241380424?v=4",
      "velocity": 20458.9,
      "is_rising_star": true,
      "heatScore": 6140.658659060952,
      "popularityScore": 18599
    },
    {
      "id": "github-simonw-llm",
      "name": "llm",
      "author": "simonw",
      "description": "Access large language models from the command-line",
      "task": "tool",
      "tags": [
        "ai",
        "llms",
        "openai",
        "ggml",
        "llm",
        "ml",
        "rust"
      ],
      "likes": 32808,
      "downloads": 32808,
      "lastModified": "2025-11-20T15:47:01Z",
      "lastModifiedTimestamp": 1763653621000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/simonw/llm",
          "homepage": "https://llm.datasette.io",
          "language": "Python",
          "forks": 677,
          "open_issues": 527,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/rustformers/llm",
          "homepage": "https://docs.rs/llm/latest/llm/",
          "language": "Rust",
          "forks": 372,
          "open_issues": 81,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/9599?v=4",
      "velocity": 18044.4,
      "is_rising_star": true,
      "heatScore": 5416.270483364306,
      "popularityScore": 16404
    },
    {
      "id": "github-Arindam200-awesome-ai-apps",
      "name": "awesome-ai-apps",
      "author": "Arindam200",
      "description": "A collection of projects showcasing RAG, agents, workflows, and other AI use cases",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "hacktoberfest",
        "llm",
        "mcp",
        "rag-knowledge-base-qa"
      ],
      "likes": 15124,
      "downloads": 15124,
      "lastModified": "2025-11-20T15:46:50Z",
      "lastModifiedTimestamp": 1763653610000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Arindam200/awesome-ai-apps",
          "homepage": "https://ggl.link/arindam-youtube",
          "language": "Python",
          "forks": 917,
          "open_issues": 30,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/109217591?v=4",
      "velocity": 8318.2,
      "is_rising_star": true,
      "heatScore": 2498.175085870277,
      "popularityScore": 7562
    },
    {
      "id": "github-pathwaycom-llm-app",
      "name": "llm-app",
      "author": "pathwaycom",
      "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
      "task": "tool",
      "tags": [
        "chatbot",
        "hugging-face",
        "llm",
        "llm-local",
        "llm-prompting",
        "llm-security",
        "llmops",
        "machine-learning",
        "open-ai",
        "pathway",
        "rag",
        "real-time",
        "retrieval-augmented-generation",
        "vector-database",
        "vector-index",
        "general-dialogue-qa",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 94666,
      "downloads": 94666,
      "lastModified": "2025-11-20T15:46:47Z",
      "lastModifiedTimestamp": 1763653607000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/llm-app",
          "homepage": "https://pathway.com/developers/templates/",
          "language": "Jupyter Notebook",
          "forks": 1214,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 52066.3,
      "is_rising_star": true,
      "heatScore": 15623.16262124451,
      "popularityScore": 47333
    },
    {
      "id": "github-AstrBotDevs-AstrBot",
      "name": "AstrBot",
      "author": "AstrBotDevs",
      "description": "‚ú® Agentic IM ChatBot Infrastructure ‚ú® Integration with multiple IMs, easy-to-use plugin system, supports OpenAI, Gemini, Anthropic, Dify, Coze, built-in Knowledge Base, Agent. ‚ú® ‰∏ÄÁ´ôÂºèÂ§ßÊ®°ÂûãËÅäÂ§©Êú∫Âô®‰∫∫Âπ≥Âè∞ÂèäÂºÄÂèëÊ°ÜÊû∂ ‚ú® Â§öÊ∂àÊÅØÂπ≥Âè∞ÔºàQQ, Telegram, ‰ºÅÂæÆ, È£û‰π¶, ÈíâÈíâÁ≠âÔºâÈõÜÊàêÔºåÊòìÁî®ÁöÑÊèí‰ª∂Á≥ªÁªüÔºåÊîØÊåÅÊé•ÂÖ• OpenAI, Gemini, Anthropic, Dify, Coze, ÈòøÈáå‰∫ëÁôæÁÇºÂ∫îÁî®Á≠âÂπ≥Âè∞ÔºåÂÜÖÁΩÆÁü•ËØÜÂ∫ì„ÄÅAgent Êô∫ËÉΩ‰Ωì",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "chatbot",
        "chatgpt",
        "docker",
        "gemini",
        "gpt",
        "llama",
        "llm",
        "mcp",
        "openai",
        "python",
        "qq",
        "qqbot",
        "qqchannel",
        "telegram",
        "general-dialogue-qa"
      ],
      "likes": 26972,
      "downloads": 26972,
      "lastModified": "2025-11-20T15:46:43Z",
      "lastModifiedTimestamp": 1763653603000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/AstrBotDevs/AstrBot",
          "homepage": "https://astrbot.app",
          "language": "Python",
          "forks": 1012,
          "open_issues": 327,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/197911947?v=4",
      "velocity": 14834.6,
      "is_rising_star": true,
      "heatScore": 4453.270940750253,
      "popularityScore": 13486
    },
    {
      "id": "github-rasbt-LLMs-from-scratch",
      "name": "LLMs-from-scratch",
      "author": "rasbt",
      "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "deep-learning",
        "from-scratch",
        "generative-ai",
        "gpt",
        "language-model",
        "large-language-models",
        "llm",
        "machine-learning",
        "neural-networks",
        "python",
        "pytorch",
        "transformers",
        "general-dialogue-qa"
      ],
      "likes": 158122,
      "downloads": 158122,
      "lastModified": "2025-11-20T15:46:33Z",
      "lastModifiedTimestamp": 1763653593000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/rasbt/LLMs-from-scratch",
          "homepage": "https://amzn.to/4fqvn0D",
          "language": "Jupyter Notebook",
          "forks": 11719,
          "open_issues": 0,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/5618407?v=4",
      "velocity": 86967.1,
      "is_rising_star": true,
      "heatScore": 26093.558577457425,
      "popularityScore": 79061
    },
    {
      "id": "github-dair-ai-Prompt-Engineering-Guide",
      "name": "Prompt-Engineering-Guide",
      "author": "dair-ai",
      "description": "üêô Guides, papers, lessons, notebooks and resources for prompt engineering, context engineering, RAG, and AI Agents.",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai-agents",
        "chatgpt",
        "deep-learning",
        "generative-ai",
        "language-model",
        "llms",
        "openai",
        "prompt-engineering",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 133184,
      "downloads": 133184,
      "lastModified": "2025-11-20T15:46:31Z",
      "lastModifiedTimestamp": 1763653591000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/dair-ai/Prompt-Engineering-Guide",
          "homepage": "https://www.promptingguide.ai/",
          "language": "MDX",
          "forks": 6951,
          "open_issues": 231,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/30384625?v=4",
      "velocity": 73251.2,
      "is_rising_star": true,
      "heatScore": 21978.73640000614,
      "popularityScore": 66592
    },
    {
      "id": "github-open-webui-open-webui",
      "name": "open-webui",
      "author": "open-webui",
      "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
      "task": "tool",
      "tags": [
        "ai",
        "llm",
        "llm-ui",
        "llm-webui",
        "llms",
        "mcp",
        "ollama",
        "ollama-webui",
        "open-webui",
        "openai",
        "openapi",
        "rag",
        "self-hosted",
        "ui",
        "webui",
        "rag-knowledge-base-qa"
      ],
      "likes": 231540,
      "downloads": 231540,
      "lastModified": "2025-11-20T15:46:30Z",
      "lastModifiedTimestamp": 1763653590000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/open-webui/open-webui",
          "homepage": "https://openwebui.com",
          "language": "JavaScript",
          "forks": 16219,
          "open_issues": 304,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/158137808?v=4",
      "velocity": 127347,
      "is_rising_star": true,
      "heatScore": 38207.64451984924,
      "popularityScore": 115770
    },
    {
      "id": "github-iflytek-astron-agent",
      "name": "astron-agent",
      "author": "iflytek",
      "description": "Enterprise-grade, commercial-friendly agentic workflow platform for building next-generation SuperAgents.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-workflow",
        "ai",
        "enterprise",
        "llm",
        "low-code",
        "mcp",
        "multi-agent",
        "next-gen",
        "orchestration",
        "python",
        "superagent",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 12498,
      "downloads": 12498,
      "lastModified": "2025-11-20T15:46:29Z",
      "lastModifiedTimestamp": 1763653589000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/iflytek/astron-agent",
          "homepage": "https://agent.xfyun.cn",
          "language": "Java",
          "forks": 1007,
          "open_issues": 18,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/26786495?v=4",
      "velocity": 6873.9,
      "is_rising_star": true,
      "heatScore": 2064.8271160121403,
      "popularityScore": 6249
    },
    {
      "id": "github-bytebot-ai-bytebot",
      "name": "bytebot",
      "author": "bytebot-ai",
      "description": "Bytebot is a self-hosted AI desktop agent that automates computer tasks through natural language commands, operating within a containerized Linux desktop environment.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "ai-tools",
        "anthropic",
        "automation",
        "bytebot",
        "computer-use",
        "computer-use-agent",
        "cua",
        "desktop",
        "desktop-automation",
        "docker",
        "gemini",
        "llm",
        "mcp",
        "openai"
      ],
      "likes": 19400,
      "downloads": 19400,
      "lastModified": "2025-11-20T15:46:03Z",
      "lastModifiedTimestamp": 1763653563000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/bytebot-ai/bytebot",
          "homepage": "https://www.bytebot.ai/",
          "language": "TypeScript",
          "forks": 1222,
          "open_issues": 57,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/154629106?v=4",
      "velocity": 10670,
      "is_rising_star": true,
      "heatScore": 3203.7907715532097,
      "popularityScore": 9700
    },
    {
      "id": "github-QwenLM-Qwen",
      "name": "Qwen",
      "author": "QwenLM",
      "description": "The official repo of Qwen (ÈÄö‰πâÂçÉÈóÆ) chat & pretrained large language model proposed by Alibaba Cloud.",
      "task": "tool",
      "tags": [
        "chinese",
        "flash-attention",
        "large-language-models",
        "llm",
        "natural-language-processing",
        "pretrained-models",
        "general-dialogue-qa"
      ],
      "likes": 39520,
      "downloads": 39520,
      "lastModified": "2025-11-20T15:46:01Z",
      "lastModifiedTimestamp": 1763653561000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/QwenLM/Qwen",
          "homepage": "",
          "language": "Python",
          "forks": 1651,
          "open_issues": 75,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/141221163?v=4",
      "velocity": 21736,
      "is_rising_star": true,
      "heatScore": 6523.807066242713,
      "popularityScore": 19760
    },
    {
      "id": "github-SWE-agent-SWE-agent",
      "name": "SWE-agent",
      "author": "SWE-agent",
      "description": "SWE-agent takes a GitHub issue and tries to automatically fix it, using your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges. [NeurIPS 2024] ",
      "task": "tool",
      "tags": [
        "agent",
        "agent-based-model",
        "ai",
        "cybersecurity",
        "developer-tools",
        "llm",
        "lms",
        "code-generation-assistance"
      ],
      "likes": 35628,
      "downloads": 35628,
      "lastModified": "2025-11-20T15:45:38Z",
      "lastModifiedTimestamp": 1763653538000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/SWE-agent/SWE-agent",
          "homepage": "https://swe-agent.com",
          "language": "Python",
          "forks": 1887,
          "open_issues": 64,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/166046056?v=4",
      "velocity": 19595.4,
      "is_rising_star": true,
      "heatScore": 5881.59555007868,
      "popularityScore": 17814
    },
    {
      "id": "github-huggingface-smolagents",
      "name": "smolagents",
      "author": "huggingface",
      "description": "ü§ó smolagents: a barebones library for agents that think in code.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 48104,
      "downloads": 48104,
      "lastModified": "2025-11-20T15:45:37Z",
      "lastModifiedTimestamp": 1763653537000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/smolagents",
          "homepage": "https://huggingface.co/docs/smolagents",
          "language": "Python",
          "forks": 2139,
          "open_issues": 316,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 26457.2,
      "is_rising_star": true,
      "heatScore": 7940.226818475895,
      "popularityScore": 24052
    },
    {
      "id": "github-OpenHands-OpenHands",
      "name": "OpenHands",
      "author": "OpenHands",
      "description": "üôå OpenHands: Code Less, Make More",
      "task": "tool",
      "tags": [
        "agent",
        "artificial-intelligence",
        "chatgpt",
        "claude-ai",
        "cli",
        "developer-tools",
        "gpt",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 130236,
      "downloads": 130236,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenHands/OpenHands",
          "homepage": "https://all-hands.dev",
          "language": "Python",
          "forks": 7937,
          "open_issues": 211,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/225919603?v=4",
      "velocity": 71629.8,
      "is_rising_star": true,
      "heatScore": 21492.30959540588,
      "popularityScore": 65118
    },
    {
      "id": "github-unslothai-unsloth",
      "name": "unsloth",
      "author": "unslothai",
      "description": "Fine-tuning & Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.",
      "task": "tool",
      "tags": [
        "agent",
        "deepseek",
        "deepseek-r1",
        "fine-tuning",
        "gemma",
        "gemma3",
        "gpt-oss",
        "llama",
        "llama3",
        "llm",
        "llms",
        "mistral",
        "openai",
        "qwen",
        "qwen3",
        "reinforcement-learning",
        "text-to-speech",
        "tts",
        "unsloth",
        "voice-cloning"
      ],
      "likes": 96990,
      "downloads": 96990,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unslothai/unsloth",
          "homepage": "https://docs.unsloth.ai/",
          "language": "Python",
          "forks": 3989,
          "open_issues": 856,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/150920049?v=4",
      "velocity": 53344.5,
      "is_rising_star": true,
      "heatScore": 16006.629994143315,
      "popularityScore": 48495
    },
    {
      "id": "github-labring-FastGPT",
      "name": "FastGPT",
      "author": "labring",
      "description": "FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.",
      "task": "tool",
      "tags": [
        "agent",
        "claude",
        "deepseek",
        "llm",
        "mcp",
        "nextjs",
        "openai",
        "qwen",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 52648,
      "downloads": 52648,
      "lastModified": "2025-11-20T15:45:26Z",
      "lastModifiedTimestamp": 1763653526000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/labring/FastGPT",
          "homepage": "https://fastgpt.io",
          "language": "TypeScript",
          "forks": 6777,
          "open_issues": 653,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102226726?v=4",
      "velocity": 28956.4,
      "is_rising_star": true,
      "heatScore": 8690.0142578659,
      "popularityScore": 26324
    },
    {
      "id": "github-mlflow-mlflow",
      "name": "mlflow",
      "author": "mlflow",
      "description": "The open source developer platform to build AI agents and models with confidence. Enhance your AI applications with end-to-end tracking, observability, and evaluations, all in one integrated platform.",
      "task": "tool",
      "tags": [
        "agentops",
        "agents",
        "ai",
        "ai-governance",
        "apache-spark",
        "evaluation",
        "langchain",
        "llm-evaluation",
        "llmops",
        "machine-learning",
        "ml",
        "mlflow",
        "mlops",
        "model-management",
        "observability",
        "open-source",
        "openai",
        "prompt-engineering"
      ],
      "likes": 46028,
      "downloads": 46028,
      "lastModified": "2025-11-20T15:45:22Z",
      "lastModifiedTimestamp": 1763653522000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mlflow/mlflow",
          "homepage": "https://mlflow.org",
          "language": "Python",
          "forks": 5008,
          "open_issues": 2083,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/39938107?v=4",
      "velocity": 25315.4,
      "is_rising_star": true,
      "heatScore": 7597.673407685461,
      "popularityScore": 23014
    },
    {
      "id": "github-huggingface-transformers",
      "name": "transformers",
      "author": "huggingface",
      "description": "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
      "task": "tool",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "likes": 305558,
      "downloads": 305558,
      "lastModified": "2025-11-20T15:45:12Z",
      "lastModifiedTimestamp": 1763653512000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/transformers",
          "homepage": "https://huggingface.co/transformers",
          "language": "Python",
          "forks": 31187,
          "open_issues": 2121,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 168056.9,
      "is_rising_star": true,
      "heatScore": 50420.69884655398,
      "popularityScore": 152779
    },
    {
      "id": "github-milvus-io-milvus",
      "name": "milvus",
      "author": "milvus-io",
      "description": "Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search",
      "task": "tool",
      "tags": [
        "anns",
        "cloud-native",
        "diskann",
        "distributed",
        "embedding-database",
        "embedding-similarity",
        "embedding-store",
        "faiss",
        "golang",
        "hnsw",
        "image-search",
        "llm",
        "nearest-neighbor-search",
        "rag",
        "vector-database",
        "vector-search",
        "vector-similarity",
        "vector-store",
        "rag-knowledge-base-qa"
      ],
      "likes": 79350,
      "downloads": 79350,
      "lastModified": "2025-11-20T15:45:07Z",
      "lastModifiedTimestamp": 1763653507000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/milvus-io/milvus",
          "homepage": "https://milvus.io",
          "language": "Go",
          "forks": 3586,
          "open_issues": 905,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/51735404?v=4",
      "velocity": 43642.5,
      "is_rising_star": true,
      "heatScore": 13095.968969517113,
      "popularityScore": 39675
    },
    {
      "id": "github-openai-agents.md",
      "name": "agents.md",
      "author": "openai",
      "description": "AGENTS.md ‚Äî a simple, open format for guiding coding agents",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 16804,
      "downloads": 16804,
      "lastModified": "2025-11-20T15:45:02Z",
      "lastModifiedTimestamp": 1763653502000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/openai/agents.md",
          "homepage": "https://agents.md",
          "language": "TypeScript",
          "forks": 655,
          "open_issues": 82,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/14957082?v=4",
      "velocity": 9242.2,
      "is_rising_star": true,
      "heatScore": 2775.4071040544804,
      "popularityScore": 8402
    },
    {
      "id": "github-vanna-ai-vanna",
      "name": "vanna",
      "author": "vanna-ai",
      "description": "ü§ñ Chat with your SQL database üìä. Accurate Text-to-SQL Generation via LLMs using Agentic Retrieval üîÑ.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "data-visualization",
        "database",
        "llm",
        "rag",
        "sql",
        "text-to-sql",
        "rag-knowledge-base-qa",
        "data-analysis-insights",
        "general-dialogue-qa"
      ],
      "likes": 43346,
      "downloads": 43346,
      "lastModified": "2025-11-20T15:44:55Z",
      "lastModifiedTimestamp": 1763653495000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/vanna-ai/vanna",
          "homepage": "https://vanna.ai/docs/",
          "language": "Python",
          "forks": 2041,
          "open_issues": 240,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/132533812?v=4",
      "velocity": 23840.3,
      "is_rising_star": true,
      "heatScore": 7155.125157348321,
      "popularityScore": 21673
    },
    {
      "id": "github-openvinotoolkit-openvino",
      "name": "openvino",
      "author": "openvinotoolkit",
      "description": "OpenVINO‚Ñ¢ is an open source toolkit for optimizing and deploying AI inference",
      "task": "tool",
      "tags": [
        "ai",
        "computer-vision",
        "deep-learning",
        "deploy-ai",
        "diffusion-models",
        "generative-ai",
        "good-first-issue",
        "inference",
        "llm-inference",
        "natural-language-processing",
        "nlp",
        "openvino",
        "optimize-ai",
        "performance-boost",
        "recommendation-system",
        "speech-recognition",
        "stable-diffusion",
        "transformers",
        "yolo"
      ],
      "likes": 18456,
      "downloads": 18456,
      "lastModified": "2025-11-20T15:44:49Z",
      "lastModifiedTimestamp": 1763653489000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/openvinotoolkit/openvino",
          "homepage": "https://docs.openvino.ai",
          "language": "C++",
          "forks": 2831,
          "open_issues": 558,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/55443902?v=4",
      "velocity": 10150.8,
      "is_rising_star": true,
      "heatScore": 3048.0156082521908,
      "popularityScore": 9228
    },
    {
      "id": "github-wshobson-agents",
      "name": "agents",
      "author": "wshobson",
      "description": "Intelligent automation and multi-agent orchestration for Claude Code",
      "task": "tool",
      "tags": [
        "agents",
        "ai-agents",
        "anthropic",
        "anthropic-claude",
        "automation",
        "claude",
        "claude-code",
        "claude-code-cli",
        "claude-code-commands",
        "claude-code-plugin",
        "claude-code-plugins",
        "claude-code-subagents",
        "claude-skills",
        "claudecode",
        "claudecode-config",
        "claudecode-subagents",
        "orchestration",
        "sub-agents",
        "subagents",
        "workflows",
        "agent-computer-interface",
        "computer-automation",
        "computer-use",
        "computer-use-agent",
        "cua",
        "grounding",
        "gui-agents",
        "in-context-reinforcement-learning",
        "memory",
        "mllm",
        "planning",
        "retrieval-augmented-generation",
        "ai",
        "openai",
        "real-time",
        "video",
        "voice",
        "autonomous-agents",
        "language-model",
        "llm",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 106916,
      "downloads": 106916,
      "lastModified": "2025-11-20T15:44:42Z",
      "lastModifiedTimestamp": 1763653482000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/wshobson/agents",
          "homepage": "https://sethhobson.com",
          "language": "Python",
          "forks": 2352,
          "open_issues": 4,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/contains-studio/agents",
          "homepage": null,
          "language": null,
          "forks": 2129,
          "open_issues": 9,
          "license": "No license"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/simular-ai/Agent-S",
          "homepage": "https://www.simular.ai",
          "language": "Python",
          "forks": 907,
          "open_issues": 13,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/livekit/agents",
          "homepage": "https://docs.livekit.io/agents",
          "language": "Python",
          "forks": 1776,
          "open_issues": 448,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/aiwaves-cn/agents",
          "homepage": "",
          "language": "Python",
          "forks": 452,
          "open_issues": 39,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
      "velocity": 58803.8,
      "is_rising_star": true,
      "heatScore": 17644.44961458143,
      "popularityScore": 53458
    },
    {
      "id": "github-sgl-project-sglang",
      "name": "sglang",
      "author": "sgl-project",
      "description": "SGLang is a fast serving framework for large language models and vision language models.",
      "task": "tool",
      "tags": [
        "blackwell",
        "cuda",
        "deepseek",
        "deepseek-r1",
        "deepseek-v3",
        "deepseek-v3-2",
        "gpt-oss",
        "inference",
        "kimi",
        "llama",
        "llama3",
        "llava",
        "llm",
        "llm-serving",
        "moe",
        "openai",
        "pytorch",
        "qwen3",
        "transformer",
        "vlm"
      ],
      "likes": 40532,
      "downloads": 40532,
      "lastModified": "2025-11-20T15:44:39Z",
      "lastModifiedTimestamp": 1763653479000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sgl-project/sglang",
          "homepage": "https://docs.sglang.ai/",
          "language": "Python",
          "forks": 3463,
          "open_issues": 1477,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/147780389?v=4",
      "velocity": 22292.6,
      "is_rising_star": true,
      "heatScore": 6690.794752627246,
      "popularityScore": 20266
    },
    {
      "id": "github-mcp-use-mcp-use",
      "name": "mcp-use",
      "author": "mcp-use",
      "description": "mcp-use is the easiest way to interact with mcp servers with custom agents",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai",
        "mcp",
        "mcp-client",
        "model-context-protocol",
        "model-context-protocol-client",
        "model-context-protocol-sdk",
        "python"
      ],
      "likes": 16542,
      "downloads": 16542,
      "lastModified": "2025-11-20T15:44:25Z",
      "lastModifiedTimestamp": 1763653465000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mcp-use/mcp-use",
          "homepage": "https://mcp-use.com",
          "language": "TypeScript",
          "forks": 982,
          "open_issues": 39,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/207005519?v=4",
      "velocity": 9098.1,
      "is_rising_star": true,
      "heatScore": 2732.1723273680245,
      "popularityScore": 8271
    },
    {
      "id": "github-kvcache-ai-ktransformers",
      "name": "ktransformers",
      "author": "kvcache-ai",
      "description": "A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations",
      "task": "tool",
      "tags": [],
      "likes": 31632,
      "downloads": 31632,
      "lastModified": "2025-11-20T15:44:06Z",
      "lastModifiedTimestamp": 1763653446000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/kvcache-ai/ktransformers",
          "homepage": "https://kvcache-ai.github.io/ktransformers/",
          "language": "Python",
          "forks": 1147,
          "open_issues": 655,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/170996193?v=4",
      "velocity": 17397.6,
      "is_rising_star": true,
      "heatScore": 5222.219386880236,
      "popularityScore": 15816
    },
    {
      "id": "github-nrwl-nx",
      "name": "nx",
      "author": "nrwl",
      "description": "Get to green PRs in half the time. Nx optimizes your builds, scales your CI, and fixes failed PRs. Built for developers and AI agents.",
      "task": "tool",
      "tags": [
        "angular",
        "build",
        "build-system",
        "build-tool",
        "building-tool",
        "cli",
        "cypress",
        "hacktoberfest",
        "javascript",
        "monorepo",
        "nextjs",
        "nodejs",
        "nx",
        "nx-workspaces",
        "react",
        "storybook",
        "typescript"
      ],
      "likes": 55054,
      "downloads": 55054,
      "lastModified": "2025-11-20T15:43:56Z",
      "lastModifiedTimestamp": 1763653436000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nrwl/nx",
          "homepage": "https://nx.dev",
          "language": "TypeScript",
          "forks": 2623,
          "open_issues": 789,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23692104?v=4",
      "velocity": 30279.7,
      "is_rising_star": true,
      "heatScore": 9087.017842261728,
      "popularityScore": 27527
    },
    {
      "id": "github-emcie-co-parlant",
      "name": "parlant",
      "author": "emcie-co",
      "description": "LLM agents built for control. Designed for real-world use. Deployed in minutes.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "ai-alignment",
        "customer-service",
        "customer-success",
        "gemini",
        "genai",
        "hacktoberfest",
        "llama3",
        "llm",
        "openai",
        "python"
      ],
      "likes": 32598,
      "downloads": 32598,
      "lastModified": "2025-11-20T15:43:43Z",
      "lastModifiedTimestamp": 1763653423000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/emcie-co/parlant",
          "homepage": "https://www.parlant.io",
          "language": "Python",
          "forks": 1357,
          "open_issues": 46,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/160175171?v=4",
      "velocity": 17928.9,
      "is_rising_star": true,
      "heatScore": 5381.618531323083,
      "popularityScore": 16299
    },
    {
      "id": "github-wdndev-llm_interview_note",
      "name": "llm_interview_note",
      "author": "wdndev",
      "description": "‰∏ªË¶ÅËÆ∞ÂΩïÂ§ßËØ≠Ë®ÄÂ§ßÊ®°ÂûãÔºàLLMsÔºâ ÁÆóÊ≥ïÔºàÂ∫îÁî®ÔºâÂ∑•Á®ãÂ∏àÁõ∏ÂÖ≥ÁöÑÁü•ËØÜÂèäÈù¢ËØïÈ¢ò",
      "task": "tool",
      "tags": [
        "interview",
        "llm",
        "llm-interview",
        "llms"
      ],
      "likes": 21896,
      "downloads": 21896,
      "lastModified": "2025-11-20T15:43:36Z",
      "lastModifiedTimestamp": 1763653416000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/wdndev/llm_interview_note",
          "homepage": "https://wdndev.github.io/llm_interview_note",
          "language": "HTML",
          "forks": 1114,
          "open_issues": 20,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/83126264?v=4",
      "velocity": 12042.8,
      "is_rising_star": true,
      "heatScore": 3615.6675621190375,
      "popularityScore": 10948
    },
    {
      "id": "github-steel-dev-steel-browser",
      "name": "steel-browser",
      "author": "steel-dev",
      "description": "üî• Open Source Browser API for AI Agents & Apps. Steel Browser is a batteries-included browser sandbox that lets you automate the web without worrying about infrastructure.",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-tools",
        "browser-automation",
        "llm"
      ],
      "likes": 11964,
      "downloads": 11964,
      "lastModified": "2025-11-20T15:43:34Z",
      "lastModifiedTimestamp": 1763653414000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/steel-dev/steel-browser",
          "homepage": "https://steel.dev",
          "language": "TypeScript",
          "forks": 911,
          "open_issues": 19,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/183960033?v=4",
      "velocity": 6580.2,
      "is_rising_star": true,
      "heatScore": 1976.7038433019893,
      "popularityScore": 5982
    },
    {
      "id": "github-camel-ai-camel",
      "name": "camel",
      "author": "camel-ai",
      "description": "üê´ CAMEL: The first and the best multi-agent framework. Finding the Scaling Law of Agents. https://www.camel-ai.org",
      "task": "tool",
      "tags": [
        "agent",
        "ai-societies",
        "artificial-intelligence",
        "communicative-ai",
        "cooperative-ai",
        "deep-learning",
        "large-language-models",
        "multi-agent-systems",
        "natural-language-processing"
      ],
      "likes": 29706,
      "downloads": 29706,
      "lastModified": "2025-11-20T15:43:11Z",
      "lastModifiedTimestamp": 1763653391000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/camel-ai/camel",
          "homepage": "https://docs.camel-ai.org/",
          "language": "Python",
          "forks": 1636,
          "open_issues": 599,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134388954?v=4",
      "velocity": 16338.3,
      "is_rising_star": true,
      "heatScore": 4904.4102903937055,
      "popularityScore": 14853
    },
    {
      "id": "github-microsoft-ai-agents-for-beginners",
      "name": "ai-agents-for-beginners",
      "author": "microsoft",
      "description": "12 Lessons to Get Started Building AI Agents",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-framework",
        "agentic-rag",
        "ai-agents",
        "ai-agents-framework",
        "autogen",
        "generative-ai",
        "semantic-kernel"
      ],
      "likes": 90478,
      "downloads": 90478,
      "lastModified": "2025-11-20T15:42:34Z",
      "lastModifiedTimestamp": 1763653354000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/ai-agents-for-beginners",
          "homepage": "https://aka.ms/ai-agents-beginners",
          "language": "Jupyter Notebook",
          "forks": 15356,
          "open_issues": 11,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 49762.9,
      "is_rising_star": true,
      "heatScore": 14932.128865817376,
      "popularityScore": 45239
    },
    {
      "id": "github-langbot-app-LangBot",
      "name": "LangBot",
      "author": "langbot-app",
      "description": "ü§© Production-grade  platform for building IM bots / Áîü‰∫ßÁ∫ßÂ§ßÊ®°ÂûãÂç≥Êó∂ÈÄö‰ø°Êú∫Âô®‰∫∫ÂºÄÂèëÂπ≥Âè∞ ‚ö°Ô∏è Bots for QQ / QQÈ¢ëÈÅì / Discord / LINE / WeChat(ÂæÆ‰ø°, ‰ºÅ‰∏öÂæÆ‰ø°)/ Telegram / È£û‰π¶ / ÈíâÈíâ / Slack üß© Integrated with ChatGPT(GPT), DeepSeek, Dify, n8n, Langflow, Coze, Claude, Google Gemini, Kimi, PPIO, Ollama, MiniMax, SiliconFlow, Qwen, Moonshot, MCP etc. LLM & Agent & RAG",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "coze",
        "deepseek",
        "dify",
        "dingtalk",
        "discord",
        "feishu",
        "langbot",
        "lark",
        "line",
        "llm",
        "n8n",
        "ollama",
        "openai",
        "plugins",
        "qq",
        "rag",
        "telegram",
        "wechat",
        "rag-knowledge-base-qa",
        "general-dialogue-qa"
      ],
      "likes": 28090,
      "downloads": 28090,
      "lastModified": "2025-11-20T15:41:53Z",
      "lastModifiedTimestamp": 1763653313000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langbot-app/LangBot",
          "homepage": "https://langbot.app",
          "language": "Python",
          "forks": 1161,
          "open_issues": 108,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/189527454?v=4",
      "velocity": 15449.5,
      "is_rising_star": true,
      "heatScore": 4637.753286864856,
      "popularityScore": 14045
    },
    {
      "id": "github-miurla-morphic",
      "name": "morphic",
      "author": "miurla",
      "description": "An AI-powered search engine with a generative UI",
      "task": "tool",
      "tags": [
        "deepseek-r1",
        "generative-ai",
        "generative-ui",
        "nextjs",
        "ollama",
        "react",
        "redis",
        "searxng",
        "shadcn-ui",
        "tailwindcss",
        "tavily",
        "typescript",
        "upstash",
        "vercel-ai-sdk"
      ],
      "likes": 16702,
      "downloads": 16702,
      "lastModified": "2025-11-20T15:40:39Z",
      "lastModifiedTimestamp": 1763653239000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/miurla/morphic",
          "homepage": "https://morphic.sh",
          "language": "TypeScript",
          "forks": 2281,
          "open_issues": 53,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/3412179?v=4",
      "velocity": 9186.1,
      "is_rising_star": true,
      "heatScore": 2758.5752533399605,
      "popularityScore": 8351
    },
    {
      "id": "github-1Panel-dev-1Panel",
      "name": "1Panel",
      "author": "1Panel-dev",
      "description": "üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.",
      "task": "tool",
      "tags": [
        "1panel",
        "cockpit",
        "docker",
        "docker-ui",
        "lamp",
        "linux",
        "lnmp",
        "ollama",
        "webmin"
      ],
      "likes": 64204,
      "downloads": 64204,
      "lastModified": "2025-11-20T15:40:23Z",
      "lastModifiedTimestamp": 1763653223000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/1Panel-dev/1Panel",
          "homepage": "https://1panel.pro",
          "language": "Go",
          "forks": 2842,
          "open_issues": 302,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/109613420?v=4",
      "velocity": 35312.2,
      "is_rising_star": true,
      "heatScore": 10596.814581933142,
      "popularityScore": 32102
    },
    {
      "id": "github-cline-cline",
      "name": "cline",
      "author": "cline",
      "description": "Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 105064,
      "downloads": 105064,
      "lastModified": "2025-11-20T15:39:22Z",
      "lastModifiedTimestamp": 1763653162000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/cline/cline",
          "homepage": "https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev",
          "language": "TypeScript",
          "forks": 5246,
          "open_issues": 895,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/184127137?v=4",
      "velocity": 57785.2,
      "is_rising_star": true,
      "heatScore": 17338.864302541922,
      "popularityScore": 52532
    },
    {
      "id": "github-topoteretes-cognee",
      "name": "cognee",
      "author": "topoteretes",
      "description": "Memory for AI Agents in 6 lines of code",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-memory",
        "cognitive-architecture",
        "cognitive-memory",
        "context-engineering",
        "contributions-welcome",
        "good-first-issue",
        "good-first-pr",
        "graph-database",
        "graph-rag",
        "graphrag",
        "help-wanted",
        "knowledge",
        "knowledge-graph",
        "neo4j",
        "open-source",
        "openai",
        "rag",
        "vector-database",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 17754,
      "downloads": 17754,
      "lastModified": "2025-11-20T15:39:14Z",
      "lastModifiedTimestamp": 1763653154000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/topoteretes/cognee",
          "homepage": "https://docs.cognee.ai",
          "language": "Python",
          "forks": 822,
          "open_issues": 58,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/125468716?v=4",
      "velocity": 9764.7,
      "is_rising_star": true,
      "heatScore": 2932.173820598483,
      "popularityScore": 8877
    },
    {
      "id": "github-oumi-ai-oumi",
      "name": "oumi",
      "author": "oumi-ai",
      "description": "Easily fine-tune, evaluate and deploy gpt-oss, Qwen3, DeepSeek-R1, or any open source LLM / VLM!",
      "task": "tool",
      "tags": [
        "dpo",
        "evaluation",
        "fine-tuning",
        "gpt-oss",
        "gpt-oss-120b",
        "gpt-oss-20b",
        "inference",
        "llama",
        "llms",
        "sft",
        "slms",
        "vlms"
      ],
      "likes": 17340,
      "downloads": 17340,
      "lastModified": "2025-11-20T15:39:04Z",
      "lastModifiedTimestamp": 1763653144000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/oumi-ai/oumi",
          "homepage": "https://oumi.ai",
          "language": "Python",
          "forks": 667,
          "open_issues": 12,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/167452922?v=4",
      "velocity": 9537,
      "is_rising_star": true,
      "heatScore": 2863.8566484303565,
      "popularityScore": 8670
    },
    {
      "id": "github-google-adk-python",
      "name": "adk-python",
      "author": "google",
      "description": "An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic",
        "agentic-ai",
        "agents",
        "agents-sdk",
        "ai",
        "ai-agents",
        "aiagentframework",
        "genai",
        "genai-chatbot",
        "llm",
        "llms",
        "multi-agent",
        "multi-agent-systems",
        "multi-agents",
        "multi-agents-collaboration",
        "code-generation-assistance"
      ],
      "likes": 30736,
      "downloads": 30736,
      "lastModified": "2025-11-20T15:39:00Z",
      "lastModifiedTimestamp": 1763653140000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/google/adk-python",
          "homepage": "https://google.github.io/adk-docs/",
          "language": "Python",
          "forks": 2409,
          "open_issues": 424,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1342004?v=4",
      "velocity": 16904.8,
      "is_rising_star": true,
      "heatScore": 5074.3706519274165,
      "popularityScore": 15368
    }
  ],
  "rising": [
    {
      "id": "github-ollama-ollama",
      "name": "ollama",
      "author": "ollama",
      "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "task": "tool",
      "tags": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "likes": 312577,
      "downloads": 312577,
      "lastModified": "2025-11-20T15:51:00Z",
      "lastModifiedTimestamp": 1763653860000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ollama/ollama",
          "homepage": "https://ollama.com",
          "language": "Go",
          "forks": 13697,
          "open_issues": 2258,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/151674099?v=4",
      "velocity": 171916.8,
      "is_rising_star": true,
      "heatScore": 51578.675749888665,
      "popularityScore": 156288
    },
    {
      "id": "github-huggingface-transformers",
      "name": "transformers",
      "author": "huggingface",
      "description": "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
      "task": "tool",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "likes": 305558,
      "downloads": 305558,
      "lastModified": "2025-11-20T15:45:12Z",
      "lastModifiedTimestamp": 1763653512000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/transformers",
          "homepage": "https://huggingface.co/transformers",
          "language": "Python",
          "forks": 31187,
          "open_issues": 2121,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 168056.9,
      "is_rising_star": true,
      "heatScore": 50420.69884655398,
      "popularityScore": 152779
    },
    {
      "id": "github-langflow-ai-langflow",
      "name": "langflow",
      "author": "langflow-ai",
      "description": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
      "task": "tool",
      "tags": [
        "agents",
        "chatgpt",
        "generative-ai",
        "large-language-models",
        "multiagent",
        "react-flow"
      ],
      "likes": 277624,
      "downloads": 277624,
      "lastModified": "2025-11-20T15:36:15Z",
      "lastModifiedTimestamp": 1763652975000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langflow-ai/langflow",
          "homepage": "http://www.langflow.org",
          "language": "Python",
          "forks": 8027,
          "open_issues": 902,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85702467?v=4",
      "velocity": 152693.2,
      "is_rising_star": true,
      "heatScore": 45811.559701098144,
      "popularityScore": 138812
    },
    {
      "id": "github-f-awesome-chatgpt-prompts",
      "name": "awesome-chatgpt-prompts",
      "author": "f",
      "description": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
      "task": "tool",
      "tags": [
        "bots",
        "chatbot",
        "chatgpt",
        "chatgpt-api",
        "language",
        "general-dialogue-qa"
      ],
      "likes": 273424,
      "downloads": 273424,
      "lastModified": "2025-11-20T15:23:26Z",
      "lastModifiedTimestamp": 1763652206000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/f/awesome-chatgpt-prompts",
          "homepage": "https://prompts.chat",
          "language": "JavaScript",
          "forks": 18184,
          "open_issues": 290,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/196477?v=4",
      "velocity": 150383.2,
      "is_rising_star": true,
      "heatScore": 45118.55506686943,
      "popularityScore": 136712
    },
    {
      "id": "github-langchain-ai-langchain",
      "name": "langchain",
      "author": "langchain-ai",
      "description": "ü¶úüîó The platform for reliable agents.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "ai-agents-framework",
        "aiagentframework",
        "anthropic",
        "chatgpt",
        "enterprise",
        "framework",
        "gemini",
        "generative-ai",
        "langchain",
        "llm",
        "multiagent",
        "open-source",
        "openai",
        "pydantic",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 240248,
      "downloads": 240248,
      "lastModified": "2025-11-20T15:50:06Z",
      "lastModifiedTimestamp": 1763653806000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langchain-ai/langchain",
          "homepage": "https://docs.langchain.com/oss/python/langchain/",
          "language": "Python",
          "forks": 19786,
          "open_issues": 241,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
      "velocity": 132136.4,
      "is_rising_star": true,
      "heatScore": 39644.47574338047,
      "popularityScore": 120124
    },
    {
      "id": "github-langgenius-dify",
      "name": "dify",
      "author": "langgenius",
      "description": "Production-ready platform for agentic workflow development.",
      "task": "tool",
      "tags": [
        "agent",
        "agentic-ai",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "automation",
        "gemini",
        "genai",
        "gpt",
        "gpt-4",
        "llm",
        "low-code",
        "mcp",
        "nextjs",
        "no-code",
        "openai",
        "orchestration",
        "python",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 238804,
      "downloads": 238804,
      "lastModified": "2025-11-20T15:50:01Z",
      "lastModifiedTimestamp": 1763653801000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/langgenius/dify",
          "homepage": "https://dify.ai",
          "language": "TypeScript",
          "forks": 18511,
          "open_issues": 682,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127165244?v=4",
      "velocity": 131342.2,
      "is_rising_star": true,
      "heatScore": 39406.21391066701,
      "popularityScore": 119402
    },
    {
      "id": "github-open-webui-open-webui",
      "name": "open-webui",
      "author": "open-webui",
      "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
      "task": "tool",
      "tags": [
        "ai",
        "llm",
        "llm-ui",
        "llm-webui",
        "llms",
        "mcp",
        "ollama",
        "ollama-webui",
        "open-webui",
        "openai",
        "openapi",
        "rag",
        "self-hosted",
        "ui",
        "webui",
        "rag-knowledge-base-qa"
      ],
      "likes": 231540,
      "downloads": 231540,
      "lastModified": "2025-11-20T15:46:30Z",
      "lastModifiedTimestamp": 1763653590000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/open-webui/open-webui",
          "homepage": "https://openwebui.com",
          "language": "JavaScript",
          "forks": 16219,
          "open_issues": 304,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/158137808?v=4",
      "velocity": 127347,
      "is_rising_star": true,
      "heatScore": 38207.64451984924,
      "popularityScore": 115770
    },
    {
      "id": "github-microsoft-generative-ai-for-beginners",
      "name": "generative-ai-for-beginners",
      "author": "microsoft",
      "description": "21 Lessons, Get Started Building with Generative AI ",
      "task": "tool",
      "tags": [
        "ai",
        "azure",
        "chatgpt",
        "dall-e",
        "generative-ai",
        "generativeai",
        "gpt",
        "language-model",
        "llms",
        "microsoft-for-beginners",
        "openai",
        "prompt-engineering",
        "semantic-search",
        "transformers"
      ],
      "likes": 204088,
      "downloads": 204088,
      "lastModified": "2025-11-20T15:11:49Z",
      "lastModifiedTimestamp": 1763651509000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/generative-ai-for-beginners",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 54251,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 112248.4,
      "is_rising_star": true,
      "heatScore": 33678.02615421101,
      "popularityScore": 102044
    },
    {
      "id": "github-x1xhlol-system-prompts-and-models-of-ai-tools",
      "name": "system-prompts-and-models-of-ai-tools",
      "author": "x1xhlol",
      "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
      "task": "tool",
      "tags": [
        "ai",
        "bolt",
        "cluely",
        "copilot",
        "cursor",
        "cursorai",
        "devin",
        "github-copilot",
        "lovable",
        "open-source",
        "perplexity",
        "replit",
        "system-prompts",
        "trae",
        "trae-ai",
        "trae-ide",
        "v0",
        "vscode",
        "windsurf",
        "windsurf-ai",
        "code-generation-assistance"
      ],
      "likes": 193011,
      "downloads": 193011,
      "lastModified": "2025-11-20T15:52:37Z",
      "lastModifiedTimestamp": 1763653957000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
          "homepage": "",
          "language": null,
          "forks": 25948,
          "open_issues": 94,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/185671340?v=4",
      "velocity": 106155.5,
      "is_rising_star": true,
      "heatScore": 31850.139188020687,
      "popularityScore": 96505
    },
    {
      "id": "github-ggml-org-llama.cpp",
      "name": "llama.cpp",
      "author": "ggml-org",
      "description": "LLM inference in C/C++",
      "task": "tool",
      "tags": [
        "ggml"
      ],
      "likes": 180265,
      "downloads": 180265,
      "lastModified": "2025-11-20T15:53:48Z",
      "lastModifiedTimestamp": 1763654028000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ggml-org/llama.cpp",
          "homepage": "",
          "language": "C++",
          "forks": 13769,
          "open_issues": 893,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134263123?v=4",
      "velocity": 99145.2,
      "is_rising_star": true,
      "heatScore": 29747.0284186785,
      "popularityScore": 90132
    },
    {
      "id": "github-google-gemini-gemini-cli",
      "name": "gemini-cli",
      "author": "google-gemini",
      "description": "An open-source AI agent that brings the power of Gemini directly into your terminal.",
      "task": "tool",
      "tags": [
        "gemini",
        "gemini-api"
      ],
      "likes": 167383,
      "downloads": 167383,
      "lastModified": "2025-11-20T15:52:04Z",
      "lastModifiedTimestamp": 1763653924000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/google-gemini/gemini-cli",
          "homepage": "https://geminicli.com",
          "language": "TypeScript",
          "forks": 9443,
          "open_issues": 3033,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/161781182?v=4",
      "velocity": 92060.1,
      "is_rising_star": true,
      "heatScore": 27621.47587876247,
      "popularityScore": 83691
    },
    {
      "id": "github-Shubhamsaboo-awesome-llm-apps",
      "name": "awesome-llm-apps",
      "author": "Shubhamsaboo",
      "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
      "task": "tool",
      "tags": [
        "llms",
        "python",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 158413,
      "downloads": 158413,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
          "homepage": "https://www.theunwindai.com",
          "language": "Python",
          "forks": 10579,
          "open_issues": 3,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/31396011?v=4",
      "velocity": 87126.6,
      "is_rising_star": true,
      "heatScore": 26141.409134495156,
      "popularityScore": 79206
    },
    {
      "id": "github-rasbt-LLMs-from-scratch",
      "name": "LLMs-from-scratch",
      "author": "rasbt",
      "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "deep-learning",
        "from-scratch",
        "generative-ai",
        "gpt",
        "language-model",
        "large-language-models",
        "llm",
        "machine-learning",
        "neural-networks",
        "python",
        "pytorch",
        "transformers",
        "general-dialogue-qa"
      ],
      "likes": 158122,
      "downloads": 158122,
      "lastModified": "2025-11-20T15:46:33Z",
      "lastModifiedTimestamp": 1763653593000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/rasbt/LLMs-from-scratch",
          "homepage": "https://amzn.to/4fqvn0D",
          "language": "Jupyter Notebook",
          "forks": 11719,
          "open_issues": 0,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/5618407?v=4",
      "velocity": 86967.1,
      "is_rising_star": true,
      "heatScore": 26093.558577457425,
      "popularityScore": 79061
    },
    {
      "id": "github-nomic-ai-gpt4all",
      "name": "gpt4all",
      "author": "nomic-ai",
      "description": "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.",
      "task": "tool",
      "tags": [
        "ai-chat",
        "llm-inference"
      ],
      "likes": 153854,
      "downloads": 153854,
      "lastModified": "2025-11-20T11:59:23Z",
      "lastModifiedTimestamp": 1763639963000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nomic-ai/gpt4all",
          "homepage": "https://nomic.ai/gpt4all",
          "language": "C++",
          "forks": 8302,
          "open_issues": 744,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102670180?v=4",
      "velocity": 84619.7,
      "is_rising_star": true,
      "heatScore": 25389.330259109156,
      "popularityScore": 76927
    },
    {
      "id": "github-browser-use-browser-use",
      "name": "browser-use",
      "author": "browser-use",
      "description": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "ai-tools",
        "browser-automation",
        "browser-use",
        "llm",
        "playwright",
        "python"
      ],
      "likes": 145557,
      "downloads": 145557,
      "lastModified": "2025-11-20T15:54:22Z",
      "lastModifiedTimestamp": 1763654062000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/browser-use/browser-use",
          "homepage": "https://browser-use.com",
          "language": "Python",
          "forks": 8663,
          "open_issues": 232,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192012301?v=4",
      "velocity": 80055.8,
      "is_rising_star": true,
      "heatScore": 24020.143404258793,
      "popularityScore": 72778
    },
    {
      "id": "github-binary-husky-gpt_academic",
      "name": "gpt_academic",
      "author": "binary-husky",
      "description": "‰∏∫GPT/GLMÁ≠âLLMÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂÆûÁî®Âåñ‰∫§‰∫íÊé•Âè£ÔºåÁâπÂà´‰ºòÂåñËÆ∫ÊñáÈòÖËØª/Ê∂¶Ëâ≤/ÂÜô‰Ωú‰ΩìÈ™åÔºåÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆ&ÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅPythonÂíåC++Á≠âÈ°πÁõÆÂâñÊûê&Ëá™ËØëËß£ÂäüËÉΩÔºåPDF/LaTexËÆ∫ÊñáÁøªËØë&ÊÄªÁªìÂäüËÉΩÔºåÊîØÊåÅÂπ∂Ë°åÈóÆËØ¢Â§öÁßçLLMÊ®°ÂûãÔºåÊîØÊåÅchatglm3Á≠âÊú¨Âú∞Ê®°Âûã„ÄÇÊé•ÂÖ•ÈÄö‰πâÂçÉÈóÆ, deepseekcoder, ËÆØÈ£ûÊòüÁÅ´, ÊñáÂøÉ‰∏ÄË®Ä, llama2, rwkv, claude2, mossÁ≠â„ÄÇ",
      "task": "tool",
      "tags": [
        "academic",
        "chatglm-6b",
        "chatgpt",
        "gpt-4",
        "large-language-models",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 139408,
      "downloads": 139408,
      "lastModified": "2025-11-20T14:41:49Z",
      "lastModifiedTimestamp": 1763649709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/binary-husky/gpt_academic",
          "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
          "language": "Python",
          "forks": 8399,
          "open_issues": 291,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/96192199?v=4",
      "velocity": 76674.4,
      "is_rising_star": true,
      "heatScore": 23005.71028475207,
      "popularityScore": 69704
    },
    {
      "id": "github-firecrawl-firecrawl",
      "name": "firecrawl",
      "author": "firecrawl",
      "description": "üî• The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agents",
        "ai-crawler",
        "ai-scraping",
        "ai-search",
        "crawler",
        "data-extraction",
        "html-to-markdown",
        "llm",
        "markdown",
        "scraper",
        "scraping",
        "web-crawler",
        "web-data",
        "web-data-extraction",
        "web-scraper",
        "web-scraping",
        "web-search",
        "webscraping"
      ],
      "likes": 136343,
      "downloads": 136343,
      "lastModified": "2025-11-20T15:52:57Z",
      "lastModifiedTimestamp": 1763653977000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/firecrawl/firecrawl",
          "homepage": "https://firecrawl.dev",
          "language": "TypeScript",
          "forks": 5309,
          "open_issues": 134,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/135057108?v=4",
      "velocity": 74988.1,
      "is_rising_star": true,
      "heatScore": 22499.813524224726,
      "popularityScore": 68171
    },
    {
      "id": "github-infiniflow-ragflow",
      "name": "ragflow",
      "author": "infiniflow",
      "description": "RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs",
      "task": "tool",
      "tags": [
        "agent",
        "agentic",
        "agentic-ai",
        "agentic-workflow",
        "ai",
        "ai-search",
        "deep-learning",
        "deep-research",
        "deepseek",
        "deepseek-r1",
        "document-parser",
        "document-understanding",
        "graphrag",
        "llm",
        "mcp",
        "multi-agent",
        "ollama",
        "openai",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 136116,
      "downloads": 136116,
      "lastModified": "2025-11-20T14:42:49Z",
      "lastModifiedTimestamp": 1763649769000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/infiniflow/ragflow",
          "homepage": "https://ragflow.io",
          "language": "Python",
          "forks": 7305,
          "open_issues": 2876,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/69962740?v=4",
      "velocity": 74863.8,
      "is_rising_star": true,
      "heatScore": 22462.52301989456,
      "popularityScore": 68058
    },
    {
      "id": "github-lobehub-lobe-chat",
      "name": "lobe-chat",
      "author": "lobehub",
      "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artifacts",
        "chat",
        "chatgpt",
        "claude",
        "deepseek",
        "deepseek-r1",
        "function-calling",
        "gemini",
        "gpt",
        "knowledge-base",
        "mcp",
        "nextjs",
        "ollama",
        "openai",
        "rag",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 135771,
      "downloads": 135771,
      "lastModified": "2025-11-20T15:53:45Z",
      "lastModifiedTimestamp": 1763654025000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/lobehub/lobe-chat",
          "homepage": "https://lobechat.com",
          "language": "TypeScript",
          "forks": 13999,
          "open_issues": 993,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
      "velocity": 74673.5,
      "is_rising_star": true,
      "heatScore": 22405.432246153854,
      "popularityScore": 67885
    },
    {
      "id": "github-mlabonne-llm-course",
      "name": "llm-course",
      "author": "mlabonne",
      "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
      "task": "tool",
      "tags": [
        "course",
        "large-language-models",
        "llm",
        "machine-learning",
        "roadmap"
      ],
      "likes": 135657,
      "downloads": 135657,
      "lastModified": "2025-11-20T15:52:59Z",
      "lastModifiedTimestamp": 1763653979000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mlabonne/llm-course",
          "homepage": "https://mlabonne.github.io/blog/",
          "language": null,
          "forks": 7688,
          "open_issues": 76,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/81252890?v=4",
      "velocity": 74610.8,
      "is_rising_star": true,
      "heatScore": 22386.62199079003,
      "popularityScore": 67828
    },
    {
      "id": "github-ansible-ansible",
      "name": "ansible",
      "author": "ansible",
      "description": "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",
      "task": "tool",
      "tags": [
        "ansible",
        "python",
        "code-generation-assistance"
      ],
      "likes": 134117,
      "downloads": 134117,
      "lastModified": "2025-11-20T15:53:03Z",
      "lastModifiedTimestamp": 1763653983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ansible/ansible",
          "homepage": "https://www.ansible.com/",
          "language": "Python",
          "forks": 24129,
          "open_issues": 878,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1507452?v=4",
      "velocity": 73763.8,
      "is_rising_star": true,
      "heatScore": 22132.518519950987,
      "popularityScore": 67058
    },
    {
      "id": "github-dair-ai-Prompt-Engineering-Guide",
      "name": "Prompt-Engineering-Guide",
      "author": "dair-ai",
      "description": "üêô Guides, papers, lessons, notebooks and resources for prompt engineering, context engineering, RAG, and AI Agents.",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai-agents",
        "chatgpt",
        "deep-learning",
        "generative-ai",
        "language-model",
        "llms",
        "openai",
        "prompt-engineering",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 133184,
      "downloads": 133184,
      "lastModified": "2025-11-20T15:46:31Z",
      "lastModifiedTimestamp": 1763653591000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/dair-ai/Prompt-Engineering-Guide",
          "homepage": "https://www.promptingguide.ai/",
          "language": "MDX",
          "forks": 6951,
          "open_issues": 231,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/30384625?v=4",
      "velocity": 73251.2,
      "is_rising_star": true,
      "heatScore": 21978.73640000614,
      "popularityScore": 66592
    },
    {
      "id": "github-OpenHands-OpenHands",
      "name": "OpenHands",
      "author": "OpenHands",
      "description": "üôå OpenHands: Code Less, Make More",
      "task": "tool",
      "tags": [
        "agent",
        "artificial-intelligence",
        "chatgpt",
        "claude-ai",
        "cli",
        "developer-tools",
        "gpt",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 130236,
      "downloads": 130236,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenHands/OpenHands",
          "homepage": "https://all-hands.dev",
          "language": "Python",
          "forks": 7937,
          "open_issues": 211,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/225919603?v=4",
      "velocity": 71629.8,
      "is_rising_star": true,
      "heatScore": 21492.30959540588,
      "popularityScore": 65118
    },
    {
      "id": "github-PaddlePaddle-PaddleOCR",
      "name": "PaddleOCR",
      "author": "PaddlePaddle",
      "description": "Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.",
      "task": "tool",
      "tags": [
        "ai4science",
        "chineseocr",
        "document-parsing",
        "document-translation",
        "kie",
        "ocr",
        "paddleocr-vl",
        "pdf-extractor-rag",
        "pdf-parser",
        "pdf2markdown",
        "pp-ocr",
        "pp-structure",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 128822,
      "downloads": 128822,
      "lastModified": "2025-11-20T15:27:27Z",
      "lastModifiedTimestamp": 1763652447000,
      "readme": "<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"./docs/images/Banner.png\" alt=\"PaddleOCR Banner\">\n  </p>\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](./readme/README_cn.md) | [ÁπÅÈ´î‰∏≠Êñá](./readme/README_tcn.md) | [Êó•Êú¨Ë™û](./readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](./readme/README_ko.md) | [Fran√ßais](./readme/README_fr.md) | [–†—É—Å—Å–∫–∏–π](./readme/README_ru.md) | [Espa√±ol](./readme/README_es.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](./readme/README_ar.md)\n\n<!-- icon -->\n[![stars](https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf)](https://github.com/PaddlePaddle/PaddleOCR)\n[![forks](https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg)](https://github.com/PaddlePaddle/PaddleOCR)\n[![arXiv](https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2507.05595)\n[![arXiv](https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.14528)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr/month)](https://pepy.tech/projectsproject/paddleocr)\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr)](https://pepy.tech/projects/paddleocr)\n[![Used by](https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue)](https://github.com/PaddlePaddle/PaddleOCR/network/dependents)\n[![PyPI version](https://img.shields.io/pypi/v/paddleocr)](https://pypi.org/project/paddleocr/)\n![python](https://img.shields.io/badge/python-3.8~3.12-aff.svg)\n\n![os](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg)\n![hardware](https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg)\n[![License](https://img.shields.io/badge/license-Apache_2.0-green)](../LICENSE)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/PaddlePaddle/PaddleOCR)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://www.paddleocr.com)\n\n\n\n**PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding**\n\n</div>\n\n# PaddleOCR\n[![Framework](https://img.shields.io/badge/PaddlePaddle-3.0-orange)](https://www.paddlepaddle.org.cn/en)\n[![Accuracy](https://img.shields.io/badge/Recognition%20Accuracy-üèÜ-green)](#)\n[![Multi-Language](https://img.shields.io/badge/Support_Languages-100+-brightgreen)](#)\n[![Handwriting](https://img.shields.io/badge/Handwriting-‚úì-success)](#)\n[![Hardware](https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red)](#)\n\n> [!TIP]\n> PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to [PaddleOCR MCP Server](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html).\n>\n> The PaddleOCR 3.0 Technical Report is now available. See details at: [PaddleOCR 3.0 Technical Report](https://arxiv.org/abs/2507.05595).\n>\n> The PaddleOCR-VL Technical Report is now available. See details at [PaddleOCR-VL Technical Report](https://arxiv.org/abs/2510.14528).\n>\n> The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the [PaddleOCR official website](https://www.paddleocr.com).\n\n\n**PaddleOCR** converts documents and images into **structured, AI-friendly data** (like JSON and Markdown) with **industry-leading accuracy**‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over **60,000 stars** and deep integration into leading projects like **MinerU, RAGFlow, pathway and cherry-studio**, PaddleOCR has become the **premier solution** for developers building intelligent document applications in the **AI era**.\n\n### PaddleOCR 3.0 Core Features\n\n[![HuggingFace](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAF8AAABYCAMAAACkl9t/AAAAk1BMVEVHcEz/nQv/nQv/nQr/nQv/nQr/nQv/nQv/nQr/wRf/txT/pg7/yRr/rBD/zRz/ngv/oAz/zhz/nwv/txT/ngv/0B3+zBz/nQv/0h7/wxn/vRb/thXkuiT/rxH/pxD/ogzcqyf/nQvTlSz/czCxky7/SjifdjT/Mj3+Mj3wMj15aTnDNz+DSD9RTUBsP0FRO0Q6O0WyIxEIAAAAGHRSTlMADB8zSWF3krDDw8TJ1NbX5efv8ff9/fxKDJ9uAAAGKklEQVR42u2Z63qjOAyGC4RwCOfB2JAGqrSb2WnTw/1f3UaWcSGYNKTdf/P+mOkTrE+yJBulvfvLT2A5ruenaVHyIks33npl/6C4s/ZLAM45SOi/1FtZPyFur1OYofBX3w7d54Bxm+E8db+nDr12ttmESZ4zludJEG5S7TO72YPlKZFyE+YCYUJTBZsMiNS5Sd7NlDmKM2Eg2JQg8awbglfqgbhArjxkS7dgp2RH6hc9AMLdZYUtZN5DJr4molC8BfKrEkPKEnEVjLbgW1fLy77ZVOJagoIcLIl+IxaQZGjiX597HopF5CkaXVMDO9Pyix3AFV3kw4lQLCbHuMovz8FallbcQIJ5Ta0vks9RnolbCK84BtjKRS5uA43hYoZcOBGIG2Epbv6CvFVQ8m8loh66WNySsnN7htL58LNp+NXT8/PhXiBXPMjLSxtwp8W9f/1AngRierBkA+kk/IpUSOeKByzn8y3kAAAfh//0oXgV4roHm/kz4E2z//zRc3/lgwBzbM2mJxQEa5pqgX7d1L0htrhx7LKxOZlKbwcAWyEOWqYSI8YPtgDQVjpB5nvaHaSnBaQSD6hweDi8PosxD6/PT09YY3xQA7LTCTKfYX+QHpA0GCcqmEHvr/cyfKQTEuwgbs2kPxJEB0iNjfJcCTPyocx+A0griHSmADiC91oNGVwJ69RudYe65vJmoqfpul0lrqXadW0jFKH5BKwAeCq+Den7s+3zfRJzA61/Uj/9H/VzLKTx9jFPPdXeeP+L7WEvDLAKAIoF8bPTKT0+TM7W8ePj3Rz/Yn3kOAp2f1Kf0Weony7pn/cPydvhQYV+eFOfmOu7VB/ViPe34/EN3RFHY/yRuT8ddCtMPH/McBAT5s+vRde/gf2c/sPsjLK+m5IBQF5tO+h2tTlBGnP6693JdsvofjOPnnEHkh2TnV/X1fBl9S5zrwuwF8NFrAVJVwCAPTe8gaJlomqlp0pv4Pjn98tJ/t/fL++6unpR1YGC2n/KCoa0tTLoKiEeUPDl94nj+5/Tv3/eT5vBQ60X1S0oZr+IWRR8Ldhu7AlLjPISlJcO9vrFotky9SpzDequlwEir5beYAc0R7D9KS1DXva0jhYRDXoExPdc6yw5GShkZXe9QdO/uOvHofxjrV/TNS6iMJS+4TcSTgk9n5agJdBQbB//IfF/HpvPt3Tbi7b6I6K0R72p6ajryEJrENW2bbeVUGjfgoals4L443c7BEE4mJO2SpbRngxQrAKRudRzGQ8jVOL2qDVjjI8K1gc3TIJ5KiFZ1q+gdsARPB4NQS4AjwVSt72DSoXNyOWUrU5mQ9nRYyjp89Xo7oRI6Bga9QNT1mQ/ptaJq5T/7WcgAZywR/XlPGAUDdet3LE+qS0TI+g+aJU8MIqjo0Kx8Ly+maxLjJmjQ18rA0YCkxLQbUZP1WqdmyQGJLUm7VnQFqodmXSqmRrdVpqdzk5LvmvgtEcW8PMGdaS23EOWyDVbACZzUJPaqMbjDxpA3Qrgl0AikimGDbqmyT8P8NOYiqrldF8rX+YN7TopX4UoHuSCYY7cgX4gHwclQKl1zhx0THf+tCAUValzjI7Wg9EhptrkIcfIJjA94evOn8B2eHaVzvBrnl2ig0So6hvPaz0IGcOvTHvUIlE2+prqAxLSQxZlU2stql1NqCCLdIiIN/i1DBEHUoElM9dBravbiAnKqgpi4IBkw+utSPIoBijDXJipSVV7MpOEJUAc5Qmm3BnUN+w3hteEieYKfRZSIUcXKMVf0u5wD4EwsUNVvZOtUT7A2GkffHjByWpHqvRBYrTV72a6j8zZ6W0DTE86Hn04bmyWX3Ri9WH7ZU6Q7h+ZHo0nHUAcsQvVhXRDZHChwiyi/hnPuOsSEF6Exk3o6Y9DT1eZ+6cASXk2Y9k+6EOQMDGm6WBK10wOQJCBwren86cPPWUcRAnTVjGcU1LBgs9FURiX/e6479yZcLwCBmTxiawEwrOcleuu12t3tbLv/N4RLYIBhYexm7Fcn4OJcn0+zc+s8/VfPeddZHAGN6TT8eGczHdR/Gts1/MzDkThr23zqrVfAMFT33Nx1RJsx1k5zuWILLnG/vsH+Fv5D4NTVcp1Gzo8AAAAAElFTkSuQmCC&labelColor=white)](https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/application/detail/98365)\n[![ModelScope](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&labelColor=white)](https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n\n[![AI Studio](https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n\n- **PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM**  \n  **The SOTA and resource-efficient model tailored for document parsing**, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.\n\n- **PP-OCRv5 ‚Äî Universal Scene Text Recognition**  \n  **Single model supports five text types** (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with **13% accuracy improvement**. Solves multilingual mixed document recognition challenges.\n\n- **PP-StructureV3 ‚Äî Complex Document Parsing**  \n  Intelligently converts complex PDFs and document images into **Markdown and JSON files that preserve original structure**. **Outperforms** numerous commercial solutions in public benchmarks. **Perfectly maintains document layout and hierarchical structure**.\n\n- **PP-ChatOCRv4 ‚Äî Intelligent Information Extraction**  \n  Natively integrates ERNIE 4.5 to **precisely extract key information** from massive documents, with 15% accuracy improvement over previous generation. Makes documents \"**understand**\" your questions and provide accurate answers.\n\nIn addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg\" alt=\"PaddleOCR Architecture\">\n  </p>\n</div>\n\n**Special Note**: PaddleOCR 3.x introduces several significant interface changes. **Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x**. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. [This document](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html) explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.\n\n## üì£ Recent updates\n\n### üî•üî• 2025.10.16: PaddleOCR 3.3.0 released, includes:\n\n- Released PaddleOCR-VL:\n    - **Model Introduction**:\n        - **PaddleOCR-VL** is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. **This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption**. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on [HuggingFace](https://huggingface.co/PaddlePaddle/PaddleOCR-VL). Everyone is welcome to download and use it! More introduction infomation can be found in [PaddleOCR-VL](https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html).\n\n    - **Core Features**:\n        - **Compact yet Powerful VLM Architecture**: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.\n        - **SOTA Performance on Document Parsing**: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.\n        - **Multilingual Support**: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.\n\n- Released PP-OCRv5 Multilingual Recognition Model:\n    - Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.\n\n\n<details>\n<summary><strong>2025.08.21: Release of PaddleOCR 3.2.0</strong></summary>\n\n- **Significant Model Additions:**\n    - Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. **The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.**\n\n- **Deployment Capability Upgrades:**\n    - **Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.**\n    - **Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.**\n    - **High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.**\n    - **The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.**\n    - The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.\n\n- **Benchmark Support:**\n    - **All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. [Here's](docs/version3.x/pipeline_usage/instructions/benchmark.en.md) how to set up and use the benchmark feature.**\n    - **Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.**\n\n- **Bug Fixes:**\n    - Resolved the issue of failed log saving during model training.\n    - Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.\n    - Fixed inconsistencies in switch behaviors (e.g., `use_chart_parsing`) in the PP-StructureV3 configuration files compared to other pipelines.\n\n- **Other Enhancements:**\n    - **Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.**\n    - **Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the [installation guide](docs/version3.x/installation.en.md) for the corresponding PaddlePaddle framework versions.**\n    - **PP-OCR series models now support returning single-character coordinates.**\n    - Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.\n    - Added support for chart-to-table conversion via the PP-Chart2Table module.\n    - Optimized documentation descriptions to improve usability.\n</details>\n\n<details>\n<summary><strong>2025.08.15: PaddleOCR 3.1.1 Released</strong></summary>\n\n- **Bug Fixes:**\n  - Added the missing methods `save_vector`, `save_visual_info_list`, `load_vector`, and `load_visual_info_list` in the `PP-ChatOCRv4` class.\n  - Added the missing parameters `glossary` and `llm_request_interval` to the `translate` method in the `PPDocTranslation` class.\n\n- **Documentation Improvements:**\n  - Added a demo to the MCP documentation.\n  - Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.\n  - Fixed errors and omissions in the production line document translation.\n\n- **Others:**\n  - Changed the MCP server dependency to use the pure Python library `puremagic` instead of `python-magic` to reduce installation issues.\n  - Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.\n\n</details>\n\n<details>\n<summary><strong>2025.06.29: PaddleOCR 3.1.0 Released</strong></summary>\n\n- **Key Models and Pipelines:**\n  - **Added PP-OCRv5 Multilingual Text Recognition Model**, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. **Average accuracy improved by over 30%.** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html)\n  - Upgraded the **PP-Chart2Table model** in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) **increased by 9.36 percentage points (71.24% -> 80.60%).**\n  - Newly launched **document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5**, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html)\n\n\n- **New MCP server:** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)\n  - **Supports both OCR and PP-StructureV3 pipelines.**\n  - Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.\n  - Supports invoking local services via stdio and remote services via Streamable HTTP.\n\n- **Documentation Optimization:** Improved the descriptions in some user guides for a smoother reading experience.\n\n</details>\n\n<details>\n    <summary><strong>2025.06.26: PaddleOCR 3.0.3 Released</strong></summary>\n- Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference.\n</details>\n\n<details>\n    <summary><strong>2025.06.19: PaddleOCR 3.0.2 Released</strong></summary>\n- **New Features:**\n\n  - The default download source has been changed from `BOS` to `HuggingFace`. Users can also change the environment variable `PADDLE_PDX_MODEL_SOURCE` to `BOS` to set the model download source back to Baidu Object Storage (BOS).\n  - Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.\n  - Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.\n  - Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language. \n  - Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.\n  - Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.\n  - Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.\n  - Added Android example for PP-OCRv5. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html).\n\n- **Bug Fixes:**\n  - Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.\n  - Resolved an issue where `export_paddlex_config_to_yaml` would not function correctly in certain cases.\n  - Corrected the discrepancy between the actual behavior of `save_path` and its documentation description.\n  - Fixed potential multithreading errors when using MKL-DNN in basic service deployment.\n  - Corrected channel order errors in image preprocessing for the Latex-OCR model.\n  - Fixed channel order errors in saving visualized images within the text recognition module.\n  - Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.\n  - Fixed an overflow issue in the calculation of `overlap_ratio` under extremely special circumstances in the PP-StructureV3 pipeline.\n\n- **Documentation Improvements:**\n  - Updated the description of the `enable_mkldnn` parameter in the documentation to accurately reflect the program's actual behavior.\n  - Fixed errors in the documentation regarding the `lang` and `ocr_version` parameters.\n  - Added instructions for exporting pipeline configuration files via CLI.\n  - Fixed missing columns in the performance data table for PP-OCRv5.\n  - Refined benchmark metrics for PP-StructureV3 across different configurations.\n\n- **Others:**\n\n  - Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.\n</details>\n\n<details>\n    <summary><strong>History Log</strong></summary>\n\n2025.06.05: **PaddleOCR 3.0.1 Released**, includes:\n\n- **Optimisation of certain models and model configurations:**\n  - Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter `limit_side_len` in the configuration has been changed from 736 to 64.\n  - Added a new text line orientation classification model `PP-LCNet_x1_0_textline_ori` with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.\n  - Optimized the text line orientation classification model `PP-LCNet_x0_25_textline_ori`, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.\n- **Optimizations and fixes for some issues in version 3.0.0, [details](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)**\n\nüî•üî•2025.05.20: Official Release of **PaddleOCR v3.0**, including:\n- **PP-OCRv5**: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.\n   1. üåê Single-model support for **five** text types - Seamlessly process **Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English** and **Japanese** within a single model.\n   2. ‚úçÔ∏è Improved **handwriting recognition**: Significantly better at complex cursive scripts and non-standard handwriting.\n   3. üéØ **13-point accuracy gain** over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.\n\n- **PP-StructureV3**: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios! \n   1. üßÆ **High-Accuracy multi-scene PDF parsing**, leading both open- and closed-source solutions on the OmniDocBench benchmark.\n   2. üß† Specialized capabilities include **seal recognition**, **chart-to-table conversion**, **table recognition with nested formulas/images**, **vertical text document parsing**, and **complex table structure analysis**.\n\n- **PP-ChatOCRv4**: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.\n   1. üî• **15-point accuracy gain** in key-information extraction on PDF/PNG/JPG files over the previous generation.\n   2. üíª Native support for **ERNIE 4.5**, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.\n   3. ü§ù Integrated [PP-DocBee2](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2), enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.\n\n[History Log](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)\n\n</details>\n\n## ‚ö° Quick Start\n### 1. Run online demo \n[![AI Studio](https://img.shields.io/badge/PP_OCRv5-AI_Studio-green)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_StructureV3-AI_Studio-green)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n### 2. Installation\n\nInstall PaddlePaddle refer to [Installation Guide](https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html), after then, install the PaddleOCR toolkit.\n\n```bash\n# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\"\n```\n\nStarting from version 3.2.0, in addition to the `all` dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:\n\n| Dependency Group Name | Corresponding Functionality |\n| - | - |\n| `doc-parser` | Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL |\n| `ie` | Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4 |\n| `trans` | Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation |\n| `all` | Complete functionality |\n\n### 3. Run inference by CLI\n```bash\n# Run PP-OCRv5 inference\npaddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  \n\n# Run PP-StructureV3 inference\npaddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False\n\n# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference\npaddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False \n\n# Run PaddleOCR-VL inference\npaddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\n\n# Get more information about \"paddleocr ocr\"\npaddleocr ocr --help\n```\n\n### 4. Run inference by API\n**4.1 PP-OCRv5 Example**\n```python\n# Initialize PaddleOCR instance\nfrom paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\n\n# Run OCR inference on a sample image \nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")\n\n# Visualize the results and save the JSON results\nfor res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")\n```\n\n<details>\n    <summary><strong>4.2 PP-StructureV3 Example</strong></summary>\n\n```python\nfrom pathlib import Path\nfrom paddleocr import PPStructureV3\n\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\n# For Image\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\n\n# Visualize the results and save the JSON results\nfor res in output:\n    res.print() \n    res.save_to_json(save_path=\"output\") \n    res.save_to_markdown(save_path=\"output\")           \n```\n\n</details>\n\n<details>\n   <summary><strong>4.3 PP-ChatOCRv4 Example</strong></summary>\n\n```python\nfrom paddleocr import PPChatOCRv4Doc\n\nchat_bot_config = {\n    \"module_name\": \"chat_bot\",\n    \"model_name\": \"ernie-3.5-8k\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"openai\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\nretriever_config = {\n    \"module_name\": \"retriever\",\n    \"model_name\": \"embedding-v1\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"qianfan\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\npipeline = PPChatOCRv4Doc(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\nvisual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)\n\nmllm_predict_info = None\nuse_mllm = False\n# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.\nif use_mllm:\n    mllm_chat_bot_config = {\n        \"module_name\": \"chat_bot\",\n        \"model_name\": \"PP-DocBee\",\n        \"base_url\": \"http://127.0.0.1:8080/\",  # your local mllm service url\n        \"api_type\": \"openai\",\n        \"api_key\": \"api_key\",  # your api_key\n    }\n\n    mllm_predict_res = pipeline.mllm_pred(\n        input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n        key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n        mllm_chat_bot_config=mllm_chat_bot_config,\n    )\n    mllm_predict_info = mllm_predict_res[\"mllm_res\"]\n\nvisual_info_list = []\nfor res in visual_predict_res:\n    visual_info_list.append(res[\"visual_info\"])\n    layout_parsing_result = res[\"layout_parsing_result\"]\n\nvector_info = pipeline.build_vector(\n    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config\n)\nchat_result = pipeline.chat(\n    key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n    visual_info=visual_info_list,\n    vector_info=vector_info,\n    mllm_predict_info=mllm_predict_info,\n    chat_bot_config=chat_bot_config,\n    retriever_config=retriever_config,\n)\nprint(chat_result)\n```\n\n</details>\n\n<details>\n   <summary><strong>4.4 PaddleOCR-VL Example</strong></summary>\n\n```python\nfrom paddleocr import PaddleOCRVL\n\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")\n```\n\n</details>\n\n### 5. Chinese Heterogeneous AI Accelerators\n- [Huawei Ascend](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html)\n- [KUNLUNXIN](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html)\n\n## üß© More Features\n\n- Convert models to ONNX format: [Obtaining ONNX Models](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html).\n- Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: [High-Performance Inference](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html).\n- Accelerate inference using multi-GPU and multi-process: [Parallel Inference for Pipelines](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html).\n- Integrate PaddleOCR into applications written in C++, C#, Java, etc.: [Serving](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html).\n\n## ‚õ∞Ô∏è Advanced Tutorials\n\n- [PP-OCRv5 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html)\n- [PP-StructureV3 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html)\n- [PP-ChatOCRv4 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html)\n- [PaddleOCR-VL Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html)\n\n## üîÑ Quick Overview of Execution Results\n\n### PP-OCRv5\n\n<div align=\"center\">\n  <p>\n       <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif\" alt=\"PP-OCRv5 Demo\">\n  </p>\n</div>\n\n\n\n### PP-StructureV3\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n### PaddleOCR-VL\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n\n## ‚ú® Stay Tuned\n\n‚≠ê **Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!** ‚≠ê\n\n<div align=\"center\">\n  <p>\n       <img width=\"1200\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif\" alt=\"Star-Project\">\n  </p>\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community\n\n<div align=\"center\">\n\n| PaddlePaddle WeChat official account |  Join the tech discussion group |\n| :---: | :---: |\n| <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg\" width=\"150\"> | <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg\" width=\"150\"> |\n</div>\n\n\n## üòÉ Awesome Projects Leveraging PaddleOCR\nPaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!\n\n<div align=\"center\">\n\n| Project Name | Description |\n| ------------ | ----------- |\n| [RAGFlow](https://github.com/infiniflow/ragflow) <a href=\"https://github.com/infiniflow/ragflow\"><img src=\"https://img.shields.io/github/stars/infiniflow/ragflow\"></a>|RAG engine based on deep document understanding.|\n| [pathway](https://github.com/pathwaycom/pathway) <a href=\"https://github.com/pathwaycom/pathway\"><img src=\"https://img.shields.io/github/stars/pathwaycom/pathway\"></a>|Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.|\n| [MinerU](https://github.com/opendatalab/MinerU) <a href=\"https://github.com/opendatalab/MinerU\"><img src=\"https://img.shields.io/github/stars/opendatalab/MinerU\"></a>|Multi-type Document to Markdown Conversion Tool|\n| [Umi-OCR](https://github.com/hiroi-sora/Umi-OCR) <a href=\"https://github.com/hiroi-sora/Umi-OCR\"><img src=\"https://img.shields.io/github/stars/hiroi-sora/Umi-OCR\"></a>|Free, Open-source, Batch Offline OCR Software.|\n| [cherry-studio](https://github.com/CherryHQ/cherry-studio) <a href=\"https://github.com/CherryHQ/cherry-studio\"><img src=\"https://img.shields.io/github/stars/CherryHQ/cherry-studio\"></a>|A desktop client that supports for multiple LLM providers.|\n| [OmniParser](https://github.com/microsoft/OmniParser)<a href=\"https://github.com/microsoft/OmniParser\"><img src=\"https://img.shields.io/github/stars/microsoft/OmniParser\"></a> |OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.|\n| [QAnything](https://github.com/netease-youdao/QAnything)<a href=\"https://github.com/netease-youdao/QAnything\"><img src=\"https://img.shields.io/github/stars/netease-youdao/QAnything\"></a> |Question and Answer based on Anything.|\n| [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit) <a href=\"https://github.com/opendatalab/PDF-Extract-Kit\"><img src=\"https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit\"></a>|A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.|\n| [Dango-Translator](https://github.com/PantsuDango/Dango-Translator)<a href=\"https://github.com/PantsuDango/Dango-Translator\"><img src=\"https://img.shields.io/github/stars/PantsuDango/Dango-Translator\"></a> |Recognize text on the screen, translate it and show the translation results in real time.|\n| [Learn more projects](./awesome_projects.md) | [More projects based on PaddleOCR](./awesome_projects.md)|\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors\n\n<div align=\"center\">\n<a href=\"https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&max=400&columns=20\"  width=\"800\"/>\n</a>\n</div>\n\n## üåü Star\n\n<div align=\"center\">\n  <p>\n      <img width=\"800\" src=\"https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&type=Date\" alt=\"Star-history\">\n  </p>\n</div>\n\n\n## üìÑ License\nThis project is released under the [Apache 2.0 license](LICENSE).\n\n## üéì Citation\n\n```bibtex\n@misc{cui2025paddleocr30technicalreport,\n      title={PaddleOCR 3.0 Technical Report}, \n      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2507.05595},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2507.05595}, \n}\n\n@misc{cui2025paddleocrvlboostingmultilingualdocument,\n      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, \n      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2510.14528},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2510.14528}, \n}\n```\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/PaddlePaddle/PaddleOCR",
          "homepage": "https://www.paddleocr.ai",
          "language": "Python",
          "forks": 9368,
          "open_issues": 280,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23534030?v=4",
      "velocity": 70852.1,
      "is_rising_star": true,
      "heatScore": 21258.99627674898,
      "popularityScore": 64411
    },
    {
      "id": "github-vllm-project-vllm",
      "name": "vllm",
      "author": "vllm-project",
      "description": "A high-throughput and memory-efficient inference and serving engine for LLMs",
      "task": "tool",
      "tags": [
        "amd",
        "blackwell",
        "cuda",
        "deepseek",
        "deepseek-v3",
        "gpt",
        "gpt-oss",
        "inference",
        "kimi",
        "llama",
        "llm",
        "llm-serving",
        "model-serving",
        "moe",
        "openai",
        "pytorch",
        "qwen",
        "qwen3",
        "tpu",
        "transformer"
      ],
      "likes": 127100,
      "downloads": 127100,
      "lastModified": "2025-11-20T15:22:49Z",
      "lastModifiedTimestamp": 1763652169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/vllm-project/vllm",
          "homepage": "https://docs.vllm.ai",
          "language": "Python",
          "forks": 11425,
          "open_issues": 3142,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/136984999?v=4",
      "velocity": 69905,
      "is_rising_star": true,
      "heatScore": 20974.86218567212,
      "popularityScore": 63550
    },
    {
      "id": "github-hiyouga-LLaMA-Factory",
      "name": "LLaMA-Factory",
      "author": "hiyouga",
      "description": "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "deepseek",
        "fine-tuning",
        "gemma",
        "gpt",
        "instruction-tuning",
        "large-language-models",
        "llama",
        "llama3",
        "llm",
        "lora",
        "moe",
        "nlp",
        "peft",
        "qlora",
        "quantization",
        "qwen",
        "rlhf",
        "transformers"
      ],
      "likes": 125604,
      "downloads": 125604,
      "lastModified": "2025-11-20T15:04:01Z",
      "lastModifiedTimestamp": 1763651041000,
      "readme": "![# LLaMA Factory](assets/logo.png)\n\n[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)\n[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)\n[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)\n[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)\n[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)\n[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)\n[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)\n\n[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)\n[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)\n[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)\n[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/en/)\n\n[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)\n[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)\n[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)\n[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)\n[![Open in Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)\n[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)\n[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)\n\n### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.\n\n<div align=\"center\" markdown=\"1\">\n\n### Supporters ‚ù§Ô∏è\n\n| <div style=\"text-align: center;\"><a href=\"https://warp.dev/llama-factory\"><img alt=\"Warp sponsorship\" width=\"400\" src=\"assets/sponsors/warp.jpg\"></a><br><a href=\"https://warp.dev/llama-factory\" style=\"font-size:larger;\">Warp, the agentic terminal for developers</a><br><a href=\"https://warp.dev/llama-factory\">Available for MacOS, Linux, & Windows</a> | <a href=\"https://serpapi.com\"><img alt=\"SerpAPI sponsorship\" width=\"250\" src=\"assets/sponsors/serpapi.svg\"> </a> |\n| ---- | ---- |\n\n----\n\n### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n\n![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)\n\n</div>\n\nüëã Join our [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg), [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg), [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg), [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg) user group.\n\n\\[ English | [‰∏≠Êñá](README_zh.md) \\]\n\n**Fine-tuning a large language model can be easy as...**\n\nhttps://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e\n\nStart local training:\n- Please refer to [usage](#getting-started)\n\nStart cloud training:\n- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing\n- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory\n- **LLaMA Factory Online**: https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory\n- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory\n\nRead technical notes:\n- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/\n- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html\n- **Official Blog**: https://blog.llamafactory.net/en/\n- **Official Course**: https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory\n\n> [!NOTE]\n> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.\n\n## Table of Contents\n\n- [Features](#features)\n- [Blogs](#blogs)\n- [Changelog](#changelog)\n- [Supported Models](#supported-models)\n- [Supported Training Approaches](#supported-training-approaches)\n- [Provided Datasets](#provided-datasets)\n- [Requirement](#requirement)\n- [Getting Started](#getting-started)\n  - [Installation](#installation)\n  - [Data Preparation](#data-preparation)\n  - [Quickstart](#quickstart)\n  - [Fine-Tuning with LLaMA Board GUI](#fine-tuning-with-llama-board-gui-powered-by-gradio)\n  - [LLaMA Factory Online](#llama-factory-online)\n  - [Build Docker](#build-docker)\n  - [Deploy with OpenAI-style API and vLLM](#deploy-with-openai-style-api-and-vllm)\n  - [Download from ModelScope Hub](#download-from-modelscope-hub)\n  - [Download from Modelers Hub](#download-from-modelers-hub)\n  - [Use W&B Logger](#use-wb-logger)\n  - [Use SwanLab Logger](#use-swanlab-logger)\n- [Projects using LLaMA Factory](#projects-using-llama-factory)\n- [License](#license)\n- [Citation](#citation)\n- [Acknowledgement](#acknowledgement)\n\n## Features\n\n- **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.\n- **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.\n- **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n- **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), [Muon](https://github.com/KellerJordan/Muon), [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.\n- **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [KTransformers](https://github.com/kvcache-ai/ktransformers/), RoPE scaling, NEFTune and rsLoRA.\n- **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.\n- **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, [SwanLab](https://github.com/SwanHubX/SwanLab), etc.\n- **Faster inference**: OpenAI-style API, Gradio UI and CLI with [vLLM worker](https://github.com/vllm-project/vllm) or [SGLang worker](https://github.com/sgl-project/sglang).\n\n### Day-N Support for Fine-Tuning Cutting-Edge Models\n\n| Support Date | Model Name                                                           |\n| ------------ | -------------------------------------------------------------------- |\n| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |\n| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |\n\n## Blogs\n\n> [!TIP]\n> Now we have a dedicated blog for LLaMA Factory!\n>\n> Website: https://blog.llamafactory.net/en/\n\n- üí° [KTransformers Fine-Tuning √ó LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/) (English)\n- üí° [Easy Dataset √ó LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g) (English)\n- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory) (Chinese)\n- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/) (Chinese)\n- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/) (English)\n\n<details><summary>All Blogs</summary>\n\n- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory) (Chinese)\n- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory) (Chinese)\n- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b) (Chinese)\n- [A One-Stop Code-Free Model Fine-Tuning \\& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/) (Chinese)\n- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl) (Chinese)\n- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory) (Chinese)\n\n</details>\n\n## Changelog\n\n[25/10/26] We support Megatron-core training backend with [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter). See [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237) to get started.\n\n[25/08/22] We supported **[OFT](https://arxiv.org/abs/2306.07280)** and **[OFTv2](https://arxiv.org/abs/2506.19847)**. See [examples](examples/README.md) for usage.\n\n[25/08/20] We supported fine-tuning the **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** models. See [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) to get started.\n\n[25/08/06] We supported fine-tuning the **[GPT-OSS](https://github.com/openai/gpt-oss)** models. See [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) to get started.\n\n<details><summary>Full Changelog</summary>\n\n[25/07/02] We supported fine-tuning the **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** model.\n\n[25/04/28] We supported fine-tuning the **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** model family.\n\n[25/04/21] We supported the **[Muon](https://github.com/KellerJordan/Muon)** optimizer. See [examples](examples/README.md) for usage. Thank [@tianshijing](https://github.com/tianshijing)'s PR.\n\n[25/04/16] We supported fine-tuning the **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** model. See [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) to get started.\n\n[25/04/14] We supported fine-tuning the **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** and **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** models.\n\n[25/04/06] We supported fine-tuning the **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** model. See [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) to get started.\n\n[25/03/31] We supported fine-tuning the **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** model. See [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) to get started.\n\n[25/03/15] We supported **[SGLang](https://github.com/sgl-project/sglang)** as inference backend. Try `infer_backend: sglang` to accelerate inference.\n\n[25/03/12] We supported fine-tuning the **[Gemma 3](https://huggingface.co/blog/gemma3)** model.\n\n[25/02/24] Announcing **[EasyR1](https://github.com/hiyouga/EasyR1)**, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.\n\n[25/02/11] We supported saving the **[Ollama](https://github.com/ollama/ollama)** modelfile when exporting the model checkpoints. See [examples](examples/README.md) for usage.\n\n[25/02/05] We supported fine-tuning the **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** and **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** on audio understanding tasks.\n\n[25/01/31] We supported fine-tuning the **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** and **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** models.\n\n[25/01/15] We supported **[APOLLO](https://arxiv.org/abs/2412.05270)** optimizer. See [examples](examples/README.md) for usage.\n\n[25/01/14] We supported fine-tuning the **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** and **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** models. Thank [@BUAADreamer](https://github.com/BUAADreamer)'s PR.\n\n[25/01/14] We supported fine-tuning the **[InternLM 3](https://huggingface.co/collections/internlm/)** models. Thank [@hhaAndroid](https://github.com/hhaAndroid)'s PR.\n\n[25/01/10] We supported fine-tuning the **[Phi-4](https://huggingface.co/microsoft/phi-4)** model.\n\n[24/12/21] We supported using **[SwanLab](https://github.com/SwanHubX/SwanLab)** for experiment tracking and visualization. See [this section](#use-swanlab-logger) for details.\n\n[24/11/27] We supported fine-tuning the **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** model and the **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** dataset.\n\n[24/10/09] We supported downloading pre-trained models and datasets from the **[Modelers Hub](https://modelers.cn/models)**. See [this tutorial](#download-from-modelers-hub) for usage.\n\n[24/09/19] We supported fine-tuning the **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** models.\n\n[24/08/30] We supported fine-tuning the **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** models. Thank [@simonJJJ](https://github.com/simonJJJ)'s PR.\n\n[24/08/27] We supported **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**. Try `enable_liger_kernel: true` for efficient training.\n\n[24/08/09] We supported **[Adam-mini](https://github.com/zyushun/Adam-mini)** optimizer. See [examples](examples/README.md) for usage. Thank [@relic-yuexi](https://github.com/relic-yuexi)'s PR.\n\n[24/07/04] We supported [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing). Use `neat_packing: true` to activate it. Thank [@chuan298](https://github.com/chuan298)'s PR.\n\n[24/06/16] We supported **[PiSSA](https://arxiv.org/abs/2404.02948)** algorithm. See [examples](examples/README.md) for usage.\n\n[24/06/07] We supported fine-tuning the **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** and **[GLM-4](https://github.com/THUDM/GLM-4)** models.\n\n[24/05/26] We supported **[SimPO](https://arxiv.org/abs/2405.14734)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/20] We supported fine-tuning the **PaliGemma** series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with `paligemma` template for chat completion.\n\n[24/05/18] We supported **[KTO](https://arxiv.org/abs/2402.01306)** algorithm for preference learning. See [examples](examples/README.md) for usage.\n\n[24/05/14] We supported training and inference on the Ascend NPU devices. Check [installation](#installation) section for details.\n\n[24/04/26] We supported fine-tuning the **LLaVA-1.5** multimodal LLMs. See [examples](examples/README.md) for usage.\n\n[24/04/22] We provided a **[Colab notebook](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)** for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) and [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese) for details.\n\n[24/04/21] We supported **[Mixture-of-Depths](https://arxiv.org/abs/2404.02258)** according to [AstraMindAI's implementation](https://github.com/astramind-ai/Mixture-of-depths). See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[BAdam](https://arxiv.org/abs/2404.02827)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/04/16] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves **117%** speed and **50%** memory compared with FlashAttention-2, more benchmarks can be found in [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison).\n\n[24/03/31] We supported **[ORPO](https://arxiv.org/abs/2403.07691)**. See [examples](examples/README.md) for usage.\n\n[24/03/21] Our paper \"[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)\" is available at arXiv!\n\n[24/03/20] We supported **FSDP+QLoRA** that fine-tunes a 70B model on 2x24GB GPUs. See [examples](examples/README.md) for usage.\n\n[24/03/13] We supported **[LoRA+](https://arxiv.org/abs/2402.12354)**. See [examples](examples/README.md) for usage.\n\n[24/03/07] We supported **[GaLore](https://arxiv.org/abs/2403.03507)** optimizer. See [examples](examples/README.md) for usage.\n\n[24/03/07] We integrated **[vLLM](https://github.com/vllm-project/vllm)** for faster and concurrent inference. Try `infer_backend: vllm` to enjoy **270%** inference speed.\n\n[24/02/28] We supported weight-decomposed LoRA (**[DoRA](https://arxiv.org/abs/2402.09353)**). Try `use_dora: true` to activate DoRA training.\n\n[24/02/15] We supported **block expansion** proposed by [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro). See [examples](examples/README.md) for usage.\n\n[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this [blog post](https://qwenlm.github.io/blog/qwen1.5/) for details.\n\n[24/01/18] We supported **agent tuning** for most models, equipping model with tool using abilities by fine-tuning with `dataset: glaive_toolcall_en`.\n\n[23/12/23] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try `use_unsloth: true` argument to activate unsloth patch. It achieves **170%** speed in our benchmark, check [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison) for details.\n\n[23/12/12] We supported fine-tuning the latest MoE model **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)** in our framework. See hardware requirement [here](#hardware-requirement).\n\n[23/12/01] We supported downloading pre-trained models and datasets from the **[ModelScope Hub](https://modelscope.cn/models)**. See [this tutorial](#download-from-modelscope-hub) for usage.\n\n[23/10/21] We supported **[NEFTune](https://arxiv.org/abs/2310.05914)** trick for fine-tuning. Try `neftune_noise_alpha: 5` argument to activate NEFTune.\n\n[23/09/27] We supported **$S^2$-Attn** proposed by [LongLoRA](https://github.com/dvlab-research/LongLoRA) for the LLaMA models. Try `shift_attn: true` argument to enable shift short attention.\n\n[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See [examples](examples/README.md) for usage.\n\n[23/09/10] We supported **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**. Try `flash_attn: fa2` argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.\n\n[23/08/12] We supported **RoPE scaling** to extend the context length of the LLaMA models. Try `rope_scaling: linear` argument in training and `rope_scaling: dynamic` argument at inference to extrapolate the position embeddings.\n\n[23/08/11] We supported **[DPO training](https://arxiv.org/abs/2305.18290)** for instruction-tuned models. See [examples](examples/README.md) for usage.\n\n[23/07/31] We supported **dataset streaming**. Try `streaming: true` and `max_steps: 10000` arguments to load your dataset in streaming mode.\n\n[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ([LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)) for details.\n\n[23/07/18] We developed an **all-in-one Web UI** for training, evaluation and inference. Try `train_web.py` to fine-tune models in your Web browser. Thank [@KanadeSiina](https://github.com/KanadeSiina) and [@codemayq](https://github.com/codemayq) for their efforts in the development.\n\n[23/07/09] We released **[FastEdit](https://github.com/hiyouga/FastEdit)** ‚ö°ü©π, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow [FastEdit](https://github.com/hiyouga/FastEdit) if you are interested.\n\n[23/06/29] We provided a **reproducible example** of training a chat model using instruction-following datasets, see [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft) for details.\n\n[23/06/22] We aligned the [demo API](src/api_demo.py) with the [OpenAI's](https://platform.openai.com/docs/api-reference/chat) format where you can insert the fine-tuned model in **arbitrary ChatGPT-based applications**.\n\n[23/06/03] We supported quantized training and inference (aka **[QLoRA](https://github.com/artidoro/qlora)**). See [examples](examples/README.md) for usage.\n\n</details>\n\n> [!TIP]\n> If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.\n\n## Supported Models\n\n| Model                                                             | Model size                       | Template             |\n| ----------------------------------------------------------------- | -------------------------------- | -------------------- |\n| [Baichuan 2](https://huggingface.co/baichuan-inc)                 | 7B/13B                           | baichuan2            |\n| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |\n| [ChatGLM3](https://huggingface.co/THUDM)                          | 6B                               | chatglm3             |\n| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |\n| [DeepSeek (Code/MoE)](https://huggingface.co/deepseek-ai)         | 7B/16B/67B/236B                  | deepseek             |\n| [DeepSeek 2.5/3](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |\n| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |\n| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |\n| [Falcon](https://huggingface.co/tiiuae)                           | 7B/11B/40B/180B                  | falcon               |\n| [Falcon-H1](https://huggingface.co/tiiuae)                        | 0.5B/1.5B/3B/7B/34B              | falcon_h1            |\n| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |\n| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |\n| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |\n| [GLM-4.1V](https://huggingface.co/zai-org)                        | 9B                               | glm4v                |\n| [GLM-4.5/GLM-4.5V](https://huggingface.co/zai-org)                | 106B/355B                        | glm4_moe/glm4v_moe   |\n| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |\n| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt                  |\n| [Granite 3.0-3.3](https://huggingface.co/ibm-granite)             | 1B/2B/3B/8B                      | granite3             |\n| [Granite 4](https://huggingface.co/ibm-granite)                   | 7B                               | granite4             |\n| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |\n| [Index](https://huggingface.co/IndexTeam)                         | 1.9B                             | index                |\n| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |\n| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |\n| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |\n| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |\n| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |\n| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |\n| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |\n| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |\n| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |\n| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |\n| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |\n| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |\n| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |\n| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B                               | mimo                 |\n| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |\n| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |\n| [Ministral/Mistral-Nemo](https://huggingface.co/mistralai)        | 8B/12B                           | ministral            |\n| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |\n| [Mistral Small](https://huggingface.co/mistralai)                 | 24B                              | mistral_small        |\n| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |\n| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |\n| [Phi-1.5/Phi-2](https://huggingface.co/microsoft)                 | 1.3B/2.7B                        | -                    |\n| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |\n| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |\n| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |\n| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |\n| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |\n| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |\n| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |\n| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |\n| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |\n| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |\n| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |\n| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |\n| [Skywork o1](https://huggingface.co/Skywork)                      | 8B                               | skywork_o1           |\n| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |\n| [TeleChat2](https://huggingface.co/Tele-AI)                       | 3B/7B/35B/115B                   | telechat2            |\n| [XVERSE](https://huggingface.co/xverse)                           | 7B/13B/65B                       | xverse               |\n| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |\n| [Yi-VL](https://huggingface.co/01-ai)                             | 6B/34B                           | yi_vl                |\n| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |\n\n> [!NOTE]\n> For the \"base\" models, the `template` argument can be chosen from `default`, `alpaca`, `vicuna` etc. But make sure to use the **corresponding template** for the \"instruct/chat\" models.\n>\n> If the model has both reasoning and non-reasoning versions, please use the `_nothink` suffix to distinguish between them. For example, `qwen3` and `qwen3_nothink`.\n>\n> Remember to use the **SAME** template in training and inference.\n>\n> \\*: You should install the `transformers` from main branch and use `DISABLE_VERSION_CHECK=1` to skip version check.\n>\n> \\*\\*: You need to install a specific version of `transformers` to use the corresponding model.\n\nPlease refer to [constants.py](src/llamafactory/extras/constants.py) for a full list of models we supported.\n\nYou also can add a custom chat template to [template.py](src/llamafactory/data/template.py).\n\n## Supported Training Approaches\n\n| Approach               |     Full-tuning    |    Freeze-tuning   |       LoRA         |       QLoRA        |        OFT         |        QOFT        |\n| ---------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |\n| Pre-Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Supervised Fine-Tuning | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Reward Modeling        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| PPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| DPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| KTO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| ORPO Training          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| SimPO Training         | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n\n> [!TIP]\n> The implementation details of PPO can be found in [this blog](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html).\n\n## Provided Datasets\n\n<details><summary>Pre-training datasets</summary>\n\n- [Wiki Demo (en)](data/wiki_demo.txt)\n- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)\n- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)\n- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)\n- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)\n- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)\n- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)\n- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)\n- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)\n- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)\n- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)\n- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)\n- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)\n- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)\n- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)\n- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)\n\n</details>\n\n<details><summary>Supervised fine-tuning datasets</summary>\n\n- [Identity (en&zh)](data/identity.json)\n- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)\n- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)\n- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)\n- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)\n- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)\n- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)\n- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)\n- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)\n- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)\n- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)\n- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)\n- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)\n- [UltraChat (en)](https://github.com/thunlp/UltraChat)\n- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)\n- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)\n- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)\n- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)\n- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)\n- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)\n- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)\n- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)\n- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)\n- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)\n- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)\n- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)\n- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)\n- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)\n- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)\n- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)\n- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)\n- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)\n- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)\n- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)\n- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)\n- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)\n- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)\n- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)\n- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)\n- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)\n- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)\n- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)\n- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)\n- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)\n- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)\n- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)\n- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)\n- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)\n- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)\n- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)\n- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)\n- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)\n- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)\n\n</details>\n\n<details><summary>Preference datasets</summary>\n\n- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)\n- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)\n- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)\n- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)\n- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)\n- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)\n- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)\n- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)\n- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)\n- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)\n- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)\n\n</details>\n\nSome datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.\n\n```bash\npip install \"huggingface_hub<1.0.0\"\nhuggingface-cli login\n```\n\n## Requirement\n\n| Mandatory    | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| python       | 3.9     | 3.10      |\n| torch        | 2.0.0   | 2.6.0     |\n| torchvision  | 0.15.0  | 0.21.0    |\n| transformers | 4.49.0  | 4.50.0    |\n| datasets     | 2.16.0  | 3.2.0     |\n| accelerate   | 0.34.0  | 1.2.1     |\n| peft         | 0.14.0  | 0.15.1    |\n| trl          | 0.8.6   | 0.9.6     |\n\n| Optional     | Minimum | Recommend |\n| ------------ | ------- | --------- |\n| CUDA         | 11.6    | 12.2      |\n| deepspeed    | 0.10.0  | 0.16.4    |\n| bitsandbytes | 0.39.0  | 0.43.1    |\n| vllm         | 0.4.3   | 0.8.2     |\n| flash-attn   | 2.5.6   | 2.7.2     |\n\n### Hardware Requirement\n\n\\* *estimated*\n\n| Method                              | Bits |   7B  |  14B  |  30B  |   70B  |   `x`B  |\n| ----------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |\n| Full (`bf16` or `fp16`)             |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |\n| Full (`pure_bf16`)                  |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |\n| Freeze/LoRA/GaLore/APOLLO/BAdam/OFT |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |\n| QLoRA / QOFT                        |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |\n| QLoRA / QOFT                        |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |\n| QLoRA / QOFT                        |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |\n\n## Getting Started\n\n### Installation\n\n> [!IMPORTANT]\n> Installation is mandatory.\n\n#### Install from Source\n\n```bash\ngit clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\npip install -e \".[torch,metrics]\" --no-build-isolation\n```\n\nExtra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev\n\n#### Install from Docker Image\n\n```bash\ndocker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest\n```\n\nThis image is built on Ubuntu 22.04 (x86\\_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.\n\nFind the pre-built images: https://hub.docker.com/r/hiyouga/llamafactory/tags\n\nPlease refer to [build docker](#build-docker) to build the image yourself.\n\n<details><summary>Setting up a virtual environment with <b>uv</b></summary>\n\nCreate an isolated Python environment with [uv](https://github.com/astral-sh/uv):\n\n```bash\nuv sync --extra torch --extra metrics --prerelease=allow\n```\n\nRun LLaMA-Factory in the isolated environment:\n\n```bash\nuv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml\n```\n\n</details>\n\n<details><summary>For Windows users</summary>\n\n#### Install PyTorch\n\nYou need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the [official website](https://pytorch.org/get-started/locally/) and the following command to install PyTorch with CUDA support:\n\n```bash\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\npython -c \"import torch; print(torch.cuda.is_available())\"\n```\n\nIf you see `True` then you have successfully installed PyTorch with CUDA support.\n\nTry `dataloader_num_workers: 0` if you encounter `Can't pickle local object` error.\n\n#### Install BitsAndBytes\n\nIf you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of `bitsandbytes` library, which supports CUDA 11.1 to 12.2, please select the appropriate [release version](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels) based on your CUDA version.\n\n```bash\npip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl\n```\n\n#### Install Flash Attention-2\n\nTo enable FlashAttention-2 on the Windows platform, please use the script from [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) to compile and install it by yourself.\n\n</details>\n\n<details><summary>For Ascend NPU users</summary>\n\nTo install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: `pip install -e \".[torch-npu,metrics]\"`. Additionally, you need to install the **[Ascend CANN Toolkit and Kernels](https://www.hiascend.com/developer/download/community/result?module=cann)**. Please follow the [installation tutorial](https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html) or use the following commands:\n\n```bash\n# replace the url according to your CANN version and devices\n# install CANN Toolkit\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# install CANN Kernels\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# set env variables\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh\n```\n\n| Requirement  | Minimum | Recommend      |\n| ------------ | ------- | -------------- |\n| CANN         | 8.0.RC1 | 8.0.0.alpha002 |\n| torch        | 2.1.0   | 2.4.0          |\n| torch-npu    | 2.1.0   | 2.4.0.post2    |\n| deepspeed    | 0.13.2  | 0.13.2         |\n| vllm-ascend  | -       | 0.7.3          |\n\nRemember to use `ASCEND_RT_VISIBLE_DEVICES` instead of `CUDA_VISIBLE_DEVICES` to specify the device to use.\n\nIf you cannot infer model on NPU devices, try setting `do_sample: false` in the configurations.\n\nDownload the pre-built Docker images: [32GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html) | [64GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html)\n\n#### Install BitsAndBytes\n\nTo use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:\n\n1. Manually compile bitsandbytes: Refer to [the installation documentation](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU) for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.\n\n```bash\n# Install bitsandbytes from source\n# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch\ngit clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git\ncd bitsandbytes/\n\n# Install dependencies\npip install -r requirements-dev.txt\n\n# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference\napt-get install -y build-essential cmake\n\n# Compile & install  \ncmake -DCOMPUTE_BACKEND=npu -S .\nmake\npip install .\n```\n\n2. Install transformers from the main branch.\n\n```bash\ngit clone -b main https://github.com/huggingface/transformers.git\ncd transformers\npip install .\n```\n\n3. Set `double_quantization: false` in the configuration. You can refer to the [example](examples/train_qlora/llama3_lora_sft_bnb_npu.yaml).\n\n</details>\n\n### Data Preparation\n\nPlease refer to [data/README.md](data/README.md) for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.\n\n> [!NOTE]\n> Please update `data/dataset_info.json` to use your custom dataset.\n\nYou can also use **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**, **[DataFlow](https://github.com/OpenDCAI/DataFlow)** and **[GraphGen](https://github.com/open-sciencelab/GraphGen)** to create synthetic data for fine-tuning.\n\n### Quickstart\n\nUse the following 3 commands to run LoRA **fine-tuning**, **inference** and **merging** of the Llama3-8B-Instruct model, respectively.\n\n```bash\nllamafactory-cli train examples/train_lora/llama3_lora_sft.yaml\nllamafactory-cli chat examples/inference/llama3_lora_sft.yaml\nllamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml\n```\n\nSee [examples/README.md](examples/README.md) for advanced usage (including distributed training).\n\n> [!TIP]\n> Use `llamafactory-cli help` to show help information.\n>\n> Read [FAQs](https://github.com/hiyouga/LLaMA-Factory/issues/4614) first if you encounter any problems.\n\n### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))\n\n```bash\nllamafactory-cli webui\n```\n\n### LLaMA Factory Online\n\nRead our [documentation](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory).\n\n### Build Docker\n\nFor CUDA users:\n\n```bash\ncd docker/docker-cuda/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ncd docker/docker-npu/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ncd docker/docker-rocm/\ndocker compose up -d\ndocker compose exec llamafactory bash\n```\n\n<details><summary>Build without Docker Compose</summary>\n\nFor CUDA users:\n\n```bash\ndocker build -f ./docker/docker-cuda/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host --gpus=all \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor Ascend NPU users:\n\n```bash\ndocker build -f ./docker/docker-npu/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=torch-npu,metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -v /usr/local/dcmi:/usr/local/dcmi \\\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n    -v /etc/ascend_install.info:/etc/ascend_install.info \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/davinci0 \\\n    --device /dev/davinci_manager \\\n    --device /dev/devmm_svm \\\n    --device /dev/hisi_hdc \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\nFor AMD ROCm users:\n\n```bash\ndocker build -f ./docker/docker-rocm/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/kfd \\\n    --device /dev/dri \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash\n```\n\n</details>\n\n<details><summary>Use Docker volumes</summary>\n\nYou can uncomment `VOLUME [ \"/root/.cache/huggingface\", \"/app/shared_data\", \"/app/output\" ]` in the Dockerfile to use data volumes.\n\nWhen building the Docker image, use `-v ./hf_cache:/root/.cache/huggingface` argument to mount the local directory to the container. The following data volumes are available.\n\n- `hf_cache`: Utilize Hugging Face cache on the host machine.\n- `shared_data`: The directionary to store datasets on the host machine.\n- `output`: Set export dir to this location so that the merged result can be accessed directly on the host machine.\n\n</details>\n\n### Deploy with OpenAI-style API and vLLM\n\n```bash\nAPI_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true\n```\n\n> [!TIP]\n> Visit [this page](https://platform.openai.com/docs/api-reference/chat/create) for API document.\n>\n> Examples: [Image understanding](scripts/api_example/test_image.py) | [Function calling](scripts/api_example/test_toolcall.py)\n\n### Download from ModelScope Hub\n\nIf you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.\n\n```bash\nexport USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the ModelScope Hub as the `model_name_or_path`. You can find a full list of model IDs at [ModelScope Hub](https://modelscope.cn/models), e.g., `LLM-Research/Meta-Llama-3-8B-Instruct`.\n\n### Download from Modelers Hub\n\nYou can also use Modelers Hub to download models and datasets.\n\n```bash\nexport USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows\n```\n\nTrain the model by specifying a model ID of the Modelers Hub as the `model_name_or_path`. You can find a full list of model IDs at [Modelers Hub](https://modelers.cn/models), e.g., `TeleAI/TeleChat-7B-pt`.\n\n### Use W&B Logger\n\nTo use [Weights & Biases](https://wandb.ai) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nreport_to: wandb\nrun_name: test_run # optional\n```\n\nSet `WANDB_API_KEY` to [your key](https://wandb.ai/authorize) when launching training tasks to log in with your W&B account.\n\n### Use SwanLab Logger\n\nTo use [SwanLab](https://github.com/SwanHubX/SwanLab) for logging experimental results, you need to add the following arguments to yaml files.\n\n```yaml\nuse_swanlab: true\nswanlab_run_name: test_run # optional\n```\n\nWhen launching training tasks, you can log in to SwanLab in three ways:\n\n1. Add `swanlab_api_key=<your_api_key>` to the yaml file, and set it to your [API key](https://swanlab.cn/settings).\n2. Set the environment variable `SWANLAB_API_KEY` to your [API key](https://swanlab.cn/settings).\n3. Use the `swanlab login` command to complete the login.\n\n## Projects using LLaMA Factory\n\nIf you have a project that should be incorporated, please contact via email or create a pull request.\n\n<details><summary>Click to show</summary>\n\n1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)\n1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)\n1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)\n1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)\n1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)\n1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)\n1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)\n1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)\n1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)\n1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)\n1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)\n1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)\n1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)\n1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)\n1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)\n1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)\n1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)\n1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)\n1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)\n1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)\n1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)\n1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)\n1. Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)\n1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)\n1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)\n1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)\n1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)\n1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)\n1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)\n1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)\n1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)\n1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)\n1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)\n1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)\n1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)\n1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)\n1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)\n1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)\n1. Dammu et al. \"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)\n1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)\n1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)\n1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)\n1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)\n1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)\n1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)\n1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)\n1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)\n1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)\n1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)\n1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)\n1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)\n1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)\n1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)\n1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)\n1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)\n1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)\n1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)\n1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)\n1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)\n1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)\n1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)\n1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)\n1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)\n1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)\n1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)\n1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)\n1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)\n1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)\n1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)\n1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)\n1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)\n1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)\n1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)\n1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)\n1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)\n1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)\n1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)\n1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)\n1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)\n1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)\n1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)\n1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)\n1. Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. [[paper]](https://aclanthology.org/2024.findings-acl.830.pdf)\n1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.\n1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.\n1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.\n1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.\n1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.\n1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**: A large language model specialized in generate metadata for stable diffusion. [[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)\n1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.\n1. **[AutoRE](https://github.com/THUDM/AutoRE)**: A document-level relation extraction system based on large language models.\n1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.\n1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.\n1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [[blog]](https://zhuanlan.zhihu.com/p/987727357)\n1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**: A modified library that supports long sequence SFT & DPO using ring attention.\n1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**: An o1-like model fine-tuned by NovaSky AI with very small cost.\n1. **[WeClone](https://github.com/xming521/WeClone)**: One-stop solution for creating your digital avatar from chat logs.\n1. **[EmoLLM](https://github.com/SmartFlowAI/EmoLLM)**: A project about large language models (LLMs) and mental health.\n</details>\n\n## License\n\nThis repository is licensed under the [Apache-2.0 License](LICENSE).\n\nPlease follow the model licenses to use the corresponding model weights: [Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)\n\n## Citation\n\nIf this work is helpful, please kindly cite as:\n\n```bibtex\n@inproceedings{zheng2024llamafactory,\n  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},\n  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},\n  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},\n  address={Bangkok, Thailand},\n  publisher={Association for Computational Linguistics},\n  year={2024},\n  url={http://arxiv.org/abs/2403.13372}\n}\n```\n\n## Acknowledgement\n\nThis repo benefits from [PEFT](https://github.com/huggingface/peft), [TRL](https://github.com/huggingface/trl), [QLoRA](https://github.com/artidoro/qlora) and [FastChat](https://github.com/lm-sys/FastChat). Thanks for their wonderful works.\n\n## Star History\n\n![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/hiyouga/LLaMA-Factory",
          "homepage": "https://llamafactory.readthedocs.io",
          "language": "Python",
          "forks": 7601,
          "open_issues": 783,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/16256802?v=4",
      "velocity": 69082.2,
      "is_rising_star": true,
      "heatScore": 20728.018586272854,
      "popularityScore": 62802
    },
    {
      "id": "github-FoundationAgents-MetaGPT",
      "name": "MetaGPT",
      "author": "FoundationAgents",
      "description": "üåü The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
      "task": "tool",
      "tags": [
        "agent",
        "gpt",
        "llm",
        "metagpt",
        "multi-agent"
      ],
      "likes": 119174,
      "downloads": 119174,
      "lastModified": "2025-11-20T13:55:30Z",
      "lastModifiedTimestamp": 1763646930000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FoundationAgents/MetaGPT",
          "homepage": "https://mgx.dev/",
          "language": "Python",
          "forks": 7283,
          "open_issues": 57,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/198047230?v=4",
      "velocity": 65545.7,
      "is_rising_star": true,
      "heatScore": 19667.052611166364,
      "popularityScore": 59587
    },
    {
      "id": "github-unclecode-crawl4ai",
      "name": "crawl4ai",
      "author": "unclecode",
      "description": "üöÄü§ñ Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN",
      "task": "tool",
      "tags": [],
      "likes": 112306,
      "downloads": 112306,
      "lastModified": "2025-11-20T15:20:08Z",
      "lastModifiedTimestamp": 1763652008000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unclecode/crawl4ai",
          "homepage": "https://crawl4ai.com",
          "language": "Python",
          "forks": 5636,
          "open_issues": 263,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/12494079?v=4",
      "velocity": 61768.3,
      "is_rising_star": true,
      "heatScore": 18533.814566488363,
      "popularityScore": 56153
    },
    {
      "id": "github-OpenBB-finance-OpenBB",
      "name": "OpenBB",
      "author": "OpenBB-finance",
      "description": "Financial data platform for analysts, quants and AI agents.",
      "task": "tool",
      "tags": [
        "ai",
        "crypto",
        "derivatives",
        "economics",
        "equity",
        "finance",
        "fixed-income",
        "machine-learning",
        "openbb",
        "options",
        "python",
        "quantitative-finance",
        "stocks"
      ],
      "likes": 109330,
      "downloads": 109330,
      "lastModified": "2025-11-20T13:41:09Z",
      "lastModifiedTimestamp": 1763646069000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBB-finance/OpenBB",
          "homepage": "https://openbb.co",
          "language": "Python",
          "forks": 5288,
          "open_issues": 52,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/80064875?v=4",
      "velocity": 60131.5,
      "is_rising_star": true,
      "heatScore": 18042.766402107914,
      "popularityScore": 54665
    },
    {
      "id": "github-wshobson-agents",
      "name": "agents",
      "author": "wshobson",
      "description": "Intelligent automation and multi-agent orchestration for Claude Code",
      "task": "tool",
      "tags": [
        "agents",
        "ai-agents",
        "anthropic",
        "anthropic-claude",
        "automation",
        "claude",
        "claude-code",
        "claude-code-cli",
        "claude-code-commands",
        "claude-code-plugin",
        "claude-code-plugins",
        "claude-code-subagents",
        "claude-skills",
        "claudecode",
        "claudecode-config",
        "claudecode-subagents",
        "orchestration",
        "sub-agents",
        "subagents",
        "workflows",
        "agent-computer-interface",
        "computer-automation",
        "computer-use",
        "computer-use-agent",
        "cua",
        "grounding",
        "gui-agents",
        "in-context-reinforcement-learning",
        "memory",
        "mllm",
        "planning",
        "retrieval-augmented-generation",
        "ai",
        "openai",
        "real-time",
        "video",
        "voice",
        "autonomous-agents",
        "language-model",
        "llm",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 106916,
      "downloads": 106916,
      "lastModified": "2025-11-20T15:44:42Z",
      "lastModifiedTimestamp": 1763653482000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/wshobson/agents",
          "homepage": "https://sethhobson.com",
          "language": "Python",
          "forks": 2352,
          "open_issues": 4,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/contains-studio/agents",
          "homepage": null,
          "language": null,
          "forks": 2129,
          "open_issues": 9,
          "license": "No license"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/simular-ai/Agent-S",
          "homepage": "https://www.simular.ai",
          "language": "Python",
          "forks": 907,
          "open_issues": 13,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/livekit/agents",
          "homepage": "https://docs.livekit.io/agents",
          "language": "Python",
          "forks": 1776,
          "open_issues": 448,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/aiwaves-cn/agents",
          "homepage": "",
          "language": "Python",
          "forks": 452,
          "open_issues": 39,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
      "velocity": 58803.8,
      "is_rising_star": true,
      "heatScore": 17644.44961458143,
      "popularityScore": 53458
    },
    {
      "id": "github-cline-cline",
      "name": "cline",
      "author": "cline",
      "description": "Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 105064,
      "downloads": 105064,
      "lastModified": "2025-11-20T15:39:22Z",
      "lastModifiedTimestamp": 1763653162000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/cline/cline",
          "homepage": "https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev",
          "language": "TypeScript",
          "forks": 5246,
          "open_issues": 895,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/184127137?v=4",
      "velocity": 57785.2,
      "is_rising_star": true,
      "heatScore": 17338.864302541922,
      "popularityScore": 52532
    },
    {
      "id": "github-microsoft-autogen",
      "name": "autogen",
      "author": "microsoft",
      "description": "A programming framework for agentic AI",
      "task": "tool",
      "tags": [
        "agentic",
        "agentic-agi",
        "agents",
        "ai",
        "autogen",
        "autogen-ecosystem",
        "chatgpt",
        "framework",
        "llm-agent",
        "llm-framework"
      ],
      "likes": 103658,
      "downloads": 103658,
      "lastModified": "2025-11-20T14:57:51Z",
      "lastModifiedTimestamp": 1763650671000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/autogen",
          "homepage": "https://microsoft.github.io/autogen/",
          "language": "Python",
          "forks": 7872,
          "open_issues": 511,
          "license": "Creative Commons Attribution 4.0 International"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 57011.9,
      "is_rising_star": true,
      "heatScore": 17106.870206846186,
      "popularityScore": 51829
    },
    {
      "id": "github-Mintplex-Labs-anything-llm",
      "name": "anything-llm",
      "author": "Mintplex-Labs",
      "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
      "task": "tool",
      "tags": [
        "ai-agents",
        "custom-ai-agents",
        "deepseek",
        "kimi",
        "llama3",
        "llm",
        "lmstudio",
        "local-llm",
        "localai",
        "mcp",
        "mcp-servers",
        "moonshot",
        "multimodal",
        "no-code",
        "ollama",
        "qwen3",
        "rag",
        "vector-database",
        "web-scraping",
        "rag-knowledge-base-qa",
        "code-generation-assistance"
      ],
      "likes": 102482,
      "downloads": 102482,
      "lastModified": "2025-11-20T15:24:23Z",
      "lastModifiedTimestamp": 1763652263000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Mintplex-Labs/anything-llm",
          "homepage": "https://anythingllm.com",
          "language": "JavaScript",
          "forks": 5428,
          "open_issues": 331,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134426827?v=4",
      "velocity": 56365.1,
      "is_rising_star": true,
      "heatScore": 16912.82673825049,
      "popularityScore": 51241
    },
    {
      "id": "github-openai-codex",
      "name": "codex",
      "author": "openai",
      "description": "Lightweight coding agent that runs in your terminal",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 101932,
      "downloads": 101932,
      "lastModified": "2025-11-20T15:27:31Z",
      "lastModifiedTimestamp": 1763652451000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/openai/codex",
          "homepage": "",
          "language": "Rust",
          "forks": 6392,
          "open_issues": 1067,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/14957082?v=4",
      "velocity": 56062.6,
      "is_rising_star": true,
      "heatScore": 16822.075102349743,
      "popularityScore": 50966
    },
    {
      "id": "github-pathwaycom-pathway",
      "name": "pathway",
      "author": "pathwaycom",
      "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
      "task": "tool",
      "tags": [
        "batch-processing",
        "data-analytics",
        "data-pipelines",
        "data-processing",
        "dataflow",
        "etl",
        "etl-framework",
        "iot-analytics",
        "kafka",
        "machine-learning-algorithms",
        "pathway",
        "python",
        "real-time",
        "rust",
        "stream-processing",
        "streaming",
        "time-series-analysis",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 100330,
      "downloads": 100330,
      "lastModified": "2025-11-20T15:47:22Z",
      "lastModifiedTimestamp": 1763653642000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/pathway",
          "homepage": "https://pathway.com",
          "language": "Python",
          "forks": 1454,
          "open_issues": 39,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 55181.5,
      "is_rising_star": true,
      "heatScore": 16557.740286631673,
      "popularityScore": 50165
    },
    {
      "id": "github-opendatalab-MinerU",
      "name": "MinerU",
      "author": "opendatalab",
      "description": "Transforms complex documents like PDFs into LLM-ready markdown/JSON for your Agentic workflows.",
      "task": "tool",
      "tags": [
        "ai4science",
        "document-analysis",
        "extract-data",
        "layout-analysis",
        "ocr",
        "parser",
        "pdf",
        "pdf-converter",
        "pdf-extractor-llm",
        "pdf-extractor-pretrain",
        "pdf-extractor-rag",
        "pdf-parser",
        "python"
      ],
      "likes": 98356,
      "downloads": 98356,
      "lastModified": "2025-11-20T15:21:22Z",
      "lastModifiedTimestamp": 1763652082000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/opendatalab/MinerU",
          "homepage": "https://opendatalab.github.io/MinerU/",
          "language": "Python",
          "forks": 4080,
          "open_issues": 128,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/97503431?v=4",
      "velocity": 54095.8,
      "is_rising_star": true,
      "heatScore": 16232.02424578552,
      "popularityScore": 49178
    },
    {
      "id": "github-unslothai-unsloth",
      "name": "unsloth",
      "author": "unslothai",
      "description": "Fine-tuning & Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, DeepSeek-R1, Qwen3, Gemma 3, TTS 2x faster with 70% less VRAM.",
      "task": "tool",
      "tags": [
        "agent",
        "deepseek",
        "deepseek-r1",
        "fine-tuning",
        "gemma",
        "gemma3",
        "gpt-oss",
        "llama",
        "llama3",
        "llm",
        "llms",
        "mistral",
        "openai",
        "qwen",
        "qwen3",
        "reinforcement-learning",
        "text-to-speech",
        "tts",
        "unsloth",
        "voice-cloning"
      ],
      "likes": 96990,
      "downloads": 96990,
      "lastModified": "2025-11-20T15:45:30Z",
      "lastModifiedTimestamp": 1763653530000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/unslothai/unsloth",
          "homepage": "https://docs.unsloth.ai/",
          "language": "Python",
          "forks": 3989,
          "open_issues": 856,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/150920049?v=4",
      "velocity": 53344.5,
      "is_rising_star": true,
      "heatScore": 16006.629994143315,
      "popularityScore": 48495
    },
    {
      "id": "github-huginn-huginn",
      "name": "huginn",
      "author": "huginn",
      "description": "Create agents that monitor and act on your behalf.  Your agents are standing by!",
      "task": "tool",
      "tags": [
        "agent",
        "automation",
        "feed",
        "feedgenerator",
        "huginn",
        "monitoring",
        "notifications",
        "rss",
        "scraper",
        "twitter",
        "twitter-streaming",
        "webscraping"
      ],
      "likes": 96214,
      "downloads": 96214,
      "lastModified": "2025-11-20T14:23:03Z",
      "lastModifiedTimestamp": 1763648583000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huginn/huginn",
          "homepage": "",
          "language": "Ruby",
          "forks": 4197,
          "open_issues": 691,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23225142?v=4",
      "velocity": 52917.7,
      "is_rising_star": true,
      "heatScore": 15878.587552111607,
      "popularityScore": 48107
    },
    {
      "id": "github-harry0703-MoneyPrinterTurbo",
      "name": "MoneyPrinterTurbo",
      "author": "harry0703",
      "description": "Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.",
      "task": "tool",
      "tags": [
        "ai",
        "automation",
        "chatgpt",
        "moviepy",
        "python",
        "shortvideo",
        "tiktok"
      ],
      "likes": 95706,
      "downloads": 95706,
      "lastModified": "2025-11-20T15:49:59Z",
      "lastModifiedTimestamp": 1763653799000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/harry0703/MoneyPrinterTurbo",
          "homepage": "",
          "language": "Python",
          "forks": 6701,
          "open_issues": 218,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/4928832?v=4",
      "velocity": 52638.3,
      "is_rising_star": true,
      "heatScore": 15794.765942771677,
      "popularityScore": 47853
    },
    {
      "id": "github-pathwaycom-llm-app",
      "name": "llm-app",
      "author": "pathwaycom",
      "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
      "task": "tool",
      "tags": [
        "chatbot",
        "hugging-face",
        "llm",
        "llm-local",
        "llm-prompting",
        "llm-security",
        "llmops",
        "machine-learning",
        "open-ai",
        "pathway",
        "rag",
        "real-time",
        "retrieval-augmented-generation",
        "vector-database",
        "vector-index",
        "general-dialogue-qa",
        "rag-knowledge-base-qa",
        "data-analysis-insights"
      ],
      "likes": 94666,
      "downloads": 94666,
      "lastModified": "2025-11-20T15:46:47Z",
      "lastModifiedTimestamp": 1763653607000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/pathwaycom/llm-app",
          "homepage": "https://pathway.com/developers/templates/",
          "language": "Jupyter Notebook",
          "forks": 1214,
          "open_issues": 6,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
      "velocity": 52066.3,
      "is_rising_star": true,
      "heatScore": 15623.16262124451,
      "popularityScore": 47333
    },
    {
      "id": "github-FlowiseAI-Flowise",
      "name": "Flowise",
      "author": "FlowiseAI",
      "description": "Build AI Agents, Visually",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-workflow",
        "agents",
        "artificial-intelligence",
        "chatbot",
        "chatgpt",
        "javascript",
        "langchain",
        "large-language-models",
        "low-code",
        "multiagent-systems",
        "no-code",
        "openai",
        "rag",
        "react",
        "typescript",
        "workflow-automation",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 93412,
      "downloads": 93412,
      "lastModified": "2025-11-20T15:27:35Z",
      "lastModifiedTimestamp": 1763652455000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/FlowiseAI/Flowise",
          "homepage": "https://flowiseai.com",
          "language": "TypeScript",
          "forks": 23141,
          "open_issues": 728,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128289781?v=4",
      "velocity": 51376.6,
      "is_rising_star": true,
      "heatScore": 15416.248567381353,
      "popularityScore": 46706
    },
    {
      "id": "github-run-llama-llama_index",
      "name": "llama_index",
      "author": "run-llama",
      "description": "LlamaIndex is the leading framework for building LLM-powered agents over your data.",
      "task": "tool",
      "tags": [
        "agents",
        "application",
        "data",
        "fine-tuning",
        "framework",
        "llamaindex",
        "llm",
        "multi-agents",
        "rag",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 90664,
      "downloads": 90664,
      "lastModified": "2025-11-20T15:48:18Z",
      "lastModifiedTimestamp": 1763653698000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/run-llama/llama_index",
          "homepage": "https://developers.llamaindex.ai",
          "language": "Python",
          "forks": 6534,
          "open_issues": 268,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/130722866?v=4",
      "velocity": 49865.2,
      "is_rising_star": true,
      "heatScore": 14962.819490122205,
      "popularityScore": 45332
    },
    {
      "id": "github-microsoft-ai-agents-for-beginners",
      "name": "ai-agents-for-beginners",
      "author": "microsoft",
      "description": "12 Lessons to Get Started Building AI Agents",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agentic-framework",
        "agentic-rag",
        "ai-agents",
        "ai-agents-framework",
        "autogen",
        "generative-ai",
        "semantic-kernel"
      ],
      "likes": 90478,
      "downloads": 90478,
      "lastModified": "2025-11-20T15:42:34Z",
      "lastModifiedTimestamp": 1763653354000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/ai-agents-for-beginners",
          "homepage": "https://aka.ms/ai-agents-beginners",
          "language": "Jupyter Notebook",
          "forks": 15356,
          "open_issues": 11,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 49762.9,
      "is_rising_star": true,
      "heatScore": 14932.128865817376,
      "popularityScore": 45239
    },
    {
      "id": "github-jeecgboot-JeecgBoot",
      "name": "JeecgBoot",
      "author": "jeecgboot",
      "description": "üî•AI‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÔºåÂä©Âäõ‰ºÅ‰∏öÂø´ÈÄüÂÆûÁé∞‰Ωé‰ª£Á†ÅÂºÄÂèëÂíåÊûÑÂª∫AIÂ∫îÁî®ÔºÅ ÈõÜÊàê‰∏ÄÂ•óÂÆåÊï¥AIÂ∫îÁî®Âπ≥Âè∞ÔºöÊ∂µÁõñAIÂ∫îÁî®„ÄÅAIÊ®°Âûã„ÄÅAIËÅäÂ§©Âä©Êâã„ÄÅÁü•ËØÜÂ∫ì„ÄÅAIÊµÅÁ®ãÁºñÊéíÁ≠âÔºåÂÖºÂÆπÂ§öÁßçÂ§ßÊ®°ÂûãÔºõÊèê‰æõÂº∫Â§ß‰ª£Á†ÅÁîüÊàêÂô®ÔºöÂÆûÁé∞ÂâçÂêéÁ´Ø‰∏ÄÈîÆÁîüÊàêÔºåÊó†ÈúÄÊâãÂÜô‰ª£Á†Å! ÂºïÈ¢ÜAIÂºÄÂèëÊ®°ÂºèÔºöAIÁîüÊàê‚ÜíÂú®Á∫øÈÖçÁΩÆ‚Üí‰ª£Á†ÅÁîüÊàê‚ÜíÊâãÂ∑•ÂêàÂπ∂ÔºåËß£ÂÜ≥JavaÈ°πÁõÆ80%ÈáçÂ§çÂ∑•‰ΩúÔºåÊèêÂçáÊïàÁéáËäÇÁúÅÊàêÊú¨ÔºåÂèà‰∏çÂ§±ÁÅµÊ¥ª~",
      "task": "tool",
      "tags": [
        "activiti",
        "agent",
        "ai",
        "aiflow",
        "ant-design-vue",
        "antd",
        "codegenerator",
        "deepseek",
        "flowable",
        "langchain4j",
        "llm",
        "low-code",
        "mcp",
        "mybatis-plus",
        "rag",
        "spring-ai",
        "springboot",
        "springboot3",
        "springcloud",
        "vue3",
        "rag-knowledge-base-qa"
      ],
      "likes": 88836,
      "downloads": 88836,
      "lastModified": "2025-11-20T14:22:51Z",
      "lastModifiedTimestamp": 1763648571000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/jeecgboot/JeecgBoot",
          "homepage": "https://jeecgboot.github.io/JeecgBoot/",
          "language": "Java",
          "forks": 15659,
          "open_issues": 54,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/86360035?v=4",
      "velocity": 48859.8,
      "is_rising_star": true,
      "heatScore": 14661.19329814397,
      "popularityScore": 44418
    },
    {
      "id": "github-mem0ai-mem0",
      "name": "mem0",
      "author": "mem0ai",
      "description": "Universal memory layer for AI Agents",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "application",
        "chatbots",
        "chatgpt",
        "genai",
        "hacktoberfest",
        "llm",
        "long-term-memory",
        "memory",
        "memory-management",
        "python",
        "rag",
        "state-management",
        "rag-knowledge-base-qa"
      ],
      "likes": 86706,
      "downloads": 86706,
      "lastModified": "2025-11-20T14:45:27Z",
      "lastModifiedTimestamp": 1763649927000,
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"docs/images/banner-sm.png\" width=\"800px\" alt=\"Mem0 - The Memory Layer for Personalized AI\">\n  </a>\n</p>\n<p align=\"center\" style=\"display: flex; justify-content: center; gap: 20px; align-items: center;\">\n  <a href=\"https://trendshift.io/repositories/11194\" target=\"blank\">\n    <img src=\"https://trendshift.io/api/badge/repositories/11194\" alt=\"mem0ai%2Fmem0 | Trendshift\" width=\"250\" height=\"55\"/>\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai\">Learn more</a>\n  ¬∑\n  <a href=\"https://mem0.dev/DiG\">Join Discord</a>\n  ¬∑\n  <a href=\"https://mem0.dev/demo\">Demo</a>\n  ¬∑\n  <a href=\"https://mem0.dev/openmemory\">OpenMemory</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.dev/DiG\">\n    <img src=\"https://img.shields.io/badge/Discord-%235865F2.svg?&logo=discord&logoColor=white\" alt=\"Mem0 Discord\">\n  </a>\n  <a href=\"https://pepy.tech/project/mem0ai\">\n    <img src=\"https://img.shields.io/pypi/dm/mem0ai\" alt=\"Mem0 PyPI - Downloads\">\n  </a>\n  <a href=\"https://github.com/mem0ai/mem0\">\n    <img src=\"https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square\" alt=\"GitHub commit activity\">\n  </a>\n  <a href=\"https://pypi.org/project/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/pypi/v/mem0ai?color=%2334D058&label=pypi%20package\" alt=\"Package version\">\n  </a>\n  <a href=\"https://www.npmjs.com/package/mem0ai\" target=\"blank\">\n    <img src=\"https://img.shields.io/npm/v/mem0ai\" alt=\"Npm package\">\n  </a>\n  <a href=\"https://www.ycombinator.com/companies/mem0\">\n    <img src=\"https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square\" alt=\"Y Combinator S24\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://mem0.ai/research\"><strong>üìÑ Building Production-Ready AI Agents with Scalable Long-Term Memory ‚Üí</strong></a>\n</p>\n<p align=\"center\">\n  <strong>‚ö° +26% Accuracy vs. OpenAI Memory ‚Ä¢ üöÄ 91% Faster ‚Ä¢ üí∞ 90% Fewer Tokens</strong>\n</p>\n\n> **üéâ mem0ai v1.0.0 is now available!** This major release includes API modernization, improved vector store support, and enhanced GCP integration. [See migration guide ‚Üí](MIGRATION_GUIDE_v1.0.md)\n\n##  üî• Research Highlights\n- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark\n- **91% Faster Responses** than full-context, ensuring low-latency at scale\n- **90% Lower Token Usage** than full-context, cutting costs without compromise\n- [Read the full paper](https://mem0.ai/research)\n\n# Introduction\n\n[Mem0](https://mem0.ai) (\"mem-zero\") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time‚Äîideal for customer support chatbots, AI assistants, and autonomous systems.\n\n### Key Features & Use Cases\n\n**Core Capabilities:**\n- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization\n- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option\n\n**Applications:**\n- **AI Assistants**: Consistent, context-rich conversations\n- **Customer Support**: Recall past tickets and user history for tailored help\n- **Healthcare**: Track patient preferences and history for personalized care\n- **Productivity & Gaming**: Adaptive workflows and environments based on user behavior\n\n## üöÄ Quickstart Guide <a name=\"quickstart\"></a>\n\nChoose between our hosted platform or self-hosted package:\n\n### Hosted Platform\n\nGet up and running in minutes with automatic updates, analytics, and enterprise security.\n\n1. Sign up on [Mem0 Platform](https://app.mem0.ai)\n2. Embed the memory layer via SDK or API keys\n\n### Self-Hosted (Open Source)\n\nInstall the sdk via pip:\n\n```bash\npip install mem0ai\n```\n\nInstall sdk via npm:\n```bash\nnpm install mem0ai\n```\n\n### Basic Usage\n\nMem0 requires an LLM to function, with `gpt-4.1-nano-2025-04-14 from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).\n\nFirst step is to instantiate the memory:\n\n```python\nfrom openai import OpenAI\nfrom mem0 import Memory\n\nopenai_client = OpenAI()\nmemory = Memory()\n\ndef chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n    # Retrieve relevant memories\n    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n\n    # Generate Assistant response\n    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n    response = openai_client.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n    assistant_response = response.choices[0].message.content\n\n    # Create new memories from the conversation\n    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n    memory.add(messages, user_id=user_id)\n\n    return assistant_response\n\ndef main():\n    print(\"Chat with AI (type 'exit' to quit)\")\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'exit':\n            print(\"Goodbye!\")\n            break\n        print(f\"AI: {chat_with_memories(user_input)}\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\nFor detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).\n\n## üîó Integrations & Demos\n\n- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))\n- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))\n- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))\n- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))\n\n## üìö Documentation & Support\n\n- Full docs: https://docs.mem0.ai\n- Community: [Discord](https://mem0.dev/DiG) ¬∑ [Twitter](https://x.com/mem0ai)\n- Contact: founders@mem0.ai\n\n## Citation\n\nWe now have a paper you can cite:\n\n```bibtex\n@article{mem0,\n  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},\n  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},\n  journal={arXiv preprint arXiv:2504.19413},\n  year={2025}\n}\n```\n\n## ‚öñÔ∏è License\n\nApache 2.0 ‚Äî see the [LICENSE](https://github.com/mem0ai/mem0/blob/main/LICENSE) file for details.",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mem0ai/mem0",
          "homepage": "https://mem0.ai",
          "language": "Python",
          "forks": 4697,
          "open_issues": 520,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/137054526?v=4",
      "velocity": 47688.3,
      "is_rising_star": true,
      "heatScore": 14309.73592042129,
      "popularityScore": 43353
    },
    {
      "id": "github-anthropics-claude-code",
      "name": "claude-code",
      "author": "anthropics",
      "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 85919,
      "downloads": 85919,
      "lastModified": "2025-11-20T15:52:02Z",
      "lastModifiedTimestamp": 1763653922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/anthropics/claude-code",
          "homepage": "https://code.claude.com/docs/en/overview",
          "language": "Shell",
          "forks": 2910,
          "open_issues": 5342,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/76263028?v=4",
      "velocity": 47254.9,
      "is_rising_star": true,
      "heatScore": 14179.713144990883,
      "popularityScore": 42959
    },
    {
      "id": "github-sst-opencode",
      "name": "opencode",
      "author": "sst",
      "description": "The AI coding agent built for the terminal.",
      "task": "tool",
      "tags": [
        "ai",
        "claude",
        "code",
        "llm",
        "openai",
        "code-generation-assistance"
      ],
      "likes": 85846,
      "downloads": 85846,
      "lastModified": "2025-11-20T15:54:52Z",
      "lastModifiedTimestamp": 1763654092000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/sst/opencode",
          "homepage": "https://opencode.ai",
          "language": "TypeScript",
          "forks": 2685,
          "open_issues": 1494,
          "license": "MIT License"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/opencode-ai/opencode",
          "homepage": "",
          "language": "Go",
          "forks": 807,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/66570915?v=4",
      "velocity": 47215.3,
      "is_rising_star": true,
      "heatScore": 14167.832890130338,
      "popularityScore": 42923
    },
    {
      "id": "github-crewAIInc-crewAI",
      "name": "crewAI",
      "author": "crewAIInc",
      "description": "Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "aiagentframework",
        "llms"
      ],
      "likes": 81234,
      "downloads": 81234,
      "lastModified": "2025-11-20T14:32:49Z",
      "lastModifiedTimestamp": 1763649169000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/crewAIInc/crewAI",
          "homepage": "https://crewai.com",
          "language": "Python",
          "forks": 5422,
          "open_issues": 197,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/170677839?v=4",
      "velocity": 44678.7,
      "is_rising_star": true,
      "heatScore": 13406.83610297468,
      "popularityScore": 40617
    },
    {
      "id": "github-ray-project-ray",
      "name": "ray",
      "author": "ray-project",
      "description": "Ray is an AI compute engine. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads.",
      "task": "tool",
      "tags": [
        "data-science",
        "deep-learning",
        "deployment",
        "distributed",
        "hyperparameter-optimization",
        "hyperparameter-search",
        "large-language-models",
        "llm",
        "llm-inference",
        "llm-serving",
        "machine-learning",
        "optimization",
        "parallel",
        "python",
        "pytorch",
        "ray",
        "reinforcement-learning",
        "rllib",
        "serving",
        "tensorflow"
      ],
      "likes": 79862,
      "downloads": 79862,
      "lastModified": "2025-11-20T15:50:42Z",
      "lastModifiedTimestamp": 1763653842000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ray-project/ray",
          "homepage": "https://ray.io",
          "language": "Python",
          "forks": 6924,
          "open_issues": 3226,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/22125274?v=4",
      "velocity": 43923,
      "is_rising_star": true,
      "heatScore": 13180.120917130518,
      "popularityScore": 39930
    },
    {
      "id": "github-zhayujie-chatgpt-on-wechat",
      "name": "chatgpt-on-wechat",
      "author": "zhayujie",
      "description": "Âü∫‰∫éÂ§ßÊ®°ÂûãÊê≠Âª∫ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂêåÊó∂ÊîØÊåÅ ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ Á≠âÊé•ÂÖ•ÔºåÂèØÈÄâÊã©ChatGPT/Claude/DeepSeek/ÊñáÂøÉ‰∏ÄË®Ä/ËÆØÈ£ûÊòüÁÅ´/ÈÄö‰πâÂçÉÈóÆ/ Gemini/GLM-4/Kimi/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥ÂíåÂõæÁâáÔºåËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíå‰∫íËÅîÁΩëÔºåÊîØÊåÅÂü∫‰∫éËá™ÊúâÁü•ËØÜÂ∫ìËøõË°åÂÆöÂà∂‰ºÅ‰∏öÊô∫ËÉΩÂÆ¢Êúç„ÄÇ",
      "task": "tool",
      "tags": [
        "ai",
        "ai-agent",
        "chatgpt",
        "claude-4",
        "deepseek",
        "dingtalk",
        "feishu-bot",
        "gemini",
        "gpt-4",
        "kimi",
        "linkai",
        "llm",
        "mcp",
        "multi-agent",
        "openai",
        "python3",
        "qwen",
        "rag",
        "wechat",
        "wechat-bot",
        "rag-knowledge-base-qa",
        "general-dialogue-qa"
      ],
      "likes": 79540,
      "downloads": 79540,
      "lastModified": "2025-11-20T15:05:28Z",
      "lastModifiedTimestamp": 1763651128000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/zhayujie/chatgpt-on-wechat",
          "homepage": "https://link-ai.tech",
          "language": "Python",
          "forks": 9502,
          "open_issues": 355,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/26161723?v=4",
      "velocity": 43747,
      "is_rising_star": true,
      "heatScore": 13127.3196965577,
      "popularityScore": 39770
    },
    {
      "id": "github-milvus-io-milvus",
      "name": "milvus",
      "author": "milvus-io",
      "description": "Milvus is a high-performance, cloud-native vector database built for scalable vector ANN search",
      "task": "tool",
      "tags": [
        "anns",
        "cloud-native",
        "diskann",
        "distributed",
        "embedding-database",
        "embedding-similarity",
        "embedding-store",
        "faiss",
        "golang",
        "hnsw",
        "image-search",
        "llm",
        "nearest-neighbor-search",
        "rag",
        "vector-database",
        "vector-search",
        "vector-similarity",
        "vector-store",
        "rag-knowledge-base-qa"
      ],
      "likes": 79350,
      "downloads": 79350,
      "lastModified": "2025-11-20T15:45:07Z",
      "lastModifiedTimestamp": 1763653507000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/milvus-io/milvus",
          "homepage": "https://milvus.io",
          "language": "Go",
          "forks": 3586,
          "open_issues": 905,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/51735404?v=4",
      "velocity": 43642.5,
      "is_rising_star": true,
      "heatScore": 13095.968969517113,
      "popularityScore": 39675
    },
    {
      "id": "github-janhq-jan",
      "name": "jan",
      "author": "janhq",
      "description": "Jan is an open source alternative to ChatGPT that runs 100% offline on your computer.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "gpt",
        "llamacpp",
        "llm",
        "localai",
        "open-source",
        "self-hosted",
        "tauri",
        "general-dialogue-qa"
      ],
      "likes": 78750,
      "downloads": 78750,
      "lastModified": "2025-11-20T13:35:09Z",
      "lastModifiedTimestamp": 1763645709000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/janhq/jan",
          "homepage": "https://jan.ai/",
          "language": "TypeScript",
          "forks": 2401,
          "open_issues": 191,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102363196?v=4",
      "velocity": 43312.5,
      "is_rising_star": true,
      "heatScore": 12996.966662117451,
      "popularityScore": 39375
    },
    {
      "id": "github-mudler-LocalAI",
      "name": "LocalAI",
      "author": "mudler",
      "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "audio-generation",
        "decentralized",
        "distributed",
        "gemma",
        "image-generation",
        "libp2p",
        "llama",
        "llm",
        "mamba",
        "mcp",
        "mistral",
        "musicgen",
        "object-detection",
        "rerank",
        "rwkv",
        "stable-diffusion",
        "text-generation",
        "tts"
      ],
      "likes": 77768,
      "downloads": 77768,
      "lastModified": "2025-11-20T15:54:00Z",
      "lastModifiedTimestamp": 1763654040000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/mudler/LocalAI",
          "homepage": "https://localai.io",
          "language": "Go",
          "forks": 3085,
          "open_issues": 244,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/2420543?v=4",
      "velocity": 42771.3,
      "is_rising_star": true,
      "heatScore": 12834.602839654122,
      "popularityScore": 38883
    },
    {
      "id": "github-QuivrHQ-quivr",
      "name": "quivr",
      "author": "QuivrHQ",
      "description": "Opiniated RAG for integrating GenAI in your apps üß†   Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want. ",
      "task": "tool",
      "tags": [
        "ai",
        "api",
        "chatbot",
        "chatgpt",
        "database",
        "docker",
        "framework",
        "frontend",
        "groq",
        "html",
        "javascript",
        "llm",
        "openai",
        "postgresql",
        "privacy",
        "rag",
        "react",
        "security",
        "typescript",
        "vector",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 77264,
      "downloads": 77264,
      "lastModified": "2025-11-20T12:53:10Z",
      "lastModifiedTimestamp": 1763643190000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/QuivrHQ/quivr",
          "homepage": "https://core.quivr.com",
          "language": "Python",
          "forks": 3689,
          "open_issues": 16,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/159330290?v=4",
      "velocity": 42495.2,
      "is_rising_star": true,
      "heatScore": 12751.770870903854,
      "popularityScore": 38632
    },
    {
      "id": "github-2noise-ChatTTS",
      "name": "ChatTTS",
      "author": "2noise",
      "description": "A generative speech model for daily dialogue.",
      "task": "tool",
      "tags": [
        "agent",
        "chat",
        "chatgpt",
        "chattts",
        "chinese",
        "chinese-language",
        "english",
        "english-language",
        "gpt",
        "llm",
        "llm-agent",
        "natural-language-inference",
        "python",
        "text-to-speech",
        "torch",
        "torchaudio",
        "tts",
        "general-dialogue-qa"
      ],
      "likes": 76366,
      "downloads": 76366,
      "lastModified": "2025-11-20T14:57:26Z",
      "lastModifiedTimestamp": 1763650646000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/2noise/ChatTTS",
          "homepage": "https://2noise.com",
          "language": "Python",
          "forks": 4148,
          "open_issues": 67,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/164844019?v=4",
      "velocity": 42001.3,
      "is_rising_star": true,
      "heatScore": 12603.597316994952,
      "popularityScore": 38183
    },
    {
      "id": "github-upstash-context7",
      "name": "context7",
      "author": "upstash",
      "description": "Context7 MCP Server -- Up-to-date code documentation for LLMs and AI code editors",
      "task": "tool",
      "tags": [
        "llm",
        "mcp",
        "mcp-server",
        "vibe-coding",
        "code-generation-assistance"
      ],
      "likes": 75160,
      "downloads": 75160,
      "lastModified": "2025-11-20T15:36:23Z",
      "lastModifiedTimestamp": 1763652983000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/upstash/context7",
          "homepage": "https://context7.com",
          "language": "JavaScript",
          "forks": 1863,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/74989412?v=4",
      "velocity": 41338,
      "is_rising_star": true,
      "heatScore": 12404.602477832499,
      "popularityScore": 37580
    },
    {
      "id": "github-chatboxai-chatbox",
      "name": "chatbox",
      "author": "chatboxai",
      "description": "User-friendly Desktop Client App for AI Models/LLMs (GPT, Claude, Gemini, Ollama...)",
      "task": "tool",
      "tags": [
        "assistant",
        "chatbot",
        "chatgpt",
        "claude",
        "copilot",
        "deepseek",
        "gemini",
        "gpt",
        "gpt-5",
        "ollama",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 74948,
      "downloads": 74948,
      "lastModified": "2025-11-20T14:27:41Z",
      "lastModifiedTimestamp": 1763648861000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatboxai/chatbox",
          "homepage": "https://chatboxai.app?utm_medium=github",
          "language": "TypeScript",
          "forks": 3786,
          "open_issues": 969,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/199570308?v=4",
      "velocity": 41221.4,
      "is_rising_star": true,
      "heatScore": 12369.621619149064,
      "popularityScore": 37474
    },
    {
      "id": "github-ToolJet-ToolJet",
      "name": "ToolJet",
      "author": "ToolJet",
      "description": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building internal tools, dashboard, business applications, workflows and AI agents üöÄ",
      "task": "tool",
      "tags": [
        "ai-app-builder",
        "docker",
        "hacktoberfest",
        "internal-applications",
        "internal-project",
        "internal-tool",
        "internal-tools",
        "javascript",
        "kubernetes",
        "low-code",
        "low-code-development-platform",
        "low-code-framework",
        "no-code",
        "nodejs",
        "reactjs",
        "self-hosted",
        "typescript",
        "web-development-tools",
        "workflow-automation"
      ],
      "likes": 73858,
      "downloads": 73858,
      "lastModified": "2025-11-20T10:01:22Z",
      "lastModifiedTimestamp": 1763632882000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ToolJet/ToolJet",
          "homepage": "https://tooljet.ai",
          "language": "JavaScript",
          "forks": 4877,
          "open_issues": 951,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/82193554?v=4",
      "velocity": 40621.9,
      "is_rising_star": true,
      "heatScore": 12189.767165515355,
      "popularityScore": 36929
    },
    {
      "id": "github-alibaba-arthas",
      "name": "arthas",
      "author": "alibaba",
      "description": "Alibaba Java Diagnostic Tool Arthas/Alibaba JavaËØäÊñ≠Âà©Âô®Arthas",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "arthas",
        "classloader",
        "diagnosis",
        "java",
        "jvm",
        "trace",
        "trouble-shooting"
      ],
      "likes": 73704,
      "downloads": 73704,
      "lastModified": "2025-11-20T11:33:25Z",
      "lastModifiedTimestamp": 1763638405000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/alibaba/arthas",
          "homepage": "https://arthas.aliyun.com/",
          "language": "Java",
          "forks": 7604,
          "open_issues": 455,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/1961952?v=4",
      "velocity": 40537.2,
      "is_rising_star": true,
      "heatScore": 12164.356530993009,
      "popularityScore": 36852
    },
    {
      "id": "github-chatchat-space-Langchain-Chatchat",
      "name": "Langchain-Chatchat",
      "author": "chatchat-space",
      "description": "Langchain-ChatchatÔºàÂéüLangchain-ChatGLMÔºâÂü∫‰∫é Langchain ‰∏é ChatGLM, Qwen ‰∏é Llama Á≠âËØ≠Ë®ÄÊ®°ÂûãÁöÑ RAG ‰∏é Agent Â∫îÁî® | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain ",
      "task": "tool",
      "tags": [
        "chatbot",
        "chatchat",
        "chatglm",
        "chatgpt",
        "embedding",
        "faiss",
        "fastchat",
        "gpt",
        "knowledge-base",
        "langchain",
        "langchain-chatglm",
        "llama",
        "llm",
        "milvus",
        "ollama",
        "qwen",
        "rag",
        "retrieval-augmented-generation",
        "streamlit",
        "xinference",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 73208,
      "downloads": 73208,
      "lastModified": "2025-11-20T14:18:54Z",
      "lastModifiedTimestamp": 1763648334000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chatchat-space/Langchain-Chatchat",
          "homepage": "",
          "language": "Python",
          "forks": 6070,
          "open_issues": 28,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/139558948?v=4",
      "velocity": 40264.4,
      "is_rising_star": true,
      "heatScore": 12082.514478287832,
      "popularityScore": 36604
    },
    {
      "id": "github-CherryHQ-cherry-studio",
      "name": "cherry-studio",
      "author": "CherryHQ",
      "description": "üçí Cherry Studio is a desktop client that supports for multiple LLM providers.",
      "task": "tool",
      "tags": [
        "agent",
        "anthropic",
        "assistant",
        "chatbot",
        "chatbotai",
        "electron",
        "llm",
        "mcp-client",
        "openai",
        "general-dialogue-qa"
      ],
      "likes": 71276,
      "downloads": 71276,
      "lastModified": "2025-11-20T13:54:08Z",
      "lastModifiedTimestamp": 1763646848000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CherryHQ/cherry-studio",
          "homepage": "https://cherry-ai.com",
          "language": "TypeScript",
          "forks": 3235,
          "open_issues": 542,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/187777663?v=4",
      "velocity": 39201.8,
      "is_rising_star": true,
      "heatScore": 11763.726347856722,
      "popularityScore": 35638
    },
    {
      "id": "github-karpathy-LLM101n",
      "name": "LLM101n",
      "author": "karpathy",
      "description": "LLM101n: Let's build a Storyteller",
      "task": "tool",
      "tags": [],
      "likes": 71188,
      "downloads": 71188,
      "lastModified": "2025-11-20T15:19:34Z",
      "lastModifiedTimestamp": 1763651974000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/LLM101n",
          "homepage": "",
          "language": null,
          "forks": 1937,
          "open_issues": 19,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 39153.4,
      "is_rising_star": true,
      "heatScore": 11749.205972298092,
      "popularityScore": 35594
    },
    {
      "id": "github-agno-agi-agno",
      "name": "agno",
      "author": "agno-agi",
      "description": "Multi-agent framework, runtime and control plane. Built for speed, privacy, and scale.",
      "task": "tool",
      "tags": [
        "agents",
        "ai",
        "ai-agents",
        "developer-tools",
        "python"
      ],
      "likes": 70800,
      "downloads": 70800,
      "lastModified": "2025-11-20T15:16:06Z",
      "lastModifiedTimestamp": 1763651766000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/agno-agi/agno",
          "homepage": "https://docs.agno.com",
          "language": "Python",
          "forks": 4648,
          "open_issues": 294,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/104874993?v=4",
      "velocity": 38940,
      "is_rising_star": true,
      "heatScore": 11685.18431087104,
      "popularityScore": 35400
    },
    {
      "id": "github-Alibaba-NLP-DeepResearch",
      "name": "DeepResearch",
      "author": "Alibaba-NLP",
      "description": "Tongyi Deep Research, the Leading Open-source Deep Research Agent",
      "task": "tool",
      "tags": [
        "agent",
        "alibaba",
        "artificial-intelligence",
        "deep-research",
        "deepresearch",
        "information-seeking",
        "llm",
        "tongyi",
        "web-agent",
        "ai",
        "gpt",
        "o3-mini",
        "research"
      ],
      "likes": 70728,
      "downloads": 70728,
      "lastModified": "2025-11-20T14:51:54Z",
      "lastModifiedTimestamp": 1763650314000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Alibaba-NLP/DeepResearch",
          "homepage": "https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/",
          "language": "Python",
          "forks": 1314,
          "open_issues": 66,
          "license": "Apache License 2.0"
        },
        {
          "platform": "GitHub",
          "url": "https://github.com/dzhng/deep-research",
          "homepage": "",
          "language": "TypeScript",
          "forks": 1867,
          "open_issues": 77,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/64211549?v=4",
      "velocity": 38900.4,
      "is_rising_star": true,
      "heatScore": 11673.304001563694,
      "popularityScore": 35364
    },
    {
      "id": "github-reworkd-AgentGPT",
      "name": "AgentGPT",
      "author": "reworkd",
      "description": "ü§ñ Assemble, configure, and deploy autonomous AI Agents in your browser.",
      "task": "tool",
      "tags": [
        "agent",
        "agentgpt",
        "agi",
        "autogpt",
        "baby-agi",
        "gpt",
        "langchain",
        "next",
        "openai",
        "t3",
        "t3-stack"
      ],
      "likes": 70512,
      "downloads": 70512,
      "lastModified": "2025-11-20T10:00:19Z",
      "lastModifiedTimestamp": 1763632819000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/reworkd/AgentGPT",
          "homepage": "https://agentgpt.reworkd.ai",
          "language": "TypeScript",
          "forks": 9487,
          "open_issues": 214,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/120154269?v=4",
      "velocity": 38781.6,
      "is_rising_star": true,
      "heatScore": 11637.663071748948,
      "popularityScore": 35256
    },
    {
      "id": "github-microsoft-qlib",
      "name": "qlib",
      "author": "microsoft",
      "description": "Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped with https://github.com/microsoft/RD-Agent to automate R&D process.",
      "task": "tool",
      "tags": [
        "algorithmic-trading",
        "auto-quant",
        "deep-learning",
        "finance",
        "fintech",
        "investment",
        "machine-learning",
        "paper",
        "platform",
        "python",
        "quant",
        "quant-dataset",
        "quant-models",
        "quantitative-finance",
        "quantitative-trading",
        "research",
        "research-paper",
        "stock-data"
      ],
      "likes": 67791,
      "downloads": 67791,
      "lastModified": "2025-11-20T15:50:29Z",
      "lastModifiedTimestamp": 1763653829000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/qlib",
          "homepage": "https://qlib.readthedocs.io/en/latest/",
          "language": "Python",
          "forks": 5248,
          "open_issues": 306,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 37284.5,
      "is_rising_star": true,
      "heatScore": 11188.521103915695,
      "popularityScore": 33895
    },
    {
      "id": "github-1Panel-dev-1Panel",
      "name": "1Panel",
      "author": "1Panel-dev",
      "description": "üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.",
      "task": "tool",
      "tags": [
        "1panel",
        "cockpit",
        "docker",
        "docker-ui",
        "lamp",
        "linux",
        "lnmp",
        "ollama",
        "webmin"
      ],
      "likes": 64204,
      "downloads": 64204,
      "lastModified": "2025-11-20T15:40:23Z",
      "lastModifiedTimestamp": 1763653223000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/1Panel-dev/1Panel",
          "homepage": "https://1panel.pro",
          "language": "Go",
          "forks": 2842,
          "open_issues": 302,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/109613420?v=4",
      "velocity": 35312.2,
      "is_rising_star": true,
      "heatScore": 10596.814581933142,
      "popularityScore": 32102
    },
    {
      "id": "github-danny-avila-LibreChat",
      "name": "LibreChat",
      "author": "danny-avila",
      "description": "Enhanced ChatGPT Clone: Features Agents, MCP, DeepSeek, Anthropic, AWS, OpenAI, Responses API, Azure, Groq, o1, GPT-5, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active.",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "artifacts",
        "aws",
        "azure",
        "chatgpt",
        "chatgpt-clone",
        "claude",
        "clone",
        "deepseek",
        "gemini",
        "google",
        "gpt-5",
        "librechat",
        "mcp",
        "o1",
        "openai",
        "responses-api",
        "vision",
        "webui",
        "general-dialogue-qa",
        "code-generation-assistance"
      ],
      "likes": 63636,
      "downloads": 63636,
      "lastModified": "2025-11-20T15:49:34Z",
      "lastModifiedTimestamp": 1763653774000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/danny-avila/LibreChat",
          "homepage": "https://librechat.ai/",
          "language": "TypeScript",
          "forks": 6245,
          "open_issues": 354,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110412045?v=4",
      "velocity": 34999.8,
      "is_rising_star": true,
      "heatScore": 10503.091880568634,
      "popularityScore": 31818
    },
    {
      "id": "github-khoj-ai-khoj",
      "name": "khoj",
      "author": "khoj-ai",
      "description": "Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "assistant",
        "chat",
        "chatgpt",
        "emacs",
        "image-generation",
        "llama3",
        "llamacpp",
        "llm",
        "obsidian",
        "obsidian-md",
        "offline-llm",
        "productivity",
        "rag",
        "research",
        "self-hosted",
        "semantic-search",
        "stt",
        "whatsapp-ai",
        "general-dialogue-qa",
        "rag-knowledge-base-qa"
      ],
      "likes": 63230,
      "downloads": 63230,
      "lastModified": "2025-11-20T14:35:37Z",
      "lastModifiedTimestamp": 1763649337000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/khoj-ai/khoj",
          "homepage": "https://khoj.dev",
          "language": "Python",
          "forks": 1863,
          "open_issues": 85,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/134046886?v=4",
      "velocity": 34776.5,
      "is_rising_star": true,
      "heatScore": 10436.099934846034,
      "popularityScore": 31615
    },
    {
      "id": "github-BerriAI-litellm",
      "name": "litellm",
      "author": "BerriAI",
      "description": "Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]",
      "task": "tool",
      "tags": [
        "ai-gateway",
        "anthropic",
        "azure-openai",
        "bedrock",
        "gateway",
        "langchain",
        "litellm",
        "llm",
        "llm-gateway",
        "llmops",
        "mcp-gateway",
        "openai",
        "openai-proxy",
        "vertex-ai"
      ],
      "likes": 62736,
      "downloads": 62736,
      "lastModified": "2025-11-20T14:16:45Z",
      "lastModifiedTimestamp": 1763648205000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/BerriAI/litellm",
          "homepage": "https://docs.litellm.ai/docs/",
          "language": "Python",
          "forks": 4769,
          "open_issues": 1382,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/121462774?v=4",
      "velocity": 34504.8,
      "is_rising_star": true,
      "heatScore": 10354.587550471952,
      "popularityScore": 31368
    },
    {
      "id": "github-continuedev-continue",
      "name": "continue",
      "author": "continuedev",
      "description": "‚è© Ship faster with Continuous AI. Open-source CLI that can be used in TUI mode as a coding agent or Headless mode to run background agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "background-agents",
        "claude",
        "cli",
        "continuous-ai",
        "developer-tools",
        "gemini",
        "gpt",
        "hacktoberfest",
        "jetbrains",
        "llm",
        "open-source",
        "qwen",
        "vscode",
        "workflows",
        "code-generation-assistance"
      ],
      "likes": 59846,
      "downloads": 59846,
      "lastModified": "2025-11-20T15:50:10Z",
      "lastModifiedTimestamp": 1763653810000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/continuedev/continue",
          "homepage": "https://docs.continue.dev/",
          "language": "TypeScript",
          "forks": 3805,
          "open_issues": 667,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/127876214?v=4",
      "velocity": 32915.3,
      "is_rising_star": true,
      "heatScore": 9877.72321375225,
      "popularityScore": 29923
    },
    {
      "id": "github-JushBJJ-Mr.-Ranedeer-AI-Tutor",
      "name": "Mr.-Ranedeer-AI-Tutor",
      "author": "JushBJJ",
      "description": "A GPT-4 AI Tutor Prompt for customizable personalized learning experiences.",
      "task": "tool",
      "tags": [
        "ai",
        "education",
        "gpt-4",
        "llm"
      ],
      "likes": 59336,
      "downloads": 59336,
      "lastModified": "2025-11-20T02:26:40Z",
      "lastModifiedTimestamp": 1763605600000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor",
          "homepage": "https://Mr-Ranedeer.com",
          "language": null,
          "forks": 3373,
          "open_issues": 14,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/36951064?v=4",
      "velocity": 32634.8,
      "is_rising_star": true,
      "heatScore": 9793.570612036001,
      "popularityScore": 29668
    },
    {
      "id": "github-microsoft-graphrag",
      "name": "graphrag",
      "author": "microsoft",
      "description": "A modular graph-based Retrieval-Augmented Generation (RAG) system",
      "task": "tool",
      "tags": [
        "gpt",
        "gpt-4",
        "gpt4",
        "graphrag",
        "llm",
        "llms",
        "rag",
        "rag-knowledge-base-qa"
      ],
      "likes": 58536,
      "downloads": 58536,
      "lastModified": "2025-11-20T15:31:55Z",
      "lastModifiedTimestamp": 1763652715000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/graphrag",
          "homepage": "https://microsoft.github.io/graphrag/",
          "language": "Python",
          "forks": 3081,
          "open_issues": 96,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 32194.8,
      "is_rising_star": true,
      "heatScore": 9661.566485519254,
      "popularityScore": 29268
    },
    {
      "id": "github-feder-cr-Jobs_Applier_AI_Agent_AIHawk",
      "name": "Jobs_Applier_AI_Agent_AIHawk",
      "author": "feder-cr",
      "description": "AIHawk aims to easy job hunt process by automating the job application process. Utilizing artificial intelligence, it enables users to apply for multiple jobs in a tailored way.",
      "task": "tool",
      "tags": [
        "agent",
        "application-resume",
        "artificial-intelligence",
        "automate",
        "automation",
        "bot",
        "chatgpt",
        "chrome",
        "gpt",
        "human-resources",
        "job",
        "jobs",
        "jobsearch",
        "jobseeker",
        "opeai",
        "python",
        "resume",
        "scraper",
        "scraping",
        "selenium"
      ],
      "likes": 58162,
      "downloads": 58162,
      "lastModified": "2025-11-20T14:18:17Z",
      "lastModifiedTimestamp": 1763648297000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/feder-cr/Jobs_Applier_AI_Agent_AIHawk",
          "homepage": "",
          "language": "Python",
          "forks": 4424,
          "open_issues": 13,
          "license": "GNU Affero General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/85809106?v=4",
      "velocity": 31989.1,
      "is_rising_star": true,
      "heatScore": 9599.854536989074,
      "popularityScore": 29081
    },
    {
      "id": "github-666ghj-BettaFish",
      "name": "BettaFish",
      "author": "666ghj",
      "description": "ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ",
      "task": "tool",
      "tags": [
        "agent-framework",
        "data-analysis",
        "deep-research",
        "deep-search",
        "llms",
        "multi-agent-system",
        "nlp",
        "public-opinion-analysis",
        "python3",
        "sentiment-analysis",
        "data-analysis-insights"
      ],
      "likes": 57118,
      "downloads": 57118,
      "lastModified": "2025-11-20T15:53:38Z",
      "lastModifiedTimestamp": 1763654018000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/666ghj/BettaFish",
          "homepage": "",
          "language": "Python",
          "forks": 5502,
          "open_issues": 69,
          "license": "GNU General Public License v2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/110395318?v=4",
      "velocity": 31413.8,
      "is_rising_star": true,
      "heatScore": 9427.259020097514,
      "popularityScore": 28558
    },
    {
      "id": "github-karpathy-llm.c",
      "name": "llm.c",
      "author": "karpathy",
      "description": "LLM training in simple, raw C/CUDA",
      "task": "tool",
      "tags": [],
      "likes": 56400,
      "downloads": 56400,
      "lastModified": "2025-11-20T14:42:34Z",
      "lastModifiedTimestamp": 1763649754000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/karpathy/llm.c",
          "homepage": "",
          "language": "Cuda",
          "forks": 3291,
          "open_issues": 215,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/241138?v=4",
      "velocity": 31020,
      "is_rising_star": true,
      "heatScore": 9309.115185155992,
      "popularityScore": 28200
    },
    {
      "id": "github-songquanpeng-one-api",
      "name": "one-api",
      "author": "songquanpeng",
      "description": "LLM API ÁÆ°ÁêÜ & ÂàÜÂèëÁ≥ªÁªüÔºåÊîØÊåÅ OpenAI„ÄÅAzure„ÄÅAnthropic Claude„ÄÅGoogle Gemini„ÄÅDeepSeek„ÄÅÂ≠óËäÇË±ÜÂåÖ„ÄÅChatGLM„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅ360 Êô∫ËÑë„ÄÅËÖæËÆØÊ∑∑ÂÖÉÁ≠â‰∏ªÊµÅÊ®°ÂûãÔºåÁªü‰∏Ä API ÈÄÇÈÖçÔºåÂèØÁî®‰∫é key ÁÆ°ÁêÜ‰∏é‰∫åÊ¨°ÂàÜÂèë„ÄÇÂçïÂèØÊâßË°åÊñá‰ª∂ÔºåÊèê‰æõ Docker ÈïúÂÉèÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÔºåÂºÄÁÆ±Âç≥Áî®„ÄÇLLM API management & key redistribution system, unifying multiple providers under a single API. Single binary, Docker-ready, with an English UI.",
      "task": "tool",
      "tags": [
        "api",
        "api-gateway",
        "azure-openai-api",
        "chatgpt",
        "claude",
        "ernie-bot",
        "gemini",
        "gpt",
        "openai",
        "openai-api",
        "proxy",
        "general-dialogue-qa"
      ],
      "likes": 56137,
      "downloads": 56137,
      "lastModified": "2025-11-20T15:51:47Z",
      "lastModifiedTimestamp": 1763653907000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/songquanpeng/one-api",
          "homepage": "https://openai.justsong.cn/",
          "language": "JavaScript",
          "forks": 5528,
          "open_issues": 969,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/39998050?v=4",
      "velocity": 30874.8,
      "is_rising_star": true,
      "heatScore": 9265.553758858363,
      "popularityScore": 28068
    },
    {
      "id": "github-OpenBMB-ChatDev",
      "name": "ChatDev",
      "author": "OpenBMB",
      "description": "Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)",
      "task": "tool",
      "tags": [],
      "likes": 55500,
      "downloads": 55500,
      "lastModified": "2025-11-20T09:53:36Z",
      "lastModifiedTimestamp": 1763632416000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/OpenBMB/ChatDev",
          "homepage": "https://arxiv.org/abs/2307.07924",
          "language": "Python",
          "forks": 3489,
          "open_issues": 50,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/89920203?v=4",
      "velocity": 30525,
      "is_rising_star": true,
      "heatScore": 9160.6102950462,
      "popularityScore": 27750
    },
    {
      "id": "github-stanford-oval-storm",
      "name": "storm",
      "author": "stanford-oval",
      "description": "An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.",
      "task": "tool",
      "tags": [
        "agentic-rag",
        "deep-research",
        "emnlp2024",
        "knowledge-curation",
        "large-language-models",
        "naacl",
        "nlp",
        "report-generation",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 55244,
      "downloads": 55244,
      "lastModified": "2025-11-20T11:29:33Z",
      "lastModifiedTimestamp": 1763638173000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/stanford-oval/storm",
          "homepage": "http://storm.genie.stanford.edu",
          "language": "Python",
          "forks": 2505,
          "open_issues": 87,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13667124?v=4",
      "velocity": 30384.2,
      "is_rising_star": true,
      "heatScore": 9118.368889590394,
      "popularityScore": 27622
    },
    {
      "id": "github-voideditor-void",
      "name": "void",
      "author": "voideditor",
      "description": "An AI tool from GitHub.",
      "task": "tool",
      "tags": [
        "chatgpt",
        "claude",
        "copilot",
        "cursor",
        "developer-tools",
        "editor",
        "llm",
        "open-source",
        "openai",
        "visual-studio-code",
        "vscode",
        "vscode-extension"
      ],
      "likes": 55124,
      "downloads": 55124,
      "lastModified": "2025-11-20T14:53:51Z",
      "lastModifiedTimestamp": 1763650431000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/voideditor/void",
          "homepage": "https://voideditor.com",
          "language": "TypeScript",
          "forks": 2149,
          "open_issues": 303,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/181171420?v=4",
      "velocity": 30318.2,
      "is_rising_star": true,
      "heatScore": 9098.568228539569,
      "popularityScore": 27562
    },
    {
      "id": "github-nrwl-nx",
      "name": "nx",
      "author": "nrwl",
      "description": "Get to green PRs in half the time. Nx optimizes your builds, scales your CI, and fixes failed PRs. Built for developers and AI agents.",
      "task": "tool",
      "tags": [
        "angular",
        "build",
        "build-system",
        "build-tool",
        "building-tool",
        "cli",
        "cypress",
        "hacktoberfest",
        "javascript",
        "monorepo",
        "nextjs",
        "nodejs",
        "nx",
        "nx-workspaces",
        "react",
        "storybook",
        "typescript"
      ],
      "likes": 55054,
      "downloads": 55054,
      "lastModified": "2025-11-20T15:43:56Z",
      "lastModifiedTimestamp": 1763653436000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/nrwl/nx",
          "homepage": "https://nx.dev",
          "language": "TypeScript",
          "forks": 2623,
          "open_issues": 789,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/23692104?v=4",
      "velocity": 30279.7,
      "is_rising_star": true,
      "heatScore": 9087.017842261728,
      "popularityScore": 27527
    },
    {
      "id": "github-microsoft-semantic-kernel",
      "name": "semantic-kernel",
      "author": "microsoft",
      "description": "Integrate cutting-edge LLM technology quickly and easily into your apps",
      "task": "tool",
      "tags": [
        "ai",
        "artificial-intelligence",
        "llm",
        "openai",
        "sdk"
      ],
      "likes": 53406,
      "downloads": 53406,
      "lastModified": "2025-11-20T12:07:50Z",
      "lastModifiedTimestamp": 1763640470000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/semantic-kernel",
          "homepage": "https://aka.ms/semantic-kernel",
          "language": "C#",
          "forks": 4352,
          "open_issues": 570,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 29373.3,
      "is_rising_star": true,
      "heatScore": 8815.088603423534,
      "popularityScore": 26703
    },
    {
      "id": "github-labring-FastGPT",
      "name": "FastGPT",
      "author": "labring",
      "description": "FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.",
      "task": "tool",
      "tags": [
        "agent",
        "claude",
        "deepseek",
        "llm",
        "mcp",
        "nextjs",
        "openai",
        "qwen",
        "rag",
        "workflow",
        "rag-knowledge-base-qa"
      ],
      "likes": 52648,
      "downloads": 52648,
      "lastModified": "2025-11-20T15:45:26Z",
      "lastModifiedTimestamp": 1763653526000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/labring/FastGPT",
          "homepage": "https://fastgpt.io",
          "language": "TypeScript",
          "forks": 6777,
          "open_issues": 653,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/102226726?v=4",
      "velocity": 28956.4,
      "is_rising_star": true,
      "heatScore": 8690.0142578659,
      "popularityScore": 26324
    },
    {
      "id": "github-ComposioHQ-composio",
      "name": "composio",
      "author": "ComposioHQ",
      "description": "Composio equips your AI agents & LLMs with 100+ high-quality integrations via function calling",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "ai-agents",
        "aiagents",
        "developer-tools",
        "function-calling",
        "gpt-4",
        "javascript",
        "js",
        "llm",
        "llmops",
        "mcp",
        "python",
        "remote-mcp-server",
        "sse",
        "typescript"
      ],
      "likes": 52338,
      "downloads": 52338,
      "lastModified": "2025-11-20T13:33:16Z",
      "lastModifiedTimestamp": 1763645596000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/ComposioHQ/composio",
          "homepage": "https://docs.composio.dev",
          "language": "TypeScript",
          "forks": 4399,
          "open_issues": 28,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/128464815?v=4",
      "velocity": 28785.9,
      "is_rising_star": true,
      "heatScore": 8638.862462605848,
      "popularityScore": 26169
    },
    {
      "id": "github-datawhalechina-self-llm",
      "name": "self-llm",
      "author": "datawhalechina",
      "description": "„ÄäÂºÄÊ∫êÂ§ßÊ®°ÂûãÈ£üÁî®ÊåáÂçó„ÄãÈíàÂØπ‰∏≠ÂõΩÂÆùÂÆùÈáèË∫´ÊâìÈÄ†ÁöÑÂü∫‰∫éLinuxÁéØÂ¢ÉÂø´ÈÄüÂæÆË∞ÉÔºàÂÖ®ÂèÇÊï∞/LoraÔºâ„ÄÅÈÉ®ÁΩ≤ÂõΩÂÜÖÂ§ñÂºÄÊ∫êÂ§ßÊ®°ÂûãÔºàLLMÔºâ/Â§öÊ®°ÊÄÅÂ§ßÊ®°ÂûãÔºàMLLMÔºâÊïôÁ®ã",
      "task": "tool",
      "tags": [
        "chatglm",
        "chatglm3",
        "gemma-2b-it",
        "glm-4",
        "internlm2",
        "llama3",
        "llm",
        "lora",
        "minicpm",
        "q-wen",
        "qwen",
        "qwen1-5",
        "qwen2"
      ],
      "likes": 52152,
      "downloads": 52152,
      "lastModified": "2025-11-20T15:48:41Z",
      "lastModifiedTimestamp": 1763653721000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/datawhalechina/self-llm",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2629,
          "open_issues": 147,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/46047812?v=4",
      "velocity": 28683.6,
      "is_rising_star": true,
      "heatScore": 8608.1713803389,
      "popularityScore": 26076
    },
    {
      "id": "github-Hannibal046-Awesome-LLM",
      "name": "Awesome-LLM",
      "author": "Hannibal046",
      "description": "Awesome-LLM: a curated list of Large Language Model",
      "task": "tool",
      "tags": [],
      "likes": 51190,
      "downloads": 51190,
      "lastModified": "2025-11-20T15:23:28Z",
      "lastModifiedTimestamp": 1763652208000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Hannibal046/Awesome-LLM",
          "homepage": "",
          "language": null,
          "forks": 2192,
          "open_issues": 51,
          "license": "Creative Commons Zero v1.0 Universal"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/38466901?v=4",
      "velocity": 28154.5,
      "is_rising_star": true,
      "heatScore": 8449.435720471049,
      "popularityScore": 25595
    },
    {
      "id": "github-warpdotdev-Warp",
      "name": "Warp",
      "author": "warpdotdev",
      "description": "Warp is the agentic development environment, built for coding with multiple AI agents.",
      "task": "tool",
      "tags": [
        "bash",
        "linux",
        "macos",
        "rust",
        "shell",
        "terminal",
        "wasm",
        "zsh",
        "code-generation-assistance"
      ],
      "likes": 50620,
      "downloads": 50620,
      "lastModified": "2025-11-20T15:49:51Z",
      "lastModifiedTimestamp": 1763653791000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/warpdotdev/Warp",
          "homepage": "https://warp.dev",
          "language": null,
          "forks": 581,
          "open_issues": 3958,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/71840468?v=4",
      "velocity": 27841,
      "is_rising_star": true,
      "heatScore": 8355.382316512678,
      "popularityScore": 25310
    },
    {
      "id": "github-TauricResearch-TradingAgents",
      "name": "TradingAgents",
      "author": "TauricResearch",
      "description": "TradingAgents: Multi-Agents LLM Financial Trading Framework",
      "task": "tool",
      "tags": [
        "agent",
        "finance",
        "llm",
        "multiagent",
        "trading"
      ],
      "likes": 50536,
      "downloads": 50536,
      "lastModified": "2025-11-20T15:34:43Z",
      "lastModifiedTimestamp": 1763652883000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/TauricResearch/TradingAgents",
          "homepage": "https://arxiv.org/pdf/2412.20138",
          "language": "Python",
          "forks": 4718,
          "open_issues": 200,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/192884433?v=4",
      "velocity": 27794.8,
      "is_rising_star": true,
      "heatScore": 8341.521811638786,
      "popularityScore": 25268
    },
    {
      "id": "github-CopilotKit-CopilotKit",
      "name": "CopilotKit",
      "author": "CopilotKit",
      "description": "React UI + elegant infrastructure for AI Copilots, AI chatbots, and in-app AI agents. The Agentic last-mile ü™Å",
      "task": "tool",
      "tags": [
        "agent",
        "agents",
        "ai",
        "ai-agent",
        "ai-assistant",
        "assistant",
        "copilot",
        "copilot-chat",
        "hacktoberfest",
        "langchain",
        "langgraph",
        "llm",
        "nextjs",
        "open-source",
        "react",
        "reactjs",
        "ts",
        "typescript",
        "general-dialogue-qa"
      ],
      "likes": 50076,
      "downloads": 50076,
      "lastModified": "2025-11-20T14:45:22Z",
      "lastModifiedTimestamp": 1763649922000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/CopilotKit/CopilotKit",
          "homepage": "https://docs.copilotkit.ai",
          "language": "TypeScript",
          "forks": 3341,
          "open_issues": 435,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/131273140?v=4",
      "velocity": 27541.8,
      "is_rising_star": true,
      "heatScore": 8265.619031886114,
      "popularityScore": 25038
    },
    {
      "id": "github-chroma-core-chroma",
      "name": "chroma",
      "author": "chroma-core",
      "description": "Open-source search and retrieval database for AI applications.",
      "task": "tool",
      "tags": [
        "ai",
        "database",
        "document-retrieval",
        "embeddings",
        "llm",
        "llms",
        "rag",
        "rust",
        "rust-lang",
        "vector-database",
        "rag-knowledge-base-qa"
      ],
      "likes": 49026,
      "downloads": 49026,
      "lastModified": "2025-11-20T14:11:20Z",
      "lastModifiedTimestamp": 1763647880000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/chroma-core/chroma",
          "homepage": "https://www.trychroma.com/",
          "language": "Rust",
          "forks": 1926,
          "open_issues": 491,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/105881770?v=4",
      "velocity": 26964.3,
      "is_rising_star": true,
      "heatScore": 8092.362589927232,
      "popularityScore": 24513
    },
    {
      "id": "github-microsoft-JARVIS",
      "name": "JARVIS",
      "author": "microsoft",
      "description": "JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf",
      "task": "tool",
      "tags": [
        "deep-learning",
        "platform",
        "pytorch"
      ],
      "likes": 48902,
      "downloads": 48902,
      "lastModified": "2025-11-20T11:10:51Z",
      "lastModifiedTimestamp": 1763637051000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/JARVIS",
          "homepage": "",
          "language": "Python",
          "forks": 2052,
          "open_issues": 344,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26896.1,
      "is_rising_star": true,
      "heatScore": 8071.901820070982,
      "popularityScore": 24451
    },
    {
      "id": "github-microsoft-BitNet",
      "name": "BitNet",
      "author": "microsoft",
      "description": "Official inference framework for 1-bit LLMs",
      "task": "tool",
      "tags": [],
      "likes": 48820,
      "downloads": 48820,
      "lastModified": "2025-11-20T12:29:27Z",
      "lastModifiedTimestamp": 1763641767000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/BitNet",
          "homepage": "",
          "language": "Python",
          "forks": 1895,
          "open_issues": 163,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26851,
      "is_rising_star": true,
      "heatScore": 8058.3713098995,
      "popularityScore": 24410
    },
    {
      "id": "github-assafelovic-gpt-researcher",
      "name": "gpt-researcher",
      "author": "assafelovic",
      "description": "An LLM agent that conducts deep research (local and web) on any given topic and generates a long report with citations.",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "automation",
        "deepresearch",
        "llms",
        "mcp",
        "mcp-server",
        "python",
        "research",
        "search",
        "webscraping"
      ],
      "likes": 48440,
      "downloads": 48440,
      "lastModified": "2025-11-20T15:20:31Z",
      "lastModifiedTimestamp": 1763652031000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/assafelovic/gpt-researcher",
          "homepage": "https://gptr.dev",
          "language": "Python",
          "forks": 3202,
          "open_issues": 149,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/13554167?v=4",
      "velocity": 26642,
      "is_rising_star": true,
      "heatScore": 7995.668934448769,
      "popularityScore": 24220
    },
    {
      "id": "github-e2b-dev-awesome-ai-agents",
      "name": "awesome-ai-agents",
      "author": "e2b-dev",
      "description": "A list of AI autonomous agents",
      "task": "tool",
      "tags": [
        "agent",
        "ai",
        "artificial-intelligence",
        "autogpt",
        "autonomous-agents",
        "awesome",
        "babyagi",
        "copilot",
        "gpt",
        "gpt-4",
        "gpt-engineer",
        "openai",
        "python"
      ],
      "likes": 48438,
      "downloads": 48438,
      "lastModified": "2025-11-20T14:47:26Z",
      "lastModifiedTimestamp": 1763650046000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/e2b-dev/awesome-ai-agents",
          "homepage": "https://e2b.dev/docs",
          "language": null,
          "forks": 2026,
          "open_issues": 78,
          "license": "Other"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/129434473?v=4",
      "velocity": 26640.9,
      "is_rising_star": true,
      "heatScore": 7995.338921897165,
      "popularityScore": 24219
    },
    {
      "id": "github-huggingface-smolagents",
      "name": "smolagents",
      "author": "huggingface",
      "description": "ü§ó smolagents: a barebones library for agents that think in code.",
      "task": "tool",
      "tags": [
        "code-generation-assistance"
      ],
      "likes": 48104,
      "downloads": 48104,
      "lastModified": "2025-11-20T15:45:37Z",
      "lastModifiedTimestamp": 1763653537000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/huggingface/smolagents",
          "homepage": "https://huggingface.co/docs/smolagents",
          "language": "Python",
          "forks": 2139,
          "open_issues": 316,
          "license": "Apache License 2.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
      "velocity": 26457.2,
      "is_rising_star": true,
      "heatScore": 7940.226818475895,
      "popularityScore": 24052
    },
    {
      "id": "github-gitleaks-gitleaks",
      "name": "gitleaks",
      "author": "gitleaks",
      "description": "Find secrets with Gitleaks üîë",
      "task": "tool",
      "tags": [
        "ai-powered",
        "ci-cd",
        "cicd",
        "cli",
        "data-loss-prevention",
        "devsecops",
        "dlp",
        "git",
        "gitleaks",
        "go",
        "golang",
        "hacktoberfest",
        "llm",
        "llm-inference",
        "llm-training",
        "nhi",
        "open-source",
        "secret",
        "security",
        "security-tools"
      ],
      "likes": 47960,
      "downloads": 47960,
      "lastModified": "2025-11-20T15:12:36Z",
      "lastModifiedTimestamp": 1763651556000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/gitleaks/gitleaks",
          "homepage": "https://gitleaks.io",
          "language": "Go",
          "forks": 1834,
          "open_issues": 315,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/90395851?v=4",
      "velocity": 26378,
      "is_rising_star": true,
      "heatScore": 7916.465907102356,
      "popularityScore": 23980
    },
    {
      "id": "github-microsoft-OmniParser",
      "name": "OmniParser",
      "author": "microsoft",
      "description": "A simple screen parsing tool towards pure vision based GUI agent",
      "task": "tool",
      "tags": [],
      "likes": 47784,
      "downloads": 47784,
      "lastModified": "2025-11-20T14:47:44Z",
      "lastModifiedTimestamp": 1763650064000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/microsoft/OmniParser",
          "homepage": "",
          "language": "Jupyter Notebook",
          "forks": 2048,
          "open_issues": 225,
          "license": "Creative Commons Attribution 4.0 International"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/6154722?v=4",
      "velocity": 26281.2,
      "is_rising_star": true,
      "heatScore": 7887.424789478167,
      "popularityScore": 23892
    },
    {
      "id": "github-HKUDS-LightRAG",
      "name": "LightRAG",
      "author": "HKUDS",
      "description": "[EMNLP2025] \"LightRAG: Simple and Fast Retrieval-Augmented Generation\"",
      "task": "tool",
      "tags": [
        "genai",
        "gpt",
        "gpt-4",
        "graphrag",
        "knowledge-graph",
        "large-language-models",
        "llm",
        "rag",
        "retrieval-augmented-generation",
        "rag-knowledge-base-qa"
      ],
      "likes": 47760,
      "downloads": 47760,
      "lastModified": "2025-11-20T15:47:31Z",
      "lastModifiedTimestamp": 1763653651000,
      "readme": "<div align=\"center\">\n\n<div style=\"margin: 20px 0;\">\n  <img src=\"./assets/logo.png\" width=\"120\" height=\"120\" alt=\"LightRAG Logo\" style=\"border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);\">\n</div>\n\n# üöÄ LightRAG: Simple and Fast Retrieval-Augmented Generation\n\n<div align=\"center\">\n    <a href=\"https://trendshift.io/repositories/13043\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/13043\" alt=\"HKUDS%2FLightRAG | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);\"></div>\n</div>\n\n<div align=\"center\">\n  <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;\">\n    <p>\n      <a href='https://github.com/HKUDS/LightRAG'><img src='https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&logo=github&logoColor=white&labelColor=1a1a2e'></a>\n      <a href='https://arxiv.org/abs/2410.05779'><img src='https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&logo=arxiv&logoColor=white&labelColor=1a1a2e'></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/stargazers\"><img src='https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&style=for-the-badge&logo=star&logoColor=white&labelColor=1a1a2e' /></a>\n    </p>\n    <p>\n      <img src=\"https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&logo=python&logoColor=white&labelColor=1a1a2e\">\n      <a href=\"https://pypi.org/project/lightrag-hku/\"><img src=\"https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&logo=pypi&logoColor=white&labelColor=1a1a2e&color=ff6b6b\"></a>\n    </p>\n    <p>\n      <a href=\"https://discord.gg/yF2MmDJyGJ\"><img src=\"https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&logo=discord&logoColor=white&labelColor=1a1a2e\"></a>\n      <a href=\"https://github.com/HKUDS/LightRAG/issues/285\"><img src=\"https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&logo=wechat&logoColor=white&labelColor=1a1a2e\"></a>\n    </p>\n    <p>\n      <a href=\"README-zh.md\"><img src=\"https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge\"></a>\n      <a href=\"README.md\"><img src=\"https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge\"></a>\n    </p>\n    <p>\n      <a href=\"https://pepy.tech/projects/lightrag-hku\"><img src=\"https://static.pepy.tech/personalized-badge/lightrag-hku?period=total&units=INTERNATIONAL_SYSTEM&left_color=BLACK&right_color=GREEN&left_text=downloads\"></a>\n    </p>\n  </div>\n</div>\n\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n  <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"800\">\n</div>\n\n<div align=\"center\" style=\"margin: 30px 0;\">\n    <img src=\"./README.assets/b2aaf634151b4706892693ffb43d9093.png\" width=\"800\" alt=\"LightRAG Diagram\">\n</div>\n\n---\n## üéâ News\n- [2025.11.05]üéØAdd **RAGAS-based** Evaluation Framework and **Langfuse** observability for LightRAG (API can return retrieved contexts with query results).\n- [2025.10.22]üéØEliminate bottlenecks in processing **large-scale datasets**.\n- [2025.09.15]üéØSignificantly enhances KG extraction accuracy for **small LLMs** like Qwen3-30B-A3B.\n- [2025.08.29]üéØ**Reranker** is supported now , significantly boosting performance for mixed queries(Set as default query mode now).\n- [2025.08.04]üéØ**Document deletion** with KG regeneration to ensure query performance.\n- [2025.06.16]üéØOur team has released [RAG-Anything](https://github.com/HKUDS/RAG-Anything) an All-in-One Multimodal RAG System for seamless text, image, table, and equation processing.\n- [2025.06.05]üéØLightRAG now supports comprehensive multimodal data handling through [RAG-Anything](https://github.com/HKUDS/RAG-Anything) integration, enabling seamless document parsing and RAG capabilities across diverse formats including PDFs, images, Office documents, tables, and formulas. Please refer to the new [multimodal section](https://github.com/HKUDS/LightRAG/?tab=readme-ov-file#multimodal-document-processing-rag-anything-integration) for details.\n- [2025.03.18]üéØLightRAG now supports citation functionality, enabling proper source attribution.\n- [2025.02.12]üéØYou can now use MongoDB as all in-one Storage.\n- [2025.02.05]üéØOur team has released [VideoRAG](https://github.com/HKUDS/VideoRAG) understanding extremely long-context videos.\n- [2025.01.13]üéØOur team has released [MiniRAG](https://github.com/HKUDS/MiniRAG) making RAG simpler with small models.\n- [2025.01.06]üéØYou can now use PostgreSQL as all in-one Storage.\n- [2024.11.19]üéØA comprehensive guide to LightRAG is now available on [LearnOpenCV](https://learnopencv.com/lightrag). Many thanks to the blog author.\n- [2024.11.09]üéØIntroducing the LightRAG Webui, which allows you to insert, query, visualize LightRAG knowledge.\n- [2024.11.04]üéØYou can now [use Neo4J for Storage](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage).\n- [2024.10.18]üéØWe've added a link to a [LightRAG Introduction Video](https://youtu.be/oageL-1I0GE). Thanks to the author!\n- [2024.10.17]üéØWe have created a [Discord channel](https://discord.gg/yF2MmDJyGJ)! Welcome to join for sharing and discussions! üéâüéâ\n- [2024.10.16]üéØLightRAG now supports [Ollama models](https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start)!\n\n<details>\n  <summary style=\"font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;\">\n    Algorithm Flowchart\n  </summary>\n\n![LightRAG Indexing Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg)\n*Figure 1: LightRAG Indexing Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n![LightRAG Retrieval and Querying Flowchart](https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg)\n*Figure 2: LightRAG Retrieval and Querying Flowchart - Img Caption : [Source](https://learnopencv.com/lightrag/)*\n\n</details>\n\n## Installation\n\n> **üí° Using uv for Package Management**: This project uses [uv](https://docs.astral.sh/uv/) for fast and reliable Python package management.\n> Install uv first: `curl -LsSf https://astral.sh/uv/install.sh | sh` (Unix/macOS) or `powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"` (Windows)\n>\n> **Note**: You can also use pip if you prefer, but uv is recommended for better performance and more reliable dependency management.\n>\n> **üì¶ Offline Deployment**: For offline or air-gapped environments, see the [Offline Deployment Guide](./docs/OfflineDeployment.md) for instructions on pre-installing all dependencies and cache files.\n\n### Install LightRAG Server\n\nThe LightRAG Server is designed to provide Web UI and API support. The Web UI facilitates document indexing, knowledge graph exploration, and a simple RAG query interface. LightRAG Server also provide an Ollama compatible interfaces, aiming to emulate LightRAG as an Ollama chat model. This allows AI chat bot, such as Open WebUI, to access LightRAG easily.\n\n* Install from PyPI\n\n```bash\n# Using uv (recommended)\nuv pip install \"lightrag-hku[api]\"\n# Or using pip\n# pip install \"lightrag-hku[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\nlightrag-server\n```\n\n* Installation from Source\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\n\n# Using uv (recommended)\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync --extra api\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or using pip with virtual environment\n# python -m venv .venv\n# source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n# pip install -e \".[api]\"\n\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n\n# Build front-end artifacts\ncd lightrag_webui\nbun install --frozen-lockfile\nbun run build\ncd ..\n\nlightrag-server\n```\n\n* Launching the LightRAG Server with Docker Compose\n\n```bash\ngit clone https://github.com/HKUDS/LightRAG.git\ncd LightRAG\ncp env.example .env  # Update the .env with your LLM and embedding configurations\n# modify LLM and Embedding settings in .env\ndocker compose up\n```\n\n> Historical versions of LightRAG docker images can be found here: [LightRAG Docker Images]( https://github.com/HKUDS/LightRAG/pkgs/container/lightrag)\n\n### Install  LightRAG Core\n\n* Install from source (Recommended)\n\n```bash\ncd LightRAG\n# Note: uv sync automatically creates a virtual environment in .venv/\nuv sync\nsource .venv/bin/activate  # Activate the virtual environment (Linux/macOS)\n# Or on Windows: .venv\\Scripts\\activate\n\n# Or: pip install -e .\n```\n\n* Install from PyPI\n\n```bash\nuv pip install lightrag-hku\n# Or: pip install lightrag-hku\n```\n\n## Quick Start\n\n### LLM and Technology Stack Requirements for LightRAG\n\nLightRAG's demands on the capabilities of Large Language Models (LLMs) are significantly higher than those of traditional RAG, as it requires the LLM to perform entity-relationship extraction tasks from documents. Configuring appropriate Embedding and Reranker models is also crucial for improving query performance.\n\n- **LLM Selection**:\n  - It is recommended to use an LLM with at least 32 billion parameters.\n  - The context length should be at least 32KB, with 64KB being recommended.\n  - It is not recommended to choose reasoning models during the document indexing stage.\n  - During the query stage, it is recommended to choose models with stronger capabilities than those used in the indexing stage to achieve better query results.\n- **Embedding Model**:\n  - A high-performance Embedding model is essential for RAG.\n  - We recommend using mainstream multilingual Embedding models, such as: `BAAI/bge-m3` and `text-embedding-3-large`.\n  - **Important Note**: The Embedding model must be determined before document indexing, and the same model must be used during the document query phase. For certain storage solutions (e.g., PostgreSQL), the vector dimension must be defined upon initial table creation. Therefore, when changing embedding models, it is necessary to delete the existing vector-related tables and allow LightRAG to recreate them with the new dimensions.\n- **Reranker Model Configuration**:\n  - Configuring a Reranker model can significantly enhance LightRAG's retrieval performance.\n  - When a Reranker model is enabled, it is recommended to set the \"mix mode\" as the default query mode.\n  - We recommend using mainstream Reranker models, such as: `BAAI/bge-reranker-v2-m3` or models provided by services like Jina.\n\n### Quick Start for LightRAG Server\n\n* For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).\n\n### Quick Start for LightRAG core\n\nTo get started with LightRAG core, refer to the sample codes available in the `examples` folder. Additionally, a [video demo](https://www.youtube.com/watch?v=g21royNJ4fw) demonstration is provided to guide you through the local setup process. If you already possess an OpenAI API key, you can run the demo right away:\n\n```bash\n### you should run the demo code with project folder\ncd LightRAG\n### provide your API-KEY for OpenAI\nexport OPENAI_API_KEY=\"sk-...your_opeai_key...\"\n### download the demo document of \"A Christmas Carol\" by Charles Dickens\ncurl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt > ./book.txt\n### run the demo code\npython examples/lightrag_openai_demo.py\n```\n\nFor a streaming response implementation example, please see `examples/lightrag_openai_compatible_demo.py`. Prior to execution, ensure you modify the sample code's LLM and embedding configurations accordingly.\n\n**Note 1**: When running the demo program, please be aware that different test scripts may use different embedding models. If you switch to a different embedding model, you must clear the data directory (`./dickens`); otherwise, the program may encounter errors. If you wish to retain the LLM cache, you can preserve the `kv_store_llm_response_cache.json` file while clearing the data directory.\n\n**Note 2**: Only `lightrag_openai_demo.py` and `lightrag_openai_compatible_demo.py` are officially supported sample codes. Other sample files are community contributions that haven't undergone full testing and optimization.\n\n## Programing with LightRAG Core\n\n> ‚ö†Ô∏è **If you would like to integrate LightRAG into your project, we recommend utilizing the REST API provided by the LightRAG Server**. LightRAG Core is typically intended for embedded applications or for researchers who wish to conduct studies and evaluations.\n\n### ‚ö†Ô∏è Important: Initialization Requirements\n\n**LightRAG requires explicit initialization before use.** You must call `await rag.initialize_storages()` after creating a LightRAG instance, otherwise you will encounter errors.\n\n### A Simple Program\n\nUse the below Python snippet to initialize LightRAG, insert text to it, and perform queries:\n\n```python\nimport os\nimport asyncio\nfrom lightrag import LightRAG, QueryParam\nfrom lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed\nfrom lightrag.utils import setup_logger\n\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nWORKING_DIR = \"./rag_storage\"\nif not os.path.exists(WORKING_DIR):\n    os.mkdir(WORKING_DIR)\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        embedding_func=openai_embed,\n        llm_model_func=gpt_4o_mini_complete,\n    )\n    # IMPORTANT: Both initialization calls are required!\n    await rag.initialize_storages()  # Initialize storage backends    return rag\n\nasync def main():\n    try:\n        # Initialize RAG instance\n        rag = await initialize_rag()\n        await rag.ainsert(\"Your text\")\n\n        # Perform hybrid search\n        mode = \"hybrid\"\n        print(\n          await rag.aquery(\n              \"What are the top themes in this story?\",\n              param=QueryParam(mode=mode)\n          )\n        )\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        if rag:\n            await rag.finalize_storages()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\nImportant notes for the above snippet:\n\n- Export your OPENAI_API_KEY environment variable before running the script.\n- This program uses the default storage settings for LightRAG, so all data will be persisted to WORKING_DIR/rag_storage.\n- This program demonstrates only the simplest way to initialize a LightRAG object: Injecting the embedding and LLM functions, and initializing storage and pipeline status after creating the LightRAG object.\n\n### LightRAG init parameters\n\nA full list of LightRAG init parameters:\n\n<details>\n<summary> Parameters </summary>\n\n| **Parameter** | **Type** | **Explanation** | **Default** |\n|--------------|----------|-----------------|-------------|\n| **working_dir** | `str` | Directory where the cache will be stored | `lightrag_cache+timestamp` |\n| **workspace** | str | Workspace name for data isolation between different LightRAG Instances |  |\n| **kv_storage** | `str` | Storage type for documents and text chunks. Supported types: `JsonKVStorage`,`PGKVStorage`,`RedisKVStorage`,`MongoKVStorage` | `JsonKVStorage` |\n| **vector_storage** | `str` | Storage type for embedding vectors. Supported types: `NanoVectorDBStorage`,`PGVectorStorage`,`MilvusVectorDBStorage`,`ChromaVectorDBStorage`,`FaissVectorDBStorage`,`MongoVectorDBStorage`,`QdrantVectorDBStorage` | `NanoVectorDBStorage` |\n| **graph_storage** | `str` | Storage type for graph edges and nodes. Supported types: `NetworkXStorage`,`Neo4JStorage`,`PGGraphStorage`,`AGEStorage` | `NetworkXStorage` |\n| **doc_status_storage** | `str` | Storage type for documents process status. Supported types: `JsonDocStatusStorage`,`PGDocStatusStorage`,`MongoDocStatusStorage` | `JsonDocStatusStorage` |\n| **chunk_token_size** | `int` | Maximum token size per chunk when splitting documents | `1200` |\n| **chunk_overlap_token_size** | `int` | Overlap token size between two chunks when splitting documents | `100` |\n| **tokenizer** | `Tokenizer` | The function used to convert text into tokens (numbers) and back using .encode() and .decode() functions following `TokenizerInterface` protocol. If you don't specify one, it will use the default Tiktoken tokenizer. | `TiktokenTokenizer` |\n| **tiktoken_model_name** | `str` | If you're using the default Tiktoken tokenizer, this is the name of the specific Tiktoken model to use. This setting is ignored if you provide your own tokenizer. | `gpt-4o-mini` |\n| **entity_extract_max_gleaning** | `int` | Number of loops in the entity extraction process, appending history messages | `1` |\n| **node_embedding_algorithm** | `str` | Algorithm for node embedding (currently not used) | `node2vec` |\n| **node2vec_params** | `dict` | Parameters for node embedding | `{\"dimensions\": 1536,\"num_walks\": 10,\"walk_length\": 40,\"window_size\": 2,\"iterations\": 3,\"random_seed\": 3,}` |\n| **embedding_func** | `EmbeddingFunc` | Function to generate embedding vectors from text | `openai_embed` |\n| **embedding_batch_num** | `int` | Maximum batch size for embedding processes (multiple texts sent per batch) | `32` |\n| **embedding_func_max_async** | `int` | Maximum number of concurrent asynchronous embedding processes | `16` |\n| **llm_model_func** | `callable` | Function for LLM generation | `gpt_4o_mini_complete` |\n| **llm_model_name** | `str` | LLM model name for generation | `meta-llama/Llama-3.2-1B-Instruct` |\n| **summary_context_size** | `int` | Maximum tokens send to LLM to generate summaries for entity relation merging | `10000`Ôºàconfigured by env var SUMMARY_CONTEXT_SIZE) |\n| **summary_max_tokens** | `int` | Maximum token size for entity/relation description | `500`Ôºàconfigured by env var SUMMARY_MAX_TOKENS) |\n| **llm_model_max_async** | `int` | Maximum number of concurrent asynchronous LLM processes | `4`Ôºàdefault value changed by env var MAX_ASYNC) |\n| **llm_model_kwargs** | `dict` | Additional parameters for LLM generation | |\n| **vector_db_storage_cls_kwargs** | `dict` | Additional parameters for vector database, like setting the threshold for nodes and relations retrieval | cosine_better_than_threshold: 0.2Ôºàdefault value changed by env var COSINE_THRESHOLD) |\n| **enable_llm_cache** | `bool` | If `TRUE`, stores LLM results in cache; repeated prompts return cached responses | `TRUE` |\n| **enable_llm_cache_for_entity_extract** | `bool` | If `TRUE`, stores LLM results in cache for entity extraction; Good for beginners to debug your application | `TRUE` |\n| **addon_params** | `dict` | Additional parameters, e.g., `{\"language\": \"Simplified Chinese\", \"entity_types\": [\"organization\", \"person\", \"location\", \"event\"]}`: sets example limit, entiy/relation extraction output language | language: English` |\n| **embedding_cache_config** | `dict` | Configuration for question-answer caching. Contains three parameters: `enabled`: Boolean value to enable/disable cache lookup functionality. When enabled, the system will check cached responses before generating new answers. `similarity_threshold`: Float value (0-1), similarity threshold. When a new question's similarity with a cached question exceeds this threshold, the cached answer will be returned directly without calling the LLM. `use_llm_check`: Boolean value to enable/disable LLM similarity verification. When enabled, LLM will be used as a secondary check to verify the similarity between questions before returning cached answers. | Default: `{\"enabled\": False, \"similarity_threshold\": 0.95, \"use_llm_check\": False}` |\n\n</details>\n\n### Query Param\n\nUse QueryParam to control the behavior your query:\n\n```python\nclass QueryParam:\n    \"\"\"Configuration parameters for query execution in LightRAG.\"\"\"\n\n    mode: Literal[\"local\", \"global\", \"hybrid\", \"naive\", \"mix\", \"bypass\"] = \"global\"\n    \"\"\"Specifies the retrieval mode:\n    - \"local\": Focuses on context-dependent information.\n    - \"global\": Utilizes global knowledge.\n    - \"hybrid\": Combines local and global retrieval methods.\n    - \"naive\": Performs a basic search without advanced techniques.\n    - \"mix\": Integrates knowledge graph and vector retrieval.\n    \"\"\"\n\n    only_need_context: bool = False\n    \"\"\"If True, only returns the retrieved context without generating a response.\"\"\"\n\n    only_need_prompt: bool = False\n    \"\"\"If True, only returns the generated prompt without producing a response.\"\"\"\n\n    response_type: str = \"Multiple Paragraphs\"\n    \"\"\"Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'.\"\"\"\n\n    stream: bool = False\n    \"\"\"If True, enables streaming output for real-time responses.\"\"\"\n\n    top_k: int = int(os.getenv(\"TOP_K\", \"60\"))\n    \"\"\"Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode.\"\"\"\n\n    chunk_top_k: int = int(os.getenv(\"CHUNK_TOP_K\", \"20\"))\n    \"\"\"Number of text chunks to retrieve initially from vector search and keep after reranking.\n    If None, defaults to top_k value.\n    \"\"\"\n\n    max_entity_tokens: int = int(os.getenv(\"MAX_ENTITY_TOKENS\", \"6000\"))\n    \"\"\"Maximum number of tokens allocated for entity context in unified token control system.\"\"\"\n\n    max_relation_tokens: int = int(os.getenv(\"MAX_RELATION_TOKENS\", \"8000\"))\n    \"\"\"Maximum number of tokens allocated for relationship context in unified token control system.\"\"\"\n\n    max_total_tokens: int = int(os.getenv(\"MAX_TOTAL_TOKENS\", \"30000\"))\n    \"\"\"Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt).\"\"\"\n\n    # History mesages is only send to LLM for context, not used for retrieval\n    conversation_history: list[dict[str, str]] = field(default_factory=list)\n    \"\"\"Stores past conversation history to maintain context.\n    Format: [{\"role\": \"user/assistant\", \"content\": \"message\"}].\n    \"\"\"\n\n    ids: list[str] | None = None\n    \"\"\"List of ids to filter the results.\"\"\"\n\n    model_func: Callable[..., object] | None = None\n    \"\"\"Optional override for the LLM model function to use for this specific query.\n    If provided, this will be used instead of the global model function.\n    This allows using different models for different query modes.\n    \"\"\"\n\n    user_prompt: str | None = None\n    \"\"\"User-provided prompt for the query.\n    Addition instructions for LLM. If provided, this will be inject into the prompt template.\n    It's purpose is the let user customize the way LLM generate the response.\n    \"\"\"\n\n    enable_rerank: bool = True\n    \"\"\"Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.\n    Default is True to enable reranking when rerank model is available.\n    \"\"\"\n```\n\n> default value of Top_k can be change by environment  variables  TOP_K.\n\n### LLM and Embedding Injection\n\nLightRAG requires the utilization of LLM and Embedding models to accomplish document indexing and querying tasks. During the initialization phase, it is necessary to inject the invocation methods of the relevant models into LightRAGÔºö\n\n<details>\n<summary> <b>Using Open AI-like APIs</b> </summary>\n\n* LightRAG also supports Open AI-like chat/embeddings APIs:\n\n```python\nasync def llm_model_func(\n    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n) -> str:\n    return await openai_complete_if_cache(\n        \"solar-mini\",\n        prompt,\n        system_prompt=system_prompt,\n        history_messages=history_messages,\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\",\n        **kwargs\n    )\n\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    return await openai_embed(\n        texts,\n        model=\"solar-embedding-1-large-query\",\n        api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n        base_url=\"https://api.upstage.ai/v1/solar\"\n    )\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=llm_model_func,\n        embedding_func=EmbeddingFunc(\n            embedding_dim=4096,\n            func=embedding_func\n        )\n    )\n\n    await rag.initialize_storages()\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using Hugging Face Models</b> </summary>\n\n* If you want to use Hugging Face models, you only need to set LightRAG as follows:\n\nSee `lightrag_hf_demo.py`\n\n```python\n# Initialize LightRAG with Hugging Face model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=hf_model_complete,  # Use Hugging Face model for text generation\n    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face\n    # Use Hugging Face embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=lambda texts: hf_embed(\n            texts,\n            tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\"),\n            embed_model=AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n        )\n    ),\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Ollama Models</b> </summary>\n**Overview**\n\nIf you want to use Ollama models, you need to pull model you plan to use and embedding model, for example `nomic-embed-text`.\n\nThen you only need to set LightRAG as follows:\n\n```python\n# Initialize LightRAG with Ollama model\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Increasing context size**\n\nIn order for LightRAG to work context should be at least 32k tokens. By default Ollama models have context size of 8k. You can achieve this using one of two ways:\n\n* **Increasing the `num_ctx` parameter in Modelfile**\n\n1. Pull the model:\n\n```bash\nollama pull qwen2\n```\n\n2. Display the model file:\n\n```bash\nollama show --modelfile qwen2 > Modelfile\n```\n\n3. Edit the Modelfile by adding the following line:\n\n```bash\nPARAMETER num_ctx 32768\n```\n\n4. Create the modified model:\n\n```bash\nollama create -f Modelfile qwen2m\n```\n\n* **Setup `num_ctx` via Ollama API**\n\nTiy can use `llm_model_kwargs` param to configure ollama:\n\n```python\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation\n    llm_model_name='your_model_name', # Your model name\n    llm_model_kwargs={\"options\": {\"num_ctx\": 32768}},\n    # Use Ollama embedding function\n    embedding_func=EmbeddingFunc(\n        embedding_dim=768,\n        func=lambda texts: ollama_embed(\n            texts,\n            embed_model=\"nomic-embed-text\"\n        )\n    ),\n)\n```\n\n* **Low RAM GPUs**\n\nIn order to run this experiment on low RAM GPU you should select small model and tune context window (increasing context increase memory consumption). For example, running this ollama example on repurposed mining GPU with 6Gb of RAM required to set context size to 26k while using `gemma2:2b`. It was able to find 197 entities and 19 relations on `book.txt`.\n\n</details>\n<details>\n<summary> <b>LlamaIndex</b> </summary>\n\nLightRAG supports integration with LlamaIndex (`llm/llama_index_impl.py`):\n\n- Integrates with OpenAI and other providers through LlamaIndex\n- See [LlamaIndex Documentation](lightrag/llm/Readme.md) for detailed setup and examples\n\n**Example Usage**\n\n```python\n# Using LlamaIndex with direct OpenAI access\nimport asyncio\nfrom lightrag import LightRAG\nfrom lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom lightrag.utils import setup_logger\n\n# Setup log handler for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=\"your/path\",\n        llm_model_func=llama_index_complete_if_cache,  # LlamaIndex-compatible completion function\n        embedding_func=EmbeddingFunc(    # LlamaIndex-compatible embedding function\n            embedding_dim=1536,\n            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)\n        ),\n    )\n\n    await rag.initialize_storages()\n    return rag\n\ndef main():\n    # Initialize RAG instance\n    rag = asyncio.run(initialize_rag())\n\n    with open(\"./book.txt\", \"r\", encoding=\"utf-8\") as f:\n        rag.insert(f.read())\n\n    # Perform naive search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\n    )\n\n    # Perform local search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\n    )\n\n    # Perform global search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\n    )\n\n    # Perform hybrid search\n    print(\n        rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\n    )\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**For detailed documentation and examples, see:**\n\n- [LlamaIndex Documentation](lightrag/llm/Readme.md)\n- [Direct OpenAI Example](examples/lightrag_llamaindex_direct_demo.py)\n- [LiteLLM Proxy Example](examples/lightrag_llamaindex_litellm_demo.py)\n\n</details>\n\n### Rerank Function Injection\n\nTo enhance retrieval quality, documents can be re-ranked based on a more effective relevance scoring model. The `rerank.py` file provides three Reranker provider driver functions:\n\n* **Cohere / vLLM**: `cohere_rerank`\n* **Jina AI**: `jina_rerank`\n* **Aliyun**: `ali_rerank`\n\nYou can inject one of these functions into the `rerank_model_func` attribute of the LightRAG object. This will enable LightRAG's query function to re-order retrieved text blocks using the injected function. For detailed usage, please refer to the `examples/rerank_example.py` file.\n\n### User Prompt vs. Query\n\nWhen using LightRAG for content queries, avoid combining the search process with unrelated output processing, as this significantly impacts query effectiveness. The `user_prompt` parameter in Query Param is specifically designed to address this issue ‚Äî it does not participate in the RAG retrieval phase, but rather guides the LLM on how to process the retrieved results after the query is completed. Here's how to use it:\n\n```python\n# Create query parameters\nquery_param = QueryParam(\n    mode = \"hybrid\",  # Other modesÔºölocal, global, hybrid, mix, naive\n    user_prompt = \"For diagrams, use mermaid format with English/Pinyin node names and Chinese display labels\",\n)\n\n# Query and process\nresponse_default = rag.query(\n    \"Please draw a character relationship diagram for Scrooge\",\n    param=query_param\n)\nprint(response_default)\n```\n\n### Insert\n\n<details>\n  <summary> <b> Basic Insert </b></summary>\n\n```python\n# Basic Insert\nrag.insert(\"Text\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Batch Insert </b></summary>\n\n```python\n# Basic Batch Insert: Insert multiple texts at once\nrag.insert([\"TEXT1\", \"TEXT2\",...])\n\n# Batch Insert with custom batch size configuration\nrag = LightRAG(\n    ...\n    working_dir=WORKING_DIR,\n    max_parallel_insert = 4\n)\n\nrag.insert([\"TEXT1\", \"TEXT2\", \"TEXT3\", ...])  # Documents will be processed in batches of 4\n```\n\nThe `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.The `max_parallel_insert` parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is **2**. We recommend keeping this setting **below 10**, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.\n\n</details>\n\n<details>\n  <summary> <b> Insert with ID </b></summary>\n\nIf you want to provide your own IDs for your documents, number of documents and number of IDs must be the same.\n\n```python\n# Insert single text, and provide ID for it\nrag.insert(\"TEXT1\", ids=[\"ID_FOR_TEXT1\"])\n\n# Insert multiple texts, and provide IDs for them\nrag.insert([\"TEXT1\", \"TEXT2\",...], ids=[\"ID_FOR_TEXT1\", \"ID_FOR_TEXT2\"])\n```\n\n</details>\n\n<details>\n  <summary><b>Insert using Pipeline</b></summary>\n\nThe `apipeline_enqueue_documents` and `apipeline_process_enqueue_documents` functions allow you to perform incremental insertion of documents into the graph.\n\nThis is useful for scenarios where you want to process documents in the background while still allowing the main thread to continue executing.\n\nAnd using a routine to process new documents.\n\n```python\nrag = LightRAG(..)\n\nawait rag.apipeline_enqueue_documents(input)\n# Your routine in loop\nawait rag.apipeline_process_enqueue_documents(input)\n```\n\n</details>\n\n<details>\n  <summary><b>Insert Multi-file Type Support</b></summary>\n\nThe `textract` supports reading file types such as TXT, DOCX, PPTX, CSV, and PDF.\n\n```python\nimport textract\n\nfile_path = 'TEXT.pdf'\ntext_content = textract.process(file_path)\n\nrag.insert(text_content.decode('utf-8'))\n```\n\n</details>\n\n<details>\n  <summary><b>Citation Functionality</b></summary>\n\nBy providing file paths, the system ensures that sources can be traced back to their original documents.\n\n```python\n# Define documents and their file paths\ndocuments = [\"Document content 1\", \"Document content 2\"]\nfile_paths = [\"path/to/doc1.txt\", \"path/to/doc2.txt\"]\n\n# Insert documents with file paths\nrag.insert(documents, file_paths=file_paths)\n```\n\n</details>\n\n### Storage\n\nLightRAG uses 4 types of storage for different purposes:\n\n* KV_STORAGE: llm response cache, text chunks, document information\n* VECTOR_STORAGE: entities vectors, relation vectors, chunks vectors\n* GRAPH_STORAGE: entity relation graph\n* DOC_STATUS_STORAGE: document indexing status\n\nEach storage type has several implementations:\n\n* KV_STORAGE supported implementations:\n\n```\nJsonKVStorage    JsonFile (default)\nPGKVStorage      Postgres\nRedisKVStorage   Redis\nMongoKVStorage   MongoDB\n```\n\n* GRAPH_STORAGE supported implementations:\n\n```\nNetworkXStorage      NetworkX (default)\nNeo4JStorage         Neo4J\nPGGraphStorage       PostgreSQL with AGE plugin\nMemgraphStorage.     Memgraph\n```\n\n> Testing has shown that Neo4J delivers superior performance in production environments compared to PostgreSQL with AGE plugin.\n\n* VECTOR_STORAGE supported implementations:\n\n```\nNanoVectorDBStorage         NanoVector (default)\nPGVectorStorage             Postgres\nMilvusVectorDBStorage       Milvus\nFaissVectorDBStorage        Faiss\nQdrantVectorDBStorage       Qdrant\nMongoVectorDBStorage        MongoDB\n```\n\n* DOC_STATUS_STORAGE: supported implementations:\n\n```\nJsonDocStatusStorage        JsonFile (default)\nPGDocStatusStorage          Postgres\nMongoDocStatusStorage       MongoDB\n```\n\nExample connection configurations for each storage type can be found in the `env.example` file. The database instance in the connection string needs to be created by you on the database server beforehand. LightRAG is only responsible for creating tables within the database instance, not for creating the database instance itself. If using Redis as storage, remember to configure automatic data persistence rules for Redis, otherwise data will be lost after the Redis service restarts. If using PostgreSQL, it is recommended to use version 16.6 or above.\n\n<details>\n<summary> <b>Using Neo4J Storage</b> </summary>\n\n* For production level scenarios you will most likely want to leverage an enterprise solution\n* for KG storage. Running Neo4J in Docker is recommended for seamless local testing.\n* See: https://hub.docker.com/_/neo4j\n\n```python\nexport NEO4J_URI=\"neo4j://localhost:7687\"\nexport NEO4J_USERNAME=\"neo4j\"\nexport NEO4J_PASSWORD=\"password\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project be sure to override the default KG: NetworkX\n# by specifying kg=\"Neo4JStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Neo4J implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"Neo4JStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\nsee test_neo4j.py for a working example.\n\n</details>\n\n<details>\n<summary> <b>Using PostgreSQL Storage</b> </summary>\n\nFor production level scenarios you will most likely want to leverage an enterprise solution. PostgreSQL can provide a one-stop solution for you as KV store, VectorDB (pgvector) and GraphDB (apache AGE). PostgreSQL version 16.6 or higher is supported.\n\n* PostgreSQL is lightweight,the whole binary distribution including all necessary plugins can be zipped to 40MB: Ref to [Windows Release](https://github.com/ShanGor/apache-age-windows/releases/tag/PG17%2Fv1.5.0-rc0) as it is easy to install for Linux/Mac.\n* If you prefer docker, please start with this image if you are a beginner to avoid hiccups (Default user password:rag/rag): https://hub.docker.com/r/gzdaniel/postgres-for-rag\n* How to start? Ref to: [examples/lightrag_zhipu_postgres_demo.py](https://github.com/HKUDS/LightRAG/blob/main/examples/lightrag_zhipu_postgres_demo.py)\n* For high-performance graph database requirements, Neo4j is recommended as Apache AGE's performance is not as competitive.\n\n</details>\n\n<details>\n<summary> <b>Using Faiss Storage</b> </summary>\nBefore using Faiss vector database, you must manually install `faiss-cpu` or `faiss-gpu`.\n\n- Install the required dependencies:\n\n```\npip install faiss-cpu\n```\n\nYou can also install `faiss-gpu` if you have GPU support.\n\n- Here we are using `sentence-transformers` but you can also use `OpenAIEmbedding` model with `3072` dimensions.\n\n```python\nasync def embedding_func(texts: list[str]) -> np.ndarray:\n    model = SentenceTransformer('all-MiniLM-L6-v2')\n    embeddings = model.encode(texts, convert_to_numpy=True)\n    return embeddings\n\n# Initialize LightRAG with the LLM model function and embedding function\nrag = LightRAG(\n    working_dir=WORKING_DIR,\n    llm_model_func=llm_model_func,\n    embedding_func=EmbeddingFunc(\n        embedding_dim=384,\n        func=embedding_func,\n    ),\n    vector_storage=\"FaissVectorDBStorage\",\n    vector_db_storage_cls_kwargs={\n        \"cosine_better_than_threshold\": 0.3  # Your desired threshold\n    }\n)\n```\n\n</details>\n\n<details>\n<summary> <b>Using Memgraph for Storage</b> </summary>\n\n* Memgraph is a high-performance, in-memory graph database compatible with the Neo4j Bolt protocol.\n* You can run Memgraph locally using Docker for easy testing:\n* See: https://memgraph.com/download\n\n```python\nexport MEMGRAPH_URI=\"bolt://localhost:7687\"\n\n# Setup logger for LightRAG\nsetup_logger(\"lightrag\", level=\"INFO\")\n\n# When you launch the project, override the default KG: NetworkX\n# by specifying kg=\"MemgraphStorage\".\n\n# Note: Default settings use NetworkX\n# Initialize LightRAG with Memgraph implementation.\nasync def initialize_rag():\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model\n        graph_storage=\"MemgraphStorage\", #<-----------override KG default\n    )\n\n    # Initialize database connections\n    await rag.initialize_storages()\n    # Initialize pipeline status for document processing\n    return rag\n```\n\n</details>\n\n<details>\n<summary> <b>Using MongoDB Storage</b> </summary>\n\nMongoDB provides a one-stop storage solution for LightRAG. MongoDB offers native KV storage and vector storage. LightRAG uses MongoDB collections to implement a simple graph storage. MongoDB's official vector search functionality (`$vectorSearch`) currently requires their official cloud service MongoDB Atlas. This functionality cannot be used on self-hosted MongoDB Community/Enterprise versions.\n\n</details>\n\n<details>\n<summary> <b>Using Redis Storage</b> </summary>\n\nLightRAG supports using Redis as KV storage. When using Redis storage, attention should be paid to persistence configuration and memory usage configuration. The following is the recommended Redis configuration:\n\n```\nsave 900 1\nsave 300 10\nsave 60 1000\nstop-writes-on-bgsave-error yes\nmaxmemory 4gb\nmaxmemory-policy noeviction\nmaxclients 500\n```\n\n</details>\n\n### Data Isolation Between LightRAG Instances\n\nThe `workspace` parameter ensures data isolation between different LightRAG instances. Once initialized, the `workspace` is immutable and cannot be changed.Here is how workspaces are implemented for different types of storage:\n\n- **For local file-based databases, data isolation is achieved through workspace subdirectories:** `JsonKVStorage`, `JsonDocStatusStorage`, `NetworkXStorage`, `NanoVectorDBStorage`, `FaissVectorDBStorage`.\n- **For databases that store data in collections, it's done by adding a workspace prefix to the collection name:** `RedisKVStorage`, `RedisDocStatusStorage`, `MilvusVectorDBStorage`, `MongoKVStorage`, `MongoDocStatusStorage`, `MongoVectorDBStorage`, `MongoGraphStorage`, `PGGraphStorage`.\n- **For Qdrant vector database, data isolation is achieved through payload-based partitioning (Qdrant's recommended multitenancy approach):** `QdrantVectorDBStorage` uses shared collections with payload filtering for unlimited workspace scalability.\n- **For relational databases, data isolation is achieved by adding a `workspace` field to the tables for logical data separation:** `PGKVStorage`, `PGVectorStorage`, `PGDocStatusStorage`.\n- **For the Neo4j graph database, logical data isolation is achieved through labels:** `Neo4JStorage`\n\nTo maintain compatibility with legacy data, the default workspace for PostgreSQL non-graph storage is `default` and, for PostgreSQL AGE graph storage is null, for Neo4j graph storage is `base` when no workspace is configured. For all external storages, the system provides dedicated workspace environment variables to override the common `WORKSPACE` environment variable configuration. These storage-specific workspace environment variables are: `REDIS_WORKSPACE`, `MILVUS_WORKSPACE`, `QDRANT_WORKSPACE`, `MONGODB_WORKSPACE`, `POSTGRES_WORKSPACE`, `NEO4J_WORKSPACE`.\n\n### AGENTS.md -- Guiding Coding Agents\n\nAGENTS.md is a simple, open format for guiding coding agents (https://agents.md/). It is a dedicated, predictable place to provide the context and instructions to help AI coding agents work on LightRAG project. Different AI coders should not maintain separate guidance files individually. If any AI coder cannot automatically recognize AGENTS.md, symbolic links can be used as a solution. After establishing symbolic links, you can prevent them from being committed to the Git repository by configuring your local `.gitignore_global`.\n\n## Edit Entities and Relations\n\nLightRAG now supports comprehensive knowledge graph management capabilities, allowing you to create, edit, and delete entities and relationships within your knowledge graph.\n\n<details>\n  <summary> <b> Create Entities and Relations </b></summary>\n\n```python\n# Create new entity\nentity = rag.create_entity(\"Google\", {\n    \"description\": \"Google is a multinational technology company specializing in internet-related services and products.\",\n    \"entity_type\": \"company\"\n})\n\n# Create another entity\nproduct = rag.create_entity(\"Gmail\", {\n    \"description\": \"Gmail is an email service developed by Google.\",\n    \"entity_type\": \"product\"\n})\n\n# Create relation between entities\nrelation = rag.create_relation(\"Google\", \"Gmail\", {\n    \"description\": \"Google develops and operates Gmail.\",\n    \"keywords\": \"develops operates service\",\n    \"weight\": 2.0\n})\n```\n\n</details>\n\n<details>\n  <summary> <b> Edit Entities and Relations </b></summary>\n\n```python\n# Edit an existing entity\nupdated_entity = rag.edit_entity(\"Google\", {\n    \"description\": \"Google is a subsidiary of Alphabet Inc., founded in 1998.\",\n    \"entity_type\": \"tech_company\"\n})\n\n# Rename an entity (with all its relationships properly migrated)\nrenamed_entity = rag.edit_entity(\"Gmail\", {\n    \"entity_name\": \"Google Mail\",\n    \"description\": \"Google Mail (formerly Gmail) is an email service.\"\n})\n\n# Edit a relation between entities\nupdated_relation = rag.edit_relation(\"Google\", \"Google Mail\", {\n    \"description\": \"Google created and maintains Google Mail service.\",\n    \"keywords\": \"creates maintains email service\",\n    \"weight\": 3.0\n})\n```\n\nAll operations are available in both synchronous and asynchronous versions. The asynchronous versions have the prefix \"a\" (e.g., `acreate_entity`, `aedit_relation`).\n\n</details>\n\n<details>\n  <summary> <b> Insert Custom KG </b></summary>\n\n```python\ncustom_kg = {\n        \"chunks\": [\n            {\n                \"content\": \"Alice and Bob are collaborating on quantum computing research.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\",\n            }\n        ],\n        \"entities\": [\n            {\n                \"entity_name\": \"Alice\",\n                \"entity_type\": \"person\",\n                \"description\": \"Alice is a researcher specializing in quantum physics.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Bob\",\n                \"entity_type\": \"person\",\n                \"description\": \"Bob is a mathematician.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"entity_name\": \"Quantum Computing\",\n                \"entity_type\": \"technology\",\n                \"description\": \"Quantum computing utilizes quantum mechanical phenomena for computation.\",\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ],\n        \"relationships\": [\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Bob\",\n                \"description\": \"Alice and Bob are research partners.\",\n                \"keywords\": \"collaboration research\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Alice\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Alice conducts research on quantum computing.\",\n                \"keywords\": \"research expertise\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            },\n            {\n                \"src_id\": \"Bob\",\n                \"tgt_id\": \"Quantum Computing\",\n                \"description\": \"Bob researches quantum computing.\",\n                \"keywords\": \"research application\",\n                \"weight\": 1.0,\n                \"source_id\": \"doc-1\",\n                \"file_path\": \"test_file\"\n            }\n        ]\n    }\n\nrag.insert_custom_kg(custom_kg)\n```\n\n</details>\n\n<details>\n  <summary> <b>Other Entity and Relation Operations</b></summary>\n\n- **create_entity**: Creates a new entity with specified attributes\n- **edit_entity**: Updates an existing entity's attributes or renames it\n\n\n- **create_relation**: Creates a new relation between existing entities\n- **edit_relation**: Updates an existing relation's attributes\n\nThese operations maintain data consistency across both the graph database and vector database components, ensuring your knowledge graph remains coherent.\n\n</details>\n\n## Delete Functions\n\nLightRAG provides comprehensive deletion capabilities, allowing you to delete documents, entities, and relationships.\n\n<details>\n<summary> <b>Delete Entities</b> </summary>\n\nYou can delete entities by their name along with all associated relationships:\n\n```python\n# Delete entity and all its relationships (synchronous version)\nrag.delete_by_entity(\"Google\")\n\n# Asynchronous version\nawait rag.adelete_by_entity(\"Google\")\n```\n\nWhen deleting an entity:\n- Removes the entity node from the knowledge graph\n- Deletes all associated relationships\n- Removes related embedding vectors from the vector database\n- Maintains knowledge graph integrity\n\n</details>\n\n<details>\n<summary> <b>Delete Relations</b> </summary>\n\nYou can delete relationships between two specific entities:\n\n```python\n# Delete relationship between two entities (synchronous version)\nrag.delete_by_relation(\"Google\", \"Gmail\")\n\n# Asynchronous version\nawait rag.adelete_by_relation(\"Google\", \"Gmail\")\n```\n\nWhen deleting a relationship:\n- Removes the specified relationship edge\n- Deletes the relationship's embedding vector from the vector database\n- Preserves both entity nodes and their other relationships\n\n</details>\n\n<details>\n<summary> <b>Delete by Document ID</b> </summary>\n\nYou can delete an entire document and all its related knowledge through document ID:\n\n```python\n# Delete by document ID (asynchronous version)\nawait rag.adelete_by_doc_id(\"doc-12345\")\n```\n\nOptimized processing when deleting by document ID:\n- **Smart Cleanup**: Automatically identifies and removes entities and relationships that belong only to this document\n- **Preserve Shared Knowledge**: If entities or relationships exist in other documents, they are preserved and their descriptions are rebuilt\n- **Cache Optimization**: Clears related LLM cache to reduce storage overhead\n- **Incremental Rebuilding**: Reconstructs affected entity and relationship descriptions from remaining documents\n\nThe deletion process includes:\n1. Delete all text chunks related to the document\n2. Identify and delete entities and relationships that belong only to this document\n3. Rebuild entities and relationships that still exist in other documents\n4. Update all related vector indexes\n5. Clean up document status records\n\nNote: Deletion by document ID is an asynchronous operation as it involves complex knowledge graph reconstruction processes.\n\n</details>\n\n**Important Reminders:**\n\n1. **Irreversible Operations**: All deletion operations are irreversible, please use with caution\n2. **Performance Considerations**: Deleting large amounts of data may take some time, especially deletion by document ID\n3. **Data Consistency**: Deletion operations automatically maintain consistency between the knowledge graph and vector database\n4. **Backup Recommendations**: Consider backing up data before performing important deletion operations\n\n**Batch Deletion Recommendations:**\n- For batch deletion operations, consider using asynchronous methods for better performance\n- For large-scale deletions, consider processing in batches to avoid excessive system load\n\n## Entity Merging\n\n<details>\n<summary> <b>Merge Entities and Their Relationships</b> </summary>\n\nLightRAG now supports merging multiple entities into a single entity, automatically handling all relationships:\n\n```python\n# Basic entity merging\nrag.merge_entities(\n    source_entities=[\"Artificial Intelligence\", \"AI\", \"Machine Intelligence\"],\n    target_entity=\"AI Technology\"\n)\n```\n\nWith custom merge strategy:\n\n```python\n# Define custom merge strategy for different fields\nrag.merge_entities(\n    source_entities=[\"John Smith\", \"Dr. Smith\", \"J. Smith\"],\n    target_entity=\"John Smith\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"entity_type\": \"keep_first\",   # Keep the entity type from the first entity\n        \"source_id\": \"join_unique\"     # Combine all unique source IDs\n    }\n)\n```\n\nWith custom target entity data:\n\n```python\n# Specify exact values for the merged entity\nrag.merge_entities(\n    source_entities=[\"New York\", \"NYC\", \"Big Apple\"],\n    target_entity=\"New York City\",\n    target_entity_data={\n        \"entity_type\": \"LOCATION\",\n        \"description\": \"New York City is the most populous city in the United States.\",\n    }\n)\n```\n\nAdvanced usage combining both approaches:\n\n```python\n# Merge company entities with both strategy and custom data\nrag.merge_entities(\n    source_entities=[\"Microsoft Corp\", \"Microsoft Corporation\", \"MSFT\"],\n    target_entity=\"Microsoft\",\n    merge_strategy={\n        \"description\": \"concatenate\",  # Combine all descriptions\n        \"source_id\": \"join_unique\"     # Combine source IDs\n    },\n    target_entity_data={\n        \"entity_type\": \"ORGANIZATION\",\n    }\n)\n```\n\nWhen merging entities:\n\n* All relationships from source entities are redirected to the target entity\n* Duplicate relationships are intelligently merged\n* Self-relationships (loops) are prevented\n* Source entities are removed after merging\n* Relationship weights and attributes are preserved\n\n</details>\n\n## Multimodal Document Processing (RAG-Anything Integration)\n\nLightRAG now seamlessly integrates with [RAG-Anything](https://github.com/HKUDS/RAG-Anything), a comprehensive **All-in-One Multimodal Document Processing RAG system** built specifically for LightRAG. RAG-Anything enables advanced parsing and retrieval-augmented generation (RAG) capabilities, allowing you to handle multimodal documents seamlessly and extract structured content‚Äîincluding text, images, tables, and formulas‚Äîfrom various document formats for integration into your RAG pipeline.\n\n**Key Features:**\n- **End-to-End Multimodal Pipeline**: Complete workflow from document ingestion and parsing to intelligent multimodal query answering\n- **Universal Document Support**: Seamless processing of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse file formats\n- **Specialized Content Analysis**: Dedicated processors for images, tables, mathematical equations, and heterogeneous content types\n- **Multimodal Knowledge Graph**: Automatic entity extraction and cross-modal relationship discovery for enhanced understanding\n- **Hybrid Intelligent Retrieval**: Advanced search capabilities spanning textual and multimodal content with contextual understanding\n\n**Quick Start:**\n1. Install RAG-Anything:\n   ```bash\n   pip install raganything\n   ```\n2. Process multimodal documents:\n    <details>\n    <summary> <b> RAGAnything Usage Example </b></summary>\n\n    ```python\n        import asyncio\n        from raganything import RAGAnything\n        from lightrag import LightRAG\n        from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n        from lightrag.utils import EmbeddingFunc\n        import os\n\n        async def load_existing_lightrag():\n            # First, create or load an existing LightRAG instance\n            lightrag_working_dir = \"./existing_lightrag_storage\"\n\n            # Check if previous LightRAG instance exists\n            if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):\n                print(\"‚úÖ Found existing LightRAG instance, loading...\")\n            else:\n                print(\"‚ùå No existing LightRAG instance found, will create new one\")\n\n            # Create/Load LightRAG instance with your configurations\n            lightrag_instance = LightRAG(\n                working_dir=lightrag_working_dir,\n                llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ),\n                embedding_func=EmbeddingFunc(\n                    embedding_dim=3072,\n                    func=lambda texts: openai_embed(\n                        texts,\n                        model=\"text-embedding-3-large\",\n                        api_key=api_key,\n                        base_url=base_url,\n                    ),\n                )\n            )\n\n            # Initialize storage (this will load existing data if available)\n            await lightrag_instance.initialize_storages()\n\n            # Now initialize RAGAnything with the existing LightRAG instance\n            rag = RAGAnything(\n                lightrag=lightrag_instance,  # Pass the existing LightRAG instance\n                # Only need vision model for multimodal processing\n                vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(\n                    \"gpt-4o\",\n                    \"\",\n                    system_prompt=None,\n                    history_messages=[],\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_prompt} if system_prompt else None,\n                        {\"role\": \"user\", \"content\": [\n                            {\"type\": \"text\", \"text\": prompt},\n                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"}}\n                        ]} if image_data else {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                ) if image_data else openai_complete_if_cache(\n                    \"gpt-4o-mini\",\n                    prompt,\n                    system_prompt=system_prompt,\n                    history_messages=history_messages,\n                    api_key=\"your-api-key\",\n                    **kwargs,\n                )\n                # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance\n            )\n\n            # Query the existing knowledge base\n            result = await rag.query_with_multimodal(\n                \"What data has been processed in this LightRAG instance?\",\n                mode=\"hybrid\"\n            )\n            print(\"Query result:\", result)\n\n            # Add new multimodal documents to the existing LightRAG instance\n            await rag.process_document_complete(\n                file_path=\"path/to/new/multimodal_document.pdf\",\n                output_dir=\"./output\"\n            )\n\n        if __name__ == \"__main__\":\n            asyncio.run(load_existing_lightrag())\n    ```\n    </details>\n\nFor detailed documentation and advanced usage, please refer to the [RAG-Anything repository](https://github.com/HKUDS/RAG-Anything).\n\n## Token Usage Tracking\n\n<details>\n<summary> <b>Overview and Usage</b> </summary>\n\nLightRAG provides a TokenTracker tool to monitor and manage token consumption by large language models. This feature is particularly useful for controlling API costs and optimizing performance.\n\n### Usage\n\n```python\nfrom lightrag.utils import TokenTracker\n\n# Create TokenTracker instance\ntoken_tracker = TokenTracker()\n\n# Method 1: Using context manager (Recommended)\n# Suitable for scenarios requiring automatic token usage tracking\nwith token_tracker:\n    result1 = await llm_model_func(\"your question 1\")\n    result2 = await llm_model_func(\"your question 2\")\n\n# Method 2: Manually adding token usage records\n# Suitable for scenarios requiring more granular control over token statistics\ntoken_tracker.reset()\n\nrag.insert()\n\nrag.query(\"your question 1\", param=QueryParam(mode=\"naive\"))\nrag.query(\"your question 2\", param=QueryParam(mode=\"mix\"))\n\n# Display total token usage (including insert and query operations)\nprint(\"Token usage:\", token_tracker.get_usage())\n```\n\n### Usage Tips\n- Use context managers for long sessions or batch operations to automatically track all token consumption\n- For scenarios requiring segmented statistics, use manual mode and call reset() when appropriate\n- Regular checking of token usage helps detect abnormal consumption early\n- Actively use this feature during development and testing to optimize production costs\n\n### Practical Examples\nYou can refer to these examples for implementing token tracking:\n- `examples/lightrag_gemini_track_token_demo.py`: Token tracking example using Google Gemini model\n- `examples/lightrag_siliconcloud_track_token_demo.py`: Token tracking example using SiliconCloud model\n\nThese examples demonstrate how to effectively use the TokenTracker feature with different models and scenarios.\n\n</details>\n\n## Data Export Functions\n\n### Overview\n\nLightRAG allows you to export your knowledge graph data in various formats for analysis, sharing, and backup purposes. The system supports exporting entities, relations, and relationship data.\n\n### Export Functions\n\n<details>\n  <summary> <b> Basic Usage </b></summary>\n\n```python\n# Basic CSV export (default format)\nrag.export_data(\"knowledge_graph.csv\")\n\n# Specify any format\nrag.export_data(\"output.xlsx\", file_format=\"excel\")\n```\n\n</details>\n\n<details>\n  <summary> <b> Different File Formats supported </b></summary>\n\n```python\n#Export data in CSV format\nrag.export_data(\"graph_data.csv\", file_format=\"csv\")\n\n# Export data in Excel sheet\nrag.export_data(\"graph_data.xlsx\", file_format=\"excel\")\n\n# Export data in markdown format\nrag.export_data(\"graph_data.md\", file_format=\"md\")\n\n# Export data in Text\nrag.export_data(\"graph_data.txt\", file_format=\"txt\")\n```\n</details>\n\n<details>\n  <summary> <b> Additional Options </b></summary>\n\nInclude vector embeddings in the export (optional):\n\n```python\nrag.export_data(\"complete_data.csv\", include_vector_data=True)\n```\n</details>\n\n### Data Included in Export\n\nAll exports include:\n\n* Entity information (names, IDs, metadata)\n* Relation data (connections between entities)\n* Relationship information from vector database\n\n## Cache\n\n<details>\n  <summary> <b>Clear Cache</b> </summary>\n\nYou can clear the LLM response cache with different modes:\n\n```python\n# Clear all cache\nawait rag.aclear_cache()\n\n# Clear local mode cache\nawait rag.aclear_cache(modes=[\"local\"])\n\n# Clear extraction cache\nawait rag.aclear_cache(modes=[\"default\"])\n\n# Clear multiple modes\nawait rag.aclear_cache(modes=[\"local\", \"global\", \"hybrid\"])\n\n# Synchronous version\nrag.clear_cache(modes=[\"local\"])\n```\n\nValid modes are:\n\n- `\"default\"`: Extraction cache\n- `\"naive\"`: Naive search cache\n- `\"local\"`: Local search cache\n- `\"global\"`: Global search cache\n- `\"hybrid\"`: Hybrid search cache\n- `\"mix\"`: Mix search cache\n\n</details>\n\n## Troubleshooting\n\n### Common Initialization Errors\n\nIf you encounter these errors when using LightRAG:\n\n1. **`AttributeError: __aenter__`**\n   - **Cause**: Storage backends not initialized\n   - **Solution**: Call `await rag.initialize_storages()` after creating the LightRAG instance\n\n2. **`KeyError: 'history_messages'`**\n   - **Cause**: Pipeline status not initialized\n   - **Solution**: Call `\n3. **Both errors in sequence**\n   - **Cause**: Neither initialization method was called\n   - **Solution**: Always follow this pattern:\n   ```python\n   rag = LightRAG(...)\n   await rag.initialize_storages()   ```\n\n### Model Switching Issues\n\nWhen switching between different embedding models, you must clear the data directory to avoid errors. The only file you may want to preserve is `kv_store_llm_response_cache.json` if you wish to retain the LLM cache.\n\n## LightRAG API\n\nThe LightRAG Server is designed to provide Web UI and API support.  **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n## Graph Visualization\n\nThe LightRAG Server offers a comprehensive knowledge graph visualization feature. It supports various gravity layouts, node queries, subgraph filtering, and more. **For more information about LightRAG Server, please refer to [LightRAG Server](./lightrag/api/README.md).**\n\n![iShot_2025-03-23_12.40.08](./README.assets/iShot_2025-03-23_12.40.08.png)\n\n## Langfuse observability integration\n\nLangfuse provides a drop-in replacement for the OpenAI client that automatically tracks all LLM interactions, enabling developers to monitor, debug, and optimize their RAG systems without code changes.\n\n### Installation with Langfuse option\n\n```\npip install lightrag-hku\npip install lightrag-hku[observability]\n\n# Or install from souce code with debug mode enabled\npip install -e .\npip install -e \".[observability]\"\n```\n\n### Config Langfuse env vars\n\nmodify .env file:\n\n```\n## Langfuse Observability (Optional)\n# LLM observability and tracing platform\n# Install with: pip install lightrag-hku[observability]\n# Sign up at: https://cloud.langfuse.com or self-host\nLANGFUSE_SECRET_KEY=\"\"\nLANGFUSE_PUBLIC_KEY=\"\"\nLANGFUSE_HOST=\"https://cloud.langfuse.com\"  # or your self-hosted instance\nLANGFUSE_ENABLE_TRACE=true\n```\n\n### Langfuse Usage\n\nOnce installed and configured, Langfuse automatically traces all OpenAI LLM calls. Langfuse dashboard features include:\n\n- **Tracing**: View complete LLM call chains\n- **Analytics**: Token usage, latency, cost metrics\n- **Debugging**: Inspect prompts and responses\n- **Evaluation**: Compare model outputs\n- **Monitoring**: Real-time alerting\n\n### Important Notice\n\n**Note**: LightRAG currently only integrates OpenAI-compatible API calls with Langfuse. APIs such as Ollama, Azure, and AWS Bedrock are not yet supported for Langfuse observability.\n\n## RAGAS-based Evaluation\n\n**RAGAS** (Retrieval Augmented Generation Assessment) is a framework for reference-free evaluation of RAG systems using LLMs. There is an evaluation script based on RAGAS. For detailed information, please refer to [RAGAS-based Evaluation Framework](lightrag/evaluation/README.md).\n\n## Evaluation\n\n### Dataset\n\nThe dataset used in LightRAG can be downloaded from [TommyChien/UltraDomain](https://huggingface.co/datasets/TommyChien/UltraDomain).\n\n### Generate Query\n\nLightRAG uses the following prompt to generate high-level queries, with the corresponding code in `examples/generate_query.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\nGiven the following description of a dataset:\n\n{description}\n\nPlease identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.\n\nOutput the results in the following structure:\n- User 1: [user description]\n    - Task 1: [task description]\n        - Question 1:\n        - Question 2:\n        - Question 3:\n        - Question 4:\n        - Question 5:\n    - Task 2: [task description]\n        ...\n    - Task 5: [task description]\n- User 2: [user description]\n    ...\n- User 5: [user description]\n    ...\n```\n\n</details>\n\n### Batch Eval\n\nTo evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt, with the specific code available in `reproduce/batch_eval.py`.\n\n<details>\n<summary> Prompt </summary>\n\n```python\n---Role---\nYou are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n---Goal---\nYou will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.\n\n- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?\n- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?\n- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?\n\nFor each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.\n\nHere is the question:\n{query}\n\nHere are the two answers:\n\n**Answer 1:**\n{answer1}\n\n**Answer 2:**\n{answer2}\n\nEvaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.\n\nOutput your evaluation in the following JSON format:\n\n{{\n    \"Comprehensiveness\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Empowerment\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Provide explanation here]\"\n    }},\n    \"Overall Winner\": {{\n        \"Winner\": \"[Answer 1 or Answer 2]\",\n        \"Explanation\": \"[Summarize why this answer is the overall winner based on the three criteria]\"\n    }}\n}}\n```\n\n</details>\n\n### Overall Performance Table\n\n|                      |**Agriculture**|            |**CS**|            |**Legal**|            |**Mix**|            |\n|----------------------|---------------|------------|------|------------|---------|------------|-------|------------|\n|                      |NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|NaiveRAG|**LightRAG**|\n|**Comprehensiveness**|32.4%|**67.6%**|38.4%|**61.6%**|16.4%|**83.6%**|38.8%|**61.2%**|\n|**Diversity**|23.6%|**76.4%**|38.0%|**62.0%**|13.6%|**86.4%**|32.4%|**67.6%**|\n|**Empowerment**|32.4%|**67.6%**|38.8%|**61.2%**|16.4%|**83.6%**|42.8%|**57.2%**|\n|**Overall**|32.4%|**67.6%**|38.8%|**61.2%**|15.2%|**84.8%**|40.0%|**60.0%**|\n|                      |RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|RQ-RAG|**LightRAG**|\n|**Comprehensiveness**|31.6%|**68.4%**|38.8%|**61.2%**|15.2%|**84.8%**|39.2%|**60.8%**|\n|**Diversity**|29.2%|**70.8%**|39.2%|**60.8%**|11.6%|**88.4%**|30.8%|**69.2%**|\n|**Empowerment**|31.6%|**68.4%**|36.4%|**63.6%**|15.2%|**84.8%**|42.4%|**57.6%**|\n|**Overall**|32.4%|**67.6%**|38.0%|**62.0%**|14.4%|**85.6%**|40.0%|**60.0%**|\n|                      |HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|HyDE|**LightRAG**|\n|**Comprehensiveness**|26.0%|**74.0%**|41.6%|**58.4%**|26.8%|**73.2%**|40.4%|**59.6%**|\n|**Diversity**|24.0%|**76.0%**|38.8%|**61.2%**|20.0%|**80.0%**|32.4%|**67.6%**|\n|**Empowerment**|25.2%|**74.8%**|40.8%|**59.2%**|26.0%|**74.0%**|46.0%|**54.0%**|\n|**Overall**|24.8%|**75.2%**|41.6%|**58.4%**|26.4%|**73.6%**|42.4%|**57.6%**|\n|                      |GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|GraphRAG|**LightRAG**|\n|**Comprehensiveness**|45.6%|**54.4%**|48.4%|**51.6%**|48.4%|**51.6%**|**50.4%**|49.6%|\n|**Diversity**|22.8%|**77.2%**|40.8%|**59.2%**|26.4%|**73.6%**|36.0%|**64.0%**|\n|**Empowerment**|41.2%|**58.8%**|45.2%|**54.8%**|43.6%|**56.4%**|**50.8%**|49.2%|\n|**Overall**|45.2%|**54.8%**|48.0%|**52.0%**|47.2%|**52.8%**|**50.4%**|49.6%|\n\n## Reproduce\n\nAll the code can be found in the `./reproduce` directory.\n\n### Step-0 Extract Unique Contexts\n\nFirst, we need to extract unique contexts in the datasets.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_unique_contexts(input_directory, output_directory):\n\n    os.makedirs(output_directory, exist_ok=True)\n\n    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))\n    print(f\"Found {len(jsonl_files)} JSONL files.\")\n\n    for file_path in jsonl_files:\n        filename = os.path.basename(file_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_unique_contexts.json\"\n        output_path = os.path.join(output_directory, output_filename)\n\n        unique_contexts_dict = {}\n\n        print(f\"Processing file: {filename}\")\n\n        try:\n            with open(file_path, 'r', encoding='utf-8') as infile:\n                for line_number, line in enumerate(infile, start=1):\n                    line = line.strip()\n                    if not line:\n                        continue\n                    try:\n                        json_obj = json.loads(line)\n                        context = json_obj.get('context')\n                        if context and context not in unique_contexts_dict:\n                            unique_contexts_dict[context] = None\n                    except json.JSONDecodeError as e:\n                        print(f\"JSON decoding error in file {filename} at line {line_number}: {e}\")\n        except FileNotFoundError:\n            print(f\"File not found: {filename}\")\n            continue\n        except Exception as e:\n            print(f\"An error occurred while processing file {filename}: {e}\")\n            continue\n\n        unique_contexts_list = list(unique_contexts_dict.keys())\n        print(f\"There are {len(unique_contexts_list)} unique `context` entries in the file {filename}.\")\n\n        try:\n            with open(output_path, 'w', encoding='utf-8') as outfile:\n                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)\n            print(f\"Unique `context` entries have been saved to: {output_filename}\")\n        except Exception as e:\n            print(f\"An error occurred while saving to the file {output_filename}: {e}\")\n\n    print(\"All files have been processed.\")\n\n```\n\n</details>\n\n### Step-1 Insert Contexts\n\nFor the extracted contexts, we insert them into the LightRAG system.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef insert_text(rag, file_path):\n    with open(file_path, mode='r') as f:\n        unique_contexts = json.load(f)\n\n    retries = 0\n    max_retries = 3\n    while retries < max_retries:\n        try:\n            rag.insert(unique_contexts)\n            break\n        except Exception as e:\n            retries += 1\n            print(f\"Insertion failed, retrying ({retries}/{max_retries}), error: {e}\")\n            time.sleep(10)\n    if retries == max_retries:\n        print(\"Insertion failed after exceeding the maximum number of retries\")\n```\n\n</details>\n\n### Step-2 Generate Queries\n\nWe extract tokens from the first and the second half of each context in the dataset, then combine them as dataset descriptions to generate queries.\n\n<details>\n<summary> Code </summary>\n\n```python\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\ndef get_summary(context, tot_tokens=2000):\n    tokens = tokenizer.tokenize(context)\n    half_tokens = tot_tokens // 2\n\n    start_tokens = tokens[1000:1000 + half_tokens]\n    end_tokens = tokens[-(1000 + half_tokens):1000]\n\n    summary_tokens = start_tokens + end_tokens\n    summary = tokenizer.convert_tokens_to_string(summary_tokens)\n\n    return summary\n```\n\n</details>\n\n### Step-3 Query\n\nFor the queries generated in Step-2, we will extract them and query LightRAG.\n\n<details>\n<summary> Code </summary>\n\n```python\ndef extract_queries(file_path):\n    with open(file_path, 'r') as f:\n        data = f.read()\n\n    data = data.replace('**', '')\n\n    queries = re.findall(r'- Question \\d+: (.+)', data)\n\n    return queries\n```\n\n</details>\n\n## üîó Related Projects\n\n*Ecosystem & Extensions*\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/RAG-Anything\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üì∏</span>\n          </div>\n          <b>RAG-Anything</b><br>\n          <sub>Multimodal RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/VideoRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">üé•</span>\n          </div>\n          <b>VideoRAG</b><br>\n          <sub>Extreme Long-Context Video RAG</sub>\n        </a>\n      </td>\n      <td align=\"center\">\n        <a href=\"https://github.com/HKUDS/MiniRAG\">\n          <div style=\"width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;\">\n            <span style=\"font-size: 32px;\">‚ú®</span>\n          </div>\n          <b>MiniRAG</b><br>\n          <sub>Extremely Simple RAG</sub>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## ‚≠ê Star History\n\n<a href=\"https://star-history.com/#HKUDS/LightRAG&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=HKUDS/LightRAG&type=Date\" />\n </picture>\n</a>\n\n## ü§ù Contribution\n\n<div align=\"center\">\n  We thank all our contributors for their valuable contributions.\n</div>\n\n<div align=\"center\">\n  <a href=\"https://github.com/HKUDS/LightRAG/graphs/contributors\">\n    <img src=\"https://contrib.rocks/image?repo=HKUDS/LightRAG\" style=\"border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);\" />\n  </a>\n</div>\n\n---\n\n\n## üìñ Citation\n\n```python\n@article{guo2024lightrag,\ntitle={LightRAG: Simple and Fast Retrieval-Augmented Generation},\nauthor={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},\nyear={2024},\neprint={2410.05779},\narchivePrefix={arXiv},\nprimaryClass={cs.IR}\n}\n```\n\n---\n\n<div align=\"center\" style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;\">\n  <div>\n    <img src=\"https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif\" width=\"500\">\n  </div>\n  <div style=\"margin-top: 20px;\">\n    <a href=\"https://github.com/HKUDS/LightRAG\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/issues\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n    <a href=\"https://github.com/HKUDS/LightRAG/discussions\" style=\"text-decoration: none;\">\n      <img src=\"https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&logo=github&logoColor=white\">\n    </a>\n  </div>\n</div>\n\n<div align=\"center\">\n  <div style=\"width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);\">\n    <div style=\"display: flex; justify-content: center; align-items: center; gap: 15px;\">\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n      <span style=\"color: #00d9ff; font-size: 18px;\">Thank you for visiting LightRAG!</span>\n      <span style=\"font-size: 24px;\">‚≠ê</span>\n    </div>\n  </div>\n</div>\n",
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/HKUDS/LightRAG",
          "homepage": "https://arxiv.org/abs/2410.05779",
          "language": "Python",
          "forks": 3507,
          "open_issues": 170,
          "license": "MIT License"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/118165258?v=4",
      "velocity": 26268,
      "is_rising_star": true,
      "heatScore": 7883.464636756028,
      "popularityScore": 23880
    },
    {
      "id": "github-asgeirtj-system_prompts_leaks",
      "name": "system_prompts_leaks",
      "author": "asgeirtj",
      "description": "Collection of extracted System Prompts from popular chatbots like ChatGPT, Claude & Gemini",
      "task": "tool",
      "tags": [
        "ai",
        "anthropic",
        "chatbots",
        "chatgpt",
        "claude",
        "gemini",
        "generative-ai",
        "google-deepmind",
        "large-language-models",
        "llm",
        "openai",
        "prompt-engineering",
        "prompt-injection",
        "prompts",
        "general-dialogue-qa"
      ],
      "likes": 47548,
      "downloads": 47548,
      "lastModified": "2025-11-20T14:37:50Z",
      "lastModifiedTimestamp": 1763649470000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/asgeirtj/system_prompts_leaks",
          "homepage": "",
          "language": "JavaScript",
          "forks": 3636,
          "open_issues": 22,
          "license": "No license"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/27446620?v=4",
      "velocity": 26151.4,
      "is_rising_star": true,
      "heatScore": 7848.483284367927,
      "popularityScore": 23774
    },
    {
      "id": "github-Fosowl-agenticSeek",
      "name": "agenticSeek",
      "author": "Fosowl",
      "description": "Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)",
      "task": "tool",
      "tags": [
        "agentic-ai",
        "agents",
        "ai",
        "autonomous-agents",
        "deepseek-r1",
        "llm",
        "llm-agents",
        "voice-assistant",
        "code-generation-assistance"
      ],
      "likes": 47425,
      "downloads": 47425,
      "lastModified": "2025-11-20T15:52:39Z",
      "lastModifiedTimestamp": 1763653959000,
      "readme": null,
      "downloadUrl": null,
      "sources": [
        {
          "platform": "GitHub",
          "url": "https://github.com/Fosowl/agenticSeek",
          "homepage": "http://agenticseek.tech",
          "language": "Python",
          "forks": 2570,
          "open_issues": 36,
          "license": "GNU General Public License v3.0"
        }
      ],
      "thumbnail": "https://avatars.githubusercontent.com/u/49105846?v=4",
      "velocity": 26083.2,
      "is_rising_star": true,
      "heatScore": 7828.022490550911,
      "popularityScore": 23712
    }
  ],
  "categories": {
    "general-dialogue-qa": [
      {
        "id": "github-f-awesome-chatgpt-prompts",
        "name": "awesome-chatgpt-prompts",
        "author": "f",
        "description": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
        "task": "tool",
        "tags": [
          "bots",
          "chatbot",
          "chatgpt",
          "chatgpt-api",
          "language",
          "general-dialogue-qa"
        ],
        "likes": 273424,
        "downloads": 273424,
        "lastModified": "2025-11-20T15:23:26Z",
        "lastModifiedTimestamp": 1763652206000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/f/awesome-chatgpt-prompts",
            "homepage": "https://prompts.chat",
            "language": "JavaScript",
            "forks": 18184,
            "open_issues": 290,
            "license": "Creative Commons Zero v1.0 Universal"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/196477?v=4",
        "velocity": 150383.2,
        "is_rising_star": true,
        "heatScore": 45118.55506686943,
        "popularityScore": 136712
      },
      {
        "id": "github-rasbt-LLMs-from-scratch",
        "name": "LLMs-from-scratch",
        "author": "rasbt",
        "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
        "task": "tool",
        "tags": [
          "ai",
          "artificial-intelligence",
          "chatbot",
          "chatgpt",
          "deep-learning",
          "from-scratch",
          "generative-ai",
          "gpt",
          "language-model",
          "large-language-models",
          "llm",
          "machine-learning",
          "neural-networks",
          "python",
          "pytorch",
          "transformers",
          "general-dialogue-qa"
        ],
        "likes": 158122,
        "downloads": 158122,
        "lastModified": "2025-11-20T15:46:33Z",
        "lastModifiedTimestamp": 1763653593000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/rasbt/LLMs-from-scratch",
            "homepage": "https://amzn.to/4fqvn0D",
            "language": "Jupyter Notebook",
            "forks": 11719,
            "open_issues": 0,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/5618407?v=4",
        "velocity": 86967.1,
        "is_rising_star": true,
        "heatScore": 26093.558577457425,
        "popularityScore": 79061
      },
      {
        "id": "github-binary-husky-gpt_academic",
        "name": "gpt_academic",
        "author": "binary-husky",
        "description": "‰∏∫GPT/GLMÁ≠âLLMÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂÆûÁî®Âåñ‰∫§‰∫íÊé•Âè£ÔºåÁâπÂà´‰ºòÂåñËÆ∫ÊñáÈòÖËØª/Ê∂¶Ëâ≤/ÂÜô‰Ωú‰ΩìÈ™åÔºåÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆ&ÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅPythonÂíåC++Á≠âÈ°πÁõÆÂâñÊûê&Ëá™ËØëËß£ÂäüËÉΩÔºåPDF/LaTexËÆ∫ÊñáÁøªËØë&ÊÄªÁªìÂäüËÉΩÔºåÊîØÊåÅÂπ∂Ë°åÈóÆËØ¢Â§öÁßçLLMÊ®°ÂûãÔºåÊîØÊåÅchatglm3Á≠âÊú¨Âú∞Ê®°Âûã„ÄÇÊé•ÂÖ•ÈÄö‰πâÂçÉÈóÆ, deepseekcoder, ËÆØÈ£ûÊòüÁÅ´, ÊñáÂøÉ‰∏ÄË®Ä, llama2, rwkv, claude2, mossÁ≠â„ÄÇ",
        "task": "tool",
        "tags": [
          "academic",
          "chatglm-6b",
          "chatgpt",
          "gpt-4",
          "large-language-models",
          "general-dialogue-qa",
          "code-generation-assistance"
        ],
        "likes": 139408,
        "downloads": 139408,
        "lastModified": "2025-11-20T14:41:49Z",
        "lastModifiedTimestamp": 1763649709000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/binary-husky/gpt_academic",
            "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
            "language": "Python",
            "forks": 8399,
            "open_issues": 291,
            "license": "GNU General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/96192199?v=4",
        "velocity": 76674.4,
        "is_rising_star": true,
        "heatScore": 23005.71028475207,
        "popularityScore": 69704
      },
      {
        "id": "github-lobehub-lobe-chat",
        "name": "lobe-chat",
        "author": "lobehub",
        "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
        "task": "tool",
        "tags": [
          "agent",
          "ai",
          "artifacts",
          "chat",
          "chatgpt",
          "claude",
          "deepseek",
          "deepseek-r1",
          "function-calling",
          "gemini",
          "gpt",
          "knowledge-base",
          "mcp",
          "nextjs",
          "ollama",
          "openai",
          "rag",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 135771,
        "downloads": 135771,
        "lastModified": "2025-11-20T15:53:45Z",
        "lastModifiedTimestamp": 1763654025000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/lobehub/lobe-chat",
            "homepage": "https://lobechat.com",
            "language": "TypeScript",
            "forks": 13999,
            "open_issues": 993,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
        "velocity": 74673.5,
        "is_rising_star": true,
        "heatScore": 22405.432246153854,
        "popularityScore": 67885
      },
      {
        "id": "github-pathwaycom-llm-app",
        "name": "llm-app",
        "author": "pathwaycom",
        "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
        "task": "tool",
        "tags": [
          "chatbot",
          "hugging-face",
          "llm",
          "llm-local",
          "llm-prompting",
          "llm-security",
          "llmops",
          "machine-learning",
          "open-ai",
          "pathway",
          "rag",
          "real-time",
          "retrieval-augmented-generation",
          "vector-database",
          "vector-index",
          "general-dialogue-qa",
          "rag-knowledge-base-qa",
          "data-analysis-insights"
        ],
        "likes": 94666,
        "downloads": 94666,
        "lastModified": "2025-11-20T15:46:47Z",
        "lastModifiedTimestamp": 1763653607000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/pathwaycom/llm-app",
            "homepage": "https://pathway.com/developers/templates/",
            "language": "Jupyter Notebook",
            "forks": 1214,
            "open_issues": 6,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
        "velocity": 52066.3,
        "is_rising_star": true,
        "heatScore": 15623.16262124451,
        "popularityScore": 47333
      },
      {
        "id": "github-FlowiseAI-Flowise",
        "name": "Flowise",
        "author": "FlowiseAI",
        "description": "Build AI Agents, Visually",
        "task": "tool",
        "tags": [
          "agentic-ai",
          "agentic-workflow",
          "agents",
          "artificial-intelligence",
          "chatbot",
          "chatgpt",
          "javascript",
          "langchain",
          "large-language-models",
          "low-code",
          "multiagent-systems",
          "no-code",
          "openai",
          "rag",
          "react",
          "typescript",
          "workflow-automation",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 93412,
        "downloads": 93412,
        "lastModified": "2025-11-20T15:27:35Z",
        "lastModifiedTimestamp": 1763652455000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/FlowiseAI/Flowise",
            "homepage": "https://flowiseai.com",
            "language": "TypeScript",
            "forks": 23141,
            "open_issues": 728,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/128289781?v=4",
        "velocity": 51376.6,
        "is_rising_star": true,
        "heatScore": 15416.248567381353,
        "popularityScore": 46706
      },
      {
        "id": "github-zhayujie-chatgpt-on-wechat",
        "name": "chatgpt-on-wechat",
        "author": "zhayujie",
        "description": "Âü∫‰∫éÂ§ßÊ®°ÂûãÊê≠Âª∫ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂêåÊó∂ÊîØÊåÅ ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ Á≠âÊé•ÂÖ•ÔºåÂèØÈÄâÊã©ChatGPT/Claude/DeepSeek/ÊñáÂøÉ‰∏ÄË®Ä/ËÆØÈ£ûÊòüÁÅ´/ÈÄö‰πâÂçÉÈóÆ/ Gemini/GLM-4/Kimi/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥ÂíåÂõæÁâáÔºåËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíå‰∫íËÅîÁΩëÔºåÊîØÊåÅÂü∫‰∫éËá™ÊúâÁü•ËØÜÂ∫ìËøõË°åÂÆöÂà∂‰ºÅ‰∏öÊô∫ËÉΩÂÆ¢Êúç„ÄÇ",
        "task": "tool",
        "tags": [
          "ai",
          "ai-agent",
          "chatgpt",
          "claude-4",
          "deepseek",
          "dingtalk",
          "feishu-bot",
          "gemini",
          "gpt-4",
          "kimi",
          "linkai",
          "llm",
          "mcp",
          "multi-agent",
          "openai",
          "python3",
          "qwen",
          "rag",
          "wechat",
          "wechat-bot",
          "rag-knowledge-base-qa",
          "general-dialogue-qa"
        ],
        "likes": 79540,
        "downloads": 79540,
        "lastModified": "2025-11-20T15:05:28Z",
        "lastModifiedTimestamp": 1763651128000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/zhayujie/chatgpt-on-wechat",
            "homepage": "https://link-ai.tech",
            "language": "Python",
            "forks": 9502,
            "open_issues": 355,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/26161723?v=4",
        "velocity": 43747,
        "is_rising_star": true,
        "heatScore": 13127.3196965577,
        "popularityScore": 39770
      },
      {
        "id": "github-janhq-jan",
        "name": "jan",
        "author": "janhq",
        "description": "Jan is an open source alternative to ChatGPT that runs 100% offline on your computer.",
        "task": "tool",
        "tags": [
          "chatgpt",
          "gpt",
          "llamacpp",
          "llm",
          "localai",
          "open-source",
          "self-hosted",
          "tauri",
          "general-dialogue-qa"
        ],
        "likes": 78750,
        "downloads": 78750,
        "lastModified": "2025-11-20T13:35:09Z",
        "lastModifiedTimestamp": 1763645709000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/janhq/jan",
            "homepage": "https://jan.ai/",
            "language": "TypeScript",
            "forks": 2401,
            "open_issues": 191,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/102363196?v=4",
        "velocity": 43312.5,
        "is_rising_star": true,
        "heatScore": 12996.966662117451,
        "popularityScore": 39375
      },
      {
        "id": "github-QuivrHQ-quivr",
        "name": "quivr",
        "author": "QuivrHQ",
        "description": "Opiniated RAG for integrating GenAI in your apps üß†   Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want. ",
        "task": "tool",
        "tags": [
          "ai",
          "api",
          "chatbot",
          "chatgpt",
          "database",
          "docker",
          "framework",
          "frontend",
          "groq",
          "html",
          "javascript",
          "llm",
          "openai",
          "postgresql",
          "privacy",
          "rag",
          "react",
          "security",
          "typescript",
          "vector",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 77264,
        "downloads": 77264,
        "lastModified": "2025-11-20T12:53:10Z",
        "lastModifiedTimestamp": 1763643190000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/QuivrHQ/quivr",
            "homepage": "https://core.quivr.com",
            "language": "Python",
            "forks": 3689,
            "open_issues": 16,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/159330290?v=4",
        "velocity": 42495.2,
        "is_rising_star": true,
        "heatScore": 12751.770870903854,
        "popularityScore": 38632
      },
      {
        "id": "PokeeAI/pokee_research_7b",
        "name": "pokee_research_7b",
        "description": "A model for text-generation.",
        "task": "text-generation",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "agent",
          "deepresearch",
          "llm",
          "rl",
          "reinforcementlearning",
          "conversational",
          "en",
          "dataset:miromind-ai/MiroRL-GenQA",
          "arxiv:2510.15862",
          "base_model:Qwen/Qwen2.5-7B-Instruct",
          "base_model:finetune:Qwen/Qwen2.5-7B-Instruct",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us",
          "general-dialogue-qa"
        ],
        "likes": 990,
        "downloads": 191670,
        "lastModifiedTimestamp": null,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
            "files": [],
            "modelId": "PokeeAI/pokee_research_7b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
            "files": [],
            "modelId": "PokeeAI/pokee_research_7b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
            "files": [],
            "modelId": "PokeeAI/pokee_research_7b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
            "files": [],
            "modelId": "PokeeAI/pokee_research_7b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/PokeeAI/pokee_research_7b",
            "files": [],
            "modelId": "PokeeAI/pokee_research_7b"
          }
        ],
        "thumbnail": null,
        "velocity": null,
        "is_rising_star": false,
        "heatScore": null,
        "popularityScore": 38631
      }
    ],
    "code-generation-assistance": [
      {
        "id": "github-x1xhlol-system-prompts-and-models-of-ai-tools",
        "name": "system-prompts-and-models-of-ai-tools",
        "author": "x1xhlol",
        "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
        "task": "tool",
        "tags": [
          "ai",
          "bolt",
          "cluely",
          "copilot",
          "cursor",
          "cursorai",
          "devin",
          "github-copilot",
          "lovable",
          "open-source",
          "perplexity",
          "replit",
          "system-prompts",
          "trae",
          "trae-ai",
          "trae-ide",
          "v0",
          "vscode",
          "windsurf",
          "windsurf-ai",
          "code-generation-assistance"
        ],
        "likes": 193011,
        "downloads": 193011,
        "lastModified": "2025-11-20T15:52:37Z",
        "lastModifiedTimestamp": 1763653957000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
            "homepage": "",
            "language": null,
            "forks": 25948,
            "open_issues": 94,
            "license": "GNU General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/185671340?v=4",
        "velocity": 106155.5,
        "is_rising_star": true,
        "heatScore": 31850.139188020687,
        "popularityScore": 96505
      },
      {
        "id": "github-binary-husky-gpt_academic",
        "name": "gpt_academic",
        "author": "binary-husky",
        "description": "‰∏∫GPT/GLMÁ≠âLLMÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂÆûÁî®Âåñ‰∫§‰∫íÊé•Âè£ÔºåÁâπÂà´‰ºòÂåñËÆ∫ÊñáÈòÖËØª/Ê∂¶Ëâ≤/ÂÜô‰Ωú‰ΩìÈ™åÔºåÊ®°ÂùóÂåñËÆæËÆ°ÔºåÊîØÊåÅËá™ÂÆö‰πâÂø´Êç∑ÊåâÈíÆ&ÂáΩÊï∞Êèí‰ª∂ÔºåÊîØÊåÅPythonÂíåC++Á≠âÈ°πÁõÆÂâñÊûê&Ëá™ËØëËß£ÂäüËÉΩÔºåPDF/LaTexËÆ∫ÊñáÁøªËØë&ÊÄªÁªìÂäüËÉΩÔºåÊîØÊåÅÂπ∂Ë°åÈóÆËØ¢Â§öÁßçLLMÊ®°ÂûãÔºåÊîØÊåÅchatglm3Á≠âÊú¨Âú∞Ê®°Âûã„ÄÇÊé•ÂÖ•ÈÄö‰πâÂçÉÈóÆ, deepseekcoder, ËÆØÈ£ûÊòüÁÅ´, ÊñáÂøÉ‰∏ÄË®Ä, llama2, rwkv, claude2, mossÁ≠â„ÄÇ",
        "task": "tool",
        "tags": [
          "academic",
          "chatglm-6b",
          "chatgpt",
          "gpt-4",
          "large-language-models",
          "general-dialogue-qa",
          "code-generation-assistance"
        ],
        "likes": 139408,
        "downloads": 139408,
        "lastModified": "2025-11-20T14:41:49Z",
        "lastModifiedTimestamp": 1763649709000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/binary-husky/gpt_academic",
            "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
            "language": "Python",
            "forks": 8399,
            "open_issues": 291,
            "license": "GNU General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/96192199?v=4",
        "velocity": 76674.4,
        "is_rising_star": true,
        "heatScore": 23005.71028475207,
        "popularityScore": 69704
      },
      {
        "id": "github-ansible-ansible",
        "name": "ansible",
        "author": "ansible",
        "description": "Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.",
        "task": "tool",
        "tags": [
          "ansible",
          "python",
          "code-generation-assistance"
        ],
        "likes": 134117,
        "downloads": 134117,
        "lastModified": "2025-11-20T15:53:03Z",
        "lastModifiedTimestamp": 1763653983000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/ansible/ansible",
            "homepage": "https://www.ansible.com/",
            "language": "Python",
            "forks": 24129,
            "open_issues": 878,
            "license": "GNU General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/1507452?v=4",
        "velocity": 73763.8,
        "is_rising_star": true,
        "heatScore": 22132.518519950987,
        "popularityScore": 67058
      },
      {
        "id": "github-OpenHands-OpenHands",
        "name": "OpenHands",
        "author": "OpenHands",
        "description": "üôå OpenHands: Code Less, Make More",
        "task": "tool",
        "tags": [
          "agent",
          "artificial-intelligence",
          "chatgpt",
          "claude-ai",
          "cli",
          "developer-tools",
          "gpt",
          "llm",
          "openai",
          "code-generation-assistance"
        ],
        "likes": 130236,
        "downloads": 130236,
        "lastModified": "2025-11-20T15:45:30Z",
        "lastModifiedTimestamp": 1763653530000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/OpenHands/OpenHands",
            "homepage": "https://all-hands.dev",
            "language": "Python",
            "forks": 7937,
            "open_issues": 211,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/225919603?v=4",
        "velocity": 71629.8,
        "is_rising_star": true,
        "heatScore": 21492.30959540588,
        "popularityScore": 65118
      },
      {
        "id": "github-wshobson-agents",
        "name": "agents",
        "author": "wshobson",
        "description": "Intelligent automation and multi-agent orchestration for Claude Code",
        "task": "tool",
        "tags": [
          "agents",
          "ai-agents",
          "anthropic",
          "anthropic-claude",
          "automation",
          "claude",
          "claude-code",
          "claude-code-cli",
          "claude-code-commands",
          "claude-code-plugin",
          "claude-code-plugins",
          "claude-code-subagents",
          "claude-skills",
          "claudecode",
          "claudecode-config",
          "claudecode-subagents",
          "orchestration",
          "sub-agents",
          "subagents",
          "workflows",
          "agent-computer-interface",
          "computer-automation",
          "computer-use",
          "computer-use-agent",
          "cua",
          "grounding",
          "gui-agents",
          "in-context-reinforcement-learning",
          "memory",
          "mllm",
          "planning",
          "retrieval-augmented-generation",
          "ai",
          "openai",
          "real-time",
          "video",
          "voice",
          "autonomous-agents",
          "language-model",
          "llm",
          "rag-knowledge-base-qa",
          "code-generation-assistance"
        ],
        "likes": 106916,
        "downloads": 106916,
        "lastModified": "2025-11-20T15:44:42Z",
        "lastModifiedTimestamp": 1763653482000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/wshobson/agents",
            "homepage": "https://sethhobson.com",
            "language": "Python",
            "forks": 2352,
            "open_issues": 4,
            "license": "MIT License"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/contains-studio/agents",
            "homepage": null,
            "language": null,
            "forks": 2129,
            "open_issues": 9,
            "license": "No license"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/simular-ai/Agent-S",
            "homepage": "https://www.simular.ai",
            "language": "Python",
            "forks": 907,
            "open_issues": 13,
            "license": "Apache License 2.0"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/livekit/agents",
            "homepage": "https://docs.livekit.io/agents",
            "language": "Python",
            "forks": 1776,
            "open_issues": 448,
            "license": "Apache License 2.0"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/aiwaves-cn/agents",
            "homepage": "",
            "language": "Python",
            "forks": 452,
            "open_issues": 39,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
        "velocity": 58803.8,
        "is_rising_star": true,
        "heatScore": 17644.44961458143,
        "popularityScore": 53458
      },
      {
        "id": "github-cline-cline",
        "name": "cline",
        "author": "cline",
        "description": "Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.",
        "task": "tool",
        "tags": [
          "code-generation-assistance"
        ],
        "likes": 105064,
        "downloads": 105064,
        "lastModified": "2025-11-20T15:39:22Z",
        "lastModifiedTimestamp": 1763653162000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/cline/cline",
            "homepage": "https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev",
            "language": "TypeScript",
            "forks": 5246,
            "open_issues": 895,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/184127137?v=4",
        "velocity": 57785.2,
        "is_rising_star": true,
        "heatScore": 17338.864302541922,
        "popularityScore": 52532
      },
      {
        "id": "github-Mintplex-Labs-anything-llm",
        "name": "anything-llm",
        "author": "Mintplex-Labs",
        "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
        "task": "tool",
        "tags": [
          "ai-agents",
          "custom-ai-agents",
          "deepseek",
          "kimi",
          "llama3",
          "llm",
          "lmstudio",
          "local-llm",
          "localai",
          "mcp",
          "mcp-servers",
          "moonshot",
          "multimodal",
          "no-code",
          "ollama",
          "qwen3",
          "rag",
          "vector-database",
          "web-scraping",
          "rag-knowledge-base-qa",
          "code-generation-assistance"
        ],
        "likes": 102482,
        "downloads": 102482,
        "lastModified": "2025-11-20T15:24:23Z",
        "lastModifiedTimestamp": 1763652263000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/Mintplex-Labs/anything-llm",
            "homepage": "https://anythingllm.com",
            "language": "JavaScript",
            "forks": 5428,
            "open_issues": 331,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/134426827?v=4",
        "velocity": 56365.1,
        "is_rising_star": true,
        "heatScore": 16912.82673825049,
        "popularityScore": 51241
      },
      {
        "id": "github-openai-codex",
        "name": "codex",
        "author": "openai",
        "description": "Lightweight coding agent that runs in your terminal",
        "task": "tool",
        "tags": [
          "code-generation-assistance"
        ],
        "likes": 101932,
        "downloads": 101932,
        "lastModified": "2025-11-20T15:27:31Z",
        "lastModifiedTimestamp": 1763652451000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/openai/codex",
            "homepage": "",
            "language": "Rust",
            "forks": 6392,
            "open_issues": 1067,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/14957082?v=4",
        "velocity": 56062.6,
        "is_rising_star": true,
        "heatScore": 16822.075102349743,
        "popularityScore": 50966
      },
      {
        "id": "github-anthropics-claude-code",
        "name": "claude-code",
        "author": "anthropics",
        "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
        "task": "tool",
        "tags": [
          "code-generation-assistance"
        ],
        "likes": 85919,
        "downloads": 85919,
        "lastModified": "2025-11-20T15:52:02Z",
        "lastModifiedTimestamp": 1763653922000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/anthropics/claude-code",
            "homepage": "https://code.claude.com/docs/en/overview",
            "language": "Shell",
            "forks": 2910,
            "open_issues": 5342,
            "license": "No license"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/76263028?v=4",
        "velocity": 47254.9,
        "is_rising_star": true,
        "heatScore": 14179.713144990883,
        "popularityScore": 42959
      },
      {
        "id": "github-sst-opencode",
        "name": "opencode",
        "author": "sst",
        "description": "The AI coding agent built for the terminal.",
        "task": "tool",
        "tags": [
          "ai",
          "claude",
          "code",
          "llm",
          "openai",
          "code-generation-assistance"
        ],
        "likes": 85846,
        "downloads": 85846,
        "lastModified": "2025-11-20T15:54:52Z",
        "lastModifiedTimestamp": 1763654092000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/sst/opencode",
            "homepage": "https://opencode.ai",
            "language": "TypeScript",
            "forks": 2685,
            "open_issues": 1494,
            "license": "MIT License"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/opencode-ai/opencode",
            "homepage": "",
            "language": "Go",
            "forks": 807,
            "open_issues": 163,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/66570915?v=4",
        "velocity": 47215.3,
        "is_rising_star": true,
        "heatScore": 14167.832890130338,
        "popularityScore": 42923
      }
    ],
    "rag-knowledge-base-qa": [
      {
        "id": "github-langchain-ai-langchain",
        "name": "langchain",
        "author": "langchain-ai",
        "description": "ü¶úüîó The platform for reliable agents.",
        "task": "tool",
        "tags": [
          "agents",
          "ai",
          "ai-agents",
          "ai-agents-framework",
          "aiagentframework",
          "anthropic",
          "chatgpt",
          "enterprise",
          "framework",
          "gemini",
          "generative-ai",
          "langchain",
          "llm",
          "multiagent",
          "open-source",
          "openai",
          "pydantic",
          "python",
          "rag",
          "rag-knowledge-base-qa"
        ],
        "likes": 240248,
        "downloads": 240248,
        "lastModified": "2025-11-20T15:50:06Z",
        "lastModifiedTimestamp": 1763653806000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/langchain-ai/langchain",
            "homepage": "https://docs.langchain.com/oss/python/langchain/",
            "language": "Python",
            "forks": 19786,
            "open_issues": 241,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/126733545?v=4",
        "velocity": 132136.4,
        "is_rising_star": true,
        "heatScore": 39644.47574338047,
        "popularityScore": 120124
      },
      {
        "id": "github-langgenius-dify",
        "name": "dify",
        "author": "langgenius",
        "description": "Production-ready platform for agentic workflow development.",
        "task": "tool",
        "tags": [
          "agent",
          "agentic-ai",
          "agentic-framework",
          "agentic-workflow",
          "ai",
          "automation",
          "gemini",
          "genai",
          "gpt",
          "gpt-4",
          "llm",
          "low-code",
          "mcp",
          "nextjs",
          "no-code",
          "openai",
          "orchestration",
          "python",
          "rag",
          "workflow",
          "rag-knowledge-base-qa"
        ],
        "likes": 238804,
        "downloads": 238804,
        "lastModified": "2025-11-20T15:50:01Z",
        "lastModifiedTimestamp": 1763653801000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/langgenius/dify",
            "homepage": "https://dify.ai",
            "language": "TypeScript",
            "forks": 18511,
            "open_issues": 682,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/127165244?v=4",
        "velocity": 131342.2,
        "is_rising_star": true,
        "heatScore": 39406.21391066701,
        "popularityScore": 119402
      },
      {
        "id": "github-open-webui-open-webui",
        "name": "open-webui",
        "author": "open-webui",
        "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
        "task": "tool",
        "tags": [
          "ai",
          "llm",
          "llm-ui",
          "llm-webui",
          "llms",
          "mcp",
          "ollama",
          "ollama-webui",
          "open-webui",
          "openai",
          "openapi",
          "rag",
          "self-hosted",
          "ui",
          "webui",
          "rag-knowledge-base-qa"
        ],
        "likes": 231540,
        "downloads": 231540,
        "lastModified": "2025-11-20T15:46:30Z",
        "lastModifiedTimestamp": 1763653590000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/open-webui/open-webui",
            "homepage": "https://openwebui.com",
            "language": "JavaScript",
            "forks": 16219,
            "open_issues": 304,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/158137808?v=4",
        "velocity": 127347,
        "is_rising_star": true,
        "heatScore": 38207.64451984924,
        "popularityScore": 115770
      },
      {
        "id": "github-Shubhamsaboo-awesome-llm-apps",
        "name": "awesome-llm-apps",
        "author": "Shubhamsaboo",
        "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
        "task": "tool",
        "tags": [
          "llms",
          "python",
          "rag",
          "rag-knowledge-base-qa"
        ],
        "likes": 158413,
        "downloads": 158413,
        "lastModified": "2025-11-20T15:51:47Z",
        "lastModifiedTimestamp": 1763653907000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
            "homepage": "https://www.theunwindai.com",
            "language": "Python",
            "forks": 10579,
            "open_issues": 3,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/31396011?v=4",
        "velocity": 87126.6,
        "is_rising_star": true,
        "heatScore": 26141.409134495156,
        "popularityScore": 79206
      },
      {
        "id": "github-infiniflow-ragflow",
        "name": "ragflow",
        "author": "infiniflow",
        "description": "RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs",
        "task": "tool",
        "tags": [
          "agent",
          "agentic",
          "agentic-ai",
          "agentic-workflow",
          "ai",
          "ai-search",
          "deep-learning",
          "deep-research",
          "deepseek",
          "deepseek-r1",
          "document-parser",
          "document-understanding",
          "graphrag",
          "llm",
          "mcp",
          "multi-agent",
          "ollama",
          "openai",
          "rag",
          "retrieval-augmented-generation",
          "rag-knowledge-base-qa"
        ],
        "likes": 136116,
        "downloads": 136116,
        "lastModified": "2025-11-20T14:42:49Z",
        "lastModifiedTimestamp": 1763649769000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/infiniflow/ragflow",
            "homepage": "https://ragflow.io",
            "language": "Python",
            "forks": 7305,
            "open_issues": 2876,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/69962740?v=4",
        "velocity": 74863.8,
        "is_rising_star": true,
        "heatScore": 22462.52301989456,
        "popularityScore": 68058
      },
      {
        "id": "github-lobehub-lobe-chat",
        "name": "lobe-chat",
        "author": "lobehub",
        "description": "ü§Ø LobeHub - an open-source, modern design AI Agent Workspace. Supports multiple AI providers, Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.",
        "task": "tool",
        "tags": [
          "agent",
          "ai",
          "artifacts",
          "chat",
          "chatgpt",
          "claude",
          "deepseek",
          "deepseek-r1",
          "function-calling",
          "gemini",
          "gpt",
          "knowledge-base",
          "mcp",
          "nextjs",
          "ollama",
          "openai",
          "rag",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 135771,
        "downloads": 135771,
        "lastModified": "2025-11-20T15:53:45Z",
        "lastModifiedTimestamp": 1763654025000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/lobehub/lobe-chat",
            "homepage": "https://lobechat.com",
            "language": "TypeScript",
            "forks": 13999,
            "open_issues": 993,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/131470832?v=4",
        "velocity": 74673.5,
        "is_rising_star": true,
        "heatScore": 22405.432246153854,
        "popularityScore": 67885
      },
      {
        "id": "github-dair-ai-Prompt-Engineering-Guide",
        "name": "Prompt-Engineering-Guide",
        "author": "dair-ai",
        "description": "üêô Guides, papers, lessons, notebooks and resources for prompt engineering, context engineering, RAG, and AI Agents.",
        "task": "tool",
        "tags": [
          "agent",
          "agents",
          "ai-agents",
          "chatgpt",
          "deep-learning",
          "generative-ai",
          "language-model",
          "llms",
          "openai",
          "prompt-engineering",
          "rag",
          "rag-knowledge-base-qa"
        ],
        "likes": 133184,
        "downloads": 133184,
        "lastModified": "2025-11-20T15:46:31Z",
        "lastModifiedTimestamp": 1763653591000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/dair-ai/Prompt-Engineering-Guide",
            "homepage": "https://www.promptingguide.ai/",
            "language": "MDX",
            "forks": 6951,
            "open_issues": 231,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/30384625?v=4",
        "velocity": 73251.2,
        "is_rising_star": true,
        "heatScore": 21978.73640000614,
        "popularityScore": 66592
      },
      {
        "id": "github-PaddlePaddle-PaddleOCR",
        "name": "PaddleOCR",
        "author": "PaddlePaddle",
        "description": "Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.",
        "task": "tool",
        "tags": [
          "ai4science",
          "chineseocr",
          "document-parsing",
          "document-translation",
          "kie",
          "ocr",
          "paddleocr-vl",
          "pdf-extractor-rag",
          "pdf-parser",
          "pdf2markdown",
          "pp-ocr",
          "pp-structure",
          "rag",
          "rag-knowledge-base-qa"
        ],
        "likes": 128822,
        "downloads": 128822,
        "lastModified": "2025-11-20T15:27:27Z",
        "lastModifiedTimestamp": 1763652447000,
        "readme": "<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"./docs/images/Banner.png\" alt=\"PaddleOCR Banner\">\n  </p>\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](./readme/README_cn.md) | [ÁπÅÈ´î‰∏≠Êñá](./readme/README_tcn.md) | [Êó•Êú¨Ë™û](./readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](./readme/README_ko.md) | [Fran√ßais](./readme/README_fr.md) | [–†—É—Å—Å–∫–∏–π](./readme/README_ru.md) | [Espa√±ol](./readme/README_es.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](./readme/README_ar.md)\n\n<!-- icon -->\n[![stars](https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf)](https://github.com/PaddlePaddle/PaddleOCR)\n[![forks](https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg)](https://github.com/PaddlePaddle/PaddleOCR)\n[![arXiv](https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2507.05595)\n[![arXiv](https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.14528)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr/month)](https://pepy.tech/projectsproject/paddleocr)\n[![PyPI Downloads](https://static.pepy.tech/badge/paddleocr)](https://pepy.tech/projects/paddleocr)\n[![Used by](https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue)](https://github.com/PaddlePaddle/PaddleOCR/network/dependents)\n[![PyPI version](https://img.shields.io/pypi/v/paddleocr)](https://pypi.org/project/paddleocr/)\n![python](https://img.shields.io/badge/python-3.8~3.12-aff.svg)\n\n![os](https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg)\n![hardware](https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg)\n[![License](https://img.shields.io/badge/license-Apache_2.0-green)](../LICENSE)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/PaddlePaddle/PaddleOCR)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://www.paddleocr.com)\n\n\n\n**PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding**\n\n</div>\n\n# PaddleOCR\n[![Framework](https://img.shields.io/badge/PaddlePaddle-3.0-orange)](https://www.paddlepaddle.org.cn/en)\n[![Accuracy](https://img.shields.io/badge/Recognition%20Accuracy-üèÜ-green)](#)\n[![Multi-Language](https://img.shields.io/badge/Support_Languages-100+-brightgreen)](#)\n[![Handwriting](https://img.shields.io/badge/Handwriting-‚úì-success)](#)\n[![Hardware](https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red)](#)\n\n> [!TIP]\n> PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to [PaddleOCR MCP Server](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html).\n>\n> The PaddleOCR 3.0 Technical Report is now available. See details at: [PaddleOCR 3.0 Technical Report](https://arxiv.org/abs/2507.05595).\n>\n> The PaddleOCR-VL Technical Report is now available. See details at [PaddleOCR-VL Technical Report](https://arxiv.org/abs/2510.14528).\n>\n> The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the [PaddleOCR official website](https://www.paddleocr.com).\n\n\n**PaddleOCR** converts documents and images into **structured, AI-friendly data** (like JSON and Markdown) with **industry-leading accuracy**‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over **60,000 stars** and deep integration into leading projects like **MinerU, RAGFlow, pathway and cherry-studio**, PaddleOCR has become the **premier solution** for developers building intelligent document applications in the **AI era**.\n\n### PaddleOCR 3.0 Core Features\n\n[![HuggingFace](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&labelColor=white)](https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n[![AI Studio](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/application/detail/98365)\n[![ModelScope](https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&labelColor=white)](https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo)\n\n[![AI Studio](https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAMAAADDpiTIAAAABlBMVEU2P+X///+1KuUwAAAHKklEQVR42u3dS5bjOAwEwALvf2fMavZum6IAImI7b2yYSqU+1Zb//gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADKCR/+fzly7rD92yVg69xh8zeLwOa5w+ZvFYHtc4ft3ykB++cOm79PAp6YO2z/Ngl4ZO5l+9+yT4QAvLqS748VF33Ylzdvzpl72f6z53YIGJ6SZdPeNHcIwOycaADdLgCSIgAIgCOAACAAykIAEAAEAAFAABCAT+WQuQVgeBqXhXQIQAAYegowLQBpbg3gZGFyAC6vgBQAMREA2/YfDPxyaDQNyTNz+3Zwn5J4ZG7PB2h0kHhi7plPCImmJwkPzO0RMa3OET0i5uGlzHFze0xcu0vE2Dq3J4U2vEPgSaHbFzPNDQAAAAAAAMBNovdw+cP/ny+uaf7w/+eYADy8kE+F4Offdjn6zZXhAXgiA78G4MNNsmnu1Xr7b3mbOL8T5Ja5bw/A35EC2LiWpzt1y9jRugBy30fLg3NvHPvnuZcC2NsCUXA/aRmA89V07Fwgt37uH8deCmBr6N44pP4UgaUATpdA7v/cMbIB8okliY65/SW5HhJ1ehPmM+8edwXgpbu4R88FayR32Y/P7oZZbOx13/Zr//ZHx27bAPnkFoyewYlbAhD3TvBobr95gaUAtr1EdNx1lgI4OcTTuR3z6+FZMEDRcu9ZCuDgGCdyGxMa4EgBRMvcjrkM7NgBZw5c0TwAUWUhZwRXA2xaya65Xa3jO2qYZ8bu2AD5w38tG5V8aZpoGN6Tz0bOfa9bceyWAciTO0jWyO1Tc5cLwJmF/JfPnXVyu3/slgHIg1n79O2O5fZv+1cHV7sC2HYqmUdHysNzX3sVkMcjUK5Gc+dMs28E5bGtm0V3gloBOP9vgZv+4sYn3RUaYFMCol5uN77g6lUApc8pWs69Zn7snS9Z9Q8G0S0AUTVUUTG3A54R1KSvo/diLAv5fKzynZeN6xogC75u93+AtBTA47OlAFSv6qY/vp3DAjD8iv2ZdFYJwKynMhTK1rInPfzaxW81LnvSgFP9KxrATaCLA3DxHpbFX31ZyNm5XRZyXG5bNkAWfP0rcrsUwOgC6NIAzgBcBiqAWwPgLrAGuGBP6jr2sifdfiJ6QQM4Bbw4AK4B3129ZSFn53ZZyA/GyFty27IBFMDFAXAG8PbyLQv5xULGPRl0K3h2AbwcgCZPhs+LD1zLnjS6AN4NwMU/DVFh7LyhASreTbvqrxdr/J4XT4Swz4FrTS+AGJ7bNbwAYkxuWzZAVljHrJfbjb9wviYXwFO/FJ8Vli4vaICsEMFyBbA3tmtsAUS0zG1c/bj4YwsZH2/+Whd0+1Nb+S7IE2sfPw4RL0XmsR8Nqvz7qFngmPHF34EqjP15AAofAkosZKPC/K6FVoeP02Ehi540NG6AK/4pYP3cLgVwXwHkDQ1QcSGb/uF4WwCmfX8u/+4vgLINcMUlQIfcLgXwXAF0+BGkpQDuuJx7/hwgpu//cWVuO3wxJOz/z8297vgYBwaIO3O7Kn+c194578ltywbIgu8fl+Z2lS+APvnLjnOv8hsgSqxjgwL4Ln9LAezaj98tgPzy7ZcC+GQzxrWxXQpgx370dm6/H7v6jaBoso5dY1swAFlwHWvfBf5pxVa93fCtdx64+1dsgCy4joWvAfPX9VoKYMs6Zse9/8Mlvv7LILlhAfKFFdsSutJXAdFkL3qlADJPrXFcXAC5KYaH586jO9mtAch9S3T0GQJ726ZWAE49kjP3rlDJuetdaL/1zeqZY9c7CRz7s0wCUPxienQBnAuAAtAAlxaAAAxfyBQABSAACkAAFIAAKAABUAACMEkKwL170oh7V8ueNLoAjgTAXWAN4BRwcABcA2oABTA4AApAAyiAwQFQABpAAQwOgALQADMWUgCuEmNyu15fSIY3gFPAiwPgFFADKIDBAVAAGkABCIACmBqAUAAaQAHMDUCMWkgBuMWw3K43F5LhDeAU8OIAuAmkARTA4AAoAA2gAARAAUwNgLvAGkABDA6Au8AaoKOJuV0vLSTDG8Ap4MUBcBNIAyiAwQFQABpAAQwOgALQAApAABTA1AC4C6wBOhqb23V+IRneAE4BLw6Aa0ANoAAGB0ABaAAFMDgACkADKAABUABTA+AusAboKATAQs4trjV+IYcfuJYCcA6gAATAQk69dFkKQANYyLkFcLIBFIDLQAVwawDsSRrAEWBwAJwCagAFMDgACkADKIDBAVAAGkABCIACmBoAzwXWAApgcADsSRrg0iNACoACEADXgAIwdCFTACykALgGFIAfl0kBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBv/gN+IH8U6YveYgAAAABJRU5ErkJggg==&labelColor=white)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&labelColor=white)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n\n- **PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM**  \n  **The SOTA and resource-efficient model tailored for document parsing**, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.\n\n- **PP-OCRv5 ‚Äî Universal Scene Text Recognition**  \n  **Single model supports five text types** (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with **13% accuracy improvement**. Solves multilingual mixed document recognition challenges.\n\n- **PP-StructureV3 ‚Äî Complex Document Parsing**  \n  Intelligently converts complex PDFs and document images into **Markdown and JSON files that preserve original structure**. **Outperforms** numerous commercial solutions in public benchmarks. **Perfectly maintains document layout and hierarchical structure**.\n\n- **PP-ChatOCRv4 ‚Äî Intelligent Information Extraction**  \n  Natively integrates ERNIE 4.5 to **precisely extract key information** from massive documents, with 15% accuracy improvement over previous generation. Makes documents \"**understand**\" your questions and provide accurate answers.\n\nIn addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg\" alt=\"PaddleOCR Architecture\">\n  </p>\n</div>\n\n**Special Note**: PaddleOCR 3.x introduces several significant interface changes. **Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x**. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. [This document](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html) explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.\n\n## üì£ Recent updates\n\n### üî•üî• 2025.10.16: PaddleOCR 3.3.0 released, includes:\n\n- Released PaddleOCR-VL:\n    - **Model Introduction**:\n        - **PaddleOCR-VL** is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. **This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption**. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on [HuggingFace](https://huggingface.co/PaddlePaddle/PaddleOCR-VL). Everyone is welcome to download and use it! More introduction infomation can be found in [PaddleOCR-VL](https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html).\n\n    - **Core Features**:\n        - **Compact yet Powerful VLM Architecture**: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.\n        - **SOTA Performance on Document Parsing**: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.\n        - **Multilingual Support**: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.\n\n- Released PP-OCRv5 Multilingual Recognition Model:\n    - Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.\n\n\n<details>\n<summary><strong>2025.08.21: Release of PaddleOCR 3.2.0</strong></summary>\n\n- **Significant Model Additions:**\n    - Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. **The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.**\n\n- **Deployment Capability Upgrades:**\n    - **Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.**\n    - **Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.**\n    - **High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.**\n    - **The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.**\n    - The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.\n\n- **Benchmark Support:**\n    - **All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. [Here's](docs/version3.x/pipeline_usage/instructions/benchmark.en.md) how to set up and use the benchmark feature.**\n    - **Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.**\n\n- **Bug Fixes:**\n    - Resolved the issue of failed log saving during model training.\n    - Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.\n    - Fixed inconsistencies in switch behaviors (e.g., `use_chart_parsing`) in the PP-StructureV3 configuration files compared to other pipelines.\n\n- **Other Enhancements:**\n    - **Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.**\n    - **Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the [installation guide](docs/version3.x/installation.en.md) for the corresponding PaddlePaddle framework versions.**\n    - **PP-OCR series models now support returning single-character coordinates.**\n    - Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.\n    - Added support for chart-to-table conversion via the PP-Chart2Table module.\n    - Optimized documentation descriptions to improve usability.\n</details>\n\n<details>\n<summary><strong>2025.08.15: PaddleOCR 3.1.1 Released</strong></summary>\n\n- **Bug Fixes:**\n  - Added the missing methods `save_vector`, `save_visual_info_list`, `load_vector`, and `load_visual_info_list` in the `PP-ChatOCRv4` class.\n  - Added the missing parameters `glossary` and `llm_request_interval` to the `translate` method in the `PPDocTranslation` class.\n\n- **Documentation Improvements:**\n  - Added a demo to the MCP documentation.\n  - Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.\n  - Fixed errors and omissions in the production line document translation.\n\n- **Others:**\n  - Changed the MCP server dependency to use the pure Python library `puremagic` instead of `python-magic` to reduce installation issues.\n  - Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.\n\n</details>\n\n<details>\n<summary><strong>2025.06.29: PaddleOCR 3.1.0 Released</strong></summary>\n\n- **Key Models and Pipelines:**\n  - **Added PP-OCRv5 Multilingual Text Recognition Model**, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. **Average accuracy improved by over 30%.** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html)\n  - Upgraded the **PP-Chart2Table model** in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) **increased by 9.36 percentage points (71.24% -> 80.60%).**\n  - Newly launched **document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5**, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html)\n\n\n- **New MCP server:** [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html)\n  - **Supports both OCR and PP-StructureV3 pipelines.**\n  - Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.\n  - Supports invoking local services via stdio and remote services via Streamable HTTP.\n\n- **Documentation Optimization:** Improved the descriptions in some user guides for a smoother reading experience.\n\n</details>\n\n<details>\n    <summary><strong>2025.06.26: PaddleOCR 3.0.3 Released</strong></summary>\n- Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference.\n</details>\n\n<details>\n    <summary><strong>2025.06.19: PaddleOCR 3.0.2 Released</strong></summary>\n- **New Features:**\n\n  - The default download source has been changed from `BOS` to `HuggingFace`. Users can also change the environment variable `PADDLE_PDX_MODEL_SOURCE` to `BOS` to set the model download source back to Baidu Object Storage (BOS).\n  - Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.\n  - Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.\n  - Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language. \n  - Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.\n  - Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.\n  - Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.\n  - Added Android example for PP-OCRv5. [Details](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html).\n\n- **Bug Fixes:**\n  - Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.\n  - Resolved an issue where `export_paddlex_config_to_yaml` would not function correctly in certain cases.\n  - Corrected the discrepancy between the actual behavior of `save_path` and its documentation description.\n  - Fixed potential multithreading errors when using MKL-DNN in basic service deployment.\n  - Corrected channel order errors in image preprocessing for the Latex-OCR model.\n  - Fixed channel order errors in saving visualized images within the text recognition module.\n  - Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.\n  - Fixed an overflow issue in the calculation of `overlap_ratio` under extremely special circumstances in the PP-StructureV3 pipeline.\n\n- **Documentation Improvements:**\n  - Updated the description of the `enable_mkldnn` parameter in the documentation to accurately reflect the program's actual behavior.\n  - Fixed errors in the documentation regarding the `lang` and `ocr_version` parameters.\n  - Added instructions for exporting pipeline configuration files via CLI.\n  - Fixed missing columns in the performance data table for PP-OCRv5.\n  - Refined benchmark metrics for PP-StructureV3 across different configurations.\n\n- **Others:**\n\n  - Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.\n</details>\n\n<details>\n    <summary><strong>History Log</strong></summary>\n\n2025.06.05: **PaddleOCR 3.0.1 Released**, includes:\n\n- **Optimisation of certain models and model configurations:**\n  - Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter `limit_side_len` in the configuration has been changed from 736 to 64.\n  - Added a new text line orientation classification model `PP-LCNet_x1_0_textline_ori` with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.\n  - Optimized the text line orientation classification model `PP-LCNet_x0_25_textline_ori`, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.\n- **Optimizations and fixes for some issues in version 3.0.0, [details](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)**\n\nüî•üî•2025.05.20: Official Release of **PaddleOCR v3.0**, including:\n- **PP-OCRv5**: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.\n   1. üåê Single-model support for **five** text types - Seamlessly process **Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English** and **Japanese** within a single model.\n   2. ‚úçÔ∏è Improved **handwriting recognition**: Significantly better at complex cursive scripts and non-standard handwriting.\n   3. üéØ **13-point accuracy gain** over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.\n\n- **PP-StructureV3**: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios! \n   1. üßÆ **High-Accuracy multi-scene PDF parsing**, leading both open- and closed-source solutions on the OmniDocBench benchmark.\n   2. üß† Specialized capabilities include **seal recognition**, **chart-to-table conversion**, **table recognition with nested formulas/images**, **vertical text document parsing**, and **complex table structure analysis**.\n\n- **PP-ChatOCRv4**: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.\n   1. üî• **15-point accuracy gain** in key-information extraction on PDF/PNG/JPG files over the previous generation.\n   2. üíª Native support for **ERNIE 4.5**, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.\n   3. ü§ù Integrated [PP-DocBee2](https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2), enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.\n\n[History Log](https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html)\n\n</details>\n\n## ‚ö° Quick Start\n### 1. Run online demo \n[![AI Studio](https://img.shields.io/badge/PP_OCRv5-AI_Studio-green)](https://aistudio.baidu.com/community/app/91660/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_StructureV3-AI_Studio-green)](https://aistudio.baidu.com/community/app/518494/webUI)\n[![AI Studio](https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green)](https://aistudio.baidu.com/community/app/518493/webUI)\n\n### 2. Installation\n\nInstall PaddlePaddle refer to [Installation Guide](https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html), after then, install the PaddleOCR toolkit.\n\n```bash\n# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\"\n```\n\nStarting from version 3.2.0, in addition to the `all` dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:\n\n| Dependency Group Name | Corresponding Functionality |\n| - | - |\n| `doc-parser` | Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL |\n| `ie` | Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4 |\n| `trans` | Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation |\n| `all` | Complete functionality |\n\n### 3. Run inference by CLI\n```bash\n# Run PP-OCRv5 inference\npaddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  \n\n# Run PP-StructureV3 inference\npaddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False\n\n# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference\npaddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False \n\n# Run PaddleOCR-VL inference\npaddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\n\n# Get more information about \"paddleocr ocr\"\npaddleocr ocr --help\n```\n\n### 4. Run inference by API\n**4.1 PP-OCRv5 Example**\n```python\n# Initialize PaddleOCR instance\nfrom paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\n\n# Run OCR inference on a sample image \nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")\n\n# Visualize the results and save the JSON results\nfor res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")\n```\n\n<details>\n    <summary><strong>4.2 PP-StructureV3 Example</strong></summary>\n\n```python\nfrom pathlib import Path\nfrom paddleocr import PPStructureV3\n\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\n# For Image\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\n\n# Visualize the results and save the JSON results\nfor res in output:\n    res.print() \n    res.save_to_json(save_path=\"output\") \n    res.save_to_markdown(save_path=\"output\")           \n```\n\n</details>\n\n<details>\n   <summary><strong>4.3 PP-ChatOCRv4 Example</strong></summary>\n\n```python\nfrom paddleocr import PPChatOCRv4Doc\n\nchat_bot_config = {\n    \"module_name\": \"chat_bot\",\n    \"model_name\": \"ernie-3.5-8k\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"openai\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\nretriever_config = {\n    \"module_name\": \"retriever\",\n    \"model_name\": \"embedding-v1\",\n    \"base_url\": \"https://qianfan.baidubce.com/v2\",\n    \"api_type\": \"qianfan\",\n    \"api_key\": \"api_key\",  # your api_key\n}\n\npipeline = PPChatOCRv4Doc(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\n\nvisual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)\n\nmllm_predict_info = None\nuse_mllm = False\n# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.\nif use_mllm:\n    mllm_chat_bot_config = {\n        \"module_name\": \"chat_bot\",\n        \"model_name\": \"PP-DocBee\",\n        \"base_url\": \"http://127.0.0.1:8080/\",  # your local mllm service url\n        \"api_type\": \"openai\",\n        \"api_key\": \"api_key\",  # your api_key\n    }\n\n    mllm_predict_res = pipeline.mllm_pred(\n        input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n        key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n        mllm_chat_bot_config=mllm_chat_bot_config,\n    )\n    mllm_predict_info = mllm_predict_res[\"mllm_res\"]\n\nvisual_info_list = []\nfor res in visual_predict_res:\n    visual_info_list.append(res[\"visual_info\"])\n    layout_parsing_result = res[\"layout_parsing_result\"]\n\nvector_info = pipeline.build_vector(\n    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config\n)\nchat_result = pipeline.chat(\n    key_list=[\"È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞\"],\n    visual_info=visual_info_list,\n    vector_info=vector_info,\n    mllm_predict_info=mllm_predict_info,\n    chat_bot_config=chat_bot_config,\n    retriever_config=retriever_config,\n)\nprint(chat_result)\n```\n\n</details>\n\n<details>\n   <summary><strong>4.4 PaddleOCR-VL Example</strong></summary>\n\n```python\nfrom paddleocr import PaddleOCRVL\n\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")\n```\n\n</details>\n\n### 5. Chinese Heterogeneous AI Accelerators\n- [Huawei Ascend](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html)\n- [KUNLUNXIN](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html)\n\n## üß© More Features\n\n- Convert models to ONNX format: [Obtaining ONNX Models](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html).\n- Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: [High-Performance Inference](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html).\n- Accelerate inference using multi-GPU and multi-process: [Parallel Inference for Pipelines](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html).\n- Integrate PaddleOCR into applications written in C++, C#, Java, etc.: [Serving](https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html).\n\n## ‚õ∞Ô∏è Advanced Tutorials\n\n- [PP-OCRv5 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html)\n- [PP-StructureV3 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html)\n- [PP-ChatOCRv4 Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html)\n- [PaddleOCR-VL Tutorial](https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html)\n\n## üîÑ Quick Overview of Execution Results\n\n### PP-OCRv5\n\n<div align=\"center\">\n  <p>\n       <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif\" alt=\"PP-OCRv5 Demo\">\n  </p>\n</div>\n\n\n\n### PP-StructureV3\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n### PaddleOCR-VL\n\n<div align=\"center\">\n  <p>\n      <img width=\"100%\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif\" alt=\"PP-StructureV3 Demo\">\n  </p>\n</div>\n\n\n## ‚ú® Stay Tuned\n\n‚≠ê **Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!** ‚≠ê\n\n<div align=\"center\">\n  <p>\n       <img width=\"1200\" src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif\" alt=\"Star-Project\">\n  </p>\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community\n\n<div align=\"center\">\n\n| PaddlePaddle WeChat official account |  Join the tech discussion group |\n| :---: | :---: |\n| <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg\" width=\"150\"> | <img src=\"https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg\" width=\"150\"> |\n</div>\n\n\n## üòÉ Awesome Projects Leveraging PaddleOCR\nPaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!\n\n<div align=\"center\">\n\n| Project Name | Description |\n| ------------ | ----------- |\n| [RAGFlow](https://github.com/infiniflow/ragflow) <a href=\"https://github.com/infiniflow/ragflow\"><img src=\"https://img.shields.io/github/stars/infiniflow/ragflow\"></a>|RAG engine based on deep document understanding.|\n| [pathway](https://github.com/pathwaycom/pathway) <a href=\"https://github.com/pathwaycom/pathway\"><img src=\"https://img.shields.io/github/stars/pathwaycom/pathway\"></a>|Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.|\n| [MinerU](https://github.com/opendatalab/MinerU) <a href=\"https://github.com/opendatalab/MinerU\"><img src=\"https://img.shields.io/github/stars/opendatalab/MinerU\"></a>|Multi-type Document to Markdown Conversion Tool|\n| [Umi-OCR](https://github.com/hiroi-sora/Umi-OCR) <a href=\"https://github.com/hiroi-sora/Umi-OCR\"><img src=\"https://img.shields.io/github/stars/hiroi-sora/Umi-OCR\"></a>|Free, Open-source, Batch Offline OCR Software.|\n| [cherry-studio](https://github.com/CherryHQ/cherry-studio) <a href=\"https://github.com/CherryHQ/cherry-studio\"><img src=\"https://img.shields.io/github/stars/CherryHQ/cherry-studio\"></a>|A desktop client that supports for multiple LLM providers.|\n| [OmniParser](https://github.com/microsoft/OmniParser)<a href=\"https://github.com/microsoft/OmniParser\"><img src=\"https://img.shields.io/github/stars/microsoft/OmniParser\"></a> |OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.|\n| [QAnything](https://github.com/netease-youdao/QAnything)<a href=\"https://github.com/netease-youdao/QAnything\"><img src=\"https://img.shields.io/github/stars/netease-youdao/QAnything\"></a> |Question and Answer based on Anything.|\n| [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit) <a href=\"https://github.com/opendatalab/PDF-Extract-Kit\"><img src=\"https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit\"></a>|A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.|\n| [Dango-Translator](https://github.com/PantsuDango/Dango-Translator)<a href=\"https://github.com/PantsuDango/Dango-Translator\"><img src=\"https://img.shields.io/github/stars/PantsuDango/Dango-Translator\"></a> |Recognize text on the screen, translate it and show the translation results in real time.|\n| [Learn more projects](./awesome_projects.md) | [More projects based on PaddleOCR](./awesome_projects.md)|\n</div>\n\n## üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors\n\n<div align=\"center\">\n<a href=\"https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&max=400&columns=20\"  width=\"800\"/>\n</a>\n</div>\n\n## üåü Star\n\n<div align=\"center\">\n  <p>\n      <img width=\"800\" src=\"https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&type=Date\" alt=\"Star-history\">\n  </p>\n</div>\n\n\n## üìÑ License\nThis project is released under the [Apache 2.0 license](LICENSE).\n\n## üéì Citation\n\n```bibtex\n@misc{cui2025paddleocr30technicalreport,\n      title={PaddleOCR 3.0 Technical Report}, \n      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2507.05595},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2507.05595}, \n}\n\n@misc{cui2025paddleocrvlboostingmultilingualdocument,\n      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, \n      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},\n      year={2025},\n      eprint={2510.14528},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2510.14528}, \n}\n```\n",
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/PaddlePaddle/PaddleOCR",
            "homepage": "https://www.paddleocr.ai",
            "language": "Python",
            "forks": 9368,
            "open_issues": 280,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/23534030?v=4",
        "velocity": 70852.1,
        "is_rising_star": true,
        "heatScore": 21258.99627674898,
        "popularityScore": 64411
      },
      {
        "id": "github-wshobson-agents",
        "name": "agents",
        "author": "wshobson",
        "description": "Intelligent automation and multi-agent orchestration for Claude Code",
        "task": "tool",
        "tags": [
          "agents",
          "ai-agents",
          "anthropic",
          "anthropic-claude",
          "automation",
          "claude",
          "claude-code",
          "claude-code-cli",
          "claude-code-commands",
          "claude-code-plugin",
          "claude-code-plugins",
          "claude-code-subagents",
          "claude-skills",
          "claudecode",
          "claudecode-config",
          "claudecode-subagents",
          "orchestration",
          "sub-agents",
          "subagents",
          "workflows",
          "agent-computer-interface",
          "computer-automation",
          "computer-use",
          "computer-use-agent",
          "cua",
          "grounding",
          "gui-agents",
          "in-context-reinforcement-learning",
          "memory",
          "mllm",
          "planning",
          "retrieval-augmented-generation",
          "ai",
          "openai",
          "real-time",
          "video",
          "voice",
          "autonomous-agents",
          "language-model",
          "llm",
          "rag-knowledge-base-qa",
          "code-generation-assistance"
        ],
        "likes": 106916,
        "downloads": 106916,
        "lastModified": "2025-11-20T15:44:42Z",
        "lastModifiedTimestamp": 1763653482000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/wshobson/agents",
            "homepage": "https://sethhobson.com",
            "language": "Python",
            "forks": 2352,
            "open_issues": 4,
            "license": "MIT License"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/contains-studio/agents",
            "homepage": null,
            "language": null,
            "forks": 2129,
            "open_issues": 9,
            "license": "No license"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/simular-ai/Agent-S",
            "homepage": "https://www.simular.ai",
            "language": "Python",
            "forks": 907,
            "open_issues": 13,
            "license": "Apache License 2.0"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/livekit/agents",
            "homepage": "https://docs.livekit.io/agents",
            "language": "Python",
            "forks": 1776,
            "open_issues": 448,
            "license": "Apache License 2.0"
          },
          {
            "platform": "GitHub",
            "url": "https://github.com/aiwaves-cn/agents",
            "homepage": "",
            "language": "Python",
            "forks": 452,
            "open_issues": 39,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/553618?v=4",
        "velocity": 58803.8,
        "is_rising_star": true,
        "heatScore": 17644.44961458143,
        "popularityScore": 53458
      },
      {
        "id": "github-Mintplex-Labs-anything-llm",
        "name": "anything-llm",
        "author": "Mintplex-Labs",
        "description": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, No-code agent builder, MCP compatibility,  and more.",
        "task": "tool",
        "tags": [
          "ai-agents",
          "custom-ai-agents",
          "deepseek",
          "kimi",
          "llama3",
          "llm",
          "lmstudio",
          "local-llm",
          "localai",
          "mcp",
          "mcp-servers",
          "moonshot",
          "multimodal",
          "no-code",
          "ollama",
          "qwen3",
          "rag",
          "vector-database",
          "web-scraping",
          "rag-knowledge-base-qa",
          "code-generation-assistance"
        ],
        "likes": 102482,
        "downloads": 102482,
        "lastModified": "2025-11-20T15:24:23Z",
        "lastModifiedTimestamp": 1763652263000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/Mintplex-Labs/anything-llm",
            "homepage": "https://anythingllm.com",
            "language": "JavaScript",
            "forks": 5428,
            "open_issues": 331,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/134426827?v=4",
        "velocity": 56365.1,
        "is_rising_star": true,
        "heatScore": 16912.82673825049,
        "popularityScore": 51241
      }
    ],
    "image-generation": [
      {
        "id": "github-mudler-LocalAI",
        "name": "LocalAI",
        "author": "mudler",
        "description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference",
        "task": "tool",
        "tags": [
          "ai",
          "api",
          "audio-generation",
          "decentralized",
          "distributed",
          "gemma",
          "image-generation",
          "libp2p",
          "llama",
          "llm",
          "mamba",
          "mcp",
          "mistral",
          "musicgen",
          "object-detection",
          "rerank",
          "rwkv",
          "stable-diffusion",
          "text-generation",
          "tts"
        ],
        "likes": 77768,
        "downloads": 77768,
        "lastModified": "2025-11-20T15:54:00Z",
        "lastModifiedTimestamp": 1763654040000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/mudler/LocalAI",
            "homepage": "https://localai.io",
            "language": "Go",
            "forks": 3085,
            "open_issues": 244,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/2420543?v=4",
        "velocity": 42771.3,
        "is_rising_star": true,
        "heatScore": 12834.602839654122,
        "popularityScore": 38883
      },
      {
        "id": "github-khoj-ai-khoj",
        "name": "khoj",
        "author": "khoj-ai",
        "description": "Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.",
        "task": "tool",
        "tags": [
          "agent",
          "ai",
          "assistant",
          "chat",
          "chatgpt",
          "emacs",
          "image-generation",
          "llama3",
          "llamacpp",
          "llm",
          "obsidian",
          "obsidian-md",
          "offline-llm",
          "productivity",
          "rag",
          "research",
          "self-hosted",
          "semantic-search",
          "stt",
          "whatsapp-ai",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 63230,
        "downloads": 63230,
        "lastModified": "2025-11-20T14:35:37Z",
        "lastModifiedTimestamp": 1763649337000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/khoj-ai/khoj",
            "homepage": "https://khoj.dev",
            "language": "Python",
            "forks": 1863,
            "open_issues": 85,
            "license": "GNU Affero General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/134046886?v=4",
        "velocity": 34776.5,
        "is_rising_star": true,
        "heatScore": 10436.099934846034,
        "popularityScore": 31615
      },
      {
        "id": "github-FoundationVision-VAR",
        "name": "VAR",
        "author": "FoundationVision",
        "description": "[NeurIPS 2024 Best Paper Award][GPT beats diffusionüî•] [scaling laws in visual generationüìà] Official impl. of \"Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction\". An *ultra-simple, user-friendly yet state-of-the-art* codebase for autoregressive image generation!",
        "task": "tool",
        "tags": [
          "auto-regressive-model",
          "autoregressive-models",
          "diffusion-models",
          "generative-ai",
          "generative-model",
          "gpt",
          "gpt-2",
          "image-generation",
          "large-language-models",
          "neurips",
          "transformers",
          "vision-transformer",
          "code-generation-assistance"
        ],
        "likes": 16974,
        "downloads": 16974,
        "lastModified": "2025-11-20T14:57:17Z",
        "lastModifiedTimestamp": 1763650637000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/FoundationVision/VAR",
            "homepage": "",
            "language": "Jupyter Notebook",
            "forks": 546,
            "open_issues": 54,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/151817217?v=4",
        "velocity": 9335.7,
        "is_rising_star": true,
        "heatScore": 2803.460163759625,
        "popularityScore": 8487
      },
      {
        "id": "github-open-mmlab-mmagic",
        "name": "mmagic",
        "author": "open-mmlab",
        "description": "OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox. Unlock the magic ü™Ñ: Generative-AI (AIGC), easy-to-use APIs, awsome model zoo, diffusion models, for text-to-image generation, image/video restoration/enhancement, etc.",
        "task": "tool",
        "tags": [
          "aigc",
          "computer-vision",
          "deep-learning",
          "diffusion",
          "diffusion-models",
          "generative-adversarial-network",
          "generative-ai",
          "image-editing",
          "image-generation",
          "image-processing",
          "image-synthesis",
          "inpainting",
          "matting",
          "pytorch",
          "super-resolution",
          "text2image",
          "video-frame-interpolation",
          "video-interpolation",
          "video-super-resolution"
        ],
        "likes": 14656,
        "downloads": 14656,
        "lastModified": "2025-11-19T11:20:16Z",
        "lastModifiedTimestamp": 1763551216000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/open-mmlab/mmagic",
            "homepage": "https://mmagic.readthedocs.io/en/latest/",
            "language": "Jupyter Notebook",
            "forks": 1097,
            "open_issues": 69,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/10245193?v=4",
        "velocity": 6785.809402009814,
        "is_rising_star": true,
        "heatScore": 2038.4483519081293,
        "popularityScore": 7328
      }
    ],
    "data-analysis-insights": [
      {
        "id": "github-pathwaycom-pathway",
        "name": "pathway",
        "author": "pathwaycom",
        "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
        "task": "tool",
        "tags": [
          "batch-processing",
          "data-analytics",
          "data-pipelines",
          "data-processing",
          "dataflow",
          "etl",
          "etl-framework",
          "iot-analytics",
          "kafka",
          "machine-learning-algorithms",
          "pathway",
          "python",
          "real-time",
          "rust",
          "stream-processing",
          "streaming",
          "time-series-analysis",
          "rag-knowledge-base-qa",
          "data-analysis-insights"
        ],
        "likes": 100330,
        "downloads": 100330,
        "lastModified": "2025-11-20T15:47:22Z",
        "lastModifiedTimestamp": 1763653642000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/pathwaycom/pathway",
            "homepage": "https://pathway.com",
            "language": "Python",
            "forks": 1454,
            "open_issues": 39,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
        "velocity": 55181.5,
        "is_rising_star": true,
        "heatScore": 16557.740286631673,
        "popularityScore": 50165
      },
      {
        "id": "github-pathwaycom-llm-app",
        "name": "llm-app",
        "author": "pathwaycom",
        "description": "Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.",
        "task": "tool",
        "tags": [
          "chatbot",
          "hugging-face",
          "llm",
          "llm-local",
          "llm-prompting",
          "llm-security",
          "llmops",
          "machine-learning",
          "open-ai",
          "pathway",
          "rag",
          "real-time",
          "retrieval-augmented-generation",
          "vector-database",
          "vector-index",
          "general-dialogue-qa",
          "rag-knowledge-base-qa",
          "data-analysis-insights"
        ],
        "likes": 94666,
        "downloads": 94666,
        "lastModified": "2025-11-20T15:46:47Z",
        "lastModifiedTimestamp": 1763653607000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/pathwaycom/llm-app",
            "homepage": "https://pathway.com/developers/templates/",
            "language": "Jupyter Notebook",
            "forks": 1214,
            "open_issues": 6,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/25750857?v=4",
        "velocity": 52066.3,
        "is_rising_star": true,
        "heatScore": 15623.16262124451,
        "popularityScore": 47333
      },
      {
        "id": "github-666ghj-BettaFish",
        "name": "BettaFish",
        "author": "666ghj",
        "description": "ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ",
        "task": "tool",
        "tags": [
          "agent-framework",
          "data-analysis",
          "deep-research",
          "deep-search",
          "llms",
          "multi-agent-system",
          "nlp",
          "public-opinion-analysis",
          "python3",
          "sentiment-analysis",
          "data-analysis-insights"
        ],
        "likes": 57118,
        "downloads": 57118,
        "lastModified": "2025-11-20T15:53:38Z",
        "lastModifiedTimestamp": 1763654018000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/666ghj/BettaFish",
            "homepage": "",
            "language": "Python",
            "forks": 5502,
            "open_issues": 69,
            "license": "GNU General Public License v2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/110395318?v=4",
        "velocity": 31413.8,
        "is_rising_star": true,
        "heatScore": 9427.259020097514,
        "popularityScore": 28558
      },
      {
        "id": "github-sinaptik-ai-pandas-ai",
        "name": "pandas-ai",
        "author": "sinaptik-ai",
        "description": "Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.",
        "task": "tool",
        "tags": [
          "ai",
          "csv",
          "data",
          "data-analysis",
          "data-science",
          "data-visualization",
          "database",
          "datalake",
          "gpt-4",
          "llm",
          "pandas",
          "sql",
          "text-to-sql",
          "data-analysis-insights",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 45230,
        "downloads": 45230,
        "lastModified": "2025-11-20T15:30:10Z",
        "lastModifiedTimestamp": 1763652610000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/sinaptik-ai/pandas-ai",
            "homepage": "https://pandas-ai.com",
            "language": "Python",
            "forks": 2212,
            "open_issues": 12,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/154438448?v=4",
        "velocity": 24876.5,
        "is_rising_star": true,
        "heatScore": 7465.9980910568365,
        "popularityScore": 22615
      },
      {
        "id": "github-vanna-ai-vanna",
        "name": "vanna",
        "author": "vanna-ai",
        "description": "ü§ñ Chat with your SQL database üìä. Accurate Text-to-SQL Generation via LLMs using Agentic Retrieval üîÑ.",
        "task": "tool",
        "tags": [
          "agent",
          "ai",
          "data-visualization",
          "database",
          "llm",
          "rag",
          "sql",
          "text-to-sql",
          "rag-knowledge-base-qa",
          "data-analysis-insights",
          "general-dialogue-qa"
        ],
        "likes": 43346,
        "downloads": 43346,
        "lastModified": "2025-11-20T15:44:55Z",
        "lastModifiedTimestamp": 1763653495000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/vanna-ai/vanna",
            "homepage": "https://vanna.ai/docs/",
            "language": "Python",
            "forks": 2041,
            "open_issues": 240,
            "license": "MIT License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/132533812?v=4",
        "velocity": 23840.3,
        "is_rising_star": true,
        "heatScore": 7155.125157348321,
        "popularityScore": 21673
      },
      {
        "id": "github-huggingface-datasets",
        "name": "datasets",
        "author": "huggingface",
        "description": "ü§ó The largest hub of ready-to-use datasets for AI models with fast, easy-to-use and efficient data manipulation tools",
        "task": "tool",
        "tags": [
          "ai",
          "artificial-intelligence",
          "computer-vision",
          "dataset-hub",
          "datasets",
          "deep-learning",
          "huggingface",
          "llm",
          "machine-learning",
          "natural-language-processing",
          "nlp",
          "numpy",
          "pandas",
          "pytorch",
          "speech",
          "tensorflow",
          "data-analysis-insights"
        ],
        "likes": 41758,
        "downloads": 41758,
        "lastModified": "2025-11-20T15:47:47Z",
        "lastModifiedTimestamp": 1763653667000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/huggingface/datasets",
            "homepage": "https://huggingface.co/docs/datasets",
            "language": "Python",
            "forks": 3014,
            "open_issues": 994,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/25720743?v=4",
        "velocity": 22966.9,
        "is_rising_star": true,
        "heatScore": 6893.0938113460315,
        "popularityScore": 20879
      },
      {
        "id": "github-qax-os-excelize",
        "name": "excelize",
        "author": "qax-os",
        "description": "Go language library for reading and writing Microsoft Excel‚Ñ¢ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets",
        "task": "tool",
        "tags": [
          "agent",
          "ai",
          "analytics",
          "chart",
          "ecma-376",
          "excel",
          "excelize",
          "formula",
          "go",
          "mcp",
          "microsoft",
          "office",
          "ooxml",
          "spreadsheet",
          "statistics",
          "table",
          "vba",
          "visualization",
          "xlsx",
          "xml",
          "data-analysis-insights"
        ],
        "likes": 39908,
        "downloads": 39908,
        "lastModified": "2025-11-20T12:04:33Z",
        "lastModifiedTimestamp": 1763640273000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/qax-os/excelize",
            "homepage": "https://xuri.me/excelize",
            "language": "Go",
            "forks": 1852,
            "open_issues": 132,
            "license": "BSD 3-Clause \"New\" or \"Revised\" License"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/29733149?v=4",
        "velocity": 21949.4,
        "is_rising_star": true,
        "heatScore": 6587.830036212485,
        "popularityScore": 19954
      },
      {
        "id": "github-langfuse-langfuse",
        "name": "langfuse",
        "author": "langfuse",
        "description": "ü™¢ Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. üçäYC W23 ",
        "task": "tool",
        "tags": [
          "analytics",
          "autogen",
          "evaluation",
          "langchain",
          "large-language-models",
          "llama-index",
          "llm",
          "llm-evaluation",
          "llm-observability",
          "llmops",
          "monitoring",
          "observability",
          "open-source",
          "openai",
          "playground",
          "prompt-engineering",
          "prompt-management",
          "self-hosted",
          "ycombinator",
          "data-analysis-insights"
        ],
        "likes": 36954,
        "downloads": 36954,
        "lastModified": "2025-11-20T15:52:33Z",
        "lastModifiedTimestamp": 1763653953000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/langfuse/langfuse",
            "homepage": "https://langfuse.com/docs",
            "language": "TypeScript",
            "forks": 1788,
            "open_issues": 432,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/134601687?v=4",
        "velocity": 20324.7,
        "is_rising_star": true,
        "heatScore": 6100.396658473941,
        "popularityScore": 18477
      },
      {
        "id": "github-google-langextract",
        "name": "langextract",
        "author": "google",
        "description": "A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.",
        "task": "tool",
        "tags": [
          "gemini",
          "gemini-ai",
          "gemini-api",
          "gemini-flash",
          "gemini-pro",
          "information-extration",
          "large-language-models",
          "llm",
          "nlp",
          "python",
          "structured-data",
          "data-analysis-insights"
        ],
        "likes": 33854,
        "downloads": 33854,
        "lastModified": "2025-11-20T15:05:30Z",
        "lastModifiedTimestamp": 1763651130000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/google/langextract",
            "homepage": "https://pypi.org/project/langextract/",
            "language": "Python",
            "forks": 1196,
            "open_issues": 83,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/1342004?v=4",
        "velocity": 18619.7,
        "is_rising_star": true,
        "heatScore": 5588.870023955248,
        "popularityScore": 16927
      },
      {
        "id": "github-raga-ai-hub-RagaAI-Catalyst",
        "name": "RagaAI-Catalyst",
        "author": "raga-ai-hub",
        "description": "Python SDK for Agent AI Observability, Monitoring and Evaluation Framework. Includes features like agent, llm and tools tracing, debugging multi-agentic system, self-hosted dashboard and advanced analytics with timeline and execution graph view ",
        "task": "tool",
        "tags": [
          "agentic-ai",
          "agentic-ai-development",
          "agentneo",
          "agents",
          "ai-agent-monitoring",
          "ai-application-debugging",
          "ai-evaluation-tools",
          "ai-performance-optimization",
          "ai-tool-interaction-monitoring",
          "llm-testing",
          "llm-tracing",
          "llmops",
          "data-analysis-insights"
        ],
        "likes": 32132,
        "downloads": 32132,
        "lastModified": "2025-11-20T07:18:03Z",
        "lastModifiedTimestamp": 1763623083000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/raga-ai-hub/RagaAI-Catalyst",
            "homepage": "https://catalyst.raga.ai/",
            "language": "Python",
            "forks": 3713,
            "open_issues": 21,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/161833182?v=4",
        "velocity": 17672.6,
        "is_rising_star": true,
        "heatScore": 5304.724154355579,
        "popularityScore": 16066
      }
    ],
    "summarization-extraction": [
      {
        "id": "github-deepset-ai-haystack",
        "name": "haystack",
        "author": "deepset-ai",
        "description": "AI orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.",
        "task": "tool",
        "tags": [
          "agent",
          "agents",
          "ai",
          "gemini",
          "generative-ai",
          "gpt-4",
          "information-retrieval",
          "large-language-models",
          "llm",
          "machine-learning",
          "nlp",
          "orchestration",
          "python",
          "pytorch",
          "question-answering",
          "rag",
          "retrieval-augmented-generation",
          "semantic-search",
          "summarization",
          "transformers",
          "rag-knowledge-base-qa",
          "summarization-extraction",
          "general-dialogue-qa"
        ],
        "likes": 46874,
        "downloads": 46874,
        "lastModified": "2025-11-20T15:29:51Z",
        "lastModifiedTimestamp": 1763652591000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/deepset-ai/haystack",
            "homepage": "https://haystack.deepset.ai",
            "language": "MDX",
            "forks": 2485,
            "open_issues": 121,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/51827949?v=4",
        "velocity": 25780.7,
        "is_rising_star": true,
        "heatScore": 7737.268944384946,
        "popularityScore": 23437
      },
      {
        "id": "Lamapi/next-1b",
        "name": "next-1b",
        "description": "A model for text-generation.",
        "task": "text-generation",
        "tags": [
          "transformers",
          "safetensors",
          "gguf",
          "gemma3_text",
          "text-generation",
          "turkish",
          "t√ºrkiye",
          "english",
          "ai",
          "lamapi",
          "gemma3",
          "next",
          "next-x1",
          "efficient",
          "open-source",
          "1b",
          "huggingface",
          "large-language-model",
          "llm",
          "causal",
          "transformer",
          "artificial-intelligence",
          "machine-learning",
          "ai-research",
          "natural-language-processing",
          "nlp",
          "finetuned",
          "lightweight",
          "creative",
          "summarization",
          "question-answering",
          "chat-model",
          "generative-ai",
          "optimized-model",
          "unsloth",
          "trl",
          "sft",
          "chemistry",
          "biology",
          "finance",
          "legal",
          "music",
          "art",
          "code",
          "climate",
          "medical",
          "agent",
          "text-generation-inference",
          "conversational",
          "tr",
          "ar",
          "af",
          "az",
          "es",
          "en",
          "el",
          "ro",
          "ru",
          "rm",
          "th",
          "uk",
          "uz",
          "pl",
          "pt",
          "fa",
          "sk",
          "sl",
          "da",
          "de",
          "nl",
          "fr",
          "fi",
          "ka",
          "hi",
          "hu",
          "hy",
          "ja",
          "kk",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lb",
          "id",
          "is",
          "it",
          "zh",
          "cs",
          "vi",
          "be",
          "bg",
          "bs",
          "ne",
          "mn",
          "dataset:mlabonne/FineTome-100k",
          "dataset:ITCL/FineTomeOs",
          "dataset:Gryphe/ChatGPT-4o-Writing-Prompts",
          "dataset:dongguanting/ARPO-SFT-54K",
          "dataset:GreenerPastures/All-Your-Base-Full",
          "dataset:Gryphe/Opus-WritingPrompts",
          "dataset:HuggingFaceH4/MATH-500",
          "dataset:mlabonne/smoltalk-flat",
          "dataset:mlabonne/natural_reasoning-formatted",
          "dataset:OpenSPG/KAG-Thinker-training-dataset",
          "dataset:uclanlp/Brief-Pro",
          "dataset:CognitiveKernel/CognitiveKernel-Pro-SFT",
          "dataset:SuperbEmphasis/Claude-4.0-DeepSeek-R1-RP-SFWish",
          "dataset:QuixiAI/dolphin-r1",
          "dataset:mlabonne/lmsys-arena-human-sft-55k",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us",
          "summarization-extraction",
          "code-generation-assistance",
          "general-dialogue-qa"
        ],
        "likes": 90,
        "downloads": 35590,
        "lastModifiedTimestamp": null,
        "readme": "---\nlanguage:\n- tr\n- ar\n- af\n- az\n- es\n- en\n- el\n- ro\n- ru\n- rm\n- th\n- uk\n- uz\n- pl\n- pt\n- fa\n- sk\n- sl\n- da\n- de\n- nl\n- fr\n- fi\n- ka\n- hi\n- hu\n- hy\n- ja\n- kk\n- kn\n- ko\n- ku\n- ky\n- la\n- lb\n- id\n- is\n- it\n- zh\n- cs\n- vi\n- be\n- bg\n- bs\n- ne\n- mn\nlicense: mit\ntags:\n- turkish\n- t√ºrkiye\n- english\n- ai\n- lamapi\n- gemma3\n- next\n- next-x1\n- efficient\n- text-generation\n- open-source\n- 1b\n- huggingface\n- large-language-model\n- llm\n- causal\n- transformer\n- artificial-intelligence\n- machine-learning\n- ai-research\n- natural-language-processing\n- nlp\n- finetuned\n- lightweight\n- creative\n- summarization\n- question-answering\n- chat-model\n- generative-ai\n- optimized-model\n- unsloth\n- trl\n- sft\n- chemistry\n- biology\n- finance\n- legal\n- music\n- art\n- code\n- climate\n- medical\n- agent\n- text-generation-inference\npipeline_tag: text-generation\ndatasets:\n- mlabonne/FineTome-100k\n- ITCL/FineTomeOs\n- Gryphe/ChatGPT-4o-Writing-Prompts\n- dongguanting/ARPO-SFT-54K\n- GreenerPastures/All-Your-Base-Full\n- Gryphe/Opus-WritingPrompts\n- HuggingFaceH4/MATH-500\n- mlabonne/smoltalk-flat\n- mlabonne/natural_reasoning-formatted\n- OpenSPG/KAG-Thinker-training-dataset\n- uclanlp/Brief-Pro\n- CognitiveKernel/CognitiveKernel-Pro-SFT\n- SuperbEmphasis/Claude-4.0-DeepSeek-R1-RP-SFWish\n- QuixiAI/dolphin-r1\n- mlabonne/lmsys-arena-human-sft-55k\nlibrary_name: transformers\n---\n\n<img src='assets/banner.png'>\n\n# üöÄ Next-1B (t416)\n\n### *Lightweight, Efficient, and T√ºrkiye-Focused AI*\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Language: English](https://img.shields.io/badge/Language-Multilingual-red.svg)]()\n[![HuggingFace](https://img.shields.io/badge/ü§ó-Lamapi/Next--1B-orange.svg)](https://huggingface.co/Lamapi/next-1b)\n\n---\n\n## üìñ Overview\n\n**Next-1B** is a **1-billion parameter causal language model** based on **Gemma 3**, designed for **efficiency, low-resource deployment, and reasoning-focused natural language understanding**.\n\nKey highlights:\n\n* Extremely **lightweight** ‚Äî can run on consumer GPUs with low VRAM.\n* Optimized for **text reasoning, summarization, and creative generation**.\n* Supports **Turkish natively** while remaining multilingual.\n* Open-source and transparent for research and applications.\n\nIdeal for **developers, students, and organizations** needing **fast, reliable, and low-resource text-generation**.\n\n---\n\n# Our Next 1B and Next 4B models are leading to all of the tiny models in benchmarks. \n\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>MMLU (5-shot) %</th>\n      <th>MMLU-Pro %</th>\n      <th>GSM8K %</th>\n      <th>MATH %</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr class=\"next\">\n      <td data-label=\"Model\">Next 4B preview</td>\n      <td data-label=\"MMLU (5-shot) %\">84.6</td>\n      <td data-label=\"MMLU-Pro %\">66.9</td>\n      <td data-label=\"GSM8K %\">82.7</td>\n      <td data-label=\"MATH %\"><strong>70.5</strong></td>\n    </tr>\n    <tr class=\"next\">\n      <td data-label=\"Model\">Next 1B <em>Version t327</em></td>\n      <td data-label=\"MMLU (5-shot) %\"><strong>87.3</strong></td>\n      <td data-label=\"MMLU-Pro %\"><strong>69.2</strong></td>\n      <td data-label=\"GSM8K %\"><strong>90.5</strong></td>\n      <td data-label=\"MATH %\">70.1</td>\n    </tr>\n    <tr>\n      <td data-label=\"Model\">Qwen 3 0.6B</td>\n      <td data-label=\"MMLU (5-shot) %\">52.81</td>\n      <td data-label=\"MMLU-Pro %\">37.6</td>\n      <td data-label=\"GSM8K %\">60.7</td>\n      <td data-label=\"MATH %\">20.5</td>\n    </tr>\n    <tr>\n      <td data-label=\"Model\">Llama 3.2 1B</td>\n      <td data-label=\"MMLU (5-shot) %\">49.3</td>\n      <td data-label=\"MMLU-Pro %\">44.4</td>\n      <td data-label=\"GSM8K %\">11.9</td>\n      <td data-label=\"MATH %\">30.6</td>\n    </tr>\n  </tbody>\n</table>\n\n---\n\n# Also, our Next 14b model is leading to state-of-the-art models in some of the Benchmarks.\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>MMLU (5-shot) %</th>\n      <th>MMLU-Pro %</th>\n      <th>GSM8K %</th>\n      <th>MATH %</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr class=\"next\">\n      <td><strong>Next 14B (Thinking)</strong></td>\n      <td><strong>94.6</strong></td>\n      <td><strong>93.2</strong></td>\n      <td><strong>98.8</strong></td>\n      <td>92.7</td>\n    </tr>\n    <tr>\n      <td>Next 12B</td>\n      <td>92.7</td>\n      <td>84.4</td>\n      <td>95.3</td>\n      <td>87.2</td>\n    </tr>\n    <tr>\n      <td>GPT-5</td>\n      <td>92.5</td>\n      <td>87.0</td>\n      <td>98.4</td>\n      <td><strong>96.0</strong></td>\n    </tr>\n    <tr>\n      <td>Claude Opus 4.1 (Thinking)</td>\n      <td>~92.0</td>\n      <td>87.8</td>\n      <td>84.7</td>\n      <td>95.4</td>\n    </tr>\n  </tbody>\n</table>\n\n---\n\n## üéØ Goals\n\n1. **Lightweight Efficiency:** Run smoothly on low-resource devices.\n2. **Reasoning-Focused:** Provide logical and coherent text outputs.\n3. **Accessibility:** Fully open-source with clear documentation.\n4. **Multilingual Adaptability:** Turkish-focused but supports other languages.\n\n---\n\n## ‚ú® Key Features\n\n| Feature                     | Description                                                           |\n| --------------------------- | --------------------------------------------------------------------- |\n| üîã Lightweight Architecture | Optimized for low VRAM usage; ideal for small GPUs or CPU deployment. |\n| üáπüá∑ Turkish & Multilingual | Handles complex Turkish prompts accurately.                           |\n| üß† Reasoning Capabilities   | Logical chain-of-thought for question-answering and problem-solving.  |\n| üìä Consistent Outputs       | Reliable and reproducible results across multiple runs.               |\n| üåç Open Source              | Transparent, research-friendly, and community-driven.                 |\n\n---\n\n## üìê Model Specifications\n\n| Specification      | Details                                                                |\n| ------------------ | ---------------------------------------------------------------------- |\n| Base Model         | Gemma 3                                                           |\n| Parameter Count    | 1 Billion                                                              |\n| Architecture       | Transformer, causal LLM                                                |\n| Fine-Tuning Method | Instruction fine-tuning (SFT) with Turkish and multilingual datasets   |\n| Optimizations      | Quantization-ready (q8, f16, f32)                      |\n| Use Cases          | Text generation, summarization, Q&A, creative writing, reasoning tasks |\n\n---\n\n## üöÄ Installation & Usage\n\n### Use the model:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_id = \"Lamapi/next-1b\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\n# Chat message\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are Next-X1, a smart and concise AI assistant trained by Lamapi. Always respond in the user's language. Proudly made in Turkey.\"},\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n]\n\n# Prepare input with Tokenizer\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Output from the model\noutput = model.generate(**inputs, max_new_tokens=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n```\n\n<div style='width:700px;'>\n  <div style='background-color:rgba(0,140,255,0.5);border-radius:16px;border-bottom-right-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;margin-left:250px;margin-top:-15px;margin-bottom:10px;'>\n    Hello, how are you?\n  </div>\n  <div style='background-color:rgba(42,42,40,0.7);border-radius:16px;border-bottom-left-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;'>\n  I'm fine, thank you. How are you?\n  </div>\n</div>\n\n---\n\n## üìÑ License\n\nMIT License ‚Äî free to use, modify, and distribute. Attribution appreciated.\n\n---\n\n## üìû Contact & Support\n\n* üìß **Email:** [lamapicontact@gmail.com](mailto:lamapicontact@gmail.com)\n* ü§ó **HuggingFace:** [Lamapi](https://huggingface.co/Lamapi)\n\n---\n\n> **Next-1B** ‚Äî Lightweight, **efficient, and reasoning-focused**, bringing **Turkey‚Äôs AI forward** on low-resource hardware.\n\n[![Follow on HuggingFace](https://img.shields.io/badge/Follow-HuggingFace-yellow?logo=huggingface)](https://huggingface.co/Lamapi)",
        "downloadUrl": null,
        "sources": [
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-1b",
            "files": [],
            "modelId": "Lamapi/next-1b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-1b",
            "files": [],
            "modelId": "Lamapi/next-1b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-1b",
            "files": [],
            "modelId": "Lamapi/next-1b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-1b",
            "files": [],
            "modelId": "Lamapi/next-1b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-1b",
            "files": [],
            "modelId": "Lamapi/next-1b"
          }
        ],
        "thumbnail": null,
        "velocity": null,
        "is_rising_star": false,
        "heatScore": null,
        "popularityScore": 7145
      },
      {
        "id": "Lamapi/next-12b",
        "name": "next-12b",
        "description": "A model for image-text-to-text.",
        "task": "image-text-to-text",
        "tags": [
          "transformers",
          "safetensors",
          "gguf",
          "gemma3",
          "image-text-to-text",
          "turkish",
          "t√ºrkiye",
          "english",
          "ai",
          "lamapi",
          "next",
          "next-x1",
          "efficient",
          "text-generation",
          "open-source",
          "12b",
          "huggingface",
          "large-language-model",
          "llm",
          "causal",
          "transformer",
          "artificial-intelligence",
          "machine-learning",
          "ai-research",
          "natural-language-processing",
          "language",
          "multilingual",
          "multimodal",
          "nlp",
          "finetuned",
          "lightweight",
          "creative",
          "summarization",
          "question-answering",
          "chat",
          "generative-ai",
          "optimized",
          "unsloth",
          "trl",
          "sft",
          "chemistry",
          "code",
          "biology",
          "finance",
          "legal",
          "music",
          "art",
          "state-of-the-art",
          "climate",
          "medical",
          "agent",
          "text-generation-inference",
          "merge",
          "dense",
          "conversational",
          "tr",
          "en",
          "de",
          "ka",
          "el",
          "ku",
          "es",
          "sl",
          "sk",
          "af",
          "da",
          "nl",
          "fa",
          "fi",
          "fr",
          "ga",
          "hi",
          "hu",
          "hy",
          "ja",
          "kg",
          "kk",
          "ko",
          "ky",
          "la",
          "lb",
          "id",
          "it",
          "is",
          "za",
          "zh",
          "zu",
          "cs",
          "vi",
          "be",
          "bg",
          "bs",
          "ne",
          "mn",
          "rm",
          "ro",
          "ru",
          "te",
          "th",
          "tk",
          "tt",
          "uk",
          "uz",
          "ug",
          "pl",
          "pt",
          "no",
          "dataset:mlabonne/FineTome-100k",
          "dataset:ITCL/FineTomeOs",
          "dataset:Gryphe/ChatGPT-4o-Writing-Prompts",
          "dataset:dongguanting/ARPO-SFT-54K",
          "dataset:GreenerPastures/All-Your-Base-Full",
          "dataset:Gryphe/Opus-WritingPrompts",
          "dataset:HuggingFaceH4/MATH-500",
          "dataset:mlabonne/smoltalk-flat",
          "dataset:mlabonne/natural_reasoning-formatted",
          "dataset:OpenSPG/KAG-Thinker-training-dataset",
          "dataset:uclanlp/Brief-Pro",
          "dataset:CognitiveKernel/CognitiveKernel-Pro-SFT",
          "dataset:SuperbEmphasis/Claude-4.0-DeepSeek-R1-RP-SFWish",
          "dataset:QuixiAI/dolphin-r1",
          "dataset:mlabonne/lmsys-arena-human-sft-55k",
          "license:mit",
          "endpoints_compatible",
          "region:us",
          "summarization-extraction",
          "general-dialogue-qa",
          "code-generation-assistance"
        ],
        "likes": 110,
        "downloads": 18640,
        "lastModifiedTimestamp": null,
        "readme": "---\nlanguage:\n- tr\n- en\n- de\n- ka\n- el\n- ku\n- es\n- sl\n- sk\n- af\n- da\n- nl\n- fa\n- fi\n- fr\n- ga\n- hi\n- hu\n- hy\n- ja\n- kg\n- kk\n- ko\n- ky\n- la\n- lb\n- id\n- it\n- is\n- za\n- zh\n- zu\n- cs\n- vi\n- be\n- bg\n- bs\n- ne\n- mn\n- rm\n- ro\n- ru\n- te\n- th\n- tk\n- tt\n- uk\n- uz\n- ug\n- pl\n- pt\n- 'no'\nlicense: mit\ntags:\n- turkish\n- t√ºrkiye\n- english\n- ai\n- lamapi\n- gemma3\n- next\n- next-x1\n- efficient\n- text-generation\n- open-source\n- 12b\n- huggingface\n- large-language-model\n- llm\n- causal\n- transformer\n- artificial-intelligence\n- machine-learning\n- ai-research\n- natural-language-processing\n- language\n- multilingual\n- multimodal\n- nlp\n- finetuned\n- lightweight\n- creative\n- summarization\n- question-answering\n- chat\n- generative-ai\n- optimized\n- unsloth\n- trl\n- sft\n- chemistry\n- code\n- biology\n- finance\n- legal\n- music\n- art\n- state-of-the-art\n- climate\n- medical\n- agent\n- text-generation-inference\n- merge\n- dense\npipeline_tag: image-text-to-text\ndatasets:\n- mlabonne/FineTome-100k\n- ITCL/FineTomeOs\n- Gryphe/ChatGPT-4o-Writing-Prompts\n- dongguanting/ARPO-SFT-54K\n- GreenerPastures/All-Your-Base-Full\n- Gryphe/Opus-WritingPrompts\n- HuggingFaceH4/MATH-500\n- mlabonne/smoltalk-flat\n- mlabonne/natural_reasoning-formatted\n- OpenSPG/KAG-Thinker-training-dataset\n- uclanlp/Brief-Pro\n- CognitiveKernel/CognitiveKernel-Pro-SFT\n- SuperbEmphasis/Claude-4.0-DeepSeek-R1-RP-SFWish\n- QuixiAI/dolphin-r1\n- mlabonne/lmsys-arena-human-sft-55k\nlibrary_name: transformers\n---\n\n<img src='assets/banner.png'>\n\n# üöÄ Next 12B (m200)\n\n### *T√ºrkiye's Advanced Vision-Language Model ‚Äî High Performance, Multimodal, and Enterprise-Ready* \n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Language: English](https://img.shields.io/badge/Language-Multilingual-red.svg)]()\n[![HuggingFace](https://img.shields.io/badge/ü§ó-Lamapi/Next--12B-orange.svg)](https://huggingface.co/Lamapi/next-12b)\n\n---\n\n## üìñ Overview\n\n**Next 12B** is a **12-billion parameter multimodal Vision-Language Model (VLM)** based on **Gemma 3**, fine-tuned to deliver **exceptional performance** in both text and image understanding. This is **T√ºrkiye's most advanced open-source vision-language model**, designed for: \n\n* Superior understanding and generation of **text and image descriptions**.\n* Advanced reasoning and context-aware multimodal outputs.\n* Professional-grade Turkish support with extensive multilingual capabilities.\n* Enterprise-ready deployment with optimized quantization options. \n\nThis model is ideal for **enterprises, researchers, and organizations** who need a **state-of-the-art multimodal AI** capable of **complex visual understanding, advanced reasoning, and creative generation**.\n\n---\n\n# Next 12B sets new standards for medium-sized models across all major benchmarks.\n\n<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>MMLU (5-shot) %</th>\n      <th>MMLU-Pro %</th>\n      <th>GSM8K %</th>\n      <th>MATH %</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Next 14B (Thinking)</td>\n      <td><strong>94.6</strong></td>\n      <td><strong>93.2</strong></td>\n      <td><strong>98.8</strong></td>\n      <td>92.7</td>\n    </tr>\n    <tr>\n      <td><strong>Next 12B</strong></td>\n      <td>92.7</td>\n      <td>84.4</td>\n      <td>95.3</td>\n      <td>87.2</td>\n    </tr>\n    <tr class=\"next\">\n      <td>Next 8B (Thinking)</td>\n      <td>91.0</td>\n      <td>88.5</td>\n      <td>96.2</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <td>GPT-5</td>\n      <td>92.5</td>\n      <td>87.0</td>\n      <td>98.4</td>\n      <td><strong>96.0</strong></td>\n    </tr>\n    <tr>\n      <td>Claude Opus 4.1 (Thinking)</td>\n      <td>~92.0</td>\n      <td>87.8</td>\n      <td>84.7</td>\n      <td>95.4</td>\n    </tr>\n  </tbody>\n</table>\n---\n\n## üöÄ Installation & Usage\n\n### Use with vision:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoProcessor\nfrom PIL import Image\nimport torch\n\nmodel_id = \"Lamapi/next-12b\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\nprocessor = AutoProcessor.from_pretrained(model_id) # For vision.\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n# Read image\nimage = Image.open(\"image.jpg\")\n\n# Create a message in chat format\nmessages = [\n  {\"role\": \"system\",\"content\": [{\"type\": \"text\", \"text\": \"You are Next-X1, a smart and concise AI assistant trained by Lamapi. Always respond in the user's language. Proudly made in Turkey.\"}]},\n\n  {\n      \"role\": \"user\",\"content\": [{\"type\": \"image\", \"image\": image},\n      {\"type\": \"text\", \"text\": \"Who is in this image?\"}\n    ]\n  }\n]\n\n# Prepare input with Tokenizer\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n\n# Output from the model\noutput = model.generate(**inputs, max_new_tokens=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n\n\n```\n<div style='width:700px;'>\n  <img src='/Lamapi/next-12b/resolve/main/assets/image.jpg' style='height:192px;border-radius:16px;margin-left:225px;'>\n  <div style='background-color:rgba(0,140,255,0.5);border-radius:16px;border-bottom-right-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;margin-left:250px;margin-top:-25px;margin-bottom:10px;'>\n    Who is in this image?\n  </div>\n  <div style='background-color:rgba(42,42,40,0.7);border-radius:16px;border-bottom-left-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;'>\n  The image shows <strong>Mustafa Kemal Atat√ºrk</strong>, the founder and first President of the Republic of Turkey.\n  </div>\n</div>\n\n### Use without vision:\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel_id = \"Lamapi/next-12b\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\n# Chat message\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are Next-X1, a smart and concise AI assistant trained by Lamapi. Always respond in the user's language. Proudly made in Turkey.\"},\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n]\n\n# Prepare input with Tokenizer\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Output from the model\noutput = model.generate(**inputs, max_new_tokens=50)\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n\n```\n\n<div style='width:700px;'>\n  <div style='background-color:rgba(0,140,255,0.5);border-radius:16px;border-bottom-right-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;margin-left:250px;margin-top:-15px;margin-bottom:10px;'>\n    Hello, how are you?\n  </div>\n  <div style='background-color:rgba(42,42,40,0.7);border-radius:16px;border-bottom-left-radius:0px;padding:3px 10px;width:fit-content;max-width:400px;'>\n  I'm fine, thank you. How are you?\n  </div>\n</div>\n\n---\n\n## üéØ Goals\n\n1. **Advanced Multimodal Intelligence:** Superior understanding and reasoning over images and text.\n2. **Enterprise-Grade Performance:** High accuracy and reliability for production deployments.\n3. **Efficiency:** Optimized for professional GPUs with flexible quantization options. \n4. **Accessibility:** Open-source availability for research and commercial applications.\n5. **Cultural Excellence:** Best-in-class Turkish language support while maintaining multilingual capabilities.\n\n---\n\n## ‚ú® Key Features\n\n| Feature                           | Description                                                             |\n| --------------------------------- | ----------------------------------------------------------------------- |\n| üîã Optimized Architecture         | Balanced performance and efficiency; supports multiple quantization formats.  | \n| üñºÔ∏è Advanced Vision-Language       | Deep understanding of images with sophisticated visual reasoning capabilities. |\n| üáπüá∑ Professional Turkish Support  | Industry-leading Turkish language performance with extensive multilingual reach.                        |\n| üß† Superior Reasoning             | State-of-the-art logical and analytical reasoning for complex tasks.     |\n| üìä Production-Ready               | Reliable, consistent outputs suitable for enterprise applications.                            |\n| üåç Open Source                    | Transparent, community-driven, and commercially friendly.                   |\n\n---\n\n## üìê Model Specifications\n\n| Specification      | Details                                                                            |\n| ------------------ | ---------------------------------------------------------------------------------- |\n| Base Model         | Gemma 3                                                                       | \n| Parameter Count    | 12 Billion                                                                          | \n| Architecture       | Transformer, causal LLM + Enhanced Vision Encoder                                           |\n| Fine-Tuning Method | Advanced instruction & multimodal fine-tuning (SFT) on curated Turkish and multilingual datasets    |\n| Optimizations      | Q8_0, Q4_K_M, F16, F32 quantizations for flexible deployment options                       | \n| Modalities         | Text & Image                                                                       |\n| Use Cases          | Advanced image captioning, multimodal QA, text generation, complex reasoning, creative storytelling, enterprise applications |\n\n---\n\n## üí° Performance Highlights\n\n- **MMLU Excellence:** 91.8% on MMLU benchmark, demonstrating comprehensive knowledge across diverse domains\n- **Mathematical Prowess:** 81.2% on MATH benchmark, excelling in complex mathematical reasoning\n- **Problem Solving:** 94.3% on GSM8K, showcasing superior word problem solving capabilities\n- **Professional Reasoning:** 78.4% on MMLU-Pro, handling advanced professional-level questions\n\n---\n\n## üé® Use Cases\n\n- **Enterprise Content Generation:** High-quality multilingual content creation\n- **Advanced Visual Analysis:** Detailed image understanding and description\n- **Educational Applications:** Complex tutoring and explanation systems\n- **Research Assistance:** Literature review and data analysis\n- **Creative Writing:** Story generation and creative content\n- **Technical Documentation:** Code documentation and technical writing\n- **Customer Support:** Multilingual customer service automation\n- **Data Extraction:** Visual document processing and information extraction\n\n---\n\n## üìÑ License\n\nThis project is licensed under the **MIT License** ‚Äî free to use, modify, and distribute for commercial and non-commercial purposes. Attribution is appreciated.\n\n---\n\n## üìû Contact & Support\n\n\n* üìß **Email:** [lamapicontact@gmail.com](mailto:lamapicontact@gmail.com) \n* ü§ó **HuggingFace:** [Lamapi](https://huggingface.co/Lamapi) \n\n---\n\n> **Next 12B** ‚Äî T√ºrkiye's **most advanced vision-language AI**, combining **state-of-the-art multimodal understanding, superior reasoning, and enterprise-grade reliability**.\n\n[![Follow on HuggingFace](https://img.shields.io/badge/Follow-HuggingFace-yellow?logo=huggingface)](https://huggingface.co/Lamapi)",
        "downloadUrl": null,
        "sources": [
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-12b",
            "files": [],
            "modelId": "Lamapi/next-12b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-12b",
            "files": [],
            "modelId": "Lamapi/next-12b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-12b",
            "files": [],
            "modelId": "Lamapi/next-12b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-12b",
            "files": [],
            "modelId": "Lamapi/next-12b"
          },
          {
            "platform": "Hugging Face",
            "url": "https://huggingface.co/Lamapi/next-12b",
            "files": [],
            "modelId": "Lamapi/next-12b"
          }
        ],
        "thumbnail": null,
        "velocity": null,
        "is_rising_star": false,
        "heatScore": null,
        "popularityScore": 3761
      }
    ],
    "workflow-automation": [
      {
        "id": "github-FlowiseAI-Flowise",
        "name": "Flowise",
        "author": "FlowiseAI",
        "description": "Build AI Agents, Visually",
        "task": "tool",
        "tags": [
          "agentic-ai",
          "agentic-workflow",
          "agents",
          "artificial-intelligence",
          "chatbot",
          "chatgpt",
          "javascript",
          "langchain",
          "large-language-models",
          "low-code",
          "multiagent-systems",
          "no-code",
          "openai",
          "rag",
          "react",
          "typescript",
          "workflow-automation",
          "general-dialogue-qa",
          "rag-knowledge-base-qa"
        ],
        "likes": 93412,
        "downloads": 93412,
        "lastModified": "2025-11-20T15:27:35Z",
        "lastModifiedTimestamp": 1763652455000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/FlowiseAI/Flowise",
            "homepage": "https://flowiseai.com",
            "language": "TypeScript",
            "forks": 23141,
            "open_issues": 728,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/128289781?v=4",
        "velocity": 51376.6,
        "is_rising_star": true,
        "heatScore": 15416.248567381353,
        "popularityScore": 46706
      },
      {
        "id": "github-ToolJet-ToolJet",
        "name": "ToolJet",
        "author": "ToolJet",
        "description": "ToolJet is the open-source foundation of ToolJet AI - the AI-native platform for building internal tools, dashboard, business applications, workflows and AI agents üöÄ",
        "task": "tool",
        "tags": [
          "ai-app-builder",
          "docker",
          "hacktoberfest",
          "internal-applications",
          "internal-project",
          "internal-tool",
          "internal-tools",
          "javascript",
          "kubernetes",
          "low-code",
          "low-code-development-platform",
          "low-code-framework",
          "no-code",
          "nodejs",
          "reactjs",
          "self-hosted",
          "typescript",
          "web-development-tools",
          "workflow-automation"
        ],
        "likes": 73858,
        "downloads": 73858,
        "lastModified": "2025-11-20T10:01:22Z",
        "lastModifiedTimestamp": 1763632882000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/ToolJet/ToolJet",
            "homepage": "https://tooljet.ai",
            "language": "JavaScript",
            "forks": 4877,
            "open_issues": 951,
            "license": "GNU Affero General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/82193554?v=4",
        "velocity": 40621.9,
        "is_rising_star": true,
        "heatScore": 12189.767165515355,
        "popularityScore": 36929
      },
      {
        "id": "github-activepieces-activepieces",
        "name": "activepieces",
        "author": "activepieces",
        "description": "AI Agents & MCPs & AI Workflow Automation ‚Ä¢ (~400 MCP servers for AI agents) ‚Ä¢ AI Automation / AI Agent with MCPs ‚Ä¢ AI Workflows & AI Agents ‚Ä¢ MCPs for AI Agents",
        "task": "tool",
        "tags": [
          "ai-agent",
          "ai-agent-tools",
          "ai-agents",
          "ai-agents-framework",
          "mcp",
          "mcp-server",
          "mcp-tools",
          "mcps",
          "n8n-alternative",
          "no-code-automation",
          "workflow",
          "workflow-automation",
          "workflows"
        ],
        "likes": 38468,
        "downloads": 38468,
        "lastModified": "2025-11-20T15:05:09Z",
        "lastModifiedTimestamp": 1763651109000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/activepieces/activepieces",
            "homepage": "https://www.activepieces.com",
            "language": "TypeScript",
            "forks": 2946,
            "open_issues": 338,
            "license": "Other"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/99494700?v=4",
        "velocity": 21157.4,
        "is_rising_star": true,
        "heatScore": 6350.21886453345,
        "popularityScore": 19234
      },
      {
        "id": "github-triggerdotdev-trigger.dev",
        "name": "trigger.dev",
        "author": "triggerdotdev",
        "description": "Trigger.dev ‚Äì build and deploy fully‚Äëmanaged AI agents and workflows",
        "task": "tool",
        "tags": [
          "ai",
          "ai-agent-framework",
          "ai-agents",
          "automation",
          "background-jobs",
          "mcp",
          "mcp-server",
          "nextjs",
          "orchestration",
          "scheduler",
          "serverless",
          "workflow-automation",
          "workflows"
        ],
        "likes": 25636,
        "downloads": 25636,
        "lastModified": "2025-11-20T11:41:17Z",
        "lastModifiedTimestamp": 1763638877000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/triggerdotdev/trigger.dev",
            "homepage": "https://trigger.dev/changelog",
            "language": "TypeScript",
            "forks": 895,
            "open_issues": 158,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/95297378?v=4",
        "velocity": 14099.8,
        "is_rising_star": true,
        "heatScore": 4232.815497903275,
        "popularityScore": 12818
      }
    ],
    "video-generation-editing": [
      {
        "id": "github-zai-org-CogVideo",
        "name": "CogVideo",
        "author": "zai-org",
        "description": "text and image to video generation: CogVideoX (2024) and CogVideo (ICLR 2023)",
        "task": "tool",
        "tags": [
          "cogvideox",
          "image-to-video",
          "llm",
          "sora",
          "text-to-video",
          "video-generation",
          "video-generation-editing"
        ],
        "likes": 24320,
        "downloads": 24320,
        "lastModified": "2025-11-20T07:48:33Z",
        "lastModifiedTimestamp": 1763624913000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/zai-org/CogVideo",
            "homepage": "",
            "language": "Python",
            "forks": 1218,
            "open_issues": 102,
            "license": "Apache License 2.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/223098841?v=4",
        "velocity": 13376,
        "is_rising_star": true,
        "heatScore": 4015.6594785019324,
        "popularityScore": 12160
      }
    ],
    "translation-localization": [
      {
        "id": "github-krillinai-KrillinAI",
        "name": "KrillinAI",
        "author": "krillinai",
        "description": "Video translation and dubbing tool powered by LLMs. The video translator offers 100 language translations and one-click full-process deployment. The video translation output is optimized for platforms like YouTubeÔºåTikTok.   AIËßÜÈ¢ëÁøªËØëÈÖçÈü≥Â∑•ÂÖ∑Ôºå100ÁßçËØ≠Ë®ÄÂèåÂêëÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutubeÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπÊàêÈÄÇÈÖç",
        "task": "tool",
        "tags": [
          "dubbing",
          "localization",
          "tts",
          "video-transcription",
          "video-translation",
          "translation-localization"
        ],
        "likes": 17798,
        "downloads": 17798,
        "lastModified": "2025-11-20T09:30:10Z",
        "lastModifiedTimestamp": 1763631010000,
        "readme": null,
        "downloadUrl": null,
        "sources": [
          {
            "platform": "GitHub",
            "url": "https://github.com/krillinai/KrillinAI",
            "homepage": "https://www.klic.studio",
            "language": "Go",
            "forks": 731,
            "open_issues": 17,
            "license": "GNU General Public License v3.0"
          }
        ],
        "thumbnail": "https://avatars.githubusercontent.com/u/2386538?v=4",
        "velocity": 9788.9,
        "is_rising_star": true,
        "heatScore": 2939.434573004651,
        "popularityScore": 8899
      }
    ]
  },
  "generatedAt": "2025-11-20T15:55:25.922Z"
}