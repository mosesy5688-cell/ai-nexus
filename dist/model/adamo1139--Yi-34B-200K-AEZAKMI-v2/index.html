<!DOCTYPE html><html lang="en"> <head><!-- Google Tag Manager --><script type="module">(function(e,n,r,t,m){e[t]=e[t]||[],e[t].push({"gtm.start":new Date().getTime(),event:"gtm.js"});var g=n.getElementsByTagName(r)[0],a=n.createElement(r),s="";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+m+s,g.parentNode.insertBefore(a,g)})(window,document,"script","dataLayer","GTM-58C2CQ8G");</script><!-- End Google Tag Manager --><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><!-- Open Graph Meta Tags --><meta property="og:type" content="website"><meta property="og:url" content="https://free2aitools.com/model/adamo1139--Yi-34B-200K-AEZAKMI-v2/"><meta property="og:title" content="Yi-34B-200K-AEZAKMI-v2 - AI Model Details"><meta property="og:description" content="A model for text-generation."><meta property="og:image" content="https://free2aitools.com/og-image.jpg"><!-- Twitter Card Meta Tags --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://free2aitools.com/model/adamo1139--Yi-34B-200K-AEZAKMI-v2/"><meta property="twitter:title" content="Yi-34B-200K-AEZAKMI-v2 - AI Model Details"><meta property="twitter:description" content="A model for text-generation."><meta property="twitter:image" content="https://free2aitools.com/og-image.jpg"><meta name="description" content="A model for text-generation."><title>Yi-34B-200K-AEZAKMI-v2 - AI Model Details</title><link rel="canonical" href="https://free2aitools.com/model/adamo1139--Yi-34B-200K-AEZAKMI-v2/"><!-- Google AdSense --><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2292826803755214" crossorigin="anonymous"></script><link rel="stylesheet" href="/_astro/about.C4wyk6Sp.css"></head> <body class="bg-gray-50 text-gray-800 font-sans antialiased flex flex-col min-h-screen"> <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-58C2CQ8G" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) --> <header class="sticky top-0 z-30 w-full backdrop-blur flex-none transition-colors duration-500 lg:border-b lg:border-gray-200 bg-white/80"> <nav class="container mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Site Logo --> <a href="/" class="flex items-center gap-2 text-xl sm:text-2xl font-bold text-gray-900"> <span>Free AI Tools</span> </a> <!-- Right-side items --> <div class="flex items-center gap-4"> <!-- Desktop Navigation --> <div class="hidden md:flex items-center gap-6"> <a href="/" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Explore Models </a><a href="/ranking" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Rankings </a><a href="/reports" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Reports </a><a href="/about" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> About </a> </div> <!-- Mobile Search & Menu Toggle --> <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls="navbar-default" aria-expanded="false"> <span class="sr-only">Open main menu</span> <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"></path></svg> </button> </div> </div> <!-- Mobile Collapsible Menu --> <div class="hidden w-full md:hidden" id="navbar-default"> <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50"> <li> <a href="/" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Explore Models</a> </li><li> <a href="/ranking" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Rankings</a> </li><li> <a href="/reports" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Reports</a> </li><li> <a href="/about" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">About</a> </li> </ul> </div> </nav> </header> <main class="flex-grow">  <div class="container mx-auto px-4 py-12"> <div class="max-w-4xl mx-auto"> <!-- Header Section --> <header class="mb-8"> <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-4"> <div> <h1 class="text-4xl md:text-5xl font-extrabold text-gray-900 dark:text-white mb-2">Yi-34B-200K-AEZAKMI-v2</h1> <p class="text-lg text-gray-500 dark:text-gray-400">by </p> </div>  </div> </header> <!-- Metadata Section --> <div class="mb-8 p-4 bg-gray-100 dark:bg-gray-800 rounded-lg"> <div class="grid grid-cols-2 md:grid-cols-4 gap-4 text-center"> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Likes</p> <p class="text-xl font-bold">60</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Downloads</p> <p class="text-xl font-bold">4,325</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Task</p> <p class="text-xl font-bold capitalize">text-generation</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Last Updated</p> <p class="text-xl font-bold">Invalid Date</p> </div> </div> </div> <!-- Tags and Sources --> <div class="mb-8 flex flex-wrap items-start gap-4"> <div class="flex-1"> <h3 class="text-lg font-semibold mb-2">Tags</h3> <div class="flex flex-wrap gap-2"> <a href="/?tag=transformers" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> transformers </a><a href="/?tag=safetensors" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> safetensors </a><a href="/?tag=llama" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> llama </a><a href="/?tag=text-generation" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> text-generation </a><a href="/?tag=llm" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> llm </a><a href="/?tag=fine-tune" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> fine-tune </a><a href="/?tag=yi" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> yi </a><a href="/?tag=conversational" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> conversational </a><a href="/?tag=dataset%3Aadamo1139%2FAEZAKMI_v2" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> dataset:adamo1139/AEZAKMI_v2 </a><a href="/?tag=license%3Aapache-2.0" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> license:apache-2.0 </a> </div> </div> <div class="flex-shrink-0"> <h3 class="text-lg font-semibold mb-2">Sources</h3> <div class="flex flex-col gap-2"> <a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a> </div> </div> </div> <!-- Source Specific Details --> <div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div> <!-- README Content --> <article class="model-readme-content py-8 border-t border-gray-200 dark:border-gray-700"> <div class="prose prose-lg dark:prose-invert max-w-none"> <h2>Model description</h2>
<p>Yi-34B 200K base model fine-tuned on AEZAKMI v2 dataset. Training took around 25 hours on single local RTX 3090 Ti.
It&#39;s like airoboros but with less gptslop, no refusals and less typical language used by RLHFed OpenAI models.
Say goodbye to  &quot;It&#39;s important to remember&quot;! <br>Prompt format is standard chatml. Don&#39;t expect it to be good at math, riddles or be crazy smart. My end goal with AEZAKMI is to create a cozy free chatbot.
Cost of this fine-tune is about $10 in electricity. It took me 3 tries to get it right.
Base model used for fine-tuning was 200k context Yi-34B-Llama model shared by larryvrh.</p>
<p>I had to lower max_positional_embeddings in config.json and model_max_length for training to start, otherwise I was OOMing straight away. 
My first attempt had max_positional_embeddings set to 16384 and model_max_length set to 200000. This allowed fine-tuning to finish, but that model was broken after applying LoRA and merging it. <br>This attempt had both max_position_embeddings and model_max_length set to 4096, which worked perfectly fine.</p>
<h2>Quants!</h2>
<p>Huge thank you to LoneStriker and TheBloke for providing quantized versions.</p>
<p>EXL2 <br>3bpw - <a href="https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-3.0bpw-h6-exl2">https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-3.0bpw-h6-exl2</a> <br>4bpw - <a href="https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-4.0bpw-h6-exl2">https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-4.0bpw-h6-exl2</a> <br>4.65bpw - <a href="https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2-exl2-4.65bpw">https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2-exl2-4.65bpw</a> <br>5bpw - <a href="https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-5.0bpw-h6-exl2">https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-5.0bpw-h6-exl2</a> <br>6bpw - <a href="https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-6.0bpw-h6-exl2">https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-6.0bpw-h6-exl2</a> <br>8bpw - <a href="https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-8.0bpw-h8-exl2">https://huggingface.co/LoneStriker/Yi-34B-200K-AEZAKMI-v2-8.0bpw-h8-exl2</a></p>
<p>GGUF - <a href="https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-GGUF">https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-GGUF</a></p>
<p>GPTQ - <a href="https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-GPTQ">https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-GPTQ</a></p>
<p>AWQ - <a href="https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-AWQ">https://huggingface.co/TheBloke/Yi-34B-200K-AEZAKMI-v2-AWQ</a></p>
<h2>Prompt Format</h2>
<p>I recommend using ChatML format, as this was used during fine-tune. <br>Here&#39;s a prompt format you should use, you can set a different system message, model seems to respect that fine, so it wasn&#39;t overfitted.</p>
<pre><code>&lt;|im_start|&gt;system
A chat with uncensored assistant.&lt;|im_end|&gt;
&lt;|im_start|&gt;user
{prompt}&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
</code></pre>
<h2>Intended uses &amp; limitations</h2>
<p>Use is limited by apache-2.0 license.</p>
<h2>Known Issues</h2>
<p>I recommend to set repetition penalty to something around 1.05 to avoid repetition. So far I had good experience running this model with temperature 1.2.
Stories have ChatGPT like paragraph spacing, I will work on this in the future maybe, not a high priority</p>
<p>Unrestricted-ness of the v2 isn&#39;t quite something that I am happy with yet, especially using prompt &quot;A chat.&quot;. <br>With a slightly modifed prompt it works much better, I recommend using &quot;A chat with uncensored assistant.&quot;, it&#39;s stupid but it helps a lot. <br>Base Yi-34B model is contaminated with refusals and this contaminates all models trained on Yi-34B <br>My next project is to attempt to de-contaminate base Yi-34B 4K and Yi-34B 200K using DPO with preferred data coming from uncontaminated raw models. I plan to release that dataset openly.</p>
<p>I was made aware of the frequent occurrence of the phrase &quot;sending shivers down a spine&quot; in the generations during RP of v1, so I fixed those samples - it should be better now. <br>I can hold up to 24000 ctx with 4.65bpw exl2 version and 8-bit cache - long context should work as good as other models trained on 200k version of Yi-34B <br>There is also some issue with handling long system messages for RP, I was planning to investigate it for v2 but I didn&#39;t.</p>
<h2>Axolotl training parameters</h2>
<ul>
<li>bnb_4bit_use_double_quant: true</li>
<li>is_llama_derived_model: true</li>
<li>load_in_4bit: true</li>
<li>adapter: qlora</li>
<li>sequence_len: 1400</li>
<li>sample_packing: true</li>
<li>lora_r: 16</li>
<li>lora_alpha: 32</li>
<li>lora_target_modules:<ul>
<li>q_proj</li>
<li>v_proj</li>
<li>k_proj</li>
<li>o_proj</li>
<li>gate_proj</li>
<li>down_proj</li>
<li>up_proj</li>
</ul>
</li>
<li>lora_target_linear: true</li>
<li>pad_to_sequence_len: false</li>
<li>micro_batch_size: 1</li>
<li>gradient_accumulation_steps: 1</li>
<li>num_epochs: 2.4</li>
<li>optimizer: adamw_bnb_8bit</li>
<li>lr_scheduler: constant</li>
<li>learning_rate: 0.00005</li>
<li>train_on_inputs: false</li>
<li>group_by_length: false</li>
<li>bf16: true</li>
<li>bfloat16: true</li>
<li>flash_optimum: false</li>
<li>gradient_checkpointing: true</li>
<li>flash_attention: true</li>
<li>seed: 42</li>
</ul>
<h2>Upcoming</h2>
<p>I will probably be working on de-contaminating base Yi-34B model now. <br>My second run of AEZAKMI v2 fine-tune was just 0.15 epochs and I really like how natural this model is and how rich is it&#39;s vocabulary. I will try to train less to hit the sweetspot. <br>I will be uploading LoRA adapter for that second run that was just 0.15 epochs. <br>I believe that I might have gotten what I want if I would have stopped training sooner. I don&#39;t have checkpoints older than 1500 steps back so I would need to re-run training to get it back.</p>
<h1><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM Leaderboard Evaluation Results</a></h1>
<p>Detailed results can be found <a href="https://huggingface.co/datasets/open-llm-leaderboard/details_adamo1139__Yi-34B-200K-AEZAKMI-v2">here</a></p>
<table>
<thead>
<tr>
<th>Metric</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody><tr>
<td>Avg.</td>
<td align="right">71.00</td>
</tr>
<tr>
<td>AI2 Reasoning Challenge (25-Shot)</td>
<td align="right">67.92</td>
</tr>
<tr>
<td>HellaSwag (10-Shot)</td>
<td align="right">85.61</td>
</tr>
<tr>
<td>MMLU (5-Shot)</td>
<td align="right">75.22</td>
</tr>
<tr>
<td>TruthfulQA (0-shot)</td>
<td align="right">56.74</td>
</tr>
<tr>
<td>Winogrande (5-shot)</td>
<td align="right">81.61</td>
</tr>
<tr>
<td>GSM8k (5-shot)</td>
<td align="right">58.91</td>
</tr>
</tbody></table>
<h1><a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard">Open LLM Leaderboard Evaluation Results</a></h1>
<p>Detailed results can be found <a href="https://huggingface.co/datasets/open-llm-leaderboard/details_adamo1139__Yi-34B-200K-AEZAKMI-v2">here</a></p>
<table>
<thead>
<tr>
<th>Metric</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody><tr>
<td>Avg.</td>
<td align="right">23.69</td>
</tr>
<tr>
<td>IFEval (0-Shot)</td>
<td align="right">45.55</td>
</tr>
<tr>
<td>BBH (3-Shot)</td>
<td align="right">35.28</td>
</tr>
<tr>
<td>MATH Lvl 5 (4-Shot)</td>
<td align="right">4.83</td>
</tr>
<tr>
<td>GPQA (0-shot)</td>
<td align="right">10.96</td>
</tr>
<tr>
<td>MuSR (0-shot)</td>
<td align="right">6.48</td>
</tr>
<tr>
<td>MMLU-PRO (5-shot)</td>
<td align="right">39.03</td>
</tr>
</tbody></table>
 </div> </article> <!-- Related Models Section --> <section class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-700"> <h2 class="text-3xl font-bold text-center mb-8">Related Models</h2> <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6"> <a href="/model/h2oai--h2o-danube3-4b-chat" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="h2o-danube3-4b-chat"> h2o-danube3-4b-chat </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="335 likes">‚ù§Ô∏è <span>335</span></div> <div class="flex items-center gap-1" title="3,855 downloads">üì• <span>3.9K</span></div> </div> </div> </a><a href="/model/h2oai--h2o-danube3-500m-chat" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="h2o-danube3-500m-chat"> h2o-danube3-500m-chat </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="190 likes">‚ù§Ô∏è <span>190</span></div> <div class="flex items-center gap-1" title="76,625 downloads">üì• <span>76.6K</span></div> </div> </div> </a><a href="/model/McGill-NLP--Llama-3-8B-Web" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="Llama-3-8B-Web"> Llama-3-8B-Web </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="1,070 likes">‚ù§Ô∏è <span>1.1K</span></div> <div class="flex items-center gap-1" title="230 downloads">üì• <span>230</span></div> </div> </div> </a> </div> </section> </div> </div>  </main> <footer class="bg-gray-800 text-gray-300 py-8 mt-16"> <div class="container mx-auto px-4 text-center"> <div class="flex justify-center gap-4 mb-4"> <a href="/about" class="hover:underline">About</a> <a href="/compliance" class="hover:underline">Compliance</a> </div> <p class="text-sm mt-2">
&copy; 2025 Free AI Tools. An open-source project to index the world of AI.
</p> <a href="mailto:compliance@free2aitools.com" class="text-sm text-gray-400 hover:underline mt-1 block">compliance@free2aitools.com</a> </div> </footer> </body></html>