<!DOCTYPE html><html lang="en"> <head><!-- Google Tag Manager --><script type="module">(function(e,n,r,t,m){e[t]=e[t]||[],e[t].push({"gtm.start":new Date().getTime(),event:"gtm.js"});var g=n.getElementsByTagName(r)[0],a=n.createElement(r),s="";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+m+s,g.parentNode.insertBefore(a,g)})(window,document,"script","dataLayer","GTM-58C2CQ8G");</script><!-- End Google Tag Manager --><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><!-- Open Graph Meta Tags --><meta property="og:type" content="website"><meta property="og:url" content="https://free2aitools.com/model/github-MiroMindAI-MiroThinker/"><meta property="og:title" content="MiroThinker - AI Model Details"><meta property="og:description" content="MiroThinker is open-source agentic models trained for deep research and complex tool use scenarios."><meta property="og:image" content="https://free2aitools.com/og-image.jpg"><!-- Twitter Card Meta Tags --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://free2aitools.com/model/github-MiroMindAI-MiroThinker/"><meta property="twitter:title" content="MiroThinker - AI Model Details"><meta property="twitter:description" content="MiroThinker is open-source agentic models trained for deep research and complex tool use scenarios."><meta property="twitter:image" content="https://free2aitools.com/og-image.jpg"><meta name="description" content="MiroThinker is open-source agentic models trained for deep research and complex tool use scenarios."><title>MiroThinker - AI Model Details</title><link rel="canonical" href="https://free2aitools.com/model/github-MiroMindAI-MiroThinker/"><!-- Google AdSense --><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2292826803755214" crossorigin="anonymous"></script><link rel="stylesheet" href="/_astro/about.C4wyk6Sp.css"></head> <body class="bg-gray-50 text-gray-800 font-sans antialiased flex flex-col min-h-screen"> <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-58C2CQ8G" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) --> <header class="sticky top-0 z-30 w-full backdrop-blur flex-none transition-colors duration-500 lg:border-b lg:border-gray-200 bg-white/80"> <nav class="container mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Site Logo --> <a href="/" class="flex items-center gap-2 text-xl sm:text-2xl font-bold text-gray-900"> <span>Free AI Tools</span> </a> <!-- Right-side items --> <div class="flex items-center gap-4"> <!-- Desktop Navigation --> <div class="hidden md:flex items-center gap-6"> <a href="/" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Explore Models </a><a href="/ranking" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Rankings </a><a href="/reports" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Reports </a><a href="/about" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> About </a> </div> <!-- Mobile Search & Menu Toggle --> <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls="navbar-default" aria-expanded="false"> <span class="sr-only">Open main menu</span> <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"></path></svg> </button> </div> </div> <!-- Mobile Collapsible Menu --> <div class="hidden w-full md:hidden" id="navbar-default"> <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50"> <li> <a href="/" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Explore Models</a> </li><li> <a href="/ranking" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Rankings</a> </li><li> <a href="/reports" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Reports</a> </li><li> <a href="/about" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">About</a> </li> </ul> </div> </nav> </header> <main class="flex-grow">  <div class="container mx-auto px-4 py-12"> <div class="max-w-4xl mx-auto"> <!-- Header Section --> <header class="mb-8"> <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-4"> <div> <h1 class="text-4xl md:text-5xl font-extrabold text-gray-900 dark:text-white mb-2">MiroThinker</h1> <p class="text-lg text-gray-500 dark:text-gray-400">by MiroMindAI</p> </div>  </div> </header> <!-- Metadata Section --> <div class="mb-8 p-4 bg-gray-100 dark:bg-gray-800 rounded-lg"> <div class="grid grid-cols-2 md:grid-cols-4 gap-4 text-center"> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Likes</p> <p class="text-xl font-bold">920</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Downloads</p> <p class="text-xl font-bold">920</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Task</p> <p class="text-xl font-bold capitalize">tool</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Last Updated</p> <p class="text-xl font-bold">2025/11/20</p> </div> </div> </div> <!-- Tags and Sources --> <div class="mb-8 flex flex-wrap items-start gap-4"> <div class="flex-1"> <h3 class="text-lg font-semibold mb-2">Tags</h3> <div class="flex flex-wrap gap-2"> <a href="/?tag=agent" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> agent </a><a href="/?tag=agent-framework" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> agent-framework </a><a href="/?tag=browsecomp" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> browsecomp </a><a href="/?tag=deep-research" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> deep-research </a><a href="/?tag=futurex" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> futurex </a><a href="/?tag=gaia" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> gaia </a><a href="/?tag=hle" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> hle </a><a href="/?tag=research-agent" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> research-agent </a><a href="/?tag=xbench" class="px-3 py-1 text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200 rounded-full hover:bg-blue-200 dark:hover:bg-blue-800"> xbench </a> </div> </div> <div class="flex-shrink-0"> <h3 class="text-lg font-semibold mb-2">Sources</h3> <div class="flex flex-col gap-2"> <a href="https://github.com/MiroMindAI/MiroThinker" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ“¦ GitHub </a> </div> </div> </div> <!-- Source Specific Details --> <div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ“¦ GitHub Details
</h3> <div class="grid grid-cols-2 md:grid-cols-3 gap-4 text-sm"> <div><strong>Language:</strong> Python</div> <div><strong>Stars:</strong> 920</div> <div><strong>Forks:</strong> 59</div> <div><strong>Open Issues:</strong> 7</div> <div><strong>License:</strong> MIT License</div> <div><a href="https://miromind.ai/" target="_blank" class="text-blue-600 dark:text-blue-400 hover:underline"><strong>Project Homepage â†—</strong></a></div> </div>  </div> <!-- README Content --> <article class="model-readme-content py-8 border-t border-gray-200 dark:border-gray-700"> <div class="prose prose-lg dark:prose-invert max-w-none"> <div align="center">
  <img src="assets/miro_thinker.png" width="55%" alt="MiroThinker" />
</div>

<br>

<div align="center">

<p><a href="https://dr.miromind.ai/"><img src="https://img.shields.io/badge/Demo-FFB300?style=for-the-badge&logo=airplayvideo&logoColor=white" alt="DEMO"></a>
<a href="https://huggingface.co/collections/miromind-ai/mirothinker-v10"><img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&logo=huggingface&logoColor=ffffff&labelColor" alt="MODELS"></a>
<a href="https://arxiv.org/abs/2511.11793"><img src="https://img.shields.io/badge/Paper-B31B1B?style=for-the-badge&logo=arxiv&logoColor=white" alt="Paper"></a>
<a href="https://miromind.ai/#blog"><img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&logo=google-chrome&logoColor=white" alt="Blog"></a>
<a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"><img src="https://img.shields.io/badge/Data-0040A1?style=for-the-badge&logo=huggingface&logoColor=ffffff&labelColor" alt="DATA"></a></p>
<p><a href="https://github.com/MiroMindAI"><img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&logo=github&logoColor=white" alt="GITHUB"></a>
<a href="https://miromind.ai/"><img src="https://img.shields.io/badge/Website-4285F4?style=for-the-badge&logo=google-chrome&logoColor=white" alt="WEBSITE"></a>
<a href="https://discord.com/invite/GPqEnkzQZd"><img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white" alt="DISCORD"></a>
<a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/refs/heads/main/assets/miromind_wechat.png"><img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white" alt="WeChat"></a>
<a href="https://www.xiaohongshu.com/user/profile/5e353bd80000000001000239"><img src="https://img.shields.io/badge/RedNote-FF2442?style=for-the-badge&logo=revoltdotchat&logoColor=white" alt="RedNote"></a></p>
</div>

<div align="center">

<h3>ğŸš€ <a href="https://dr.miromind.ai/">Try our Demo!</a></h3>
</div>

<blockquote>
<p><strong>MiroThinker</strong> is the official implementation of the MiroMind Research Agent Project. It is an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities, enabling complex real-world research workflows across diverse challenges.</p>
</blockquote>
<p>The project currently comprises four key components:</p>
<ul>
<li>ğŸ’¡ <strong>MiroThinker</strong>: An open-source research agent model that natively supports tool-assisted reasoning, achieving state-of-the-art performance across multiple benchmarks (e.g., HLE, HLE-Text-2158, HLE-Text-500, BrowserComp, BrowserComp-ZH, GAIA, xBench-DeepSearch, FutureX, and Frames). See <a href="#-quick-start">Quick Start</a>.</li>
<li>ğŸ¤– <strong>MiroFlow</strong>: An open-source research agent framework that offers reproducible state-of-the-art performance across multiple benchmarks. See <a href="https://github.com/MiroMindAI/MiroFlow">MiroFlow</a> for details.</li>
<li>ğŸ“š <strong>MiroVerse</strong>: A premium open-source training dataset with 147k samples supporting research agent training. See <a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1">MiroVerse</a> on HuggingFace.</li>
<li>ğŸ”§ <strong>MiroTrain / MiroRL</strong>: Training infrastructure that supports stable and efficient training for research agent models. See <a href="https://github.com/MiroMindAI/MiroTrain">MiroTrain</a> and <a href="https://github.com/MiroMindAI/MiroRL">MiroRL</a> for details.</li>
</ul>
<h2>ğŸ“‹ Table of Contents</h2>
<ul>
<li>ğŸ“° <a href="#-news--updates">News &amp; Updates</a></li>
<li>ğŸ“ <a href="#-introduction">Introduction</a></li>
<li>âœ¨ <a href="#-key-features">Key Features</a></li>
<li>ğŸ“ˆ <a href="#-performance-on-benchmarks">Performance on Benchmarks</a></li>
<li>ğŸš€ <a href="#-quick-start">Quick Start</a></li>
<li>ğŸ“Š <a href="#-trace-collection">Trace Collection</a></li>
<li>â“ <a href="#-faq--troubleshooting">FAQ &amp; Troubleshooting</a></li>
<li>ğŸ“„ <a href="#-license">License</a></li>
<li>ğŸ™ <a href="#-acknowledgments">Acknowledgments</a></li>
</ul>
<h2>ğŸ“° News &amp; Updates</h2>
<ul>
<li><strong>[2025-11-13]</strong> ğŸ‰ğŸ‰ <a href="https://huggingface.co/collections/miromind-ai/mirothinker-v10">MiroThinker-v1.0</a> is now released! Introducing <strong>interactive scaling</strong> as a third dimension of performance improvement, MiroThinker v1.0 supports 256K context window and up to 600 tool calls per task. Available in 8B, 30B, and 72B parameter scales, achieving 37.7%, 47.1%, 55.6%, and 81.9% on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. See <a href="https://arxiv.org/abs/2511.11793">Technical Report</a> for more details.</li>
<li><strong>[2025-09-11]</strong> ğŸ‰ MiroThinker-72B-Preview ranked 4th in this week&#39;s FutureX benchmark. See <a href="https://futurex-ai.github.io/">FutureX</a>.</li>
<li><strong>[2025-09-08]</strong> <a href="https://huggingface.co/collections/miromind-ai/mirothinker-v02">MiroThinker-v0.2</a> is now released, achieving open-source SOTA performance across multiple benchmarks, including HLE (17.8%), HLE-Text-Only (19.1%), BrowserComp-EN (17.2%), BrowserComp-ZH (29.4%), xBench-DeepSearch (56.0%), and Frames (74.8%).</li>
<li><strong>[2025-09-07]</strong> We supported more benchmarks, including <a href="https://arxiv.org/abs/2504.19314">BrowseComp-ZH</a>, <a href="https://xbench.org/agi/aisearch">XBench-DeepSearch</a>, and <a href="https://futurex-ai.github.io/">FutureX</a>. We plan to add more benchmarks in the future.</li>
<li><strong>[2025-08-22]</strong> Introducing streamlined deployment options for MiroThinker models with optimized resource usage and faster startup times. Experience the interactive demo: <a href="apps/gradio-demo">ğŸš€ Try Gradio Demo</a></li>
<li><strong>[2025-08-08]</strong> <a href="https://huggingface.co/collections/miromind-ai/mirothinker-v01-689301b6d0563321862d44a1">MiroThinker-v0.1</a> released. Models, framework, and data are now fully open-sourced!</li>
</ul>
<h2>ğŸ“ Introduction</h2>
<h3>MiroThinker-v1.0</h3>
<p>Unlike previous agents that scale only model size or context length, MiroThinker v1.0 introduces <strong>interactive scaling</strong> at the model level, systematically training the model to handle deeper and more frequent agentâ€“environment interactions as a third dimension of performance improvement. Interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories.</p>
<p><img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Overall.png" alt="image"></p>
<h3>âœ¨ Key Features</h3>
<ul>
<li>ğŸš€ <strong>256K Context Window</strong>: Supports long-horizon reasoning and deep multi-step analysis</li>
<li>ğŸ”§ <strong>600 Tool Calls</strong>: Handles up to 600 tool calls per task â€” a substantial improvement over previous open-source research agents</li>
<li>ğŸ“¦ <strong>Multiple Scales</strong>: Released in 8B, 30B, and 72B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets</li>
</ul>
<div align="center">

<table>
<thead>
<tr>
<th align="center">Model Name</th>
<th align="center">Base Model</th>
<th align="center">Max Length</th>
<th align="center">Max Tool Calls</th>
<th align="center">HF Link</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MiroThinker-v1.0-8B</td>
<td align="center">Qwen3-8B</td>
<td align="center">256K</td>
<td align="center">600</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-8B">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-v1.0-30B</td>
<td align="center">Qwen3-30B-A3B-Thinking-2507</td>
<td align="center">256K</td>
<td align="center">600</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-30B">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-v1.0-72B</td>
<td align="center">Qwen2.5-72B-Instruct</td>
<td align="center">256K</td>
<td align="center">600</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-72B">ğŸ¤— link</a></td>
</tr>
</tbody></table>
</div>

<p>MiroThinker v1.0 demonstrates strong general-research performance across a broad range of benchmarks, achieving <strong>37.7%</strong>, <strong>47.1%</strong>, <strong>55.6%</strong>, and <strong>81.9%</strong> on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. These results surpass previous open-source agents and narrow the gap with commercial counterparts such as <strong>GPT-5-high</strong>.</p>
<div align="center">
  <img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Performance_1.png" width="100%" alt="MiroThinker" />
</div>

<h3>MiroThinker-v0.2</h3>
<details>
  <summary>ğŸ“¦ Click to expand MiroThinker-v0.2 details</summary>

<p>In this new version, we introduced three key improvements:</p>
<ul>
<li>ğŸ“š <strong>Richer training data</strong> from both English and Chinese sources, yielding significant gains in benchmark performance and generalization</li>
<li>ğŸ¯ <strong>Unified DPO training</strong> with a single preference dataset across all models</li>
<li>ğŸ“ <strong>Extended context length</strong> from 40k to 64k for more challenging multi-turn tool-use tasks</li>
</ul>
<p>Compared to v0.1, MiroThinker v0.2 delivers consistent gains across benchmarks. For example, scores improved from <strong>57.3 â†’ 64.1</strong> on <strong>GAIA-Text-103</strong> and from <strong>17.0 â†’ 29.4</strong> on <strong>BrowseComp-ZH</strong>, reflecting substantial advancements in the modelâ€™s general research agent capabilities.</p>
<div align="center">

<table>
<thead>
<tr>
<th align="center">Model Name</th>
<th align="center">Base Model</th>
<th align="center">Max Length</th>
<th align="center">HF Link</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MiroThinker-4B-SFT-v0.2</td>
<td align="center">Qwen3-4B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-4B-SFT-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-4B-DPO-v0.2</td>
<td align="center">Qwen3-4B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-4B-DPO-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-8B-SFT-v0.2</td>
<td align="center">Qwen3-8B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-8B-DPO-v0.2</td>
<td align="center">Qwen3-8B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-14B-SFT-v0.2</td>
<td align="center">Qwen3-14B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-14B-DPO-v0.2</td>
<td align="center">Qwen3-14B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-32B-SFT-v0.2</td>
<td align="center">Qwen3-32B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.2">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-32B-DPO-v0.2</td>
<td align="center">Qwen3-32B</td>
<td align="center">64K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.2">ğŸ¤— link</a></td>
</tr>
</tbody></table>
</div>

</details>

<h3>MiroThinker-v0.1</h3>
<details>
  <summary>ğŸ“¦ Click to expand MiroThinker-v0.1 details</summary>

<div align="center">
  <img src="assets/gaia_text_103.png" width="98%" alt="MiroFlow Performance on GAIA-Validation" />
  <p><strong>Performance of Open-Source Models on GAIA-Validation Benchmark.</strong></p>
</div>

<p>We have released the <strong>MiroThinker v0.1</strong> series, including both SFT and DPO variants at parameter scales of <strong>8B</strong>, <strong>14B</strong>, and <strong>32B</strong>. Notably, MiroThinker v0.1 achieves <strong>state-of-the-art performance</strong> among open-source models on the <a href="https://huggingface.co/datasets/gaia-benchmark/GAIA">GAIA benchmark</a>, a rigorous evaluation suite for advanced agentic capabilities, demonstrating its strength in long-context, decision-intensive, and real-world task scenarios.</p>
<div align="center">

<table>
<thead>
<tr>
<th align="center">Model Name</th>
<th align="center">Base Model</th>
<th align="center">Max Length</th>
<th align="center">HF Link</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MiroThinker-8B-SFT-v0.1</td>
<td align="center">Qwen3-8B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.1">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-8B-DPO-v0.1</td>
<td align="center">Qwen3-8B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.1">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-14B-SFT-v0.1</td>
<td align="center">Qwen3-14B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.1">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-14B-DPO-v0.1</td>
<td align="center">Qwen3-14B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.1">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-32B-SFT-v0.1</td>
<td align="center">Qwen3-32B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.1">ğŸ¤— link</a></td>
</tr>
<tr>
<td align="center">MiroThinker-32B-DPO-v0.1</td>
<td align="center">Qwen3-32B</td>
<td align="center">40K</td>
<td align="center"><a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.1">ğŸ¤— link</a></td>
</tr>
</tbody></table>
</div>

</details>

<h2>âœ¨ Key Features</h2>
<h3>ğŸ¤– <strong>MiroThinker-Optimized Framework</strong></h3>
<ul>
<li>ğŸ”“ <strong>Fully Open-Source Agent Framework</strong>: Complete transparency with open framework and open models</li>
<li>ğŸ”— <strong>Tool Integration</strong>: Seamless integration with external tools and APIs</li>
<li>ğŸ“ <strong>Trace Collection</strong>: Comprehensive logging and analysis of agent interactions with elapsed time and estimated completion time displayed in minutes. Ready for SFT and DPO</li>
<li>ğŸ“Š <strong>Benchmark Evaluation</strong>: Extensive testing across multiple benchmark datasets</li>
</ul>
<h3>ğŸ“Š <strong>Comprehensive Benchmark Suite</strong></h3>
<details open>
  <summary>ğŸ“‹ Click to expand benchmark list</summary>

<ul>
<li><strong>GAIA Validation</strong>: A benchmark for General AI Assistants. (<a href="https://arxiv.org/abs/2311.12983">paper</a>)</li>
<li><strong>GAIA-Text-103</strong>: A subset of GAIA Validation for text-only tasks. (<a href="https://arxiv.org/abs/2505.22648">paper</a>)</li>
<li><strong>HLE</strong>: Humanity&#39;s Last Exam. (<a href="https://arxiv.org/abs/2501.14249">paper</a>)</li>
<li><strong>HLE-Text-2158</strong>: A subset of HLE for text-only tasks. (<a href="https://arxiv.org/abs/2501.14249">paper</a>)</li>
<li><strong>HLE-Text-500</strong>: A subset of HLE for text-only tasks, created by <a href="https://arxiv.org/pdf/2504.21776">WebThinker</a>. (<a href="https://arxiv.org/pdf/2504.21776">paper</a>)</li>
<li><strong>BrowseComp-EN</strong>: Web browsing and comprehension tasks. (<a href="https://arxiv.org/abs/2504.12516">paper</a>)</li>
<li><strong>BrowseComp-ZH</strong>: A Chinese version of BrowseComp. (<a href="https://arxiv.org/abs/2504.19314">paper</a>)</li>
<li><strong>WebWalkerQA</strong>: Web navigation and question answering. (<a href="https://arxiv.org/abs/2501.07572">paper</a>)</li>
<li><strong>Frames</strong>: Factuality, Retrieval, And reasoning MEasurement Set. (<a href="https://arxiv.org/abs/2409.12941">paper</a>)</li>
<li><strong>XBench-DeepSearch</strong>: A benchmark for deep research agents. (<a href="https://xbench.org/agi/aisearch">website</a>)</li>
<li><strong>FutureX</strong>: A live benchmark designed for predicting unknown future. (<a href="https://futurex-ai.github.io/">website</a>)</li>
<li><strong>SEAL-0</strong>: A benchmark for evaluating LLMs on conflicting-evidence web questions. (<a href="https://arxiv.org/abs/2506.01062">paper</a>)</li>
<li><strong>AIME2025</strong>: American Invitational Mathematics Examination 2025. (<a href="https://artificialanalysis.ai/evaluations/aime-2025">website</a>)</li>
</ul>
</details>

<h2>ğŸ“ˆ Performance on Benchmarks</h2>
<h3>MiroThinker-v1.0</h3>
<div align="center">
  <img src="https://github.com/user-attachments/assets/108a2105-4e1d-499e-a001-4713a03fd8ac" width="100%" alt="MiroThinker" />
</div>

<h3>MiroThinker-v0.2</h3>
<details>
  <summary>ğŸ“¦ Click to expand MiroThinker-v0.2 details</summary>

<h4>Comparison with SOTA Research Agents</h4>
<div align="center">
  <img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_2.png" width="90%" alt="MiroThinker" />
</div>

<h4>GAIA Benchmark</h4>
<div align="center">
  <img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_1.png" width="80%" alt="MiroThinker" />
</div>

</details>

<h3>MiroThinker-v0.1</h3>
<details>
  <summary>ğŸ“¦ Click to expand MiroThinker-v0.1 details</summary>

<h4>GAIA Benchmark</h4>
<div align="center">

<table>
<thead>
<tr>
<th><strong>Method</strong></th>
<th align="center">Text-103<br>Best Pass@1</th>
<th align="center">Text-103<br>Pass@1 (Avg@8)</th>
<th align="center">Val-165<br>Best Pass@1</th>
<th align="center">Val-165<br>Pass@1 (Avg@8)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ğŸ”¹â€”â€” 7B/8B Models â€”â€”</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td>Search-o1-7B</td>
<td align="center">17.5</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>R1-Searcher-7B</td>
<td align="center">20.4</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebDancer-7B</td>
<td align="center">31.0</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebSailor-7B</td>
<td align="center">37.9</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>CK-Pro-8B</td>
<td align="center">40.3</td>
<td align="center">-</td>
<td align="center">32.7</td>
<td align="center">-</td>
</tr>
<tr>
<td><strong>MiroThinker-8B-SFT-v0.1</strong></td>
<td align="center">44.7</td>
<td align="center">40.1</td>
<td align="center">34.6</td>
<td align="center">31.8</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center">46.6</td>
<td align="center">42.1</td>
<td align="center">37.6</td>
<td align="center">33.9</td>
</tr>
<tr>
<td><strong>MiroThinker-8B-DPO-v0.1</strong></td>
<td align="center">46.6</td>
<td align="center">44.8</td>
<td align="center">37.0</td>
<td align="center">35.4</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center"><strong>50.5</strong></td>
<td align="center"><strong>46.7</strong></td>
<td align="center"><strong>38.2</strong></td>
<td align="center"><strong>35.9</strong></td>
</tr>
<tr>
<td><strong>ğŸ”¹â€”â€” 14B Models â€”â€”</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td><strong>MiroThinker-14B-SFT-v0.1</strong></td>
<td align="center">47.6</td>
<td align="center">44.4</td>
<td align="center">37.0</td>
<td align="center">34.4</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center">49.5</td>
<td align="center">47.5</td>
<td align="center">41.8</td>
<td align="center">39.8</td>
</tr>
<tr>
<td><strong>MiroThinker-14B-DPO-v0.1</strong></td>
<td align="center">48.5</td>
<td align="center">46.6</td>
<td align="center">42.4</td>
<td align="center">39.2</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center"><strong>52.4</strong></td>
<td align="center"><strong>48.5</strong></td>
<td align="center"><strong>45.5</strong></td>
<td align="center"><strong>42.0</strong></td>
</tr>
<tr>
<td><strong>ğŸ”¹â€”â€” 32B Models â€”â€”</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td>Qwen3-32B</td>
<td align="center">31.1</td>
<td align="center">26.7</td>
<td align="center">29.7</td>
<td align="center">26.4</td>
</tr>
<tr>
<td>Search-o1-32B</td>
<td align="center">28.2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebThinker-32B-RL</td>
<td align="center">48.5</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebDancer-QwQ-32B</td>
<td align="center">51.5</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebSailor-32B</td>
<td align="center">53.2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebShaper-QwQ-32B</td>
<td align="center">53.3</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td><strong>MiroThinker-32B-SFT-v0.1</strong></td>
<td align="center">55.3</td>
<td align="center">51.3</td>
<td align="center">44.9</td>
<td align="center">42.7</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center">58.3</td>
<td align="center">54.2</td>
<td align="center">48.5</td>
<td align="center">45.8</td>
</tr>
<tr>
<td><strong>MiroThinker-32B-DPO-v0.1</strong></td>
<td align="center">57.3</td>
<td align="center">54.1</td>
<td align="center">48.5</td>
<td align="center">45.9</td>
</tr>
<tr>
<td>+ Commercial Tools</td>
<td align="center"><strong>60.2</strong></td>
<td align="center"><strong>57.9</strong></td>
<td align="center"><strong>50.9</strong></td>
<td align="center"><strong>48.9</strong></td>
</tr>
</tbody></table>
</div>

<ol>
<li><p>Following the practices of WebThinker, WebAgents, and CognitiveKernel, we report the Best Pass@1, the highest score across three runs, which often reflects stronger performance, though it may exhibit some variability. To provide a more stable measure, we additionally report Pass@1 (Avg@8), which offers greater consistency at the cost of slightly lower scores.</p>
</li>
<li><p>For consistency with prior open-source works, we evaluate GAIA-Text-103 using the WebAgents LLM-as-judge template, and report results on GAIA-Val-165 using the official GAIA scorer script.</p>
</li>
<li><p>By default, we use open-source tools wherever possible, except for the code tool <a href="https://github.com/e2b-dev/E2B">E2B</a> and the Google search tool <a href="https://serper.dev/">Serper</a>. We use <a href="https://huggingface.co/openai/whisper-large-v3-turbo">Whisper</a>, <a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct">Qwen2.5-VL-72B-Instruct</a>, and <a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507">Qwen3-235B-A22B-Thinking-2507</a> in our implementation. The framework can be easily extended to other open-source tools of your choice.</p>
</li>
<li><p>Replacing these open-source tools with commercial alternatives can yield performance gains. Commercial tools were mainly used for multimodal capabilities and certain complex reasoning subtasks. The majority of tasks, including planning, browsing, refinement, navigation, and more, were handled by our models.</p>
</li>
</ol>
<h4>More Benchmarks</h4>
<div align="center">

<table>
<thead>
<tr>
<th>Method</th>
<th align="center">HLE<br>Pass@1</th>
<th align="center">Frames<br>Pass@1</th>
<th align="center">BrowseComp<br>Pass@1</th>
<th align="center">BrowseComp-ZH<br>Pass@1</th>
<th align="center">WebWalkerQA<br>Pass@1</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI Deep Research</td>
<td align="center">26.6</td>
<td align="center">-</td>
<td align="center">51.5</td>
<td align="center">42.9</td>
<td align="center">-</td>
</tr>
<tr>
<td>Gemini Deep Research</td>
<td align="center">26.9</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td>Kimi-Researcher</td>
<td align="center">26.9</td>
<td align="center">78.8</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td>WebDancer-7B</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">36.0</td>
</tr>
<tr>
<td>WebSailor-7B</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">6.7</td>
<td align="center">14.2</td>
<td align="center">-</td>
</tr>
<tr>
<td><strong>MiroThinker-8B-SFT-v0.1</strong></td>
<td align="center">-</td>
<td align="center">58.0</td>
<td align="center">5.5</td>
<td align="center">9.3</td>
<td align="center">41.3</td>
</tr>
<tr>
<td><strong>MiroThinker-8B-DPO-v0.1</strong></td>
<td align="center">-</td>
<td align="center">64.4</td>
<td align="center">8.7</td>
<td align="center">13.6</td>
<td align="center">45.7</td>
</tr>
<tr>
<td></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td>WebThinker-32B-RL</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">46.5</td>
</tr>
<tr>
<td>WebDancer-QwQ-32B</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">3.8</td>
<td align="center">18.0</td>
<td align="center">47.9</td>
</tr>
<tr>
<td>WebSailor-32B</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">10.5</td>
<td align="center">25.5</td>
<td align="center">-</td>
</tr>
<tr>
<td>WebShaper-32B</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">51.4</td>
</tr>
<tr>
<td><strong>MiroThinker-32B-SFT-v0.1</strong></td>
<td align="center">10.2</td>
<td align="center">70.4</td>
<td align="center">10.6</td>
<td align="center">13.8</td>
<td align="center">45.7</td>
</tr>
<tr>
<td><strong>MiroThinker-32B-DPO-v0.1</strong></td>
<td align="center">11.8</td>
<td align="center">71.7</td>
<td align="center">13.0</td>
<td align="center">17.0</td>
<td align="center">49.3</td>
</tr>
</tbody></table>
</div>

<ol>
<li><p>MiroThinkerâ€™s performance was tested with this repository and open-source tools; other modelsâ€™ results are from their papers and official sites.</p>
</li>
<li><p>As <a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1">MiroVerse-v0.1</a> mainly contains English data, the modelâ€™s Chinese capability is limited. We plan to add more Chinese data to improve performance in the next version.</p>
</li>
</ol>
</details>

<h2>ğŸš€ Quick Start</h2>
<h3>âš¡ 5-Minute Quick Start (TL;DR)</h3>
<p>For the fastest setup with minimal configuration:</p>
<pre><code class="language-bash"># 1. Clone and setup
git clone https://github.com/MiroMindAI/MiroThinker
cd MiroThinker/apps/miroflow-agent
uv sync

# 2. Configure minimal environment (MiroThinker v1.0)
cp .env.example .env
# Edit .env with these required keys:
# - SERPER_API_KEY (for Google search)
# - JINA_API_KEY (for web scraping)
# - E2B_API_KEY (for code execution)
# - SUMMARY_LLM_BASE_URL, SUMMARY_LLM_MODEL_NAME, SUMMARY_LLM_API_KEY (for LLM summarization)
# - OPENAI_API_KEY (required for benchmark evaluation, used for LLM-as-a-Judge)

# 3. Serve your model (or use existing API)
# See &quot;Serve the MiroThinker Model&quot; section below

# 4. Run evaluation
uv run main.py llm=qwen-3 agent=single_agent_keep5 llm.base_url=https://your_base_url/v1
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Minimal Configuration</strong>: MiroThinker v1.0 uses only 3 MCP servers: <code>search_and_scrape_webpage</code>, <code>jina_scrape_llm_summary</code>, and <code>tool-python</code>. This is the simplest setup. See <a href="#tool-configuration">Tool Configuration</a> for details.</p>
</blockquote>
<h3>Prerequisites</h3>
<ul>
<li>ğŸ <strong>Python 3.10+</strong></li>
<li>ğŸ“¦ <strong>uv package manager</strong> (<a href="https://github.com/astral-sh/uv">Installation guide</a>)</li>
<li>ğŸ”‘ <strong>Required API keys</strong> (see configuration section below)</li>
</ul>
<h3>Installation</h3>
<h4>1. <strong>Clone the Repository</strong></h4>
<pre><code class="language-bash">git clone https://github.com/MiroMindAI/MiroThinker
cd MiroThinker
</code></pre>
<h4>2. <strong>Download Benchmark Data</strong></h4>
<pre><code class="language-bash">wget https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/data_20251115_password_protected.zip
unzip data_20251115_password_protected.zip
# The unzip passcode is: pf4*
rm data_20251115_password_protected.zip
</code></pre>
<blockquote>
<p><strong>ğŸ” Password</strong>: The unzip passcode is <code>pf4*</code>.</p>
</blockquote>
<h4>3. <strong>Setup Environment</strong></h4>
<pre><code class="language-bash"># Shift working dir
cd apps/miroflow-agent
# Install environment
uv sync
# Create .env file with your API keys
cp .env.example .env
# Edit .env with your actual API keys based on your chosen configuration
</code></pre>
<blockquote>
<p><strong>ğŸ“ Environment Variables</strong>: The <code>.env.example</code> file contains all available environment variables. Configure the variables according to the tools used in your chosen agent configuration (see <a href="#tool-configuration">Tool Configuration</a> section).</p>
</blockquote>
<h3>Tool Configuration</h3>
<h4>Minimal Configuration (Recommended for MiroThinker v1.0)</h4>
<table>
<thead>
<tr>
<th align="left">Server</th>
<th align="left">Description</th>
<th align="left">Tools Provided</th>
<th align="left">Required Environment Variables</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>tool-python</code></strong></td>
<td align="left">Execution environment and file management (E2B sandbox)</td>
<td align="left"><code>create_sandbox</code>, <code>run_command</code>, <code>run_python_code</code>, <code>upload_file_from_local_to_sandbox</code>, <code>download_file_from_sandbox_to_local</code>, <code>download_file_from_internet_to_sandbox</code></td>
<td align="left"><code>E2B_API_KEY</code></td>
</tr>
<tr>
<td align="left"><strong><code>search_and_scrape_webpage</code></strong></td>
<td align="left">Google search via Serper API</td>
<td align="left"><code>google_search</code></td>
<td align="left"><code>SERPER_API_KEY</code>, <code>SERPER_BASE_URL</code></td>
</tr>
<tr>
<td align="left"><strong><code>jina_scrape_llm_summary</code></strong></td>
<td align="left">Web scraping with LLM-based information extraction</td>
<td align="left"><code>scrape_and_extract_info</code></td>
<td align="left"><code>JINA_API_KEY</code>, <code>JINA_BASE_URL</code>, <code>SUMMARY_LLM_BASE_URL</code>, <code>SUMMARY_LLM_MODEL_NAME</code>, <code>SUMMARY_LLM_API_KEY</code></td>
</tr>
</tbody></table>
<p><strong>Minimal <code>.env</code> configuration example:</strong></p>
<pre><code class="language-bash"># Required for MiroThinker v1.0 (minimal setup)
SERPER_API_KEY=your_serper_key
SERPER_BASE_URL=&quot;https://google.serper.dev&quot;
JINA_API_KEY=your_jina_key
JINA_BASE_URL=&quot;https://r.jina.ai&quot;
E2B_API_KEY=your_e2b_key

# Required for jina_scrape_llm_summary
SUMMARY_LLM_BASE_URL=your_llm_base_url
SUMMARY_LLM_MODEL_NAME=your_llm_model_name
SUMMARY_LLM_API_KEY=your_llm_api_key  # Optional, depends on LLM provider

# Required for benchmark evaluation (LLM-as-a-Judge)
OPENAI_API_KEY=your_openai_key  # Required for running benchmark evaluations
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Why this is minimal</strong>: These 3 MCP servers cover the core capabilities needed for research tasks: web search, content extraction, and code execution. Each server provides multiple tools. All other servers are optional enhancements.</p>
<p><strong>ğŸ“Š For Benchmark Evaluation</strong>: If you plan to run benchmark evaluations, you also need <code>OPENAI_API_KEY</code> for LLM-as-a-Judge functionality used in evaluation scripts.</p>
<p><strong>ğŸ“– For more details</strong>: See <a href="libs/miroflow-tools/README.md">MiroFlow Tools README</a> for complete documentation of all available tools.</p>
</blockquote>
<details>
  <summary>ğŸ”§ Click to expand additional available tools</summary>

<p>The following optional tools are available but were not used in MiroThinker v1.0 evaluation:</p>
<table>
<thead>
<tr>
<th align="left">Server Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>tool-vqa</code></td>
<td align="left">Commercial</td>
<td align="left">Vision processing using Claude</td>
</tr>
<tr>
<td align="left"><code>tool-vqa-os</code></td>
<td align="left">Open-Source</td>
<td align="left">Vision processing (open-source alternative)</td>
</tr>
<tr>
<td align="left"><code>tool-transcribe</code></td>
<td align="left">Commercial</td>
<td align="left">Audio transcription using OpenAI</td>
</tr>
<tr>
<td align="left"><code>tool-transcribe-os</code></td>
<td align="left">Open-Source</td>
<td align="left">Audio transcription using Whisper</td>
</tr>
<tr>
<td align="left"><code>tool-reasoning</code></td>
<td align="left">Commercial</td>
<td align="left">Reasoning engine using Claude</td>
</tr>
<tr>
<td align="left"><code>tool-reasoning-os</code></td>
<td align="left">Open-Source</td>
<td align="left">Reasoning engine (open-source alternative)</td>
</tr>
<tr>
<td align="left"><code>tool-reading</code></td>
<td align="left">Open-Source</td>
<td align="left">Document reading using MarkItDown</td>
</tr>
<tr>
<td align="left"><code>tool-google-search</code></td>
<td align="left">Commercial</td>
<td align="left">Web search using Google + scraping</td>
</tr>
<tr>
<td align="left"><code>tool-sougou-search</code></td>
<td align="left">Commercial</td>
<td align="left">Web search using Sougou (Chinese)</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>ğŸ“– Local Deployment</strong>: For instructions on deploying open-source tools (<code>tool-vqa-os</code>, <code>tool-transcribe-os</code>, <code>tool-reasoning-os</code>) locally, see <a href="assets/LOCAL-TOOL-DEPLOYMENT.md">Local Tool Deployment Guide</a>.</p>
</blockquote>
<p>See the <a href="libs/miroflow-tools/README.md">MiroFlow Tools README</a> for complete documentation of all available tools.</p>
</details>

<h4>Pre-configured Agent Settings</h4>
<details>
  <summary>âš™ï¸ Click to expand pre-configured agent settings table</summary>

<p>The <code>apps/miroflow-agent/conf/agent/</code> directory contains several pre-configured agent settings. Each configuration uses different tools and requires corresponding environment variables in your <code>.env</code> file.</p>
<blockquote>
<p><strong>ğŸ’¡ Recommended</strong>: For MiroThinker v1.0, use <code>single_agent</code> or <code>single_agent_keep5</code> (minimal configuration with only 3 MCP servers).</p>
</blockquote>
<table>
<thead>
<tr>
<th align="left">Configuration File</th>
<th align="left">Description</th>
<th align="left">Max Turns</th>
<th align="left">Context Retention</th>
<th align="left">Required Environment Variables</th>
<th align="left">Recommended For</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>single_agent.yaml</code></strong> â­</td>
<td align="left">Single-agent configuration used in MiroThinker v1.0 (minimal setup)</td>
<td align="left">600</td>
<td align="left">Keep all results</td>
<td align="left"><code>SERPER_API_KEY</code>, <code>SERPER_BASE_URL</code>, <code>JINA_API_KEY</code>, <code>JINA_BASE_URL</code>, <code>E2B_API_KEY</code>, <code>SUMMARY_LLM_BASE_URL</code>, <code>SUMMARY_LLM_MODEL_NAME</code>, <code>SUMMARY_LLM_API_KEY</code></td>
<td align="left"><strong>v1.0 (default)</strong></td>
</tr>
<tr>
<td align="left"><strong><code>single_agent_keep5.yaml</code></strong> â­</td>
<td align="left">Single-agent with recency-based context retention (minimal setup)</td>
<td align="left">600</td>
<td align="left">Keep 5 most recent</td>
<td align="left">Same as <code>single_agent.yaml</code></td>
<td align="left"><strong>v1.0 (recommended)</strong></td>
</tr>
<tr>
<td align="left"><strong><code>multi_agent.yaml</code></strong></td>
<td align="left">Multi-agent with commercial tools (v0.1/v0.2)</td>
<td align="left">50</td>
<td align="left">Keep all results</td>
<td align="left"><code>E2B_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, <code>ANTHROPIC_BASE_URL</code>, <code>OPENAI_API_KEY</code>, <code>OPENAI_BASE_URL</code>, <code>SERPER_API_KEY</code>, <code>SERPER_BASE_URL</code>, <code>JINA_API_KEY</code>, <code>JINA_BASE_URL</code></td>
<td align="left">v0.1/v0.2</td>
</tr>
<tr>
<td align="left"><strong><code>multi_agent_os.yaml</code></strong></td>
<td align="left">Multi-agent with open-source tools (v0.1/v0.2)</td>
<td align="left">50</td>
<td align="left">Keep all results</td>
<td align="left"><code>E2B_API_KEY</code>, <code>VISION_API_KEY</code>, <code>VISION_BASE_URL</code>, <code>VISION_MODEL_NAME</code>, <code>WHISPER_API_KEY</code>, <code>WHISPER_BASE_URL</code>, <code>WHISPER_MODEL_NAME</code>, <code>REASONING_API_KEY</code>, <code>REASONING_BASE_URL</code>, <code>REASONING_MODEL_NAME</code>, <code>SERPER_API_KEY</code>, <code>SERPER_BASE_URL</code>, <code>JINA_API_KEY</code>, <code>JINA_BASE_URL</code></td>
<td align="left">v0.1/v0.2</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>ğŸ’¡ Note</strong>: All environment variables are listed in <code>apps/miroflow-agent/.env.example</code>. Copy it to <code>.env</code> and fill in the values for the tools you plan to use.</p>
</blockquote>
</details>

<h4>Creating Custom Tool Configurations</h4>
<details>
  <summary>ğŸ”§ Click to expand custom tool configuration guide</summary>

<p>You can create your own YAML configuration file to freely combine MCP servers. Here&#39;s how:</p>
<ol>
<li><strong>Create a new YAML file</strong> in <code>apps/miroflow-agent/conf/agent/</code>:</li>
</ol>
<pre><code class="language-yaml"># conf/agent/my_custom_config.yaml
defaults:
  - default
  - _self_

main_agent:
  tools:
    - tool-python                    # Execution environment
    - search_and_scrape_webpage      # Google search
    - jina_scrape_llm_summary        # Web scraping with LLM
    - tool-vqa                       # Vision processing (optional)
    - tool-transcribe                # Audio processing (optional)
    - tool-reasoning                 # Reasoning engine (optional)
    - tool-reading                   # Document reading (optional)
  max_turns: 400  # Maximum number of turns

sub_agents:
  agent-browsing:  # Optional sub-agent
    tools:
      - tool-google-search
      - tool-vqa
      - tool-reading
      - tool-python
    max_turns: 50

keep_tool_result: -1  # Context retention budget: -1 keeps all tool results, or specify K to keep only the K most recent tool responses
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Context Retention Strategy</strong>: The <code>keep_tool_result</code> parameter implements a <strong>recency-based context retention</strong> strategy. In the standard ReAct paradigm, all tool outputs are retained in the message history, which can lead to inefficient context utilization. Empirically, we observe that the model&#39;s subsequent actions depend primarily on recent observations rather than distant ones. This strategy retains only the most recent K tool responses (where K is the <code>keep_tool_result</code> value) while preserving the complete sequence of thoughts and actions.</p>
<p><strong>Benefits:</strong></p>
<ul>
<li>âœ… Preserves the reasoning and action trace</li>
<li>âœ… Focuses the model&#39;s attention on the most contextually relevant observations</li>
<li>âœ… Frees additional context space for extended reasoning and deeper tool-use trajectories</li>
<li>âœ… Does not lead to performance degradation while allowing more context space for interactive scaling</li>
</ul>
<p><strong>Usage:</strong> Set <code>keep_tool_result: -1</code> to keep all tool results, or specify a positive integer K (e.g., <code>keep_tool_result: 5</code>) to keep only the K most recent tool responses.</p>
</blockquote>
<ol start="2">
<li><strong>Use your custom configuration</strong> when running evaluations:</li>
</ol>
<pre><code class="language-bash">cd apps/miroflow-agent
uv run main.py llm=qwen-3 agent=my_custom_config llm.base_url=https://your_base_url/v1
</code></pre>
<ol start="3">
<li><p><strong>Configure environment variables</strong> in <code>.env</code> based on the tools you use.</p>
<p>All available environment variables are listed in <code>apps/miroflow-agent/.env.example</code>. Copy it to <code>.env</code> and configure the variables according to your chosen configuration:</p>
<pre><code class="language-bash">cd apps/miroflow-agent
cp .env.example .env
# Edit .env with your actual API keys
</code></pre>
<p><strong>For MiroThinker v1.0</strong> (<code>single_agent.yaml</code> or <code>single_agent_keep5.yaml</code>), see the <a href="#minimal-configuration-recommended-for-mirothinker-v10">Minimal Configuration</a> section above for the complete configuration example.</p>
<p><strong>For other configurations</strong>, refer to the <a href="#pre-configured-agent-settings">Pre-configured Agent Settings</a> table above to see which environment variables are required.</p>
</li>
</ol>
</details>

<details>
  <summary>ğŸ”‘ Click to expand optional API keys</summary>

<pre><code class="language-bash"># API for LLM-as-Judge (for benchmark testing, required for benchmark evaluation)
OPENAI_API_KEY=your_openai_key

# API for Open-Source Audio Transcription Tool (for benchmark testing, optional)
WHISPER_MODEL_NAME=&quot;openai/whisper-large-v3-turbo&quot;
WHISPER_API_KEY=your_whisper_key
WHISPER_BASE_URL=&quot;https://your_whisper_base_url/v1&quot;

# API for Open-Source VQA Tool (for benchmark testing, optional)
VISION_MODEL_NAME=&quot;Qwen/Qwen2.5-VL-72B-Instruct&quot;
VISION_API_KEY=your_vision_key
VISION_BASE_URL=&quot;https://your_vision_base_url/v1/chat/completions&quot;

# API for Open-Source Reasoning Tool (for benchmark testing, optional)
REASONING_MODEL_NAME=&quot;Qwen/Qwen3-235B-A22B-Thinking-2507&quot;
REASONING_API_KEY=your_reasoning_key
REASONING_BASE_URL=&quot;https://your_reasoning_base_url/v1/chat/completions&quot;

# API for Claude Sonnet 3.7 as Commercial Tools (optional)
ANTHROPIC_API_KEY=your_anthropic_key

# API for Sougou Search (optional)
TENCENTCLOUD_SECRET_ID=your_tencent_cloud_secret_id
TENCENTCLOUD_SECRET_KEY=your_tencent_cloud_secret_key

# API for Summary LLM (optional)
SUMMARY_LLM_BASE_URL=your_summary_llm_base_url
SUMMARY_LLM_MODEL_NAME=your_summary_llm_model_name
SUMMARY_LLM_API_KEY=your_summary_llm_api_key
</code></pre>
</details>

<h3>Serve the MiroThinker Model</h3>
<h4>Option 1 (Recommended): Serve with SGLang</h4>
<p>Use SGLang to serve MiroThinker models at port 61002:</p>
<pre><code class="language-bash">NUM_GPUS=4
PORT=61002

# Downloading model from HF
MODEL_PATH=miromind-ai/MiroThinker-v1.0-30B

python3 -m sglang.launch_server \
    --model-path $MODEL_PATH \
    --tp $NUM_GPUS \
    --dp 1 \
    --host 0.0.0.0 \
    --port $PORT \
    --trust-remote-code
</code></pre>
<blockquote>
<p><strong>ğŸ“ Server URL</strong>: This will start a server at <code>http://0.0.0.0:$PORT</code>. Use this as your server base URL (e.g., <code>http://0.0.0.0:61002/v1</code>).</p>
</blockquote>
<h4>Option 2: Quantized Light-Weight Options</h4>
<p>We also provide comprehensive guidance for serving MiroThinker models using CPU-optimized and GPU-accelerated quantization techniques, along with detailed analysis and guidelines for deployment with llama.cpp, Ollama, SGLang, and other inference frameworks.</p>
<blockquote>
<p><strong>ğŸ“– Complete Guide</strong>: See <a href="apps/gradio-demo/">Deployment Documentation</a> for detailed deployment instructions.</p>
</blockquote>
<h3>Basic Usage</h3>
<h4>1. <strong>Run a single evaluation</strong></h4>
<pre><code class="language-bash">cd apps/miroflow-agent
uv run main.py llm=qwen-3 agent=single_agent llm.base_url=https://your_base_url/v1
</code></pre>
<blockquote>
<p><strong>ğŸ’¡ Tip</strong>: For MiroThinker v1.0, use <code>agent=single_agent</code> or <code>agent=single_agent_keep5</code>. Replace <code>https://your_base_url/v1</code> with your actual model server URL.</p>
</blockquote>
<h4>2. <strong>Run comprehensive benchmark evaluation</strong></h4>
<blockquote>
<p><strong>Note:</strong> For MiroThinker v1.0, use <code>single_agent</code> or <code>single_agent_keep5</code> configurations. The <code>multi_agent</code> and <code>multi_agent_os</code> configurations are for v0.1/v0.2.</p>
</blockquote>
<p><strong>Available Parameters:</strong></p>
<p>You can customize the evaluation by setting the following environment variables before running the script:</p>
<table>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Default</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>LLM_MODEL</code></td>
<td align="left"><code>&quot;MiroThinker-Models&quot;</code></td>
<td align="left">Model name identifier</td>
</tr>
<tr>
<td align="left"><code>BASE_URL</code></td>
<td align="left"><code>&quot;https://your-api.com/v1&quot;</code></td>
<td align="left">Base URL of your model server</td>
</tr>
<tr>
<td align="left"><code>NUM_RUNS</code></td>
<td align="left"><code>8</code> (varies by benchmark)</td>
<td align="left">Number of evaluation runs</td>
</tr>
<tr>
<td align="left"><code>LLM_PROVIDER</code></td>
<td align="left"><code>&quot;qwen&quot;</code></td>
<td align="left">LLM provider (e.g., <code>qwen</code>, <code>openai</code>, <code>anthropic</code>)</td>
</tr>
<tr>
<td align="left"><code>AGENT_SET</code></td>
<td align="left"><code>&quot;single_agent_keep5&quot;</code></td>
<td align="left">Agent configuration (e.g., <code>single_agent</code>, <code>single_agent_keep5</code>, <code>multi_agent</code>, <code>multi_agent_os</code>)</td>
</tr>
<tr>
<td align="left"><code>MAX_CONTEXT_LENGTH</code></td>
<td align="left"><code>262144</code></td>
<td align="left">Maximum context length (256K)</td>
</tr>
<tr>
<td align="left"><code>MAX_CONCURRENT</code></td>
<td align="left"><code>10</code></td>
<td align="left">Maximum concurrent tasks</td>
</tr>
<tr>
<td align="left"><code>PASS_AT_K</code></td>
<td align="left"><code>1</code></td>
<td align="left">Pass@K evaluation metric</td>
</tr>
<tr>
<td align="left"><code>TEMPERATURE</code></td>
<td align="left"><code>1.0</code></td>
<td align="left">Sampling temperature</td>
</tr>
<tr>
<td align="left"><code>API_KEY</code></td>
<td align="left"><code>&quot;xxx&quot;</code></td>
<td align="left">API key for the model server</td>
</tr>
</tbody></table>
<p><strong>Example Usage:</strong></p>
<pre><code class="language-bash"># Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# Basic usage with required parameters
LLM_MODEL=&quot;MiroThinker-v1.0-32B&quot; BASE_URL=&quot;https://your-api.com/v1&quot; bash scripts/run_evaluate_multiple_runs_gaia-validation.sh

# Customize number of runs and agent configuration
LLM_MODEL=&quot;MiroThinker-v1.0-32B&quot; \
BASE_URL=&quot;https://your-api.com/v1&quot; \
NUM_RUNS=3 \
AGENT_SET=&quot;single_agent&quot; \
bash scripts/run_evaluate_multiple_runs_gaia-validation.sh
</code></pre>
<details open>
  <summary>ğŸ“‹ Click to expand all benchmark commands</summary>

<pre><code class="language-bash"># Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# GAIA-Text-103
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# WebWalkerQA
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_webwalkerqa.sh

# HLE
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_hle.sh

# HLE-Text-2158
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_hle-text-2158.sh

# HLE-Text-500
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_hle-text-500.sh

# FRAMES
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_frames.sh

# BrowseComp-EN
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_browsecomp.sh

# BrowseComp-ZH
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_browsecomp_zh.sh

# XBench-DeepSearch
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_xbench_deepsearch.sh

# FutureX
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_futurex.sh

# SEAL-0
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_seal-0.sh

# AIME2025
LLM_MODEL=&quot;xxx&quot; BASE_URL=&quot;xxx&quot; bash scripts/run_evaluate_multiple_runs_aime2025.sh
</code></pre>
</details>

<h4>3. <strong>Monitor evaluation progress</strong></h4>
<details>
  <summary>ğŸ“Š Click to expand progress monitoring commands</summary>

<pre><code class="language-bash"># Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# For GAIA-Validation
python benchmarks/check_progress/check_progress_gaia-validation.py /path/to/evaluation/logs

# For GAIA-Text-103
python benchmarks/check_progress/check_progress_gaia-validation-text-103.py /path/to/evaluation/logs

# For HLE
python benchmarks/check_progress/check_progress_hle.py /path/to/evaluation/logs

# For HLE-Text-2158
python benchmarks/check_progress/check_progress_hle-text-2158.py /path/to/evaluation/logs

# For HLE-Text-500
python benchmarks/check_progress/check_progress_hle-text-500.py /path/to/evaluation/logs

# For BrowseComp-EN
python benchmarks/check_progress/check_progress_browsecomp.py /path/to/evaluation/logs

# For BrowseComp-ZH
python benchmarks/check_progress/check_progress_browsecomp_zh.py /path/to/evaluation/logs

# For WebWalkerQA
python benchmarks/check_progress/check_progress_webwalkerqa.py /path/to/evaluation/logs

# For Frames
python benchmarks/check_progress/check_progress_frames.py /path/to/evaluation/logs

# For XBench-DeepSearch
python benchmarks/check_progress/check_progress_xbench_deepsearch.py /path/to/evaluation/logs

# For SEAL-0
python benchmarks/check_progress/check_progress_seal-0.py /path/to/evaluation/logs

# For AIME2025
python benchmarks/check_progress/check_progress_aime2025.py /path/to/evaluation/logs
</code></pre>
</details>

<h2>ğŸ“Š Trace Collection</h2>
<details>
<summary>ğŸ“‹ Click to expand trace collection commands</summary>

<pre><code class="language-bash">cd apps/collect-trace

# Collect Traces for SFT
uv run bash scripts/collect_trace_claude37.sh
uv run bash scripts/collect_trace_gpt5.sh

# Collect Traces for DPO
uv run bash scripts/collect_trace_qwen3.sh
</code></pre>
</details>

<h2>â“ FAQ &amp; Troubleshooting</h2>
<h3>Common Issues</h3>
<details>
  <summary>ğŸ”§ Click to expand troubleshooting guide</summary>

<h4><strong>Q: Which version should I use?</strong></h4>
<p><strong>A:</strong> For most users, we recommend <strong>MiroThinker v1.0</strong> with the minimal configuration:</p>
<ul>
<li><strong>v1.0</strong>: Latest version with 256K context, 600 tool calls, best performance. Use <code>single_agent</code> or <code>single_agent_keep5</code> config.</li>
<li><strong>v0.2</strong>: Good performance with 64K context, 50 tool calls. Use <code>multi_agent</code> or <code>multi_agent_os</code> config.</li>
<li><strong>v0.1</strong>: Legacy version with 40K context. Use <code>multi_agent</code> or <code>multi_agent_os</code> config.</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Version</th>
<th align="left">Context</th>
<th align="center">Max Tool Calls</th>
<th align="left">Recommended Config</th>
<th align="left">Use Case</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>v1.0</strong></td>
<td align="left">256K</td>
<td align="center">600</td>
<td align="left"><code>single_agent_keep5</code></td>
<td align="left">Latest, best performance, long-horizon tasks</td>
</tr>
<tr>
<td align="left"><strong>v0.2</strong></td>
<td align="left">64K</td>
<td align="center">50</td>
<td align="left"><code>multi_agent_os</code></td>
<td align="left">Good balance, multi-agent workflows</td>
</tr>
<tr>
<td align="left"><strong>v0.1</strong></td>
<td align="left">40K</td>
<td align="center">50</td>
<td align="left"><code>multi_agent_os</code></td>
<td align="left">Legacy support</td>
</tr>
</tbody></table>
<h4><strong>Q: How do I get API keys?</strong></h4>
<p><strong>A:</strong> You need these keys for minimal setup:</p>
<ul>
<li><strong>SERPER_API_KEY</strong>: Get from <a href="https://serper.dev/">Serper.dev</a> (Google search API)</li>
<li><strong>JINA_API_KEY</strong>: Get from <a href="https://jina.ai/">Jina.ai</a> (Web scraping)</li>
<li><strong>E2B_API_KEY</strong>: Get from <a href="https://e2b.dev/">E2B.dev</a> (Code execution sandbox)</li>
<li><strong>SUMMARY_LLM_</strong>*: Your LLM API credentials (for content summarization)</li>
<li><strong>OPENAI_API_KEY</strong>: Get from <a href="https://platform.openai.com/">OpenAI</a> (Required for benchmark evaluation, used for LLM-as-a-Judge)</li>
</ul>
<h4><strong>Q: Model server connection errors</strong></h4>
<p><strong>A:</strong> Common issues:</p>
<ul>
<li><strong>Check base URL format</strong>: Should end with <code>/v1</code> (e.g., <code>https://your-api.com/v1</code>)</li>
<li><strong>Verify API key</strong>: Ensure <code>API_KEY</code> is set correctly in environment or script</li>
<li><strong>Check server status</strong>: Make sure your model server is running and accessible</li>
<li><strong>Network issues</strong>: Verify firewall/network settings allow connections</li>
</ul>
<h4><strong>Q: Evaluation script fails to run</strong></h4>
<p><strong>A:</strong> Troubleshooting steps:</p>
<ol>
<li><strong>Check working directory</strong>: Make sure you&#39;re in <code>apps/miroflow-agent</code> directory</li>
<li><strong>Verify environment</strong>: Run <code>uv sync</code> to ensure dependencies are installed</li>
<li><strong>Check .env file</strong>: Ensure all required environment variables are set</li>
<li><strong>Review logs</strong>: Check <code>logs/</code> directory for detailed error messages</li>
<li><strong>Verify data path</strong>: Ensure benchmark data is downloaded and in correct location</li>
</ol>
<h4><strong>Q: Out of memory errors</strong></h4>
<p><strong>A:</strong> Solutions:</p>
<ul>
<li><strong>Reduce context length</strong>: Set <code>MAX_CONTEXT_LENGTH</code> to a smaller value (e.g., 131072 for 128K)</li>
<li><strong>Use context retention</strong>: Use <code>single_agent_keep5</code> instead of <code>single_agent</code> to reduce memory usage</li>
<li><strong>Reduce concurrent tasks</strong>: Set <code>MAX_CONCURRENT</code> to a smaller number (e.g., 5)</li>
<li><strong>Use smaller model</strong>: Try 8B or 30B models instead of 72B</li>
</ul>
<h4><strong>Q: Tool execution errors</strong></h4>
<p><strong>A:</strong> Common fixes:</p>
<ul>
<li><strong>E2B errors</strong>: Verify <code>E2B_API_KEY</code> is valid and account has credits</li>
<li><strong>Serper errors</strong>: Check <code>SERPER_API_KEY</code> and rate limits</li>
<li><strong>Jina errors</strong>: Verify <code>JINA_API_KEY</code> and <code>JINA_BASE_URL</code> are correct</li>
<li><strong>LLM summarization errors</strong>: Check <code>SUMMARY_LLM_*</code> variables and model availability</li>
</ul>
<h4><strong>Q: How to monitor long-running evaluations?</strong></h4>
<p><strong>A:</strong> Use the progress monitoring scripts:</p>
<pre><code class="language-bash">cd apps/miroflow-agent
python benchmarks/check_progress/check_progress_&lt;benchmark_name&gt;.py /path/to/logs
</code></pre>
<p>The scripts show completion status, elapsed time, and estimated remaining time.</p>
<h4><strong>Q: Can I use commercial tools instead of open-source ones?</strong></h4>
<p><strong>A:</strong> Yes! You can replace open-source tools with commercial alternatives:</p>
<ul>
<li>Replace <code>tool-vqa-os</code> with <code>tool-vqa</code> (Claude)</li>
<li>Replace <code>tool-transcribe-os</code> with <code>tool-transcribe</code> (OpenAI)</li>
<li>Replace <code>tool-reasoning-os</code> with <code>tool-reasoning</code> (Claude)</li>
</ul>
<p>This typically improves performance but requires additional API keys. See <a href="#pre-configured-agent-settings">Pre-configured Agent Settings</a> for details.</p>
</details>

<h3>Getting Help</h3>
<ul>
<li>ğŸ“– <strong>Documentation</strong>: Check <a href="libs/miroflow-tools/README.md">MiroFlow Tools README</a> for tool details</li>
<li>ğŸ’¬ <strong>Discord</strong>: Join our <a href="https://discord.com/invite/GPqEnkzQZd">Discord community</a></li>
<li>ğŸ› <strong>Issues</strong>: Report bugs on <a href="https://github.com/MiroMindAI/MiroThinker/issues">GitHub Issues</a></li>
<li>ğŸ“§ <strong>Contact</strong>: Visit <a href="https://miromind.ai/">our website</a> for more information</li>
</ul>
<h2>ğŸ“„ License</h2>
<p>This project is licensed under the MIT License - see the <a href="LICENSE">LICENSE</a> file for details.</p>
<h2>ğŸ™ Acknowledgments</h2>
<p>We extend our sincere gratitude to:</p>
<ul>
<li>ğŸ† <strong>Benchmark Contributors</strong> for the comprehensive evaluation datasets</li>
<li>ğŸŒ <strong>Open Source Community</strong> for the tools and libraries that make this possible</li>
<li>ğŸ‘¥ <strong>All Contributors</strong> who have helped make MiroThinker better</li>
</ul>
<div align="center">
  <a href="https://github.com/MiroMindAI/MiroThinker/graphs/contributors">
    <img src="https://contrib.rocks/image?repo=MiroMindAI/MiroThinker" />
  </a>
</div>

<p>Join our community and help us build the future of AI agents!</p>
<h3>References</h3>
<p>If you find this project useful in your research, please consider cite:</p>
<pre><code>@article{miromind2025mirothinker,
  title={MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling},
  author={MiroMind Team and Bai, Song and Bing, Lidong and Chen, Carson and Chen, Guanzheng and Chen, Yuntao and Chen, Zhe and Chen, Ziyi and Dai, Jifeng and Dong, Xuan and others},
  journal={arXiv preprint arXiv:2511.11793},
  year={2025}
}
</code></pre>
<p><a href="https://star-history.com/#MiroMindAI/MiroThinker&Date"><img src="https://api.star-history.com/svg?repos=MiroMindAI/MiroThinker&type=Date" alt="Star History Chart"></a></p>
 </div> </article> <!-- Related Models Section --> <section class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-700"> <h2 class="text-3xl font-bold text-center mb-8">Related Models</h2> <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6"> <a href="/model/github-infiniflow-ragflow" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full"> <div class="absolute top-2 right-2 bg-yellow-400 text-yellow-900 text-xs font-bold px-2 py-1 rounded-full animate-pulse" title="Rising Star">
ğŸ”¥
</div> <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="ragflow"> ragflow </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by infiniflow</p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capa...
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="68,058 likes">â¤ï¸ <span>68.1K</span></div> <div class="flex items-center gap-1" title="68,058 downloads">ğŸ“¥ <span>68.1K</span></div> </div> </div> </a><a href="/model/github-Alibaba-NLP-DeepResearch" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full"> <div class="absolute top-2 right-2 bg-yellow-400 text-yellow-900 text-xs font-bold px-2 py-1 rounded-full animate-pulse" title="Rising Star">
ğŸ”¥
</div> <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="DeepResearch"> DeepResearch </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by Alibaba-NLP</p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> Tongyi Deep Research, the Leading Open-source Deep Research Agent...
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="35,364 likes">â¤ï¸ <span>35.4K</span></div> <div class="flex items-center gap-1" title="35,364 downloads">ğŸ“¥ <span>35.4K</span></div> </div> </div> </a><a href="/model/github-666ghj-BettaFish" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full"> <div class="absolute top-2 right-2 bg-yellow-400 text-yellow-900 text-xs font-bold px-2 py-1 rounded-full animate-pulse" title="Rising Star">
ğŸ”¥
</div> <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="BettaFish"> BettaFish </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by 666ghj</p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚...
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="28,552 likes">â¤ï¸ <span>28.6K</span></div> <div class="flex items-center gap-1" title="28,552 downloads">ğŸ“¥ <span>28.6K</span></div> </div> </div> </a> </div> </section> </div> </div>  </main> <footer class="bg-gray-800 text-gray-300 py-8 mt-16"> <div class="container mx-auto px-4 text-center"> <div class="flex justify-center gap-4 mb-4"> <a href="/about" class="hover:underline">About</a> <a href="/compliance" class="hover:underline">Compliance</a> </div> <p class="text-sm mt-2">
&copy; 2025 Free AI Tools. An open-source project to index the world of AI.
</p> <a href="mailto:compliance@free2aitools.com" class="text-sm text-gray-400 hover:underline mt-1 block">compliance@free2aitools.com</a> </div> </footer> </body></html>