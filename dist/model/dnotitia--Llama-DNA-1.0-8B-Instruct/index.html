<!DOCTYPE html><html lang="en"> <head><!-- Google Tag Manager --><script type="module">(function(e,n,r,t,m){e[t]=e[t]||[],e[t].push({"gtm.start":new Date().getTime(),event:"gtm.js"});var g=n.getElementsByTagName(r)[0],a=n.createElement(r),s="";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+m+s,g.parentNode.insertBefore(a,g)})(window,document,"script","dataLayer","GTM-58C2CQ8G");</script><!-- End Google Tag Manager --><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><!-- Open Graph Meta Tags --><meta property="og:type" content="website"><meta property="og:url" content="https://free2aitools.com/model/dnotitia--Llama-DNA-1.0-8B-Instruct/"><meta property="og:title" content="Llama-DNA-1.0-8B-Instruct - AI Model Details"><meta property="og:description" content="A model for text-generation."><meta property="og:image" content="https://free2aitools.com/og-image.jpg"><!-- Twitter Card Meta Tags --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://free2aitools.com/model/dnotitia--Llama-DNA-1.0-8B-Instruct/"><meta property="twitter:title" content="Llama-DNA-1.0-8B-Instruct - AI Model Details"><meta property="twitter:description" content="A model for text-generation."><meta property="twitter:image" content="https://free2aitools.com/og-image.jpg"><meta name="description" content="A model for text-generation."><title>Llama-DNA-1.0-8B-Instruct - AI Model Details</title><link rel="canonical" href="https://free2aitools.com/model/dnotitia--Llama-DNA-1.0-8B-Instruct/"><!-- Google AdSense --><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2292826803755214" crossorigin="anonymous"></script><link rel="stylesheet" href="/_astro/about.CAZw8hUu.css"></head> <body class="bg-gray-50 text-gray-800 font-sans antialiased flex flex-col min-h-screen"> <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-58C2CQ8G" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) --> <header class="sticky top-0 z-30 w-full backdrop-blur flex-none transition-colors duration-500 lg:border-b lg:border-gray-200 bg-white/80"> <nav class="container mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Site Logo --> <a href="/" class="flex items-center gap-2 text-xl sm:text-2xl font-bold text-gray-900"> <span>Free AI Tools</span> </a> <!-- Right-side items --> <div class="flex items-center gap-4"> <!-- Desktop Navigation --> <div class="hidden md:flex items-center gap-6"> <a href="/" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Explore Models </a><a href="/ranking" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Rankings </a><a href="/reports" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Reports </a><a href="/about" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> About </a> </div> <!-- Mobile Search & Menu Toggle --> <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls="navbar-default" aria-expanded="false"> <span class="sr-only">Open main menu</span> <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"></path></svg> </button> </div> </div> <!-- Mobile Collapsible Menu --> <div class="hidden w-full md:hidden" id="navbar-default"> <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50"> <li> <a href="/" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Explore Models</a> </li><li> <a href="/ranking" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Rankings</a> </li><li> <a href="/reports" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Reports</a> </li><li> <a href="/about" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">About</a> </li> </ul> </div> </nav> </header> <main class="flex-grow">  <div class="container mx-auto px-4 py-12"> <div class="max-w-4xl mx-auto"> <!-- Header Section --> <header class="mb-8"> <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-4"> <div> <h1 class="text-4xl md:text-5xl font-extrabold text-gray-900 dark:text-white mb-2">Llama-DNA-1.0-8B-Instruct</h1> <p class="text-lg text-gray-500 dark:text-gray-400">by </p> </div>  </div> </header> <!-- Metadata Section --> <div class="mb-8 p-4 bg-gray-100 dark:bg-gray-800 rounded-lg"> <div class="grid grid-cols-2 md:grid-cols-4 gap-4 text-center"> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Likes</p> <p class="text-xl font-bold">610</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Downloads</p> <p class="text-xl font-bold">3,530</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Task</p> <p class="text-xl font-bold capitalize">text-generation</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Last Updated</p> <p class="text-xl font-bold">Invalid Date</p> </div> </div> </div> <h3 class="text-lg font-semibold mb-2">Sources</h3> <div class="flex flex-col gap-2"> <a href="https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ¤— Hugging Face </a><a href="https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ¤— Hugging Face </a><a href="https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ¤— Hugging Face </a><a href="https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ¤— Hugging Face </a><a href="https://huggingface.co/dnotitia/Llama-DNA-1.0-8B-Instruct" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ğŸ¤— Hugging Face </a> </div> </div> </div>  <div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ¤— Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ¤— Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ¤— Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ¤— Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ğŸ¤— Hugging Face Details
</h3>   </div> <article class="model-readme-content py-8 border-t border-gray-200 dark:border-gray-700"> <div class="prose prose-lg dark:prose-invert max-w-none"> <h1>DNA 1.0 8B Instruct</h1>
<p align="center">
<img src="assets/dna-logo.png" width="400" style="margin: 40px auto;">
</p>

<p><strong>DNA 1.0 8B Instruct</strong> is a <u>state-of-the-art (<strong>SOTA</strong>)</u> bilingual language model based on Llama architecture, specifically optimized for Korean language understanding and generation, while also maintaining strong English capabilities. The model was developed through a sophisticated process involving model merging via spherical linear interpolation (<strong>SLERP</strong>) with Llama 3.1 8B Instruct, and underwent knowledge distillation (<strong>KD</strong>) using Llama 3.1 405B as the teacher model. It was extensively trained through continual pre-training (<strong>CPT</strong>) with a high-quality Korean dataset. The training pipeline was completed with supervised fine-tuning (<strong>SFT</strong>) and direct preference optimization (<strong>DPO</strong>) to align with human preferences and enhance instruction-following abilities.</p>
<p align="center">
<img src="assets/training-procedure.png" width="600" style="margin: 40px auto;">
</p>

<p>DNA 1.0 8B Instruct was fine-tuned on approximately 7B tokens of carefully curated data and has undergone extensive instruction tuning to enhance its ability to follow complex instructions and engage in natural conversations.</p>
<p>For more details, please refer to our <a href="https://arxiv.org/abs/2501.10648">Technical Report</a>.</p>
<ul>
<li><strong>Developed by:</strong> Dnotitia Inc.</li>
<li><strong>Supported Languages:</strong> Korean, English</li>
<li><strong>Model Release Date:</strong> Dec 10, 2024</li>
<li><strong>Vocab Size:</strong> 128,256</li>
<li><strong>Context Length:</strong> 131,072 tokens (128k)</li>
<li><strong>License:</strong> CC BY-NC 4.0</li>
</ul>
<div style="padding: 2px 8px; background-color: hsl(240, 100%, 50%, 0.1); border-radius: 5px">
  <p><strong>NOTICE (Korean):</strong></p>
  <p>ë³¸ ëª¨ë¸ì€ ìƒì—…ì  ëª©ì ìœ¼ë¡œ í™œìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒì—…ì  ì´ìš©ì„ ì›í•˜ì‹œëŠ” ê²½ìš°, <a href="https://www.dnotitia.com/contact/post-form">Contact us</a>ë¥¼ í†µí•´ ë¬¸ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. ê°„ë‹¨í•œ í˜‘ì˜ ì ˆì°¨ë¥¼ ê±°ì³ ìƒì—…ì  í™œìš©ì„ ìŠ¹ì¸í•´ ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p>
</div>

<h2>Evaluation</h2>
<p>We evaluated DNA 1.0 8B Instruct against other prominent language models of similar size across various benchmarks, including Korean-specific tasks and general language understanding metrics.</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Benchmark</th>
<th><strong>dnotitia/Llama-DNA-1.0-8B-Instruct</strong></th>
<th>LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct</th>
<th>LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct</th>
<th>yanolja/EEVE-Korean-Instruct-10.8B-v1.0</th>
<th>Qwen/Qwen2.5-7B-Instruct</th>
<th>meta-llama/Llama-3.1-8B-Instruct</th>
<th>mistralai/Mistral-7B-Instruct-v0.3</th>
<th>NCSOFT/Llama-VARCO-8B-Instruct</th>
<th>upstage/SOLAR-10.7B-Instruct-v1.0</th>
</tr>
</thead>
<tbody><tr>
<td>Korean</td>
<td>KMMLU</td>
<td><strong>53.26</strong> (1st)</td>
<td>45.30</td>
<td>45.28</td>
<td>42.17</td>
<td><u>45.66</u></td>
<td>41.66</td>
<td>31.45</td>
<td>38.49</td>
<td>41.50</td>
</tr>
<tr>
<td></td>
<td>KMMLU-hard</td>
<td><strong>29.46</strong> (1st)</td>
<td>23.17</td>
<td>20.78</td>
<td>19.25</td>
<td><u>24.78</u></td>
<td>20.49</td>
<td>17.86</td>
<td>19.83</td>
<td>20.61</td>
</tr>
<tr>
<td></td>
<td>KoBEST</td>
<td><strong>83.40</strong> (1st)</td>
<td>79.05</td>
<td>80.13</td>
<td><u>81.67</u></td>
<td>78.51</td>
<td>67.56</td>
<td>63.77</td>
<td>72.99</td>
<td>73.26</td>
</tr>
<tr>
<td></td>
<td>Belebele</td>
<td><strong>57.99</strong> (1st)</td>
<td>40.97</td>
<td>45.11</td>
<td>49.40</td>
<td><u>54.85</u></td>
<td>54.70</td>
<td>40.31</td>
<td>53.17</td>
<td>48.68</td>
</tr>
<tr>
<td></td>
<td>CSATQA</td>
<td><u>43.32</u> (2nd)</td>
<td>40.11</td>
<td>34.76</td>
<td>39.57</td>
<td><strong>45.45</strong></td>
<td>36.90</td>
<td>27.27</td>
<td>32.62</td>
<td>34.22</td>
</tr>
<tr>
<td>English</td>
<td>MMLU</td>
<td>66.64 (3rd)</td>
<td>65.27</td>
<td>64.32</td>
<td>63.63</td>
<td><strong>74.26</strong></td>
<td><u>68.26</u></td>
<td>62.04</td>
<td>63.25</td>
<td>65.30</td>
</tr>
<tr>
<td></td>
<td>MMLU-Pro</td>
<td><strong>43.05</strong> (1st)</td>
<td>40.73</td>
<td>38.90</td>
<td>32.79</td>
<td><u>42.5</u></td>
<td>40.92</td>
<td>33.49</td>
<td>37.11</td>
<td>30.25</td>
</tr>
<tr>
<td></td>
<td>GSM8K</td>
<td><strong>80.52</strong> (1st)</td>
<td>65.96</td>
<td><u>80.06</u></td>
<td>56.18</td>
<td>75.74</td>
<td>75.82</td>
<td>49.66</td>
<td>64.14</td>
<td>69.22</td>
</tr>
</tbody></table>
<ul>
<li>The <em>highest</em> <em>scores</em> are in <strong>bold</strong> form, and the <em>second</em>-<em>highest</em> <em>scores</em> are <u>underlined</u>.</li>
</ul>
<p><strong>Evaluation Protocol</strong><br>For easy reproduction of our evaluation results, we list the evaluation tools and settings used below:</p>
<table>
<thead>
<tr>
<th></th>
<th>Evaluation setting</th>
<th>Metric</th>
<th>Evaluation tool</th>
</tr>
</thead>
<tbody><tr>
<td>KMMLU</td>
<td>5-shot</td>
<td>macro_avg / exact_match</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>KMMLU Hard</td>
<td>5-shot</td>
<td>macro_avg / exact_match</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>KoBEST</td>
<td>5-shot</td>
<td>macro_avg / f1</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>Belebele</td>
<td>0-shot</td>
<td>acc</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>CSATQA</td>
<td>0-shot</td>
<td>acc_norm</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>MMLU</td>
<td>5-shot</td>
<td>macro_avg / acc</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>MMLU Pro</td>
<td>5-shot</td>
<td>macro_avg / exact_match</td>
<td>lm-eval-harness</td>
</tr>
<tr>
<td>GSM8K</td>
<td>5-shot</td>
<td>acc, exact_match &amp; strict_extract</td>
<td>lm-eval-harness</td>
</tr>
</tbody></table>
<h2>Quickstart</h2>
<p>This model requires <code>transformers &gt;= 4.43.0</code>.</p>
<pre><code class="language-python">from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer

tokenizer = AutoTokenizer.from_pretrained(&#39;dnotitia/Llama-DNA-1.0-8B-Instruct&#39;)
model = AutoModelForCausalLM.from_pretrained(&#39;dnotitia/Llama-DNA-1.0-8B-Instruct&#39;, device_map=&#39;auto&#39;)
streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

conversation = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant, Dnotitia DNA.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ë„ˆì˜ ì´ë¦„ì€?&quot;},
]
inputs = tokenizer.apply_chat_template(conversation,
                                       add_generation_prompt=True,
                                       return_dict=True,
                                       return_tensors=&quot;pt&quot;).to(model.device)
_ = model.generate(**inputs, streamer=streamer)
</code></pre>
<h2>Limitations</h2>
<p>While DNA 1.0 8B Instruct demonstrates strong performance, users should be aware of the following limitations:</p>
<ul>
<li>The model may occasionally generate biased or inappropriate content</li>
<li>Responses are based on training data and may not reflect current information</li>
<li>The model may sometimes produce factually incorrect or inconsistent answers</li>
<li>Performance may vary depending on the complexity and domain of the task</li>
<li>Generated content should be reviewed for accuracy and appropriateness</li>
</ul>
<h2>License</h2>
<p>This model is released under CC BY-NC 4.0 license. For commercial usage inquiries, please <a href="https://www.dnotitia.com/contact/post-form">Contact us</a>.</p>
<h2>Appendix</h2>
<ul>
<li><p>KMMLU scores comparison chart:</p>
<img src="assets/comparison-chart.png" width="100%" style="margin: 40px auto;">
</li>
<li><p>DNA 1.0 8B Instruct model architecture <sup><a href="https://www.linkedin.com/posts/sebastianraschka_the-llama-32-1b-and-3b-models-are-my-favorite-activity-7248317830943686656-yyYD/">1</a></sup>:</p>
<img src="assets/model-architecture.png" width="500" style="margin: 40px auto;"></li>
</ul>
<ul>
<li>The median percentage of modelâ€™s weight difference between before and after the merge (our SFT model + Llama 3.1 8B Instruct):<img src="assets/ours-vs-merged.png" width="100%" style="margin: 40px auto;"></li>
</ul>
<h2>Citation</h2>
<p>If you use or discuss this model in your academic research, please cite the project to help spread awareness:</p>
<pre><code>@misc{lee2025dna10technicalreport,
      title={DNA 1.0 Technical Report}, 
      author={Jungyup Lee and Jemin Kim and Sang Park and SeungJae Lee},
      year={2025},
      eprint={2501.10648},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.10648}, 
}
</code></pre>
 </div> </article>  <section class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-700"> <h2 class="text-3xl font-bold text-center mb-8">Related Models</h2> <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6"> <a href="/model/dnotitia--DNA-R1" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="DNA-R1"> DNA-R1 </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="390 likes">â¤ï¸ <span>390</span></div> <div class="flex items-center gap-1" title="150 downloads">ğŸ“¥ <span>150</span></div> </div> </div> </a><a href="/model/dnotitia--Smoothie-Qwen3-8B" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="Smoothie-Qwen3-8B"> Smoothie-Qwen3-8B </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="120 likes">â¤ï¸ <span>120</span></div> <div class="flex items-center gap-1" title="100 downloads">ğŸ“¥ <span>100</span></div> </div> </div> </a><a href="/model/h2oai--h2o-danube3-4b-chat" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="h2o-danube3-4b-chat"> h2o-danube3-4b-chat </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="670 likes">â¤ï¸ <span>670</span></div> <div class="flex items-center gap-1" title="7,710 downloads">ğŸ“¥ <span>7.7K</span></div> </div> </div> </a> </div> </section> </main> <footer class="bg-gray-800 text-gray-300 py-8 mt-16"> <div class="container mx-auto px-4 text-center"> <div class="flex justify-center gap-4 mb-4"> <a href="/about" class="hover:underline">About</a> <a href="/compliance" class="hover:underline">Compliance</a> </div> <p class="text-sm mt-2">
&copy; 2025 Free AI Tools. An open-source project to index the world of AI.
</p> <a href="mailto:compliance@free2aitools.com" class="text-sm text-gray-400 hover:underline mt-1 block">compliance@free2aitools.com</a> </div> </footer> </body></html>