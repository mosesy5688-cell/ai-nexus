<!DOCTYPE html><html lang="en"> <head><!-- Google Tag Manager --><script type="module">(function(e,n,r,t,m){e[t]=e[t]||[],e[t].push({"gtm.start":new Date().getTime(),event:"gtm.js"});var g=n.getElementsByTagName(r)[0],a=n.createElement(r),s="";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+m+s,g.parentNode.insertBefore(a,g)})(window,document,"script","dataLayer","GTM-58C2CQ8G");</script><!-- End Google Tag Manager --><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><!-- Open Graph Meta Tags --><meta property="og:type" content="website"><meta property="og:url" content="https://free2aitools.com/model/LLM360--CrystalChat/"><meta property="og:title" content="CrystalChat - AI Model Details"><meta property="og:description" content="A model for text-generation."><meta property="og:image" content="https://free2aitools.com/og-image.jpg"><!-- Twitter Card Meta Tags --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://free2aitools.com/model/LLM360--CrystalChat/"><meta property="twitter:title" content="CrystalChat - AI Model Details"><meta property="twitter:description" content="A model for text-generation."><meta property="twitter:image" content="https://free2aitools.com/og-image.jpg"><meta name="description" content="A model for text-generation."><title>CrystalChat - AI Model Details</title><link rel="canonical" href="https://free2aitools.com/model/LLM360--CrystalChat/"><!-- Google AdSense --><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2292826803755214" crossorigin="anonymous"></script><link rel="stylesheet" href="/_astro/about.CAZw8hUu.css"></head> <body class="bg-gray-50 text-gray-800 font-sans antialiased flex flex-col min-h-screen"> <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-58C2CQ8G" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) --> <header class="sticky top-0 z-30 w-full backdrop-blur flex-none transition-colors duration-500 lg:border-b lg:border-gray-200 bg-white/80"> <nav class="container mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex items-center justify-between h-16"> <!-- Site Logo --> <a href="/" class="flex items-center gap-2 text-xl sm:text-2xl font-bold text-gray-900"> <span>Free AI Tools</span> </a> <!-- Right-side items --> <div class="flex items-center gap-4"> <!-- Desktop Navigation --> <div class="hidden md:flex items-center gap-6"> <a href="/" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Explore Models </a><a href="/ranking" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Rankings </a><a href="/reports" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> Reports </a><a href="/about" class="text-base font-medium text-gray-600 hover:text-blue-600 transition-colors"> About </a> </div> <!-- Mobile Search & Menu Toggle --> <button data-collapse-toggle="navbar-default" type="button" class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls="navbar-default" aria-expanded="false"> <span class="sr-only">Open main menu</span> <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"></path></svg> </button> </div> </div> <!-- Mobile Collapsible Menu --> <div class="hidden w-full md:hidden" id="navbar-default"> <ul class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50"> <li> <a href="/" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Explore Models</a> </li><li> <a href="/ranking" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Rankings</a> </li><li> <a href="/reports" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">Reports</a> </li><li> <a href="/about" class="block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0">About</a> </li> </ul> </div> </nav> </header> <main class="flex-grow">  <div class="container mx-auto px-4 py-12"> <div class="max-w-4xl mx-auto"> <!-- Header Section --> <header class="mb-8"> <div class="flex flex-col md:flex-row md:items-start md:justify-between gap-4"> <div> <h1 class="text-4xl md:text-5xl font-extrabold text-gray-900 dark:text-white mb-2">CrystalChat</h1> <p class="text-lg text-gray-500 dark:text-gray-400">by </p> </div>  </div> </header> <!-- Metadata Section --> <div class="mb-8 p-4 bg-gray-100 dark:bg-gray-800 rounded-lg"> <div class="grid grid-cols-2 md:grid-cols-4 gap-4 text-center"> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Likes</p> <p class="text-xl font-bold">360</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Downloads</p> <p class="text-xl font-bold">470</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Task</p> <p class="text-xl font-bold capitalize">text-generation</p> </div> <div> <p class="text-sm text-gray-500 dark:text-gray-400">Last Updated</p> <p class="text-xl font-bold">Invalid Date</p> </div> </div> </div> <h3 class="text-lg font-semibold mb-2">Sources</h3> <div class="flex flex-col gap-2"> <a href="https://huggingface.co/LLM360/CrystalChat" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/LLM360/CrystalChat" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/LLM360/CrystalChat" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/LLM360/CrystalChat" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a><a href="https://huggingface.co/LLM360/CrystalChat" target="_blank" rel="noopener noreferrer" class="text-blue-600 dark:text-blue-400 hover:underline flex items-center gap-2"> ü§ó Hugging Face </a> </div> </div> </div>  <div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div><div class="mb-8 p-4 border border-gray-200 dark:border-gray-700 rounded-lg"> <h3 class="text-2xl font-bold mb-4 flex items-center gap-2"> ü§ó Hugging Face Details
</h3>   </div> <article class="model-readme-content py-8 border-t border-gray-200 dark:border-gray-700"> <div class="prose prose-lg dark:prose-invert max-w-none"> <h1>CrystalChat</h1>
<p>We present CrystalChat, an instruction following model finetuned from <a href="https://huggingface.co/LLM360/CrystalCoder">LLM360/Crystal</a>. </p>
<p>CrystalChat pushes the Llama 2 frontier for models excelling at both langauge and coding tasks.  CrystalChat is part of LLM360&#39;s Pebble model series.</p>
<h1>CrystalChat Performance</h1>
<table>
<thead>
<tr>
<th>Model</th>
<th>Trained Tokens</th>
<th>Avg. of Avg.</th>
<th>Language Avg.</th>
<th>Coding Avg.</th>
</tr>
</thead>
<tbody><tr>
<td>CrystalChat 7B</td>
<td>1.275T</td>
<td>44.96</td>
<td>53.29</td>
<td>36.62</td>
</tr>
<tr>
<td>Mistral-7B-Instruct-v0.1</td>
<td>-</td>
<td>44.34</td>
<td>54.86</td>
<td>30.62</td>
</tr>
<tr>
<td>CodeLlama-7b-Instruct</td>
<td>2.5T</td>
<td>40.91</td>
<td>45.29</td>
<td>36.52</td>
</tr>
<tr>
<td>Llama-2-7b-Chat</td>
<td>2T</td>
<td>34.11</td>
<td>52.86</td>
<td>15.35</td>
</tr>
<tr>
<td>AmberChat 7B</td>
<td>1.25T</td>
<td>-</td>
<td>44.76</td>
<td>-</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Model</th>
<th>Trained Tokens</th>
<th>ARC</th>
<th>HellaSwag</th>
<th>MMLU (5-shot)</th>
<th>GSM8K</th>
<th>Winogrande(5-shot)</th>
<th>TruthfulQA</th>
<th>HumanEval (pass@1)</th>
<th>MBPP (pass@1)</th>
</tr>
</thead>
<tbody><tr>
<td>CrystalChat 7B</td>
<td>1.275T</td>
<td>51.71</td>
<td>76.12</td>
<td>53.22</td>
<td>28.05</td>
<td>70.64</td>
<td>47.29</td>
<td>34.12</td>
<td>39.11</td>
</tr>
<tr>
<td>Mistral-7B-Instruct-v0.1</td>
<td>-</td>
<td>58.05</td>
<td>75.71</td>
<td>55.56</td>
<td>32.00</td>
<td>74.27</td>
<td>55.90</td>
<td>29.27</td>
<td>31.96</td>
</tr>
<tr>
<td>CodeLlama-7b-Instruct</td>
<td>2.5T</td>
<td>43.35</td>
<td>66.14</td>
<td>42.75</td>
<td>15.92</td>
<td>64.33</td>
<td>39.23</td>
<td>34.12</td>
<td>38.91</td>
</tr>
<tr>
<td>Llama-2-7b-Chat</td>
<td>2T</td>
<td>53.07</td>
<td>78.39</td>
<td>48.42</td>
<td>18.88</td>
<td>73.09</td>
<td>45.30</td>
<td>13.26</td>
<td>17.43</td>
</tr>
<tr>
<td>AmberChat 7B</td>
<td>1.25T</td>
<td>42.83</td>
<td>74.03</td>
<td>38.88</td>
<td>5.31</td>
<td>66.77</td>
<td>40.72</td>
<td>-</td>
<td>-</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Combined Language and Coding Ability</th>
</tr>
</thead>
<tbody><tr>
<td><img src="CC-Compare.jpg" alt="arc" width="800"/></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Performance on Standard Benchmarks</th>
</tr>
</thead>
<tbody><tr>
<td><img src="cc-eval-std-benchmarks.png" alt="std-bench" width="800"/></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Perforamnce on Language Benchmarks</th>
</tr>
</thead>
<tbody><tr>
<td><img src="cc-eval-lang-compare.png" alt="arc" width="800"/></td>
</tr>
</tbody></table>
<h1>Instruction Tuning Training</h1>
<p><strong>CrystalChat</strong> is using the last <strong>CrystalCoder</strong> checkpoint of phase2 (<a href="https://huggingface.co/LLM360/CrystalCoder/tree/CrystalCoder_phase2_checkpoint_214387">CrystalCoder_phase2_checkpoint_214387</a>) as the initialization checkpoint. We then finetune the model using the dataset mentioned below.</p>
<p>We also performed the same finetuning on the last <strong>CrystalCoder</strong> checkpoint of phase3 (<a href="https://huggingface.co/LLM360/CrystalCoder/tree/CrystalCoder_phase3_checkpoint_027728">CrystalCoder_phase3_checkpoint_027728</a>). The phase2 and phase3 finetuning results are very similar, but phase2 finetuning exhibits slightly better performance on the English language benchmarks. We choose the phase2 finetuning result as the final model for <strong>CrystalChat</strong>.</p>
<h1>Instruction Tuning Data</h1>
<p>The fine-tuning data is a mix of publicly available language and code datasets, plus a orginally created dataset called <strong>WebAlpaca</strong> on HTML coding instructions.
The WebAlpaca dataset is created by us and is used as part of our instruction tuning training data. We will release the WebAlpaca dataset in a separate repository soon.</p>
<p>The summary of the fine-tuning data is as follows:</p>
<!-- <center><img src="data_table.jpg" alt="Instruction Data"/></center> -->
<table>
<thead>
<tr>
<th>Subset</th>
<th>#Tokens</th>
<th>Avg. #Q</th>
<th>Avg. Query Len</th>
<th>Avg. #R</th>
<th>Avg. Reply Len</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://huggingface.co/datasets/openaccess-ai-collective/oasst1-guanaco-extended-sharegpt">OASST1-guanaco</a></td>
<td>4,464,640</td>
<td>1.36</td>
<td>38.28</td>
<td>1.36</td>
<td>271.69</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/Open-Orca/SlimOrca">SlimOrca</a></td>
<td>225,628,160</td>
<td>1.00</td>
<td>259.16</td>
<td>1.00</td>
<td>151.12</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/Aeala/ShareGPT_Vicuna_unfiltered">ShareGPT</a></td>
<td>112,914,432</td>
<td>3.28</td>
<td>94.53</td>
<td>3.64</td>
<td>365.81</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k">Evol-ShareGPT</a></td>
<td>85,954,560</td>
<td>1.00</td>
<td>145.99</td>
<td>1.00</td>
<td>425.17</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/winglian/chatlogs-en-cleaned">ChatLogs</a></td>
<td>29,337,600</td>
<td>3.39</td>
<td>95.58</td>
<td>3.24</td>
<td>191.42</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/lucasmccabe-lmi/CodeAlpaca-20k">CodeAlpaca</a></td>
<td>2,623,488</td>
<td>1.00</td>
<td>32.46</td>
<td>1.00</td>
<td>67.68</td>
</tr>
<tr>
<td><a href="https://github.com/sahil280114/codealpaca/blob/master/data/rosetta_alpaca.json">Rosetta Code</a></td>
<td>7,987,200</td>
<td>1.00</td>
<td>450.09</td>
<td>1.00</td>
<td>533.52</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1">Evol-CodeAlpaca 1</a></td>
<td>73,803,776</td>
<td>1.00</td>
<td>210.33</td>
<td>1.00</td>
<td>437.92</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/nickrosh/Evol-Instruct-Code-80k-v1">Evol-CodeAlpaca 2</a></td>
<td>34,910,208</td>
<td>1.00</td>
<td>114.99</td>
<td>1.00</td>
<td>300.29</td>
</tr>
<tr>
<td>WebAlpaca</td>
<td>43,673,600</td>
<td>1.00</td>
<td>96.29</td>
<td>1.00</td>
<td>746.52</td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/open-phi/textbooks">General Textbooks</a></td>
<td>85,590,016</td>
<td>Not instruction data</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://huggingface.co/datasets/open-phi/programming_books_llama">Programming Books</a></td>
<td>395,628,544</td>
<td>Not instruction data</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Total</td>
<td>1,102,516,224</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>For more details, check out the <a href="https://huggingface.co/LLM360/CrystalChat/blob/main/data_table.jpg">data table</a>.</p>
<h1>Instruction Format</h1>
<p>We&#39;ve added some new special tokens to the CrystalCoder tokenizer to support the instruction tuning.</p>
<p>List special tokens used in the instruction tuning:</p>
<pre><code>bos: &lt;s&gt; 
eos: &lt;/s&gt;
system_start: &lt;|sys_start|&gt;
system_end: &lt;|sys_end|&gt;
user_start: &lt;|im_start|&gt;
user_end: &lt;|im_end|&gt;
</code></pre>
<p>The instruction format is as follows:</p>
<pre><code>&lt;s&gt; &lt;|sys_start|&gt; system prompt &lt;|sys_end|&gt; &lt;|im_start|&gt; first user utterance &lt;|im_end|&gt; first model response &lt;|im_start|&gt; next user utterance &lt;|im_end|&gt; next model response &lt;/s&gt;
</code></pre>
<h1>Reproducing the Results</h1>
<p>We will release the training code and the training data soon. Our training code is based on <a href="https://github.com/NVIDIA/Megatron-LM">Megatron-LM</a>, with some modifications to support our training data format and Maximal Update Parametrization (ŒºP).</p>
<h2>Model Description</h2>
<ul>
<li><strong>Model type:</strong> Language model with the same architecture as LLaMA-7B</li>
<li><strong>Language(s) (NLP):</strong> English</li>
<li><strong>License:</strong> Apache 2.0</li>
<li><strong>Resources for more information:</strong><ul>
<li><a href="https://github.com/LLM360/crystalcoder-train">Training Code</a></li>
<li><a href="https://github.com/LLM360/crystalcoder-data-prep">Data Preparation</a></li>
<li><a href="https://github.com/LLM360/Analysis360">Metrics</a></li>
<li><a href="https://huggingface.co/datasets/LLM360/CrystalCoderDatasets">Fully processed CrystalCoder pretraining data</a></li>
</ul>
</li>
</ul>
<h1>Loading CrystalChat</h1>
<pre><code class="language-python">import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

device = &quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;
tokenizer = AutoTokenizer.from_pretrained(&quot;LLM360/CrystalChat&quot;, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(&quot;LLM360/CrystalChat&quot;, trust_remote_code=True).to(device)

prompt = &#39;&lt;s&gt; &lt;|sys_start|&gt; You are an AI assistant. You will be given a task. You must generate a detailed and long answer. &lt;|sys_end|&gt; &lt;|im_start|&gt; Write a python function that takes a list of integers and returns the squared sum of the list. &lt;|im_end|&gt;&#39;


input_ids = tokenizer(prompt, return_tensors=&quot;pt&quot;).input_ids.to(device)
gen_tokens = model.generate(input_ids, do_sample=True, max_length=400)

print(&quot;-&quot;*20 + &quot;Output for model&quot;  + 20 * &#39;-&#39;)
print(tokenizer.batch_decode(gen_tokens)[0])
</code></pre>
<p>Response:</p>
<pre><code>Here&#39;s a Python function named `squared_sum_list` that takes a list of integers as input and returns the squared sum of the list:

```python
def squared_sum_list(lst):
    return sum([num ** 2 for num in lst])
```

The function `squared_sum_list` uses a list comprehension to iterate over each number in the input list `lst` and calculate its square. Then, it uses the `sum` function to accumulate all the squared numbers in a single value - the squared sum of the list.

For example:

```python
numbers = [1, 2, 3, 4, 5]
print(squared_sum_list(numbers))  # Outputs: 55
```

In the above code, the list `[1, 2, 3, 4, 5]` is passed as an argument to the `squared_sum_list` function. The function calculates the sum of the squares of the elements in the list, which is `1 + 4 + 9 + 16 + 25 = 55`. The function then returns this result, which is printed to the console.&lt;/s&gt;
</code></pre>
<p>Another chat example:</p>
<pre><code class="language-python"># ...
prompt = &#39;&lt;s&gt; &lt;|sys_start|&gt; You are an AI assistant. You will be given a task. You must generate a detailed \
and long answer. &lt;|sys_end|&gt; &lt;|im_start|&gt; Give me a one-sentence description of crystal. And tell me what \
might the name &quot;Crystal&quot; mean for a transparant and open-source language model? &lt;|im_end|&gt;&#39;
# ...
</code></pre>
<p>Response:</p>
<pre><code>A crystal is an ordered, hexagonal lattice of atoms that displays a unique crystal structure resulting in transparency and diverse physical and chemical properties, and as a transparent and open-source language model, &quot;Crystal&quot; might represent transparency and accessibility by enabling users to understand the inner workings of the model.&lt;/s&gt;
</code></pre>
<h1>Bias, Risks, and Limitations</h1>
<p>CrystalChat has not been aligned to human preferences for safety within the RLHF phase or deployed with in-the-loop filtering of responses like ChatGPT, so the model can produce problematic outputs (especially when prompted to do so). The training data is known and made available <a href="https://huggingface.co/datasets/LLM360/CrystalCoderDatasets">here</a>. It primarily consists of SlimPajama, StarCoder, and WebCrawl dataset.</p>
<h1>Citation</h1>
<p><strong>BibTeX:</strong></p>
<pre><code class="language-bibtex">@misc{liu2023llm360,
      title={LLM360: Towards Fully Transparent Open-Source LLMs}, 
      author={Zhengzhong Liu and Aurick Qiao and Willie Neiswanger and Hongyi Wang and Bowen Tan and Tianhua Tao and Junbo Li and Yuqi Wang and Suqi Sun and Omkar Pangarkar and Richard Fan and Yi Gu and Victor Miller and Yonghao Zhuang and Guowei He and Haonan Li and Fajri Koto and Liping Tang and Nikhil Ranjan and Zhiqiang Shen and Xuguang Ren and Roberto Iriondo and Cun Mu and Zhiting Hu and Mark Schulze and Preslav Nakov and Tim Baldwin and Eric P. Xing},
      year={2023},
      eprint={2312.06550},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
</code></pre>
<h2>About LLM360</h2>
<p>LLM360 is an initiative for comprehensive and fully open-sourced LLMs, 
where all training details, model checkpoints, intermediate results, and 
additional analyses are made available to the community. Our goal is to advance 
the field by inviting the community to deepen the understanding of LLMs 
together. As the first step of the project LLM360, we release all intermediate 
model checkpoints, our fully-prepared pre-training dataset, all source code and
configurations, and training details. We are
committed to continually pushing the boundaries of LLMs through this open-source 
effort.</p>
<p><a href="https://www.llm360.ai/">Visit Us</a></p>
 </div> </article>  <section class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-700"> <h2 class="text-3xl font-bold text-center mb-8">Related Models</h2> <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6"> <a href="/model/LLM360--Crystal" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="Crystal"> Crystal </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="730 likes">‚ù§Ô∏è <span>730</span></div> <div class="flex items-center gap-1" title="1,330 downloads">üì• <span>1.3K</span></div> </div> </div> </a><a href="/model/tomg-group-umd--huginn-0125" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="huginn-0125"> huginn-0125 </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="2,880 likes">‚ù§Ô∏è <span>2.9K</span></div> <div class="flex items-center gap-1" title="14,170 downloads">üì• <span>14.2K</span></div> </div> </div> </a><a href="/model/OrionStarAI--Orion-14B-Base" class="group relative block bg-white dark:bg-gray-800 rounded-lg shadow-md hover:shadow-xl transition-shadow duration-300 overflow-hidden h-full">  <div class="p-5 flex flex-col h-full justify-between"> <div> <h3 class="text-lg font-bold text-gray-900 dark:text-white truncate group-hover:text-blue-600 dark:group-hover:text-blue-400 transition-colors" title="Orion-14B-Base"> Orion-14B-Base </h3> <p class="text-gray-500 dark:text-gray-400 text-xs mb-3">by </p> <p class="text-gray-600 dark:text-gray-300 text-sm h-20 overflow-hidden text-ellipsis leading-relaxed"> A model for text-generation....
</p> </div> <div class="mt-4 flex items-center justify-end gap-4 text-xs text-gray-500 dark:text-gray-400"> <div class="flex items-center gap-1" title="810 likes">‚ù§Ô∏è <span>810</span></div> <div class="flex items-center gap-1" title="3,520 downloads">üì• <span>3.5K</span></div> </div> </div> </a> </div> </section> </main> <footer class="bg-gray-800 text-gray-300 py-8 mt-16"> <div class="container mx-auto px-4 text-center"> <div class="flex justify-center gap-4 mb-4"> <a href="/about" class="hover:underline">About</a> <a href="/compliance" class="hover:underline">Compliance</a> </div> <p class="text-sm mt-2">
&copy; 2025 Free AI Tools. An open-source project to index the world of AI.
</p> <a href="mailto:compliance@free2aitools.com" class="text-sm text-gray-400 hover:underline mt-1 block">compliance@free2aitools.com</a> </div> </footer> </body></html>