<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="A model for text-generation."><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.15.3"><title>gpt-oss-20b</title><link rel="stylesheet" href="/_astro/about.BWOaSv6e.css"></head> <body class="bg-gray-50 dark:bg-gray-900 text-gray-900 dark:text-gray-100 flex flex-col min-h-screen"> <header class="bg-white dark:bg-gray-800 shadow-md sticky top-0 z-50"> <nav class="container mx-auto px-4 py-4 flex justify-between items-center"> <a href="/" class="text-2xl font-bold text-gray-900 dark:text-white shrink-0">Free AI Tools</a> <div class="w-full max-w-md mx-4"> <input type="search" id="header-search" placeholder="Search models..." class="w-full px-4 py-2 text-base bg-gray-100 dark:bg-gray-700 border border-gray-300 dark:border-gray-600 rounded-full focus:ring-2 focus:ring-blue-500 focus:border-blue-500 outline-none transition-colors"> </div> <div class="space-x-4 shrink-0"> <a href="/explore" class="text-gray-600 dark:text-gray-300 hover:text-blue-500">Explore</a> <a href="/about" class="text-gray-600 dark:text-gray-300 hover:text-blue-500">About</a> </div> </nav> </header> <main class="flex-grow">  <div class="container mx-auto px-4 py-12"> <a href="javascript:history.back()" class="text-blue-500 hover:underline mb-8 block font-medium transition-colors">&larr; Back to previous page</a> <article class="bg-white dark:bg-gray-800 p-6 rounded-xl shadow-xl"> <header class="border-b pb-4 mb-6"> <h1 class="text-4xl font-extrabold text-gray-900 dark:text-white leading-tight">gpt-oss-20b</h1>  </header> <div class="grid grid-cols-1 lg:grid-cols-4 gap-12 relative"> <div class="lg:col-span-3"> <section class="mb-8"> <h3 class="text-lg font-semibold mb-2 text-gray-800 dark:text-gray-200">Tags</h3> <div id="tags-container" class="flex flex-wrap gap-2"> <span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">transformers</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">safetensors</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">gpt_oss</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">text-generation</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">vllm</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">conversational</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">arxiv:2508.10925</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">license:apache-2.0</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">autotrain_compatible</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">endpoints_compatible</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">8-bit</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">mxfp4</span><span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">region:us</span>  </div> </section> <section id="details-usage" class="mt-8 mb-10"> <h2 class="text-3xl font-bold mb-4 text-gray-800 dark:text-gray-200 border-b pb-2">Details & Usage</h2> <div class="prose dark:prose-invert prose-lg max-w-none bg-gray-50 dark:bg-gray-900 p-6 rounded-lg prose-pre:bg-gray-200 dark:prose-pre:bg-gray-800 prose-pre:text-gray-800 dark:prose-pre:text-gray-200 border border-gray-100 dark:border-gray-700 shadow-inner"> <div>---
license: apache-2.0
pipeline_tag: text-generation
library_name: transformers
tags:
- vllm
---

<p align="center">
  <img alt="gpt-oss-20b" src="https://raw.githubusercontent.com/openai/gpt-oss/main/docs/gpt-oss-20b.svg">
</p>

<p align="center">
  <a href="https://gpt-oss.com"><strong>Try gpt-oss</strong></a> Â·
  <a href="https://cookbook.openai.com/topic/gpt-oss"><strong>Guides</strong></a> Â·
  <a href="https://arxiv.org/abs/2508.10925"><strong>Model card</strong></a> Â·
  <a href="https://openai.com/index/introducing-gpt-oss/"><strong>OpenAI blog</strong></a>
</p>

<br>

Welcome to the gpt-oss series, [OpenAIâ€™s open-weight models](https://openai.com/open-models) designed for powerful reasoning, agentic tasks, and versatile developer use cases.

Weâ€™re releasing two flavors of these open models:
- `gpt-oss-120b` â€” for production, general purpose, high reasoning use cases that fit into a single 80GB GPU (like NVIDIA H100 or AMD MI300X) (117B parameters with 5.1B active parameters)
- `gpt-oss-20b` â€” for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)

Both models were trained on our [harmony response format](https://github.com/openai/harmony) and should only be used with the harmony format as it will not work correctly otherwise.


> [!NOTE]
> This model card is dedicated to the smaller `gpt-oss-20b` model. Check out [`gpt-oss-120b`](https://huggingface.co/openai/gpt-oss-120b) for the larger model.

# Highlights

* **Permissive Apache 2.0 license:** Build freely without copyleft restrictions or patent riskâ€”ideal for experimentation, customization, and commercial deployment.  
* **Configurable reasoning effort:** Easily adjust the reasoning effort (low, medium, high) based on your specific use case and latency needs.  
* **Full chain-of-thought:** Gain complete access to the modelâ€™s reasoning process, facilitating easier debugging and increased trust in outputs. Itâ€™s not intended to be shown to end users.  
* **Fine-tunable:** Fully customize models to your specific use case through parameter fine-tuning.
* **Agentic capabilities:** Use the modelsâ€™ native capabilities for function calling, [web browsing](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#browser), [Python code execution](https://github.com/openai/gpt-oss/tree/main?tab=readme-ov-file#python), and Structured Outputs.
* **MXFP4 quantization:** The models were post-trained with MXFP4 quantization of the MoE weights, making `gpt-oss-120b` run on a single 80GB GPU (like NVIDIA H100 or AMD MI300X) and the `gpt-oss-20b` model run within 16GB of memory. All evals were performed with the same MXFP4 quantization.

---

# Inference examples

## Transformers

You can use `gpt-oss-120b` and `gpt-oss-20b` with Transformers. If you use the Transformers chat template, it will automatically apply the [harmony response format](https://github.com/openai/harmony). If you use `model.generate` directly, you need to apply the harmony format manually using the chat template or use our [openai-harmony](https://github.com/openai/harmony) package.

To get started, install the necessary dependencies to setup your environment:

```
pip install -U transformers kernels torch 
```

Once, setup you can proceed to run the model by running the snippet below:

```py
from transformers import pipeline
import torch

model_id = "openai/gpt-oss-20b"

pipe = pipeline(
    "text-generation",
    model=model_id,
    torch_dtype="auto",
    device_map="auto",
)

messages = [
    {"role": "user", "content": "Explain quantum mechanics clearly and concisely."},
]

outputs = pipe(
    messages,
    max_new_tokens=256,
)
print(outputs[0]["generated_text"][-1])
```

Alternatively, you can run the model via [`Transformers Serve`](https://huggingface.co/docs/transformers/main/serving) to spin up a OpenAI-compatible webserver:

```
transformers serve
transformers chat localhost:8000 --model-name-or-path openai/gpt-oss-20b
```

[Learn more about how to use gpt-oss with Transformers.](https://cookbook.openai.com/articles/gpt-oss/run-transformers)

## vLLM

vLLM recommends using [uv](https://docs.astral.sh/uv/) for Python dependency management. You can use vLLM to spin up an OpenAI-compatible webserver. The following command will automatically download the model and start the server.

```bash
uv pip install --pre vllm==0.10.1+gptoss \
    --extra-index-url https://wheels.vllm.ai/gpt-oss/ \
    --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \
    --index-strategy unsafe-best-match

vllm serve openai/gpt-oss-20b
```

[Learn more about how to use gpt-oss with vLLM.](https://cookbook.openai.com/articles/gpt-oss/run-vllm)

## PyTorch / Triton

To learn about how to use this model with PyTorch and Triton, check out our [reference implementations in the gpt-oss repository](https://github.com/openai/gpt-oss?tab=readme-ov-file#reference-pytorch-implementation).

## Ollama

If you are trying to run gpt-oss on consumer hardware, you can use Ollama by running the following commands after [installing Ollama](https://ollama.com/download).

```bash
# gpt-oss-20b
ollama pull gpt-oss:20b
ollama run gpt-oss:20b
```

[Learn more about how to use gpt-oss with Ollama.](https://cookbook.openai.com/articles/gpt-oss/run-locally-ollama)

#### LM Studio

If you are using [LM Studio](https://lmstudio.ai/) you can use the following commands to download.

```bash
# gpt-oss-20b
lms get openai/gpt-oss-20b
```

Check out our [awesome list](https://github.com/openai/gpt-oss/blob/main/awesome-gpt-oss.md) for a broader collection of gpt-oss resources and inference partners.

---

# Download the model

You can download the model weights from the [Hugging Face Hub](https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4) directly from Hugging Face CLI:

```shell
# gpt-oss-20b
huggingface-cli download openai/gpt-oss-20b --include "original/*" --local-dir gpt-oss-20b/
pip install gpt-oss
python -m gpt_oss.chat model/
```

# Reasoning levels

You can adjust the reasoning level that suits your task across three levels:

* **Low:** Fast responses for general dialogue.  
* **Medium:** Balanced speed and detail.  
* **High:** Deep and detailed analysis.

The reasoning level can be set in the system prompts, e.g., "Reasoning: high".

# Tool use

The gpt-oss models are excellent for:
* Web browsing (using built-in browsing tools)
* Function calling with defined schemas
* Agentic operations like browser tasks

# Fine-tuning

Both gpt-oss models can be fine-tuned for a variety of specialized use cases.

This smaller model `gpt-oss-20b` can be fine-tuned on consumer hardware, whereas the larger [`gpt-oss-120b`](https://huggingface.co/openai/gpt-oss-120b) can be fine-tuned on a single H100 node.

# Citation

```bibtex
@misc{openai2025gptoss120bgptoss20bmodel,
      title={gpt-oss-120b & gpt-oss-20b Model Card}, 
      author={OpenAI},
      year={2025},
      eprint={2508.10925},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.10925}, 
}
```</div> </div> </section> <div class="border-b border-gray-200 dark:border-gray-700 mb-6"> <nav class="-mb-px flex space-x-8" aria-label="Secondary Tabs"> <button id="tab-btn-files" class="tab-button whitespace-nowrap py-3 px-1 border-b-2 font-semibold text-xl focus:outline-none active-tab">
Files
</button> <button id="tab-btn-community" class="tab-button whitespace-nowrap py-3 px-1 border-b-2 font-semibold text-xl focus:outline-none inactive-tab">
Community
</button> </nav> </div> <div id="tab-content" class="mt-6"> <div id="tab-files" class="tab-panel"> <h2 class="text-2xl font-semibold mb-4 text-gray-800 dark:text-gray-200">Files and Versions</h2> <p class="text-gray-600 dark:text-gray-400">This section will list the model files. (Functionality to be implemented)</p> <div class="ad-container my-4 mt-10">  <div id="amazon-ad-YOUR_AMAZON_DETAIL_PAGE_AD_ID" style="width:100%;height:250px">  </div>  </div> </div> <div id="tab-community" class="tab-panel hidden"> <h2 class="text-2xl font-semibold mb-4 text-gray-800 dark:text-gray-200">Community Discussions</h2> <p class="text-gray-600 dark:text-gray-400">This section will display community discussions and showcase user-created content. (Functionality to be implemented)</p> </div> </div> </div> <aside class="lg:col-span-1"> <div class="bg-gray-50 dark:bg-gray-700 p-6 rounded-lg sticky top-6 shadow-md border border-gray-100 dark:border-gray-600"> <h3 class="text-2xl font-bold mb-4 text-gray-900 dark:text-white border-b pb-2">Model Details</h3> <div class="space-y-3 text-gray-700 dark:text-gray-300"> <div class="flex items-center gap-2"> <span class="text-xl">âš™ï¸</span> <span class="font-semibold">Task:</span> <span class="break-all">text-generation</span> </div> <div class="flex items-center gap-2"> <span class="text-xl">â¤ï¸</span> <span class="font-semibold">Likes:</span> <span>3,888</span> </div> <div class="flex items-center gap-2"> <span class="text-xl">â¬‡ï¸</span> <span class="font-semibold">Downloads:</span> <span>4,487,346</span> </div> <div class="flex items-center gap-2"> <span class="text-xl">ğŸ“…</span> <span class="font-semibold">Updated:</span> <span>N/A</span> </div> </div> <div class="mt-6 border-t border-gray-200 dark:border-gray-600 pt-6"> <h4 class="font-bold text-lg mb-3 text-gray-900 dark:text-white">Sources & Repositories</h4> <ul class="space-y-2"> <li> <a href="https://huggingface.co/openai/gpt-oss-20b" target="_blank" rel="noopener noreferrer" class="text-blue-500 hover:text-blue-600 dark:hover:text-blue-400 hover:underline transition-colors break-all flex items-center gap-1"> <span>Hugging Face</span> <span class="ml-1 text-sm">&rarr;</span> </a> </li> </ul> </div> </div> </aside> </div> </article> </div> <script>(function(){const allTags = ["transformers","safetensors","gpt_oss","text-generation","vllm","conversational","arxiv:2508.10925","license:apache-2.0","autotrain_compatible","endpoints_compatible","8-bit","mxfp4","region:us"];
const hasMoreTags = false;

Â  Â  // Tab switching logic
Â  Â  const tabButtons = document.querySelectorAll('.tab-button');
Â  Â  const tabPanels = document.querySelectorAll('.tab-panel');
Â  Â  const tabIdMap = {
Â  Â  Â  'tab-btn-files': 'tab-files',
Â  Â  Â  'tab-btn-community': 'tab-community',
Â  Â  };

Â  Â  tabButtons.forEach(button => {
Â  Â  Â  button.addEventListener('click', () => {
Â  Â  Â  Â  // Update active tab
Â  Â  Â  Â  tabButtons.forEach(t => t.classList.replace('active-tab', 'inactive-tab'));
Â  Â  Â  Â  button.classList.replace('inactive-tab', 'active-tab');

Â  Â  Â  Â  // Get the target panel ID
Â  Â  Â  Â  const targetPanelId = tabIdMap[button.id];

Â  Â  Â  Â  // Update panel visibility
Â  Â  Â  Â  tabPanels.forEach(p => p.classList.add('hidden'));
Â  Â  Â  Â  if (targetPanelId) {
Â  Â  Â  Â  Â  document.getElementById(targetPanelId)?.classList.remove('hidden');
Â  Â  Â  Â  }
Â  Â  Â  });
Â  Â  });


Â  Â  // "Show all tags" button logic
Â  Â  if (hasMoreTags) {
Â  Â  Â  const showAllBtn = document.getElementById('show-all-tags');
Â  Â  Â  const tagsContainer = document.getElementById('tags-container');

Â  Â  Â  if (showAllBtn && tagsContainer) {
Â  Â  Â  Â  showAllBtn.addEventListener('click', () => {
Â  Â  Â  Â  Â  const remainingTags = allTags.slice(15);
Â  Â  Â  Â  Â  const tagsHtml = remainingTags.map(tag =>Â 
Â  Â  Â  Â  Â  Â  `<span class="bg-blue-100 text-blue-800 text-sm font-medium px-3 py-1 rounded-full dark:bg-blue-900 dark:text-blue-300 transition-colors">${tag}</span>`
Â  Â  Â  Â  Â  ).join('');
Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  const tempDiv = document.createElement('div');
Â  Â  Â  Â  Â  tempDiv.innerHTML = tagsHtml;

Â  Â  Â  Â  Â  tagsContainer.append(...tempDiv.childNodes);
Â  Â  Â  Â  Â  showAllBtn.remove();
Â  Â  Â  Â  });
Â  Â  Â  }
Â  Â  }
Â  })();</script>  </main> <footer class="bg-gray-800 text-gray-300 py-8 mt-16"> <div class="container mx-auto px-4 text-center"> <div class="flex justify-center gap-4 mb-4"> <a href="/about" class="hover:underline">About</a> <a href="/compliance" class="hover:underline">Compliance</a> </div> <p class="text-sm">&copy; 2025 Free AI Tools. An open-source project to index the world of AI.</p> </div> </footer> <script type="module">const e=document.getElementById("header-search");e.addEventListener("keydown",n=>{if(n.key==="Enter"){const o=e.value;window.location.href=`/explore?q=${encodeURIComponent(o)}`}});</script> </body> </html>