# Factory 2/4 - Process
# V14.5 Phase 4: Modular Factory Architecture
# 
# Triggers: workflow_run from Harvest, or manual dispatch
# Inputs: entity-data artifact from Harvest
# Outputs: shard results + processed entity files
# 
# Constitution: Art 3.1-3.4 (Factory Pipeline)

name: Factory 2/4 - Process

on:
  workflow_run:
    workflows: ["Factory 1/4 - Harvest"]
    types: [completed]
  workflow_dispatch:
    inputs:
      run_id:
        description: 'Run ID of Harvest workflow (optional)'
        required: false
        type: string

jobs:
  # Validate upstream success
  check-upstream:
    name: Check Upstream
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    outputs:
      upstream-run-id: ${{ steps.get-run-id.outputs.run_id }}
    steps:
      - name: Get Upstream Run ID
        id: get-run-id
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ -n "${{ inputs.run_id }}" ]; then
            echo "run_id=${{ inputs.run_id }}" >> $GITHUB_OUTPUT
          else
            echo "run_id=${{ github.event.workflow_run.id }}" >> $GITHUB_OUTPUT
          fi

  # V14.5 Optimization: Single job to restore Cache and re-upload as Artifact
  # This avoids the cross-workflow artifact download rate limit
  prepare-data:
    name: Prepare Entity Data
    needs: check-upstream
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Directories
        run: mkdir -p data cache
        
      - name: Restore Entity Data from Cache
        uses: actions/cache/restore@v4
        with:
          path: |
            data/merged.json
            data/merged_shard_*.json
            data/manifest.json
            cache/fni-history.json
            cache/weekly-accum.json
          key: factory-entity-data-${{ needs.check-upstream.outputs.upstream-run-id }}
          fail-on-cache-miss: true
          
      - name: Validate Entity Data
        run: |
          if [ ! -f "data/merged.json" ]; then
            echo "âŒ ERROR: data/merged.json not found in cache!"
            exit 1
          fi
          ENTITY_COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/merged.json')).length)")
          echo "âœ… Found $ENTITY_COUNT entities in cache"
          
      - name: Upload for Matrix Jobs
        uses: actions/upload-artifact@v4
        with:
          name: prepared-entity-data
          path: |
            data/
            cache/
          retention-days: 1

  # Matrix shards for parallel processing
  matrix-shards:
    name: Shard ${{ matrix.shard }}
    needs: [check-upstream, prepare-data]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        shard: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
      fail-fast: false
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      # V14.5 Optimization: Download from same-workflow artifact (no rate limit issue)
      - name: Download Entity Data
        uses: actions/download-artifact@v4
        with:
          name: prepared-entity-data

      # Move downloaded files to correct locations
      # V14.5 Fix: download-artifact preserves directory structure
      # Files are already at data/merged.json, cache/fni-history.json, etc.
      - name: Setup Data Directories
        run: |
          mkdir -p data cache artifacts output
          
          echo "ðŸ“‚ Downloaded artifact structure:"
          find . -name "*.json" -type f | head -20
          
          # Handle both flat and nested download structures
          # If files are at root, move them
          [ -f merged.json ] && mv merged.json data/merged.json
          [ -f fni-history.json ] && mv fni-history.json cache/fni-history.json
          [ -f weekly-accum.json ] && mv weekly-accum.json cache/weekly-accum.json
          
          # Files may already be in correct paths from artifact
          echo "ðŸ“‚ Final data structure:"
          ls -la data/ || true
          ls -la cache/ || true
          
          # Validate merged.json exists
          if [ ! -f "data/merged.json" ]; then
            echo "âŒ ERROR: data/merged.json not found!"
            echo "Available files:"
            find . -name "*.json" -type f
            exit 1
          fi
          
          ENTITY_COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/merged.json')).length)")
          echo "âœ… Found $ENTITY_COUNT entities in merged.json"
          
          # V14.5: Fail if entity count is too low (prevents processing test data)
          if [ "$ENTITY_COUNT" -lt 1000 ]; then
            echo "âŒ ERROR: Only $ENTITY_COUNT entities found. Expected 1000+."
            echo "This indicates corrupted data or test files in artifact."
            exit 1
          fi

      # Restore entity checksums for incremental processing
      - name: Restore Entity Checksums
        uses: actions/cache@v4
        with:
          path: cache/entity-checksums.json
          key: entity-checksums-${{ github.run_id }}
          restore-keys: |
            entity-checksums-

      # Process shard
      - name: Process Shard ${{ matrix.shard }}
        env:
          ENTITIES_PATH: data/merged.json
          FNI_HISTORY_PATH: cache/fni-history.json
          ARTIFACT_DIR: artifacts
        run: |
          echo "ðŸ”„ Processing Shard ${{ matrix.shard }}/20..."
          node scripts/factory/shard-processor.js --shard=${{ matrix.shard }} --total=20

      # Upload shard artifact
      - name: Upload Shard Artifact
        uses: actions/upload-artifact@v4
        with:
          name: shard-${{ matrix.shard }}
          path: |
            artifacts/shard-${{ matrix.shard }}.json
            output/
          retention-days: 1

  # Aggregate and save checksums
  finalize:
    name: Finalize Processing
    needs: [check-upstream, matrix-shards]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      # Download shard 0 for checksum data
      - name: Download Shard 0
        uses: actions/download-artifact@v4
        with:
          name: shard-0
          path: ./shard-0/
        continue-on-error: true

      # V14.5.2: Checksum saving moved to Aggregator (Phase 3) for atomic consistency
      - name: Notify Aggregate Stage
        run: |
          echo "âœ… Shards complete. Checksums and Registry state will be finalized in 'Factory 3/4 - Aggregate'."

      - name: Summary
        run: |
          echo "## Factory 2/4 - Process Complete âš™ï¸" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Shards: 20 parallel" >> $GITHUB_STEP_SUMMARY
          echo "- Artifacts: shard-0 to shard-19" >> $GITHUB_STEP_SUMMARY
          echo "- Next: Factory 3/4 - Aggregate" >> $GITHUB_STEP_SUMMARY
