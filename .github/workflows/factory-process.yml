# Factory 2/4 - Process
# V14.5 Phase 4: Modular Factory Architecture
# 
# Triggers: workflow_run from Harvest, or manual dispatch
# Inputs: entity-data artifact from Harvest
# Outputs: shard results + processed entity files
# 
# Constitution: Art 3.1-3.4 (Factory Pipeline)

name: Factory 2/4 - Process

on:
  workflow_run:
    workflows: ["Factory 1/4 - Harvest"]
    types: [completed]
  workflow_dispatch:
    inputs:
      run_id:
        description: 'Run ID of Harvest workflow (optional)'
        required: false
        type: string

jobs:
  # Validate upstream success
  check-upstream:
    name: Check Upstream
    runs-on: ubuntu-latest
    outputs:
      upstream-run-id: ${{ steps.get-run-id.outputs.run_id }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Verify Upstream Conclusion
        if: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.conclusion != 'success' }}
        run: |
          echo "âŒ ERROR: Upstream workflow '${{ github.event.workflow_run.name }}' failed with conclusion '${{ github.event.workflow_run.conclusion }}'."
          echo "Aborting Factory 2/4 to prevent data corruption."
          exit 1
      - name: Get Upstream Run ID
        id: get-run-id
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # 1. Start with the Harvest Run ID (Triggering event or manual input)
          HARVEST_RUN_ID=${{ inputs.run_id || github.event.workflow_run.id }}
          
          # 2. If HARVEST_RUN_ID is missing, find the latest successful Harvest run on MAIN
          if [ -z "$HARVEST_RUN_ID" ] || [ "$HARVEST_RUN_ID" == "null" ]; then
            echo "ðŸ” Manual dispatch: Finding latest successful Harvest run on main branch..."
            HARVEST_RUN_ID=$(gh run list --workflow factory-harvest.yml --branch main --status success --limit 1 --json databaseId --jq '.[0].databaseId' | tr -d '[:space:]')
          fi
          
          HARVEST_RUN_ID=$(echo $HARVEST_RUN_ID | tr -d '[:space:]')
          echo "run_id=$HARVEST_RUN_ID" >> $GITHUB_OUTPUT
          echo "âœ… Resolved Harvest ID: $HARVEST_RUN_ID"

  # V4.1: Prepare data from Cache (not Artifact)
  prepare-data:
    name: Prepare Entity Data
    needs: check-upstream
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        
      - name: Setup Directories
        run: |
          rm -rf data/*.json cache/*.json
          mkdir -p data cache

      # V4.1: Restore Entity Data from Cache (Cycle Key)
      - name: "Diagnostic: Workflow Context Check"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ” Diagnostic: Inspecting Cache Visibility..."
          echo "Trigger Event: ${{ github.event_name }}"
          echo "Current Branch (REF): ${{ github.ref }}"
          echo "Harvest Run ID: ${{ needs.check-upstream.outputs.upstream-run-id }}"
          echo "Target Key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-harvest"
          echo "--- GitHub Cache Table ---"
          gh cache list --limit 100 || true
          
      - name: "Wait for Cache Indexing"
        run: sleep 30  # Account for propagation latency

      - name: Restore Entity Data from Cache
        id: cache-harvest
        uses: actions/cache/restore@v4
        with:
          path: |
            data/merged.json.gz
            data/merged_shard_*.json.gz
            data/manifest.json
            cache/
          key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-harvest
          restore-keys: |
            cycle-
          fail-on-cache-miss: false
          
      - name: "Diagnostic: Show Workspace State"
        run: |
          echo "ðŸ” Diagnostic: Checking file structure after cache restore..."
          echo "Cache Hit: ${{ steps.cache-harvest.outputs.cache-hit }}"
          echo "--- data/ content ---"
          ls -R data || echo "data is missing"
          echo "--- cache/ content ---"
          ls -R cache || echo "cache is missing"

      - name: Validate Entity Data
        run: |
          if [ ! -f "data/manifest.json" ]; then
            echo "âŒ ERROR: data/manifest.json not found in cache!"
            exit 1
          fi
          ENTITY_COUNT=$(jq -r '.total_entities' data/manifest.json)
          echo "âœ… Found $ENTITY_COUNT entities in cache (manifest)"

      # V18.12.5.1: Architectural Split (Decomposition)
      # Move sharding responsibility from 1/4 (Harvest) to 2/4 (Process)
      - name: Split Registry for Matrix
        run: |
          echo "ðŸ”ª Decomposing monolith for parallel processing..."
          node scripts/factory/split-registry.js
      - name: Upload for Matrix Jobs
        uses: actions/upload-artifact@v4
        with:
          name: prepared-entity-data
          path: |
            data/
            cache/
          retention-days: 1

  # Matrix shards for parallel processing
  matrix-shards:
    name: Shard ${{ matrix.shard }}
    needs: [check-upstream, prepare-data]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        shard: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
      fail-fast: false
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      # V14.5 Optimization: Download from same-workflow artifact (no rate limit issue)
      - name: Download Entity Data
        uses: actions/download-artifact@v4
        with:
          name: prepared-entity-data

      # Move downloaded files to correct locations
      # V14.5 Fix: download-artifact preserves directory structure
      # Files are already at data/merged.json, cache/fni-history.json, etc.
      - name: Setup Data Directories
        run: |
          mkdir -p data cache artifacts output
          
          echo "ðŸ“‚ Downloaded artifact structure:"
          find . -name "*.json*" -type f | head -20
          
          # Handle both flat and nested download structures
          # If files are at root, move them
          [ -f merged.json.gz ] && mv merged.json.gz data/merged.json.gz
          [ -f manifest.json ] && mv manifest.json data/manifest.json
          [ -f fni-history.json.gz ] && mv fni-history.json.gz cache/fni-history.json.gz
          [ -f daily-accum.json.gz ] && mv daily-accum.json.gz cache/daily-accum.json.gz
          
          # Files may already be in correct paths from artifact
          echo "ðŸ“‚ Final data structure:"
          ls -la data/ || true
          ls -la cache/ || true
          
          # Validate manifest exists
          if [ ! -f "data/manifest.json" ]; then
            echo "âŒ ERROR: data/manifest.json not found!"
            exit 1
          fi
          
          ENTITY_COUNT=$(jq -r '.total_entities' data/manifest.json)
          echo "âœ… Found $ENTITY_COUNT entities in manifest"
          
          # V14.5: Fail if entity count is too low (prevents processing test data)
          if [ "$ENTITY_COUNT" -lt 80000 ]; then
            echo "âŒ ERROR: Only $ENTITY_COUNT entities found. Expected 80000+."
            echo "This indicates corrupted data or test files in artifact."
            exit 1
          fi

      # Restore entity checksums for incremental processing
      - name: Restore Entity Checksums
        uses: actions/cache@v4
        with:
          path: cache/entity-checksums.json.gz
          key: entity-checksums-${{ github.run_id }}
          restore-keys: |
            entity-checksums-

      # Process shard
      - name: Process Shard ${{ matrix.shard }}
        env:
          CACHE_DIR: data
          ENTITIES_PATH: data/merged.json.gz
          FNI_HISTORY_PATH: cache/fni-history.json.gz
          ARTIFACT_DIR: artifacts
          STRICT_R2_LOCKDOWN: 'true'
        run: |
          echo "ðŸ”„ Processing Shard ${{ matrix.shard }}/20..."
          node scripts/factory/shard-processor.js --shard=${{ matrix.shard }} --total=20

      # V16.11: Upload ONLY the compressed monolithic shard (No debris)
      - name: Upload Shard Artifact
        uses: actions/upload-artifact@v4
        with:
          name: shard-${{ matrix.shard }}
          path: artifacts/shard-${{ matrix.shard }}.json.gz
          retention-days: 1

  # V4.1: Save all shards to Cache for next stage
  save-shards-cache:
    name: Save Shards to Cache
    needs: [check-upstream, matrix-shards]
    runs-on: ubuntu-latest
    steps:
      - name: Download All Shard Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: shard-*
          path: ./shards/
          merge-multiple: true

      - name: Organize Shards and Entity Data
        run: |
          mkdir -p output/shards
          echo "ðŸ“¦ Collecting 20 parallel compressed shards..."
          
          # Force a clean collection from the downloaded artifacts
          find ./shards -name "shard-*.json.gz" -exec cp -v {} output/shards/ \;
          
          SHARD_COUNT=$(find output/shards -name "shard-*.json.gz" | wc -l)
          echo "âœ… Total shards collected: $SHARD_COUNT"
          
          if [ "$SHARD_COUNT" -lt 20 ]; then
            echo "âŒ ERROR: Missing shards! Expected 20, found $SHARD_COUNT."
            exit 1
          fi

      - name: Save Shards to Cache
        uses: actions/cache/save@v4
        with:
          path: output/shards
          key: cycle-${{ github.run_id }}-shards

  # Aggregate and save checksums
  finalize:
    name: Finalize Processing
    needs: [check-upstream, matrix-shards]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      # Download shard 0 for checksum data
      - name: Download Shard 0
        uses: actions/download-artifact@v4
        with:
          name: shard-0
          path: ./shard-0/
        continue-on-error: true

      # V14.5.2: Checksum saving moved to Aggregator (Phase 3) for atomic consistency
      - name: Notify Aggregate Stage
        run: |
          echo "âœ… Shards complete. Checksums and Registry state will be finalized in 'Factory 3/4 - Aggregate'."

      - name: Summary
        run: |
          echo "## Factory 2/4 - Process Complete âš™ï¸" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Shards: 20 parallel" >> $GITHUB_STEP_SUMMARY
          echo "- Artifacts: shard-0 to shard-19" >> $GITHUB_STEP_SUMMARY
          echo "- Next: Factory 3/4 - Aggregate" >> $GITHUB_STEP_SUMMARY
