name: Weekly Database Backup

# NOTE: Cloudflare D1 production databases use "Time Travel" for automatic
# point-in-time recovery (last 30 days on paid, 7 days on free).
# This workflow exports a manual SQL backup for additional redundancy.

on:
  schedule:
    - cron: '0 3 * * 0'  # Every Sunday at 3 AM UTC (11 AM Beijing Time)
  workflow_dispatch:     # Manual trigger support

jobs:
  export-database:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Wrangler
        run: npm install -g wrangler@latest
      
      - name: Export D1 Database
        id: export
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "ðŸ”„ Exporting D1 database..."
          echo "Database: ai-nexus-db"
          
          # Create backups directory
          mkdir -p backups
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          EXPORT_FILE="backups/ai-nexus-db-$TIMESTAMP.sql"
          
          # Run wrangler d1 export
          set +e
          wrangler d1 export ai-nexus-db --remote --output="$EXPORT_FILE" 2>&1
          EXPORT_EXIT_CODE=$?
          set -e
          
          echo "Exit code: $EXPORT_EXIT_CODE"
          
          if [ $EXPORT_EXIT_CODE -ne 0 ]; then
            echo "âŒ Database export failed"
            echo "::error::D1 export failed with exit code $EXPORT_EXIT_CODE"
            exit 1
          fi
          
          # Verify file exists and has content
          if [ -f "$EXPORT_FILE" ]; then
            FILE_SIZE=$(stat -c%s "$EXPORT_FILE" 2>/dev/null || stat -f%z "$EXPORT_FILE")
            echo "âœ… Export successful: $EXPORT_FILE ($FILE_SIZE bytes)"
            echo "EXPORT_FILE=$EXPORT_FILE" >> $GITHUB_OUTPUT
            echo "FILE_SIZE=$FILE_SIZE" >> $GITHUB_OUTPUT
            echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT
          else
            echo "âŒ Export file not found"
            exit 1
          fi
          
          # Create metadata
          echo "Export created at: $(date -u)" >> "backups/backup-$TIMESTAMP.txt"
          echo "File: $EXPORT_FILE" >> "backups/backup-$TIMESTAMP.txt"
          echo "Size: $FILE_SIZE bytes" >> "backups/backup-$TIMESTAMP.txt"
          echo "Workflow run: ${{ github.run_id }}" >> "backups/backup-$TIMESTAMP.txt"
      
      - name: Upload Backup Artifact
        uses: actions/upload-artifact@v4
        with:
          name: db-export-${{ github.run_number }}
          path: backups/
          retention-days: 90
      
      - name: Notify Success (Slack)
        if: success() && vars.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST ${{ vars.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d "{
              \"text\": \"âœ… Database Export Successful\",
              \"blocks\": [
                {
                  \"type\": \"section\",
                  \"text\": {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Database Export Completed*\n\nâ€¢ File: \`${{ steps.export.outputs.EXPORT_FILE }}\`\nâ€¢ Size: ${{ steps.export.outputs.FILE_SIZE }} bytes\nâ€¢ Time: $(date -u)\nâ€¢ Workflow: <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>\"
                  }
                }
              ]
            }"
      
      - name: Notify Failure (Slack)
        if: failure() && vars.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST ${{ vars.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d "{
              \"text\": \"ðŸš¨ Database Export FAILED\",
              \"blocks\": [
                {
                  \"type\": \"section\",
                  \"text\": {
                    \"type\": \"mrkdwn\",
                    \"text\": \"*Database Export Failed*\n\nâ€¢ Time: $(date -u)\nâ€¢ Workflow: <https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Run>\nâ€¢ Please check logs immediately!\"
                  }
                }
              ]
            }"
      
      - name: Summary
        if: always()
        run: |
          echo "## ðŸ“Š Database Export Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Export File**: ${{ steps.export.outputs.EXPORT_FILE }}" >> $GITHUB_STEP_SUMMARY
          echo "- **File Size**: ${{ steps.export.outputs.FILE_SIZE }} bytes" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note**: D1 Time Travel provides automatic point-in-time recovery." >> $GITHUB_STEP_SUMMARY
