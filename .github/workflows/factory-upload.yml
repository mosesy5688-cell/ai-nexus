# Factory 4/4 - Finalize V14.6
# Consolidated Stage 3.5 + 4.0
# 
# Triggers: workflow_run from Aggregate, or manual dispatch
# Inputs: factory-output artifact/cache from Aggregate stage
# Jobs: Relations, Knowledge Mesh, RSS, and Final R2 Upload

name: Factory 4/4 - Finalize

on:
  workflow_run:
    workflows: ["Factory 3/4 - Aggregate"]
    types: [completed]
  workflow_dispatch:
    inputs:
      run_id:
        description: 'Aggregate workflow run ID'
        required: false
        type: string

env:
  CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
  CLOUDFLARE_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
  R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
  R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
  R2_BUCKET: ai-nexus-assets
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  NODE_OPTIONS: '--max-old-space-size=6144'

permissions:
  actions: write
  contents: read
  id-token: write

jobs:
  check-upstream:
    name: Check Upstream
    runs-on: ubuntu-latest
    outputs:
      upstream-run-id: ${{ steps.get-id.outputs.id }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Verify Upstream Conclusion
        if: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.conclusion != 'success' }}
        run: |
          echo "ERROR: Upstream workflow '${{ github.event.workflow_run.name }}' failed with conclusion '${{ github.event.workflow_run.conclusion }}'."
          exit 1
      - name: Get ID
        id: get-id
        run: |
          AGGREGATE_RUN_ID=${{ inputs.run_id || github.event.workflow_run.id }}
          if [ -z "$AGGREGATE_RUN_ID" ] || [ "$AGGREGATE_RUN_ID" == "null" ]; then
            echo "Finding latest successful Aggregate run on main..."
            AGGREGATE_RUN_ID=$(gh run list --workflow factory-aggregate.yml --branch main --status success --limit 1 --json databaseId --jq '.[0].databaseId' | tr -d '[:space:]')
          fi
          echo "id=$AGGREGATE_RUN_ID" >> $GITHUB_OUTPUT

  mesh-baking:
    name: Mesh Baking
    needs: check-upstream
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Complete Cycle Output from Cache
        uses: actions/cache/restore@v4
        with:
          path: output/
          key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-output
          restore-keys: cycle-
      - name: Bake atomized Mesh Profiles
        env:
          CACHE_DIR: ./output/cache
        run: node scripts/factory/mesh-profile-baker.js
      - name: Tar Baked Profiles
        run: tar -cf mesh-profiles.tar -C output/cache/mesh profiles
      - name: Save Baked Profiles to Cache
        uses: actions/cache/save@v4
        with:
          path: mesh-profiles.tar
          key: intra-4-4-${{ github.run_id }}-baked

  master-fusion:
    name: Master Fusion
    needs: [mesh-baking, check-upstream]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Base Output from Cache
        uses: actions/cache/restore@v4
        with:
          path: output/
          key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-output
          restore-keys: cycle-
      - name: Restore Baked Profiles from Cache
        uses: actions/cache/restore@v4
        with:
          path: mesh-profiles.tar
          key: intra-4-4-${{ github.run_id }}-baked
      - name: Extract Profiles
        run: |
          mkdir -p output/cache/mesh
          tar -xf mesh-profiles.tar -C output/cache/mesh
      - name: Organize Shards for Fusion
        run: |
          mkdir -p artifacts
          # Check output/cache/shards (standard) or output/shards (legacy)
          if [ -d "output/cache/shards" ]; then
            find output/cache/shards -name "shard-*.json.gz" -exec mv {} artifacts/ \;
          elif [ -d "output/shards" ]; then
            find output/shards -name "shard-*.json.gz" -exec mv {} artifacts/ \;
          fi
          echo "üì¶ Shards ready in artifacts/: $(ls artifacts | wc -l)"
      - name: Execute Master Fusion
        env:
          CACHE_DIR: ./output/cache
          ARTIFACT_DIR: ./artifacts
        run: node scripts/factory/master-fusion.js
      - name: Save Fused Entities to Cache
        uses: actions/cache/save@v4
        with:
          path: output/cache/fused/
          key: intra-4-4-${{ github.run_id }}-fused

  rss-feeds:
    name: RSS Feeds
    needs: check-upstream
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Base Output from Cache
        uses: actions/cache/restore@v4
        with:
          path: output/
          key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-output
          restore-keys: cycle-
      - name: Generate RSS feeds
        run: node scripts/factory/lib/rss-generator.js ./output
      - name: Save RSS Feeds to Cache
        uses: actions/cache/save@v4
        with:
          path: output/rss/
          key: intra-4-4-${{ github.run_id }}-rss-feeds
      - name: Upload RSS feeds
        uses: actions/upload-artifact@v4
        with:
          name: rss-feeds
          path: output/rss/
          retention-days: 1

  upload:
    name: Final Upload to R2
    needs: [mesh-baking, master-fusion, rss-feeds, check-upstream]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Base Output from Cache
        uses: actions/cache/restore@v4
        with:
          path: output/
          key: cycle-${{ needs.check-upstream.outputs.upstream-run-id }}-output
          restore-keys: cycle-
      - name: Restore Enrichment Results from Cache
        uses: actions/cache/restore@v4
        with:
          path: output/
          key: intra-4-4-${{ github.run_id }}-final-consolidation
          restore-keys: |
            intra-4-4-${{ github.run_id }}-
      - name: Download All Enrichment Artifacts
        uses: actions/download-artifact@v4
        with: { path: output/ }
      - name: Prepare Registry Backup for S3 Upload
        run: |
          mkdir -p output/meta/backup
          echo "‚úÖ aggregator.js has prepared baseline backups in output/meta/backup/"
      - name: Upload to R2 via S3 API
        env:
          R2_PREFIX_FILTER: checkpoint.json,entities.json,entities/,cache/entities/,cache/fused/,cache/html/,cache/rankings/,cache/search/,cache/trending.json,cache/category_stats.json,cache/search-core.json,cache/search-full.json,cache/search-manifest.json,cache/relations/,cache/relations.json,cache/trend-data.json,cache/knowledge/,cache/mesh/,cache/graph.json,cache/reports/,meta/,sitemaps/,rss/,sitemap.xml
        run: node scripts/factory/r2-upload-s3.js
      - name: Purge & Warm CDN
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
        run: |
          if [ -z "$CLOUDFLARE_ZONE_ID" ] || [ -z "$CLOUDFLARE_API_TOKEN" ]; then
            echo "‚ö†Ô∏è [PURGE] Skipping CDN purge: CLOUDFLARE_ZONE_ID/TOKEN missing"
            exit 0
          fi
          PURGE_PATHS='["https://cdn.free2aitools.com/cache/trending.json","https://cdn.free2aitools.com/cache/search-core.json","https://cdn.free2aitools.com/cache/relations.json","https://cdn.free2aitools.com/sitemap.xml"]'
          echo "üì° Purging CDN cache for paths: $PURGE_PATHS"
          curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$CLOUDFLARE_ZONE_ID/purge_cache" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" -H "Content-Type: application/json" \
            --data "{\"files\":$PURGE_PATHS}"
      - name: Trigger Health Check
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üè• Triggering Daily Health Check..."
          gh workflow run daily-health-check.yml
        continue-on-error: true
