# Image Processor Workflow V14.5
# Constitution Reference: Art 3.4 (Image Processing), V14.5 Architecture
# 
# Runs after Factory to download, convert (WebP), and upload entity images to R2

name: Image Processor V14.5

on:
  # Trigger after Factory Aggregate completes (To use GitHub Cache)
  workflow_run:
    workflows: ["Factory 3/4 - Aggregate"]
    types: [completed]
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of images to process per run'
        type: number
        default: 2000
      run_id:
        description: 'Aggregate run ID to restore cache from (Manual only)'
        type: string
        required: false

env:
  R2_BUCKET: ai-nexus-assets
  R2_ENDPOINT: https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com
  CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
  CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
  R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}

jobs:
  # V16.7: Identify upstream Aggregate run for reliable cache restoration
  check-upstream:
    name: Check Upstream
    runs-on: ubuntu-latest
    outputs:
      upstream-run-id: ${{ steps.get-id.outputs.id }}
    steps:
      - name: Verify Upstream Conclusion
        if: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.conclusion != 'success' }}
        run: |
          echo "âŒ ERROR: Upstream workflow '${{ github.event.workflow_run.name }}' failed with conclusion '${{ github.event.workflow_run.conclusion }}'."
          echo "Aborting Image Processor to prevent data corruption."
          exit 1
      - name: Get ID
        id: get-id
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # 1. Start with the Aggregate Run ID (Triggering event or manual input)
          AGGREGATE_RUN_ID=${{ inputs.run_id || github.event.workflow_run.id }}
          
          # 2. If missing, find the latest successful Aggregate run on MAIN
          if [ -z "$AGGREGATE_RUN_ID" ] || [ "$AGGREGATE_RUN_ID" == "null" ]; then
            echo "ðŸ” Manual dispatch: Finding latest successful Aggregate run on main branch..."
            AGGREGATE_RUN_ID=$(gh run list --workflow factory-aggregate.yml --branch main --status success --limit 1 --json databaseId --jq '.[0].databaseId' | tr -d '[:space:]')
          fi
          
          echo "id=$AGGREGATE_RUN_ID" >> $GITHUB_OUTPUT
          echo "âœ… Resolved Aggregate ID (Main): $AGGREGATE_RUN_ID"

  process-images:
    name: Process Entity Images
    needs: check-upstream
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust Dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            tools/rust-img-optimizer/target/
          key: rust-img-${{ hashFiles('tools/rust-img-optimizer/Cargo.lock') }}

      - name: Build Rust Optimizer
        working-directory: tools/rust-img-optimizer
        run: cargo build --release

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Setup Directories
        run: |
          rm -rf output/meta/backup/*.json # V16.8.6: Clear stale local context
          mkdir -p output/meta/backup data/images
        
      - name: Install Dependencies
        run: npm ci

      # V16.8.13: Use Artifact for context instead of volatile Cache
      - name: Download Core Registry Artifact
        uses: actions/download-artifact@v4
        with:
          name: core-registry-v2
          path: ./registry-context/
          run-id: ${{ needs.check-upstream.outputs.upstream-run-id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true

      # V16.4.1: Fetch Global Entity Registry (Artifact Priority)
      - name: Fetch Global Entity Registry
        run: |
          mkdir -p data/images data/registry
          
          echo "ðŸ” Searching for registry monolith in artifact..."
          # 1. Try Artifact Monolith (Preferred V16.8.16)
          if [ -f "./registry-context/output/entities.json" ]; then
            echo "âœ… Verified: Registry monolith found in ./registry-context/output/entities.json"
            cp ./registry-context/output/entities.json data/registry.json
            cp -r ./registry-context/cache/registry/* data/registry/ 2>/dev/null || true
          elif [ -f "./registry-context/entities.json" ]; then
            echo "âœ… Verified: Registry monolith found in ./registry-context/entities.json"
            cp ./registry-context/entities.json data/registry.json
            cp -r ./registry-context/registry/* data/registry/ 2>/dev/null || true
          # 2. Try Cache Shards (Legacy Fallback)
          elif [ -d "output/meta/backup/registry" ]; then
            echo "âœ… Verified: Registry backup exists in GitHub Cache. Using it."
            # Copy for post-processor compatibility
            cp output/meta/backup/global-registry.json data/registry.json 2>/dev/null || true
          # 3. Try R2 Fallback
          else
            echo "âš ï¸ Cache/Artifact miss: Falling back to R2..."
            npx -y wrangler r2 object get $R2_BUCKET/meta/backup/global-registry.json --file=data/registry.json --remote
          fi

          # V16.8.17: Ensure the queue is prepared regardless of which source was used
          if [ -f "data/registry.json" ]; then
            node scripts/factory/prepare-image-queue.js data ${{ inputs.batch_size || 2000 }}
          else
             echo "âŒ CRITICAL ERROR: registry.json not found in any source!"
             exit 1
          fi

      - name: Download and Convert Images
        run: |
          echo "ðŸ–¼ï¸ Processing images..."
          node scripts/factory/download-images.js

      - name: Convert to WebP (Rust)
        working-directory: tools/rust-img-optimizer
        run: |
          echo "ðŸ”„ Converting to WebP..."
          mkdir -p ../../output/images
          find ../../data/images -name "*.jpg" | while read img; do
            type_dir=$(basename $(dirname "$img"))
            mkdir -p "../../output/images/$type_dir"
            base_name=$(basename "$img" .jpg)
            ./target/release/rust-img-optimizer convert --input "$img" --output "../../output/images/$type_dir/${base_name}.webp" --format webp --quality 75 --max-width 640 2>/dev/null || true
          done

      # V16.7: Standardized R2 Upload (WebP Only Policy)
      - name: Upload Images to R2 (S3 API)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
          R2_PREFIX_FILTER: images/
        run: |
          echo "ðŸ“¤ Uploading WebP images to R2..."
          node scripts/factory/r2-upload-s3.js

      - name: Update Global Registry (Progressive Drain)
        run: |
          echo "ðŸ“ Updating registry with CDN URLs..."
          # 1. Initialize local cache and monolith from artifact context
          mkdir -p cache data registry
          if [ -f "./registry-context/output/entities.json" ]; then
            echo "âœ… Source: ./registry-context/output/entities.json"
            cp ./registry-context/output/entities.json data/registry.json
            cp -r ./registry-context/cache/registry/* cache/ 2>/dev/null || true
          elif [ -f "./registry-context/entities.json" ]; then
            echo "âœ… Source: ./registry-context/entities.json"
            cp ./registry-context/entities.json data/registry.json
            cp -r ./registry-context/registry/* cache/ 2>/dev/null || true
          fi
          
          # 2. Move output/images to data/images locally for the processor to see them as 'processed'
          cp -r output/images/* data/images/
          
          # 3. Update registry (will update both data/registry.json and cache/registry shards)
          export CACHE_DIR=cache
          node scripts/factory/lib/image-post-processor.js data/registry.json data/image-results.json
          
      - name: Close Harvest Loop (V16.8.14)
        uses: actions/cache/save@v4
        with:
          path: cache/
          key: global-registry-v2-${{ github.run_id }}-img

      - name: Summary
        run: |
          echo "## ðŸ–¼ï¸ Image Processor Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "data/image-results.json" ]; then
            cat data/image-results.json >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          WEBP_COUNT=$(find output/images -name "*.webp" | wc -l)
          echo "- WebP images created/uploaded: $WEBP_COUNT" >> $GITHUB_STEP_SUMMARY
