# Factory 3/4 - Aggregate
# V14.5 Phase 4: Modular Factory Architecture
# 
# Triggers: workflow_run from Process, or manual dispatch
# Inputs: shard-* artifacts from Process stage
# Outputs: trending.json, search-*.json, sitemaps, rankings
# 
# Constitution: Art 3.1 (Aggregator), Art 5 (Weekly), Art 6.3 (Search)

name: Factory 3/4 - Aggregate

on:
  workflow_run:
    workflows: ["Factory 2/4 - Process"]
    types: [completed]
  workflow_dispatch:
    inputs:
      run_id:
        description: 'Run ID of Process workflow to get shard artifacts from'
        required: false
        type: string

jobs:
  # V14.5.3: Identify upstream Harvest run for full data restoration
  check-upstream:
    name: Check Upstream Harvest
    runs-on: ubuntu-latest
    outputs:
      harvest-id: ${{ steps.get-ids.outputs.harvest-id }}
      process-id: ${{ steps.get-ids.outputs.process-id }}
    steps:
      - name: Verify Upstream Conclusion
        if: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.conclusion != 'success' }}
        run: |
          echo "âŒ ERROR: Upstream workflow '${{ github.event.workflow_run.name }}' failed with conclusion '${{ github.event.workflow_run.conclusion }}'."
          echo "Aborting Factory 3/4 to prevent data corruption."
          exit 1
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Get Run IDs (Harvest & Process)
        id: get-ids
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # 1. Start with the Process Run ID (Triggering event or manual input)
          PROCESS_RUN_ID=${{ inputs.run_id || github.event.workflow_run.id }}
          
          # 2. If PROCESS_RUN_ID is missing, find the latest successful Process run on MAIN
          if [ -z "$PROCESS_RUN_ID" ] || [ "$PROCESS_RUN_ID" == "null" ]; then
            echo "ðŸ” Manual dispatch: Finding latest successful Process run on main branch..."
            PROCESS_RUN_ID=$(gh run list --workflow factory-process.yml --branch main --status success --limit 1 --json databaseId --jq '.[0].databaseId' | tr -d '[:space:]')
          fi
          
          # 3. Find the latest successful Harvest run on MAIN (The Production Source of Truth)
          HARVEST_RUN_ID=$(gh run list --workflow factory-harvest.yml --branch main --status success --limit 1 --json databaseId --jq '.[0].databaseId' | tr -d '[:space:]')
          
          echo "harvest-id=$HARVEST_RUN_ID" >> $GITHUB_OUTPUT
          echo "process-id=$PROCESS_RUN_ID" >> $GITHUB_OUTPUT
          echo "âœ… Resolved Harvest ID (Main): $HARVEST_RUN_ID"
          echo "âœ… Resolved Process ID (Main): $PROCESS_RUN_ID"

  # Job 1: Core Merge (The Pivot - SPEC V2.0)
  merge-core:
    name: Merge Core Registry
    needs: check-upstream
    runs-on: ubuntu-latest
    env:
      NODE_OPTIONS: "--max-old-space-size=8192"
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      - name: Install Dependencies
        run: npm ci

      # V4.1: Restore Shards from Cache (Not Artifact)
      - name: Restore Shards from Cache
        id: cache-shards
        uses: actions/cache/restore@v4
        with:
          path: |
            output/shards/
            output/cache/entities/
          key: cycle-${{ needs.check-upstream.outputs.process-id }}-shards
          restore-keys: |
            cycle-

      - name: Organize Shards & Context
        run: |
          mkdir -p artifacts output/cache/entities data cache
          # 1. Move Shards from cache
          if [ -d "output/shards" ]; then
            SHARD_COUNT=$(find output/shards -name "shard-*.json" | wc -l)
            echo "ðŸ“¦ Found $SHARD_COUNT shards in cache"
            find output/shards -name "shard-*.json" -exec mv {} artifacts/ \;
          fi
          
          # V17.2: Check for entity data
          if [ -d "output/cache/entities" ]; then
            ENTITY_FILES=$(find output/cache/entities -type f -name "*.json" | wc -l)
            echo "ðŸ“¦ Found $ENTITY_FILES entity files in cache"
          fi
          
          if [ $(find artifacts -name "shard-*.json" | wc -l) -eq 0 ]; then
            echo "âŒ ERROR: No shard files found!"
            exit 1
          fi

      # V4.1: Restore Harvest Context from Cache
      - name: Restore Harvest Context from Cache
        uses: actions/cache/restore@v4
        with:
          path: |
            data/merged.json
            data/merged_shard_*.json
            data/manifest.json
            cache/fni-history.json
            cache/weekly-accum.json
            cache/global-registry.json
          key: cycle-${{ needs.check-upstream.outputs.harvest-id }}-harvest
          restore-keys: |
            cycle-

      - name: Validate Context
        run: |
          if [ -f "data/merged.json" ]; then
            echo "âœ… Harvest context restored from cache."
          else
            echo "âš ï¸ Harvest context not in cache. Will use shards only."
          fi

      - name: Run Core Merge & Health
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: |
            echo "ðŸ”„ Running Merge-Core (V2.0 Sharding)..."
            node scripts/factory/aggregator.js --task=health
            node scripts/factory/aggregator.js --task=core

      - name: Consolidate Final Artifact
        run: |
          mkdir -p output/cache output/meta
          [ -d "cache" ] && cp -r cache/* output/cache/ 2>/dev/null || true
          [ -d "meta" ] && cp -r meta/* output/meta/ 2>/dev/null || true
          echo "ðŸ“¦ Final output structure for R2:"
          ls -R output/ | head -20

      # V17.0: Prevent upload-artifact stack overflow from atomized entity files
      - name: Clean Atomized Entity Directory
        run: |
          if [ -d "output/cache/entities" ]; then
            FILE_COUNT=$(find output/cache/entities -type f | wc -l)
            echo "ðŸ§¹ Cleaning $FILE_COUNT atomized entity files..."
            rm -rf output/cache/entities/
            echo "âœ… Cleanup complete. Remaining file count:"
            find output/ -type f | wc -l
          fi

      # V4.1: Keep Artifact for same-workflow satellite jobs
      - name: Upload Registry Artifact (Intra-Chain)
        uses: actions/upload-artifact@v4
        with:
          name: core-registry-v2
          path: output/
          retention-days: 1

      # V17.2: Cache save moved to finalize job to include satellite outputs
      # NOTE: merge-core only uploads artifact, finalize saves complete cache

      # V4.1: Save Global Registry for next cycle's 1/4 Harvest
      - name: Save Global Registry to Cache
        uses: actions/cache/save@v4
        with:
          path: output/entities.json
          key: global-registry-${{ github.run_id }}

  # Parallel Satellite Jobs (SPEC V2.0)
  aggregate-search:
    name: "Agg: Search Index"
    needs: merge-core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Core Registry
        uses: actions/download-artifact@v4
        with: { name: core-registry-v2, path: output/ }
      - name: Generate Search Indices
        env:
          ENTITIES_PATH: output/entities.json
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: |
          export NODE_OPTIONS="--max-old-space-size=6144"
          node scripts/factory/aggregator.js --task=search
      - name: Upload Search Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agg-search
          path: output/cache/search*
          if-no-files-found: warn
          retention-days: 1

  aggregate-rankings:
    name: "Agg: Rankings"
    needs: merge-core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Core Registry
        uses: actions/download-artifact@v4
        with: { name: core-registry-v2, path: output/ }
      - name: Generate Rankings
        env:
          ENTITIES_PATH: output/entities.json
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: |
          export NODE_OPTIONS="--max-old-space-size=6144"
          node scripts/factory/aggregator.js --task=rankings
          node scripts/factory/aggregator.js --task=category
      - name: Upload Rankings Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agg-rankings
          path: |
            output/rankings/
            output/cache/category_stats.json
          if-no-files-found: warn
          retention-days: 1

  aggregate-trending:
    name: "Agg: Trending"
    needs: merge-core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Core Registry
        uses: actions/download-artifact@v4
        with: { name: core-registry-v2, path: output/ }
      - name: Generate Trending
        env:
          ENTITIES_PATH: output/entities.json
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: node scripts/factory/aggregator.js --task=trending
      - name: Upload Trending Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agg-trending
          path: output/cache/trending.json
          if-no-files-found: warn
          retention-days: 1

  aggregate-relations:
    name: "Agg: Knowledge Mesh"
    needs: merge-core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Core Registry
        uses: actions/download-artifact@v4
        with: { name: core-registry-v2, path: output/ }
      - name: Generate Relations
        env:
          ENTITIES_PATH: output/entities.json
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: |
          export NODE_OPTIONS="--max-old-space-size=7168"
          node scripts/factory/aggregator.js --task=relations
      - name: Upload Relations Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agg-relations
          path: output/cache/relations.json
          if-no-files-found: warn
          retention-days: 1

  aggregate-sitemap:
    name: "Agg: Sitemap"
    needs: merge-core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }
      - run: npm ci
      - name: Restore Core Registry
        uses: actions/download-artifact@v4
        with: { name: core-registry-v2, path: output/ }
      - name: Generate Sitemaps
        env:
          ENTITIES_PATH: output/entities.json
        run: |
          export NODE_OPTIONS="--max-old-space-size=6144"
          node scripts/factory/aggregator.js --task=sitemap
      - name: Upload Sitemap Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agg-sitemap
          path: |
            output/sitemaps/
            output/sitemap.xml
          if-no-files-found: warn
          retention-days: 1

  finalize:
    name: Finalize Aggregation
    needs: [aggregate-search, aggregate-rankings, aggregate-trending, aggregate-relations, aggregate-sitemap]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      - name: Consolidate All Results
        uses: actions/download-artifact@v4
        with:
          pattern: agg-*
          path: output/
          merge-multiple: true
      - name: Run Health Consolidation
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ai-nexus-assets
        run: node scripts/factory/consolidate-health.js

      # V17.1: Restore core-registry artifact for complete output
      - name: Restore Core Registry to Output
        uses: actions/download-artifact@v4
        with:
          name: core-registry-v2
          path: ./core-context/

      - name: Merge Core with Satellite Outputs
        run: |
          # Copy entities.json and meta from core-registry
          cp ./core-context/output/entities.json output/ 2>/dev/null || cp ./core-context/entities.json output/ || true
          cp -r ./core-context/output/meta output/ 2>/dev/null || cp -r ./core-context/meta output/ 2>/dev/null || true
          # Ensure cache directory structure
          mkdir -p output/cache
          # Move satellite outputs into cache if needed
          [ -f "output/trending.json" ] && mv output/trending.json output/cache/ || true
          [ -f "output/category_stats.json" ] && mv output/category_stats.json output/cache/ || true
          [ -f "output/relations.json" ] && mv output/relations.json output/cache/ || true
          # List final structure
          echo "ðŸ“¦ Final output structure:"
          find output -type f | head -50

      # V17.1: Save COMPLETE output (with all satellite results) to Cache for Factory 4/4
      - name: Save Complete Cycle Output to Cache
        uses: actions/cache/save@v4
        with:
          path: output/
          key: cycle-${{ github.run_id }}-output

      - name: Summary
        run: |
          echo "## Factory 3/4 - Aggregator V2.0 Complete ðŸš€" >> $GITHUB_STEP_SUMMARY
          echo "Scale: 1M+ Readiness Verified" >> $GITHUB_STEP_SUMMARY
          echo "Jobs: Parallel (Search, Rankings, Trending, Relations)" >> $GITHUB_STEP_SUMMARY
          echo "Cache: Complete output saved for Factory 4/4" >> $GITHUB_STEP_SUMMARY

