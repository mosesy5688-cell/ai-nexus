name: L5 Analyst - Unified Computation Pipeline

# V6.2 Constitution: L5 = All Computation Tasks
# L1 = Collection (Harvester) | L5 = Computation (Analyst)
#
# Schedule: Daily at 06:00 UTC
# Timeline: L1(03:00) â†’ L8(05:00) â†’ L5(06:00)
# L1 has 2 hours for multi-source harvesting
# L8 has 1 hour for data processing
#
# Tasks:
#   1. Metrics Snapshot (FNI Velocity history)
#   2. FNI Velocity Calculation
#   3. Sitemap Generation
#   4. History Cleanup

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 06:00 UTC (after L1+L8)
  workflow_dispatch:     # Manual trigger for testing

concurrency:
  group: l5-analyst
  cancel-in-progress: true

jobs:
  compute:
    name: L5 Unified Computation
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      # ============================================================
      # SETUP
      # ============================================================
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 20

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          npm install -g wrangler
          pip install boto3

      # ============================================================
      # TASK 1: SNAPSHOT CURRENT METRICS TO ENTITIES_HISTORY
      # ============================================================
      - name: Execute Daily Snapshot
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "ðŸ“¸ [Task 1/5] Creating daily metrics snapshot..."
          echo "Date: $(date -u +%Y-%m-%d)"
          
          wrangler d1 execute ai-nexus-db --remote --command "
            INSERT INTO entities_history (entity_id, umid, type, downloads, likes, fni_score, snapshot_date)
            SELECT 
              id,
              umid,
              type,
              downloads,
              likes,
              fni_score,
              date('now')
            FROM entities
            WHERE umid IS NOT NULL
            ON CONFLICT(entity_id, snapshot_date) DO UPDATE SET
              downloads = excluded.downloads,
              likes = excluded.likes,
              fni_score = excluded.fni_score;
          "
          
          echo "âœ… Snapshot completed"

      # ============================================================
      # TASK 2: CALCULATE FNI VELOCITY (V DIMENSION)
      # ============================================================
      - name: Calculate FNI Velocity
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "ðŸ“ˆ [Task 2/5] Calculating FNI Velocity..."
          
          wrangler d1 execute ai-nexus-db --remote --command "
            UPDATE entities SET fni_v = (
              SELECT CASE 
                WHEN prev.downloads > 0 AND prev.downloads IS NOT NULL THEN 
                  ROUND(((curr.downloads - prev.downloads) * 1.0 / prev.downloads) * 100, 2)
                ELSE 0
              END
              FROM entities_history curr
              LEFT JOIN entities_history prev 
                ON curr.entity_id = prev.entity_id
                AND prev.snapshot_date = date('now', '-7 days')
              WHERE curr.entity_id = entities.id
                AND curr.snapshot_date = date('now')
              LIMIT 1
            )
            WHERE umid IS NOT NULL;
          "
          
          echo "âœ… Velocity calculation completed"

      # ============================================================
      # TASK 3: VERIFY SNAPSHOT
      # ============================================================
      - name: Verify Snapshot
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "ðŸ” [Task 3/5] Verifying snapshot..."
          
          wrangler d1 execute ai-nexus-db --remote --command "
            SELECT 
              snapshot_date,
              COUNT(*) as record_count,
              SUM(downloads) as total_downloads,
              AVG(fni_score) as avg_fni
            FROM entities_history
            WHERE snapshot_date = date('now')
            GROUP BY snapshot_date;
          "
          
          echo "âœ… Verification completed"

      # ============================================================
      # TASK 4: GENERATE SITEMAPS (V6.2 - Merged from l5-sitemap.yml)
      # ============================================================
      - name: Generate Sitemaps
        env:
          R2_ENDPOINT: ${{ vars.R2_ENDPOINT }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'ai-nexus-assets' }}
        run: |
          echo "ðŸ—ºï¸ [Task 4/5] Generating sitemaps..."
          python scripts/sidecar/l5_sitemap_gen.py
          echo "âœ… Sitemap generation completed"

      - name: Verify Sitemap Index
        env:
          R2_ENDPOINT: ${{ vars.R2_ENDPOINT }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'ai-nexus-assets' }}
        run: |
          python -c "
          import boto3
          import os
          from botocore.config import Config
          
          client = boto3.client(
              's3',
              endpoint_url=os.environ['R2_ENDPOINT'],
              aws_access_key_id=os.environ['R2_ACCESS_KEY_ID'],
              aws_secret_access_key=os.environ['R2_SECRET_ACCESS_KEY'],
              config=Config(signature_version='s3v4'),
          )
          
          response = client.head_object(
              Bucket=os.environ['R2_BUCKET'],
              Key='sitemaps/sitemap-index.xml'
          )
          print(f'âœ… sitemap-index.xml exists ({response[\"ContentLength\"]} bytes)')
          "

      # ============================================================
      # TASK 5: CLEANUP OLD HISTORY (Keep 90 days)
      # ============================================================
      - name: Cleanup Old History
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "ðŸ§¹ [Task 5/5] Cleaning up old history (>90 days)..."
          
          wrangler d1 execute ai-nexus-db --remote --command "
            DELETE FROM entities_history
            WHERE snapshot_date < date('now', '-90 days');
          "
          
          echo "âœ… Cleanup completed"

      # ============================================================
      # SUMMARY
      # ============================================================
      - name: Generate Summary
        if: always()
        run: |
          echo "## ðŸ“Š L5 Analyst - Unified Computation Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date -u +%Y-%m-%d %H:%M UTC)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Task | Description | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| 1 | Metrics Snapshot | âœ… |" >> $GITHUB_STEP_SUMMARY
          echo "| 2 | FNI Velocity | âœ… |" >> $GITHUB_STEP_SUMMARY
          echo "| 3 | Snapshot Verify | âœ… |" >> $GITHUB_STEP_SUMMARY
          echo "| 4 | Sitemap Generation | âœ… |" >> $GITHUB_STEP_SUMMARY
          echo "| 5 | History Cleanup | âœ… |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Architecture:** L1=é‡‡é›† | L5=è®¡ç®—" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "*Next run: Tomorrow at 04:00 UTC (after L1 Harvester)*" >> $GITHUB_STEP_SUMMARY
