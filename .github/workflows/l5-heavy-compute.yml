# L5 Heavy Compute Workflow
# B.11 L5 Sidecar Heavy Computation Migration
#
# Runs heavy computations in GitHub Actions (free tier):
# - FNI calculation for 500K+ entities
# - Rankings generation
# - Relation graph building (weekly)
#
# Constitution V6.x: Sidecar handles heavy compute, Commander stays lightweight

name: L5 Heavy Compute

on:
  schedule:
    # Daily at 04:00 UTC (12:00 Beijing) - 1 hour after L1 Harvester (03:00 UTC)
    - cron: '0 4 * * *'
  workflow_dispatch:
    inputs:
      compute_type:
        description: 'Computation type'
        required: true
        default: 'fni-rankings'
        type: choice
        options:
          - fni-rankings
          - relations
          - full

env:
  NODE_VERSION: '20'

jobs:
  download-entities:
    name: Download Entities from R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download entities from R2 (V7.1)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì• Downloading entities from R2 (V7.1 path)..."
          mkdir -p data
          
          # Download file from V7.1 path
          npx wrangler r2 object get ai-nexus-assets/ingest/current/entities.json.gz \
            --file data/entities.json.gz --remote
          
          if [ -f "data/entities.json.gz" ]; then
            # Check if file is actually gzipped (magic bytes: 1f 8b)
            # R2 may auto-decompress when content-encoding:gzip is set
            if file data/entities.json.gz | grep -q "gzip compressed"; then
              echo "üì¶ File is gzip compressed, decompressing..."
              gunzip -c data/entities.json.gz > data/entities.json
            else
              echo "üìÑ File is already decompressed (R2 auto-decompress)"
              mv data/entities.json.gz data/entities.json
            fi
            
            COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/entities.json')).length)")
            echo "‚úÖ Downloaded: $COUNT entities"
          else
            echo "‚ùå Failed to download entities"
            exit 1
          fi
          
      - name: Upload Entities Artifact
        uses: actions/upload-artifact@v4
        with:
          name: entities
          path: data/entities.json
          retention-days: 1

  compute-enrichment:
    name: Enrich Entities (Phase B.8)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-fni
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Benchmark Fusion (B.8)
        run: |
          echo "üìä Fusing benchmark data into entities..."
          node scripts/l5/benchmark-fusion.js data/entities.json data/entities_with_benchmarks.json
          
      - name: README Code Extraction (B.8)
        run: |
          echo "üìù Extracting code examples from README..."
          node scripts/l5/readme-code-extractor.js data/entities_with_benchmarks.json data/entities_with_code.json
          
      - name: License Parsing (B.8)
        run: |
          echo "üìú Parsing license commercial usability..."
          node scripts/l5/license-parser.js data/entities_with_code.json data/entities_enriched.json
          
      - name: Upload Enriched Entities

        uses: actions/upload-artifact@v4
        with:
          name: entities-b8
          path: data/entities_enriched.json
          retention-days: 1

  compute-fni:
    name: Compute FNI Scores

    runs-on: ubuntu-latest
    # V2.1: Increased from 60 to 120 for 500K+ entity processing
    timeout-minutes: 120
    needs: download-entities
    if: github.event.inputs.compute_type != 'relations'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Compute FNI Scores
        run: |
          echo "üìä Computing FNI for all entities..."
          node scripts/l5/fni-compute.js data/entities.json data/computed
          
          echo "üì¶ FNI Results:"
          ls -la data/computed/
          
      - name: Upload FNI Results
        uses: actions/upload-artifact@v4
        with:
          name: fni-results
          path: data/computed/
          retention-days: 1

  compute-rankings:
    name: Generate Rankings
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-fni
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Generate Rankings
        run: |
          echo "üìä Generating rankings..."
          node scripts/l5/rankings-compute.js data/computed data/cache
          
          echo "üì¶ Rankings Results:"
          ls -la data/cache/
          ls -la data/cache/rankings/ || true
          
      - name: Upload Rankings
        uses: actions/upload-artifact@v4
        with:
          name: rankings
          path: data/cache/
          retention-days: 1

  compute-search-index:
    name: Generate Search Index
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: download-entities
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Generate Search Index
        run: |
          echo "üîç Generating search index..."
          mkdir -p public/data
          node scripts/l5/search-index.js
          
          echo "üì¶ Search Index Results:"
          ls -la public/data/
          
      - name: Upload Search Index
        uses: actions/upload-artifact@v4
        with:
          name: search-index
          path: public/data/search-index.json.gz
          retention-days: 1

  sync-fts-index:
    name: Sync D1 FTS5 Index
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: download-entities
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Sync FTS Index (B.17)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîÑ Syncing D1 FTS5 index (Metadata only)..."
          node scripts/l5/fts-sync.js
          echo "‚úÖ FTS Sync complete!"

  compute-similarity:
    name: Compute Similarity (Smart Recommend)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-rankings
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Compute Similarity
        run: |
          echo "üß† Computing model similarity (B.14)..."
          node scripts/l5/similarity-compute.js data/entities.json data/entities_with_similarity.json
          
      - name: Compute Relations (B.1.0/B.3)
        run: |
          echo "üîó Discovering entity relations (B.1.0 Phase 2 + B.3)..."
          mkdir -p data/cache
          node scripts/l5/relations-compute.js data/entities_with_similarity.json data/relations.json
          echo "‚úÖ Relations discovery complete!"
          
      - name: Upload Updated Entities
        uses: actions/upload-artifact@v4
        with:
          name: entities-enriched
          path: |
            data/entities_with_similarity.json
            data/relations.json
            data/relations_summary.json
            data/cache/paper-relations/
          retention-days: 1

  upload-to-r2:
    name: Upload Results to R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [compute-rankings, compute-search-index, compute-similarity, sync-fts-index]
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Download Rankings
        uses: actions/download-artifact@v4
        with:
          name: rankings
          path: data/cache
          
      - name: Download Search Index
        uses: actions/download-artifact@v4
        with:
          name: search-index
          path: public/data
          
      - name: Download Enriched Entities (B.1.0/B.3)
        uses: actions/download-artifact@v4
        with:
          name: entities-enriched
          path: data
          
      - name: Sync Relations to D1 (B.3)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîó Syncing relations to D1 (B.3 Knowledge Relations)..."
          if [ -f "data/relations.json" ]; then
            node scripts/l5/relations-sync-d1.js data/relations.json
          else
            echo "‚ö†Ô∏è relations.json not found, skipping D1 sync"
          fi
          
      - name: Upload to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì§ Uploading results to R2..."
          
          # Upload FNI results
          for file in data/computed/*.json; do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              echo "   Uploading: computed/$filename"
              npx wrangler r2 object put ai-nexus-assets/computed/$filename --file "$file"
            fi
          done
          
          # Upload trending.json
          if [ -f "data/cache/trending.json" ]; then
            echo "   Uploading: cache/trending.json"
            npx wrangler r2 object put ai-nexus-assets/cache/trending.json --file data/cache/trending.json
          fi
          
          # Upload category_stats.json
          if [ -f "data/cache/category_stats.json" ]; then
            echo "   Uploading: cache/category_stats.json"
            npx wrangler r2 object put ai-nexus-assets/cache/category_stats.json --file data/cache/category_stats.json
          fi
          
          # Upload rankings pages
          if [ -d "data/cache/rankings" ]; then
            find data/cache/rankings -name "*.json" | while read file; do
              relpath=${file#data/cache/}
              echo "   Uploading: cache/$relpath"
              npx wrangler r2 object put "ai-nexus-assets/cache/$relpath" --file "$file"
            done
          fi
          
          # Upload search index
          if [ -f "public/data/search-index.json.gz" ]; then
            echo "   Uploading: public/data/search-index.json.gz"
            npx wrangler r2 object put ai-nexus-assets/public/data/search-index.json.gz --file public/data/search-index.json.gz
          fi
          
          echo "‚úÖ Upload complete!"
          
      - name: Summary
        run: |
          echo "## L5 Heavy Compute Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### FNI Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/computed/fni_summary.json 2>/dev/null || echo "No summary"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Category Stats" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/cache/category_stats.json 2>/dev/null || echo "No stats"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  compute-relations:
    name: Build Relation Graph (Weekly)
    runs-on: ubuntu-latest
    timeout-minutes: 120
    needs: download-entities
    # Only run on Sundays or manual trigger with 'relations' or 'full'
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.compute_type == 'relations' || github.event.inputs.compute_type == 'full'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Build Relations
        run: |
          echo "üîó Building relation graph..."
          node scripts/l5/relations-compute.js data/entities.json data/relations.json
          
          echo "üì¶ Relations Results:"
          cat data/relations_summary.json
          
      - name: Upload Relations to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì§ Uploading relations to R2..."
          npx wrangler r2 object put ai-nexus-assets/computed/relations.json --file data/relations.json --remote
          npx wrangler r2 object put ai-nexus-assets/computed/relations_summary.json --file data/relations_summary.json --remote
          
          # B.1.0 Phase 2: Upload Paper-Relations cache
          echo "üìÑ Uploading paper-relations cache..."
          if [ -d "data/cache/paper-relations" ]; then
            find data/cache/paper-relations -name "*.json" | while read file; do
              filename=$(basename "$file")
              echo "   Uploading: cache/paper-relations/$filename"
              npx wrangler r2 object put "ai-nexus-assets/cache/paper-relations/$filename" --file "$file" --remote
            done
            echo "‚úÖ Paper-relations cache uploaded!"
          else
            echo "‚ö†Ô∏è No paper-relations cache found (will generate on next run)"
          fi
          echo "‚úÖ Relations uploaded!"
          
      - name: Sync Relations to D1 (500K Scale)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîÑ Syncing relations to D1 (Sidecar heavy compute)..."
          node scripts/l5/relations-sync-d1.js data/relations.json
          echo "‚úÖ D1 sync complete!"
