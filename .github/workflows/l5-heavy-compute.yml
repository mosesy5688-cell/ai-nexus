# L5 Heavy Compute Workflow
# B.11 L5 Sidecar Heavy Computation Migration
#
# Runs heavy computations in GitHub Actions (free tier):
# - FNI calculation for 500K+ entities
# - Rankings generation
# - Relation graph building (weekly)
#
# Constitution V6.x: Sidecar handles heavy compute, Commander stays lightweight

name: L5 Heavy Compute

on:
  schedule:
    # V14.2 Zero-Cost: Mon/Thu only - synced with L1 (1 hour after)
    - cron: '0 4 * * 1,4'  # Mon & Thu at 04:00 UTC
  workflow_dispatch:
    inputs:
      compute_type:
        description: 'Computation type'
        required: true
        default: 'fni-rankings'
        type: choice
        options:
          - fni-rankings
          - relations
          - full

env:
  NODE_VERSION: '20'

jobs:
  download-entities:
    name: Download Entities from R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download entities from R2 (V7.1)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì• Downloading entities from R2 (V7.1 path)..."
          mkdir -p data
          
          # Download file from V7.1 path
          npx wrangler r2 object get ai-nexus-assets/ingest/current/entities.json.gz \
            --file data/entities.json.gz --remote
          
          if [ -f "data/entities.json.gz" ]; then
            # Check if file is actually gzipped (magic bytes: 1f 8b)
            # R2 may auto-decompress when content-encoding:gzip is set
            if file data/entities.json.gz | grep -q "gzip compressed"; then
              echo "üì¶ File is gzip compressed, decompressing..."
              gunzip -c data/entities.json.gz > data/entities.json
            else
              echo "üìÑ File is already decompressed (R2 auto-decompress)"
              mv data/entities.json.gz data/entities.json
            fi
            
            COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/entities.json')).length)")
            echo "‚úÖ Downloaded: $COUNT entities"
          else
            echo "‚ùå Failed to download entities"
            exit 1
          fi
          
      - name: Upload Entities Artifact
        uses: actions/upload-artifact@v4
        with:
          name: entities
          path: data/entities.json
          retention-days: 1

  compute-enrichment:
    name: Enrich Entities (Phase B.8)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-fni
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Benchmark Fusion (B.8)
        run: |
          echo "üìä Fusing benchmark data into entities..."
          node scripts/l5/benchmark-fusion.js data/entities.json data/entities_with_benchmarks.json
          
      - name: README Code Extraction (B.8)
        run: |
          echo "üìù Extracting code examples from README..."
          node scripts/l5/readme-code-extractor.js data/entities_with_benchmarks.json data/entities_with_code.json
          
      - name: License Parsing (B.8)
        run: |
          echo "üìú Parsing license commercial usability..."
          node scripts/l5/license-parser.js data/entities_with_code.json data/entities_enriched.json
          
      - name: Upload Enriched Entities

        uses: actions/upload-artifact@v4
        with:
          name: entities-b8
          path: data/entities_enriched.json
          retention-days: 1

  compute-fni:
    name: Compute FNI Scores

    runs-on: ubuntu-latest
    # V2.1: Increased from 60 to 120 for 500K+ entity processing
    timeout-minutes: 120
    needs: download-entities
    if: github.event.inputs.compute_type != 'relations'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Compute FNI Scores
        run: |
          echo "üìä Computing FNI for all entities..."
          node scripts/l5/fni-compute.js data/entities.json data/computed
          
          echo "üì¶ FNI Results:"
          ls -la data/computed/
          
      - name: Upload FNI Results
        uses: actions/upload-artifact@v4
        with:
          name: fni-results
          path: data/computed/
          retention-days: 1

  compute-rankings:
    name: Generate Rankings
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-fni
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Generate Rankings
        run: |
          echo "üìä Generating rankings..."
          node scripts/l5/rankings-compute.js data/computed data/cache
          
          echo "üì¶ Rankings Results:"
          ls -la data/cache/
          ls -la data/cache/rankings/ || true
          
      - name: Reclassify Categories (V6.2 100% Coverage)
        run: |
          echo "üè∑Ô∏è Running L5 Category Reclassification..."
          ENTITIES_PATH=data/entities.json node scripts/l5/category-reclassify.js
          cp data/computed/category_stats.json data/cache/category_stats.json || true
          
      - name: Upload Rankings
        uses: actions/upload-artifact@v4
        with:
          name: rankings
          path: data/cache/
          retention-days: 1

  compute-search-index:
    name: Generate Search Index
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: download-entities
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Generate Search Index
        run: |
          echo "üîç Generating search index..."
          mkdir -p public/data
          node scripts/l5/search-index.js
          
          echo "üì¶ Search Index Results:"
          ls -la public/data/
          
      - name: Upload Search Index
        uses: actions/upload-artifact@v4
        with:
          name: search-index
          path: public/data/search-index.json.gz
          retention-days: 1


  # V14.2: D1 FTS job removed per Zero-Cost Constitution Art 2.1
  # Search now uses client-side MiniSearch with R2-hosted index

  compute-similarity:
    name: Compute Similarity (Smart Recommend)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-rankings
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Compute Similarity
        run: |
          echo "üß† Computing model similarity (B.14)..."
          node scripts/l5/similarity-compute.js data/entities.json data/entities_with_similarity.json
          
      - name: Compute Relations (B.1.0/B.3)
        run: |
          echo "üîó Discovering entity relations (B.1.0 Phase 2 + B.3)..."
          mkdir -p data/cache
          node scripts/l5/relations-compute.js data/entities_with_similarity.json data/relations.json
          echo "‚úÖ Relations discovery complete!"
          
      - name: Upload Updated Entities
        uses: actions/upload-artifact@v4
        with:
          name: entities-enriched
          path: |
            data/relations_summary.json
            data/cache/paper-relations/
          retention-days: 1

  # ============================================================
  # V14.2: IMAGE PROCESSING (ROOT CAUSE FIX)
  # Downloads raw_image_url, converts to WebP, uploads to R2
  # ============================================================
  process-images:
    name: Process Entity Images
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: download-entities
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Build Image Optimizer
        working-directory: tools/rust-img-optimizer
        run: |
          echo "üîß Building Rust image optimizer..."
          cargo build --release
          echo "‚úÖ Build complete"
          
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Process Images
        run: |
          echo "üñºÔ∏è Processing entity images..."
          mkdir -p data/images
          
          # Run Rust optimizer on entities
          ./tools/rust-img-optimizer/target/release/rust-img-optimizer --input data/entities.json
          
          # Count processed images
          IMG_COUNT=$(ls -1 data/images/*.webp 2>/dev/null | wc -l)
          echo "‚úÖ Processed $IMG_COUNT images"
          
      - name: Upload Images to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì§ Uploading images to R2..."
          for img in data/images/*.webp; do
            if [ -f "$img" ]; then
              FILENAME=$(basename "$img")
              npx wrangler r2 object put ai-nexus-assets/cache/images/$FILENAME \
                --file "$img" \
                --content-type "image/webp" \
                --remote
            fi
          done
          echo "‚úÖ Image upload complete"
          
      - name: Upload Image Artifact
        uses: actions/upload-artifact@v4
        with:
          name: processed-images
          path: data/images/
          retention-days: 1

  upload-to-r2:
    name: Upload Results to R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [compute-rankings, compute-search-index, compute-similarity, process-images]
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Download Rankings
        uses: actions/download-artifact@v4
        with:
          name: rankings
          path: data/cache
          
      - name: Download Search Index
        uses: actions/download-artifact@v4
        with:
          name: search-index
          path: public/data
          
      - name: Download Enriched Entities (B.1.0/B.3)
        uses: actions/download-artifact@v4
        with:
          name: entities-enriched
          path: data
          
      - name: Sync Relations to D1 (B.3)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîó Syncing relations to D1 (B.3 Knowledge Relations)..."
          if [ -f "data/relations.json" ]; then
            node scripts/l5/relations-sync-d1.js data/relations.json
          else
            echo "‚ö†Ô∏è relations.json not found, skipping D1 sync"
          fi
          
      - name: Upload to R2 (Smart Write)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì§ [V14.2] Using Smart Upload with HEAD-before-PUT..."
          
          # Generate search index first
          if [ -f "data/cache/trending.json" ]; then
            echo "üîç Generating search index..."
            node scripts/l5/build-search-index.js || echo "‚ö†Ô∏è Search index generation failed"
          fi
          
          # Smart Upload with concurrency control
          node scripts/l5/smart-upload.js --concurrency=10
          
          echo "‚úÖ Smart Upload complete!"
          
      - name: Summary
        run: |
          echo "## L5 Heavy Compute Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### FNI Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/computed/fni_summary.json 2>/dev/null || echo "No summary"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Category Stats" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/cache/category_stats.json 2>/dev/null || echo "No stats"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  compute-relations:
    name: Build Relation Graph (Weekly)
    runs-on: ubuntu-latest
    timeout-minutes: 120
    needs: download-entities
    # Only run on Sundays or manual trigger with 'relations' or 'full'
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.compute_type == 'relations' || github.event.inputs.compute_type == 'full'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Build Relations
        run: |
          echo "üîó Building relation graph..."
          node scripts/l5/relations-compute.js data/entities.json data/relations.json
          
          echo "üì¶ Relations Results:"
          cat data/relations_summary.json
          
      - name: Upload Relations to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üì§ Uploading relations to R2..."
          npx wrangler r2 object put ai-nexus-assets/computed/relations.json --file data/relations.json --remote
          npx wrangler r2 object put ai-nexus-assets/computed/relations_summary.json --file data/relations_summary.json --remote
          
          # B.1.0 Phase 2: Upload Paper-Relations cache
          echo "üìÑ Uploading paper-relations cache..."
          if [ -d "data/cache/paper-relations" ]; then
            find data/cache/paper-relations -name "*.json" | while read file; do
              filename=$(basename "$file")
              echo "   Uploading: cache/paper-relations/$filename"
              npx wrangler r2 object put "ai-nexus-assets/cache/paper-relations/$filename" --file "$file" --remote
            done
            echo "‚úÖ Paper-relations cache uploaded!"
          else
            echo "‚ö†Ô∏è No paper-relations cache found (will generate on next run)"
          fi
          echo "‚úÖ Relations uploaded!"
          
      - name: Sync Relations to D1 (500K Scale)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîÑ Syncing relations to D1 (Sidecar heavy compute)..."
          node scripts/l5/relations-sync-d1.js data/relations.json
          echo "‚úÖ D1 sync complete!"
