# L5 Heavy Compute Workflow
# B.11 L5 Sidecar Heavy Computation Migration
#
# Runs heavy computations in GitHub Actions (free tier):
# - FNI calculation for 500K+ entities
# - Rankings generation
# - Relation graph building (weekly)
#
# Constitution V6.x: Sidecar handles heavy compute, Commander stays lightweight

name: L5 Heavy Compute

on:
  schedule:
    # Daily at 02:00 UTC (10:00 Beijing)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      compute_type:
        description: 'Computation type'
        required: true
        default: 'fni-rankings'
        type: choice
        options:
          - fni-rankings
          - relations
          - full

env:
  NODE_VERSION: '20'

jobs:
  download-entities:
    name: Download Entities from R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download entities from R2 (V7.1)
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "ðŸ“¥ Downloading entities from R2 (V7.1 path)..."
          mkdir -p data
          
          # Download file from V7.1 path
          npx wrangler r2 object get ai-nexus-assets/ingest/current/entities.json.gz \
            --file data/entities.json.gz --remote
          
          if [ -f "data/entities.json.gz" ]; then
            # Check if file is actually gzipped (magic bytes: 1f 8b)
            # R2 may auto-decompress when content-encoding:gzip is set
            if file data/entities.json.gz | grep -q "gzip compressed"; then
              echo "ðŸ“¦ File is gzip compressed, decompressing..."
              gunzip -c data/entities.json.gz > data/entities.json
            else
              echo "ðŸ“„ File is already decompressed (R2 auto-decompress)"
              mv data/entities.json.gz data/entities.json
            fi
            
            COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('data/entities.json')).length)")
            echo "âœ… Downloaded: $COUNT entities"
          else
            echo "âŒ Failed to download entities"
            exit 1
          fi
          
      - name: Upload Entities Artifact
        uses: actions/upload-artifact@v4
        with:
          name: entities
          path: data/entities.json
          retention-days: 1

  compute-fni:
    name: Compute FNI Scores
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: download-entities
    if: github.event.inputs.compute_type != 'relations'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Compute FNI Scores
        run: |
          echo "ðŸ“Š Computing FNI for all entities..."
          node scripts/l5/fni-compute.js data/entities.json data/computed
          
          echo "ðŸ“¦ FNI Results:"
          ls -la data/computed/
          
      - name: Upload FNI Results
        uses: actions/upload-artifact@v4
        with:
          name: fni-results
          path: data/computed/
          retention-days: 1

  compute-rankings:
    name: Generate Rankings
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: compute-fni
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download FNI Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Generate Rankings
        run: |
          echo "ðŸ“Š Generating rankings..."
          node scripts/l5/rankings-compute.js data/computed data/cache
          
          echo "ðŸ“¦ Rankings Results:"
          ls -la data/cache/
          ls -la data/cache/rankings/ || true
          
      - name: Upload Rankings
        uses: actions/upload-artifact@v4
        with:
          name: rankings
          path: data/cache/
          retention-days: 1

  compute-search-index:
    name: Generate Search Index
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: download-entities
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Generate Search Index
        run: |
          echo "ðŸ” Generating search index..."
          mkdir -p public/data
          node scripts/l5/search-index.js
          
          echo "ðŸ“¦ Search Index Results:"
          ls -la public/data/
          
      - name: Upload Search Index
        uses: actions/upload-artifact@v4
        with:
          name: search-index
          path: public/data/search-index.json.gz
          retention-days: 1

  upload-to-r2:
    name: Upload Results to R2
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [compute-rankings, compute-search-index]
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          name: fni-results
          path: data/computed
          
      - name: Download Rankings
        uses: actions/download-artifact@v4
        with:
          name: rankings
          path: data/cache
          
      - name: Download Search Index
        uses: actions/download-artifact@v4
        with:
          name: search-index
          path: public/data
          
      - name: Upload to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "ðŸ“¤ Uploading results to R2..."
          
          # Upload FNI results
          for file in data/computed/*.json; do
            if [ -f "$file" ]; then
              filename=$(basename "$file")
              echo "   Uploading: computed/$filename"
              npx wrangler r2 object put ai-nexus-assets/computed/$filename --file "$file"
            fi
          done
          
          # Upload trending.json
          if [ -f "data/cache/trending.json" ]; then
            echo "   Uploading: cache/trending.json"
            npx wrangler r2 object put ai-nexus-assets/cache/trending.json --file data/cache/trending.json
          fi
          
          # Upload category_stats.json
          if [ -f "data/cache/category_stats.json" ]; then
            echo "   Uploading: cache/category_stats.json"
            npx wrangler r2 object put ai-nexus-assets/cache/category_stats.json --file data/cache/category_stats.json
          fi
          
          # Upload rankings pages
          if [ -d "data/cache/rankings" ]; then
            find data/cache/rankings -name "*.json" | while read file; do
              relpath=${file#data/cache/}
              echo "   Uploading: cache/$relpath"
              npx wrangler r2 object put "ai-nexus-assets/cache/$relpath" --file "$file"
            done
          fi
          
          # Upload search index
          if [ -f "public/data/search-index.json.gz" ]; then
            echo "   Uploading: public/data/search-index.json.gz"
            npx wrangler r2 object put ai-nexus-assets/public/data/search-index.json.gz --file public/data/search-index.json.gz
          fi
          
          echo "âœ… Upload complete!"
          
      - name: Summary
        run: |
          echo "## L5 Heavy Compute Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### FNI Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/computed/fni_summary.json 2>/dev/null || echo "No summary"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Category Stats" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat data/cache/category_stats.json 2>/dev/null || echo "No stats"
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  compute-relations:
    name: Build Relation Graph (Weekly)
    runs-on: ubuntu-latest
    timeout-minutes: 120
    needs: download-entities
    # Only run on Sundays or manual trigger with 'relations' or 'full'
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.compute_type == 'relations' || github.event.inputs.compute_type == 'full'
    
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
      - run: npm ci
      
      - name: Download Entities
        uses: actions/download-artifact@v4
        with:
          name: entities
          path: data
          
      - name: Build Relations (Placeholder)
        run: |
          echo "ðŸ”— Building relation graph..."
          echo "TODO: Implement relations-compute.js"
          # node scripts/l5/relations-compute.js data/entities.json data/relations.json
          
      # - name: Upload Relations to R2
      #   ...
